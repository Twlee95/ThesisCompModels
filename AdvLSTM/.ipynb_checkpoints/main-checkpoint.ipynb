{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Stock_Dataset.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\USER\\\\JupyterProjects\\\\AdvLSTM')\n",
    "from Stock_Dataset import StockDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Att_LSTM.ipynb\n",
      "importing Jupyter notebook from attention.ipynb\n",
      "importing Jupyter notebook from metric.ipynb\n",
      "importing Jupyter notebook from loss_fn1.ipynb\n",
      "importing Jupyter notebook from adv.ipynb\n",
      "importing Jupyter notebook from Stock_datasets_csv.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "from Att_LSTM import attLSTM\n",
    "import numpy as np\n",
    "import time\n",
    "from metric import metric_acc as ACC\n",
    "from metric import metric_mcc as MCC\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "from loss_fn1 import adv_loss\n",
    "from adv import adversarial\n",
    "from Stock_datasets_csv import stock_csv_read\n",
    "\n",
    "def train(attLSTM,adversarial ,lstm_optimizer,Partition, args): ## Data, loss function, argument\n",
    "    trainloader = DataLoader(Partition['train'],\n",
    "                             batch_size = args.batch_size,\n",
    "                             shuffle=False, drop_last=True)\n",
    "    attLSTM.train()\n",
    "    adversarial.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    for i, (x,y) in enumerate(trainloader):\n",
    "        \n",
    "        lstm_optimizer.zero_grad()\n",
    "        \n",
    "        true_y = y.squeeze().float().to(args.device)\n",
    "        x = x.to(args.device)\n",
    "        attLSTM.hidden = [hidden.to(args.device) for hidden in attLSTM.init_hidden()]\n",
    "        es, attention_weight, attn_applied = attLSTM(x)\n",
    "        # print(es.size()) [128, 20]\n",
    "\n",
    "        y_hat, y_hat_adv = adversarial(es, true_y)\n",
    "        \n",
    "        loss = args.loss_fn(y_hat, y_hat_adv, true_y)\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        lstm_optimizer.step()## parameter 갱신\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    return attLSTM, adversarial, train_loss\n",
    "\n",
    "\n",
    "def validation(attLSTM,adversarial, partition, args):\n",
    "    valloader = DataLoader(partition['val'],\n",
    "                           batch_size=args.batch_size,\n",
    "                           shuffle=False, drop_last=True)\n",
    "    attLSTM.eval()\n",
    "    adversarial.eval()\n",
    "    \n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(valloader):\n",
    "\n",
    "            true_y = y.squeeze().float().to(args.device)\n",
    "            x = x.to(args.device)\n",
    "\n",
    "            attLSTM.hidden = [attLSTM.to(args.device) for hidden in attLSTM.init_hidden()]\n",
    "\n",
    "            es, attention_weight, attn_applied = attLSTM(x)\n",
    "\n",
    "            y_hat, y_hat_adv = adversarial(es, true_y)\n",
    "\n",
    "            # output_ = torch.where(output1 >= 0.5, 1.0, 0.0)\n",
    "            # output_.requires_grad=True\n",
    "\n",
    "            loss = args.loss_fn(y_hat, y_hat_adv, true_y)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_loss = val_loss / len(valloader)\n",
    "        return attLSTM, adversarial, val_loss\n",
    "\n",
    "\n",
    "def test(attLSTM,adversarial,partition, args):\n",
    "    testloader = DataLoader(partition['test'],\n",
    "                           batch_size=args.batch_size,\n",
    "                           shuffle=False, drop_last=True)\n",
    "    attLSTM.eval()\n",
    "\n",
    "    ACC_metric = 0.0\n",
    "    MCC_metric = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(testloader):\n",
    "\n",
    "            # feature transform\n",
    "            true_y = y.squeeze().float().to(args.device)\n",
    "            x = x.to(args.device)\n",
    "\n",
    "            attLSTM.hidden = [hidden.to(args.device) for hidden in attLSTM.init_hidden()]\n",
    "\n",
    "            es, attention_weight, attn_applied = attLSTM(x)\n",
    "\n",
    "            y_hat, y_hat_adv = adversarial(es, true_y)\n",
    "\n",
    "            output_ = torch.where(y_hat >= 0.0, 1.0, 0.0)\n",
    "\n",
    "            output_.requires_grad = True\n",
    "\n",
    "            ACC_metric += ACC(output_, true_y)\n",
    "            MCC_metric += MCC(output_, true_y)\n",
    "\n",
    "        ACC_metric = ACC_metric / len(testloader)\n",
    "        MCC_metric = MCC_metric / len(testloader)\n",
    "\n",
    "        return ACC_metric, MCC_metric\n",
    "\n",
    "\n",
    "\n",
    "def experiment(partition, args):\n",
    "    attLSTM = args.attLSTM(args.input_dim, args.hid_dim, args.output_dim, args.num_layers, args.batch_size,\n",
    "                           args.dropout, args.use_bn, args.attention_head, args.attn_size,\n",
    "                           activation=\"ReLU\")\n",
    "    adversarial = args.adversarial(args.batch_size, args.hid_dim, args.attn_size)\n",
    "\n",
    "    attLSTM.to(args.device)\n",
    "    adversarial.to(args.device)\n",
    "\n",
    "    if args.optim == 'SGD':\n",
    "        lstm_optimizer = optim.SGD(attLSTM.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'RMSprop':\n",
    "        lstm_optimizer = optim.RMSprop(attLSTM.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'Adam':\n",
    "        lstm_optimizer = optim.Adam(attLSTM.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    else:\n",
    "        raise ValueError('In-valid optimizer choice')\n",
    "\n",
    "    # ===== List for epoch-wise data ====== #\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    # ===================================== #\n",
    "    for epoch in range(args.epoch):\n",
    "        ts = time.time()\n",
    "        attLSTM, adversarial, train_loss = train(attLSTM, adversarial, lstm_optimizer, partition, args)\n",
    "\n",
    "        attLSTM, adversarial, val_loss = validation(attLSTM, adversarial, partition, args)\n",
    "\n",
    "        te = time.time()\n",
    "\n",
    "        ## 각 에폭마다 모델을 저장하기 위한 코드\n",
    "        torch.save(attLSTM.state_dict(), args.split_file_path + '\\\\' + str(epoch) +'_attLSTM' +'.pt')\n",
    "        torch.save(adversarial.state_dict(), args.split_file_path + '\\\\' + str(epoch) +'_adversarial' +'.pt')\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print('Epoch {}, Loss(train/val) {:2.5f}/{:2.5f}. Took {:2.2f} sec'\n",
    "              .format(epoch, train_loss, val_loss, te - ts))\n",
    "\n",
    "    ## val_losses에서 가장 값이 최소인 위치를 저장함\n",
    "    site_val_losses = val_losses.index(min(val_losses)) ## 10 epoch일 경우 0번째~9번째 까지로 나옴\n",
    "    attLSTM = args.attLSTM(args.input_dim, args.hid_dim, args.output_dim, args.num_layers, args.batch_size,\n",
    "                           args.dropout, args.use_bn, args.attention_head, args.attn_size,\n",
    "                           activation=\"ReLU\")\n",
    "    adversarial = args.adversarial(args.batch_size, args.hid_dim, args.attn_size)\n",
    "\n",
    "    attLSTM.to(args.device)\n",
    "    adversarial.to(args.device)\n",
    "\n",
    "\n",
    "    attLSTM.load_state_dict(torch.load(args.split_file_path + '\\\\' + str(site_val_losses) +'_attLSTM'+ '.pt'))\n",
    "    adversarial.load_state_dict(torch.load(args.split_file_path + '\\\\' + str(site_val_losses) +'_adversarial'+ '.pt'))\n",
    "\n",
    "    ACC, MCC = test(attLSTM, adversarial, partition, args)\n",
    "    print('ACC: {}, MCC: {}'.format(ACC, MCC))\n",
    "\n",
    "    with open(args.split_file_path + '\\\\'+ str(site_val_losses)+'Epoch_test_metric' +'.csv', 'w') as fd:\n",
    "        print('ACC: {}, MCC: {}'.format(ACC, MCC), file=fd)\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    result['train_losses'] = train_losses\n",
    "    result['val_losses'] = val_losses\n",
    "    result['ACC'] = ACC\n",
    "    result['MCC'] = MCC\n",
    "\n",
    "    return vars(args), result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====== Random Seed Initialization ====== #\n",
    "seed = 666\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# ========= experiment setting ========== #\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "args.save_file_path = \"C:\\\\Users\\\\USER\\\\JupyterProjects\\\\AdvLSTM\\\\results\"\n",
    "\n",
    "# ====== hyperparameter ======= #\n",
    "args.batch_size = 64\n",
    "\n",
    "args.dropout = 0.15\n",
    "args.use_bn = True\n",
    "args.loss_fn = adv_loss  ## loss function for classification : cross entropy\n",
    "args.optim = 'Adam'\n",
    "args.lr = 0.0005\n",
    "args.l2 = 0.00001 #?\n",
    "args.epoch = 1\n",
    "# ============= model ================== #\n",
    "args.attLSTM = attLSTM\n",
    "args.adversarial = adversarial\n",
    "# ====== att_lstm hyperparameter ======= #\n",
    "\n",
    "args.x_frames = 10\n",
    "args.y_frames = 1\n",
    "args.input_dim = 10\n",
    "args.hid_dim = 10\n",
    "args.output_dim = 1\n",
    "args.attention_head = 1\n",
    "args.attn_size = 10\n",
    "args.num_layers = 1\n",
    "args.attLSTM_x_frames = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss(train/val) 70.93964/69.29726. Took 0.54 sec\n",
      "ACC: 0.4375, MCC: -0.13900960937138318\n",
      "Epoch 0, Loss(train/val) 70.36347/71.73964. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: 0.0359961928254792\n",
      "Epoch 0, Loss(train/val) 71.09585/71.03770. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.09847634407689815\n",
      "Epoch 0, Loss(train/val) 69.93436/70.24643. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.013900245738365579\n",
      "Epoch 0, Loss(train/val) 70.88764/71.27569. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.11230210775892609\n",
      "Epoch 0, Loss(train/val) 70.24099/70.54366. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: -0.018122009407318746\n",
      "Epoch 0, Loss(train/val) 71.03971/71.11021. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: 0.010419719766238846\n",
      "Epoch 0, Loss(train/val) 71.02243/69.96332. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.03253000243161777\n",
      "Epoch 0, Loss(train/val) 71.51775/71.41302. Took 0.34 sec\n",
      "ACC: 0.625, MCC: 0.19733222585543395\n",
      "Epoch 0, Loss(train/val) 71.66184/70.53793. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.03537745688386125\n",
      "Epoch 0, Loss(train/val) 69.47377/69.39447. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.047619047619047616\n",
      "Epoch 0, Loss(train/val) 70.15683/71.06644. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.1111111111111111\n",
      "Epoch 0, Loss(train/val) 70.69353/69.81426. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) 70.61567/71.13859. Took 0.33 sec\n",
      "ACC: 0.578125, MCC: 0.16282240225645903\n",
      "Epoch 0, Loss(train/val) 71.41705/71.70489. Took 0.34 sec\n",
      "ACC: 0.578125, MCC: 0.1312040762640503\n",
      "Epoch 0, Loss(train/val) 70.52679/71.08204. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.033277916281986085\n",
      "Epoch 0, Loss(train/val) 70.82664/71.01561. Took 0.33 sec\n",
      "ACC: 0.609375, MCC: 0.23294541397390262\n",
      "Epoch 0, Loss(train/val) 70.68147/69.86304. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.05890410617746685\n",
      "Epoch 0, Loss(train/val) 70.34089/69.88428. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: 0.11124684011100254\n",
      "Epoch 0, Loss(train/val) 70.32674/69.80254. Took 0.34 sec\n",
      "ACC: 0.5, MCC: -0.059046408317326424\n",
      "Epoch 0, Loss(train/val) 71.26382/70.22058. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.06129747604081894\n",
      "Epoch 0, Loss(train/val) 70.40053/69.85879. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.13010726223589664\n",
      "Epoch 0, Loss(train/val) 70.21411/68.88950. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.02404930351219409\n",
      "Epoch 0, Loss(train/val) 70.61754/70.77467. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.061541083462958945\n",
      "Epoch 0, Loss(train/val) 70.31963/70.69812. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.04222003309207491\n",
      "Epoch 0, Loss(train/val) 70.95832/72.18697. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.11056588493219922\n",
      "Epoch 0, Loss(train/val) 71.12126/71.63828. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.05419820128296849\n",
      "Epoch 0, Loss(train/val) 70.36920/70.75098. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.0710915894200724\n",
      "Epoch 0, Loss(train/val) 71.03354/69.97272. Took 0.34 sec\n",
      "ACC: 0.4375, MCC: -0.1681701764079849\n",
      "Epoch 0, Loss(train/val) 70.91178/70.42577. Took 0.34 sec\n",
      "ACC: 0.375, MCC: -0.23430202631092822\n",
      "Epoch 0, Loss(train/val) 70.63611/70.76348. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.06362847629757777\n",
      "Epoch 0, Loss(train/val) 70.22847/70.42251. Took 0.32 sec\n",
      "ACC: 0.421875, MCC: -0.1777495495783369\n",
      "Epoch 0, Loss(train/val) 70.67364/70.60637. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.0778902520624173\n",
      "Epoch 0, Loss(train/val) 70.88913/70.43183. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.03202563076101743\n",
      "Epoch 0, Loss(train/val) 71.17939/71.10940. Took 0.33 sec\n",
      "ACC: 0.4375, MCC: -0.07881104062391008\n",
      "Epoch 0, Loss(train/val) 69.78419/69.12918. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.0640210337986158\n",
      "Epoch 0, Loss(train/val) 70.40100/68.65111. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.03253000243161777\n",
      "Epoch 0, Loss(train/val) 71.30941/71.58623. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.1537645811240721\n",
      "Epoch 0, Loss(train/val) 70.43310/69.59996. Took 0.33 sec\n",
      "ACC: 0.5, MCC: 0.007889684472185849\n",
      "Epoch 0, Loss(train/val) 70.27299/70.46991. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.05419820128296849\n",
      "Epoch 0, Loss(train/val) 70.33114/70.10171. Took 0.33 sec\n",
      "ACC: 0.375, MCC: -0.29277002188455997\n",
      "Epoch 0, Loss(train/val) 71.35730/70.70017. Took 0.54 sec\n",
      "ACC: 0.453125, MCC: -0.10500815676649744\n",
      "Epoch 0, Loss(train/val) 70.62905/70.53391. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.2355861222951437\n",
      "Epoch 0, Loss(train/val) 70.02072/71.02925. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.09095880536541953\n",
      "Epoch 0, Loss(train/val) 70.41308/69.63605. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.03253000243161777\n",
      "Epoch 0, Loss(train/val) 70.00205/70.72481. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.046373889576016826\n",
      "Epoch 0, Loss(train/val) 70.27325/68.38158. Took 0.33 sec\n",
      "ACC: 0.40625, MCC: -0.17577515967558022\n",
      "Epoch 0, Loss(train/val) 69.94959/69.59014. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: -0.02421797398482414\n",
      "Epoch 0, Loss(train/val) 70.86332/70.28828. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.048507125007266595\n",
      "Epoch 0, Loss(train/val) 70.11915/69.89975. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.07953140787214905\n",
      "Epoch 0, Loss(train/val) 70.39886/70.43657. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.06815142307594586\n",
      "Epoch 0, Loss(train/val) 70.43180/70.92272. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: 0.0010820172848339962\n",
      "Epoch 0, Loss(train/val) 70.57008/71.15612. Took 0.33 sec\n",
      "ACC: 0.578125, MCC: -0.01210455065337605\n",
      "Epoch 0, Loss(train/val) 70.72640/69.85928. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: 0.010419719766238846\n",
      "Epoch 0, Loss(train/val) 70.46508/70.72449. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.09217385805597667\n",
      "Epoch 0, Loss(train/val) 70.12645/69.91455. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: -0.025200955979049554\n",
      "Epoch 0, Loss(train/val) 70.22970/70.64262. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.11030375355930092\n",
      "Epoch 0, Loss(train/val) 70.04972/69.31667. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.006424925662032356\n",
      "Epoch 0, Loss(train/val) 70.43769/70.34904. Took 0.34 sec\n",
      "ACC: 0.609375, MCC: 0.18527427542315386\n",
      "Epoch 0, Loss(train/val) 71.42893/71.23912. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: 0.044946657497549475\n",
      "Epoch 0, Loss(train/val) 70.88305/70.58133. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.013900245738365579\n",
      "Epoch 0, Loss(train/val) 70.14538/70.37982. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.15863531325832828\n",
      "Epoch 0, Loss(train/val) 70.40761/70.76946. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: -0.010419719766238846\n",
      "Epoch 0, Loss(train/val) 71.24289/71.09278. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: -0.010419719766238846\n",
      "Epoch 0, Loss(train/val) 70.57552/71.31531. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.09983374884595826\n",
      "Epoch 0, Loss(train/val) 70.07045/68.79404. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.005662746571529173\n",
      "Epoch 0, Loss(train/val) 70.66313/69.60525. Took 0.35 sec\n",
      "ACC: 0.546875, MCC: 0.07953140787214905\n",
      "Epoch 0, Loss(train/val) 71.18881/70.06973. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.14060420405767388\n",
      "Epoch 0, Loss(train/val) 70.54499/70.23675. Took 0.35 sec\n",
      "ACC: 0.5625, MCC: 0.10323631789938985\n",
      "Epoch 0, Loss(train/val) 70.88740/70.78849. Took 0.34 sec\n",
      "ACC: 0.40625, MCC: -0.11062059970467682\n",
      "Epoch 0, Loss(train/val) 70.47570/69.84086. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.05420213225174926\n",
      "Epoch 0, Loss(train/val) 71.79411/70.49954. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.018266554145039696\n",
      "Epoch 0, Loss(train/val) 70.88778/72.03795. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.03673591791853225\n",
      "Epoch 0, Loss(train/val) 71.63236/70.85454. Took 0.33 sec\n",
      "ACC: 0.625, MCC: 0.1868706368604627\n",
      "Epoch 0, Loss(train/val) 70.01776/70.83168. Took 0.35 sec\n",
      "ACC: 0.5, MCC: 0.036155076303109365\n",
      "Epoch 0, Loss(train/val) 70.62357/70.30252. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: 0.1929364015162026\n",
      "Epoch 0, Loss(train/val) 71.76580/71.82377. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.10613237065158375\n",
      "Epoch 0, Loss(train/val) 70.93838/70.14371. Took 0.34 sec\n",
      "ACC: 0.421875, MCC: -0.17485381766873062\n",
      "Epoch 0, Loss(train/val) 71.17860/70.32323. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.0418647525471434\n",
      "Epoch 0, Loss(train/val) 69.65441/69.15536. Took 0.34 sec\n",
      "ACC: 0.4375, MCC: -0.03013774920513892\n",
      "Epoch 0, Loss(train/val) 70.45753/69.69490. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: -0.03202563076101743\n",
      "Epoch 0, Loss(train/val) 70.13902/70.71768. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.09553751222296826\n",
      "Epoch 0, Loss(train/val) 70.63561/70.70174. Took 0.33 sec\n",
      "ACC: 0.578125, MCC: 0.10688429370388697\n",
      "Epoch 0, Loss(train/val) 70.50350/70.99202. Took 0.33 sec\n",
      "ACC: 0.34375, MCC: -0.36309228459184417\n",
      "Epoch 0, Loss(train/val) 70.13878/71.40629. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: 0.09048278567177281\n",
      "Epoch 0, Loss(train/val) 71.15135/70.92548. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.01659128610703117\n",
      "Epoch 0, Loss(train/val) 71.35535/70.38277. Took 0.34 sec\n",
      "ACC: 0.40625, MCC: -0.1686533906277161\n",
      "Epoch 0, Loss(train/val) 70.79876/70.59520. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.021109792565893827\n",
      "Epoch 0, Loss(train/val) 70.92771/71.42760. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: 0.13945994111797608\n",
      "Epoch 0, Loss(train/val) 69.72243/69.12074. Took 0.34 sec\n",
      "ACC: 0.421875, MCC: -0.08370786705565378\n",
      "Epoch 0, Loss(train/val) 70.93346/70.75323. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.0657951694959769\n",
      "Epoch 0, Loss(train/val) 70.82755/70.70507. Took 0.34 sec\n",
      "ACC: 0.40625, MCC: -0.11918791593025913\n",
      "Epoch 0, Loss(train/val) 70.56838/70.22176. Took 0.34 sec\n",
      "ACC: 0.609375, MCC: 0.2727487158685831\n",
      "Epoch 0, Loss(train/val) 70.09312/69.34877. Took 0.34 sec\n",
      "ACC: 0.625, MCC: 0.25308553412176554\n",
      "Epoch 0, Loss(train/val) 70.87670/70.97240. Took 0.34 sec\n",
      "ACC: 0.4375, MCC: -0.19408623801577188\n",
      "Epoch 0, Loss(train/val) 70.36593/70.66803. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.10259783520851541\n",
      "Epoch 0, Loss(train/val) 71.34028/72.10790. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.0884554607030049\n",
      "Epoch 0, Loss(train/val) 70.45946/71.43793. Took 0.34 sec\n",
      "ACC: 0.375, MCC: -0.21821789023599236\n",
      "Epoch 0, Loss(train/val) 71.76540/71.75140. Took 0.36 sec\n",
      "ACC: 0.46875, MCC: 0.03809098344162921\n",
      "Epoch 0, Loss(train/val) 71.44945/71.14139. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: 0.042040563488583385\n",
      "Epoch 0, Loss(train/val) 70.76065/71.00941. Took 0.33 sec\n",
      "ACC: 0.390625, MCC: -0.29730058149296784\n",
      "Epoch 0, Loss(train/val) 69.72802/69.73479. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.11382681986840493\n",
      "Epoch 0, Loss(train/val) 70.47739/70.37753. Took 0.35 sec\n",
      "ACC: 0.484375, MCC: 0.041824288840651425\n",
      "Epoch 0, Loss(train/val) 70.41019/70.14901. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.10131991994766791\n",
      "Epoch 0, Loss(train/val) 70.94425/70.31329. Took 0.34 sec\n",
      "ACC: 0.578125, MCC: 0.19856113239375686\n",
      "Epoch 0, Loss(train/val) 71.20345/70.71548. Took 0.34 sec\n",
      "ACC: 0.390625, MCC: -0.18262637225482492\n",
      "Epoch 0, Loss(train/val) 71.30034/71.95415. Took 0.34 sec\n",
      "ACC: 0.53125, MCC: 0.008756782291545563\n",
      "Epoch 0, Loss(train/val) 71.02827/69.60417. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: 0.12167029203938934\n",
      "Epoch 0, Loss(train/val) 70.41416/70.40453. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: 0.00883021571376696\n",
      "Epoch 0, Loss(train/val) 70.22611/69.70162. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.07192118226600985\n",
      "Epoch 0, Loss(train/val) 70.78833/70.97379. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.0885319710087594\n",
      "Epoch 0, Loss(train/val) 70.38121/70.19345. Took 0.32 sec\n",
      "ACC: 0.609375, MCC: 0.15081791634582414\n",
      "Epoch 0, Loss(train/val) 70.29455/70.02532. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: -0.13846153846153847\n",
      "Epoch 0, Loss(train/val) 71.11052/71.07343. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.1014574359634967\n",
      "Epoch 0, Loss(train/val) 70.14212/69.95660. Took 0.33 sec\n",
      "ACC: 0.4375, MCC: -0.1088776457161647\n",
      "Epoch 0, Loss(train/val) 70.69913/71.48598. Took 0.35 sec\n",
      "ACC: 0.515625, MCC: 0.03883678186903087\n",
      "Epoch 0, Loss(train/val) 70.17040/70.20311. Took 0.34 sec\n",
      "ACC: 0.5, MCC: -0.049969626464415974\n",
      "Epoch 0, Loss(train/val) 70.92700/70.93728. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.0885319710087594\n",
      "Epoch 0, Loss(train/val) 70.11517/70.23895. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.16265001215808886\n",
      "Epoch 0, Loss(train/val) 70.06797/70.53851. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: 0.02017425108896008\n",
      "Epoch 0, Loss(train/val) 70.86264/70.62419. Took 0.33 sec\n",
      "ACC: 0.5, MCC: 0.03546361409014303\n",
      "Epoch 0, Loss(train/val) 70.65681/69.65071. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.004034850217792016\n",
      "Epoch 0, Loss(train/val) 70.63365/71.13718. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: 0.041824288840651425\n",
      "Epoch 0, Loss(train/val) 69.51724/69.65128. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: -0.004232389556904849\n",
      "Epoch 0, Loss(train/val) 70.66361/70.28638. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.07216878364870323\n",
      "Epoch 0, Loss(train/val) 70.51100/70.38988. Took 0.33 sec\n",
      "ACC: 0.4375, MCC: -0.01063154867907501\n",
      "Epoch 0, Loss(train/val) 70.53305/70.68381. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.13064015512799124\n",
      "Epoch 0, Loss(train/val) 70.57413/69.79398. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.059863071616150634\n",
      "Epoch 0, Loss(train/val) 70.75840/71.34082. Took 0.33 sec\n",
      "ACC: 0.375, MCC: -0.2581784245713871\n",
      "Epoch 0, Loss(train/val) 71.04362/70.66460. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.07160575596310784\n",
      "Epoch 0, Loss(train/val) 70.72947/70.90484. Took 0.34 sec\n",
      "ACC: 0.53125, MCC: 0.021098286729420077\n",
      "Epoch 0, Loss(train/val) 70.48803/70.62934. Took 0.35 sec\n",
      "ACC: 0.53125, MCC: 0.026948402781814772\n",
      "Epoch 0, Loss(train/val) 69.20277/68.13130. Took 0.33 sec\n",
      "ACC: 0.359375, MCC: -0.24234852357906997\n",
      "Epoch 0, Loss(train/val) 71.02364/70.54625. Took 0.34 sec\n",
      "ACC: 0.359375, MCC: -0.22848503740117349\n",
      "Epoch 0, Loss(train/val) 70.12455/70.63073. Took 0.35 sec\n",
      "ACC: 0.609375, MCC: 0.11862459640308527\n",
      "Epoch 0, Loss(train/val) 70.50098/70.67659. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.10613237065158375\n",
      "Epoch 0, Loss(train/val) 70.04401/69.60457. Took 0.36 sec\n",
      "ACC: 0.515625, MCC: 0.0640210337986158\n",
      "Epoch 0, Loss(train/val) 70.73593/70.55630. Took 0.35 sec\n",
      "ACC: 0.53125, MCC: 0.08738077349703083\n",
      "Epoch 0, Loss(train/val) 71.04413/70.70733. Took 0.35 sec\n",
      "ACC: 0.421875, MCC: -0.12565352717793946\n",
      "Epoch 0, Loss(train/val) 70.95081/71.40497. Took 0.34 sec\n",
      "ACC: 0.328125, MCC: -0.3231528059706172\n",
      "Epoch 0, Loss(train/val) 70.51266/70.49113. Took 0.34 sec\n",
      "ACC: 0.53125, MCC: 0.06362847629757777\n",
      "Epoch 0, Loss(train/val) 70.44488/69.62217. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.08233222475801151\n",
      "Epoch 0, Loss(train/val) 69.50989/69.81283. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.04222003309207491\n",
      "Epoch 0, Loss(train/val) 70.72989/70.35007. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.16952581789376897\n",
      "Epoch 0, Loss(train/val) 69.96977/70.08332. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: -0.0861259199332045\n",
      "Epoch 0, Loss(train/val) 70.89564/70.98149. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.11382681986840493\n",
      "Epoch 0, Loss(train/val) 70.30154/70.68380. Took 0.34 sec\n",
      "ACC: 0.375, MCC: -0.29277002188455997\n",
      "Epoch 0, Loss(train/val) 70.41643/69.78237. Took 0.37 sec\n",
      "ACC: 0.4375, MCC: -0.12173183529737108\n",
      "Epoch 0, Loss(train/val) 70.58553/70.06359. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: -0.06527939662729701\n",
      "Epoch 0, Loss(train/val) 70.28705/70.22130. Took 0.36 sec\n",
      "ACC: 0.453125, MCC: -0.12682630177432805\n",
      "Epoch 0, Loss(train/val) 71.88581/69.59040. Took 0.35 sec\n",
      "ACC: 0.4375, MCC: -0.12173183529737108\n",
      "Epoch 0, Loss(train/val) 70.36489/70.47808. Took 0.34 sec\n",
      "ACC: 0.53125, MCC: 0.11056588493219922\n",
      "Epoch 0, Loss(train/val) 70.21873/70.42077. Took 0.34 sec\n",
      "ACC: 0.53125, MCC: 0.05464091115261005\n",
      "Epoch 0, Loss(train/val) 70.86046/69.50121. Took 0.35 sec\n",
      "ACC: 0.46875, MCC: 0.00857966199371452\n",
      "Epoch 0, Loss(train/val) 68.38900/67.39307. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.013900245738365579\n",
      "Epoch 0, Loss(train/val) 70.57956/69.68166. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.07721695794343067\n",
      "Epoch 0, Loss(train/val) 70.22576/70.03435. Took 0.33 sec\n",
      "ACC: 0.40625, MCC: -0.1913956913205722\n",
      "Epoch 0, Loss(train/val) 70.46506/69.90572. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: -0.03202563076101743\n",
      "Epoch 0, Loss(train/val) 70.84350/70.77354. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: 0.004102738897530597\n",
      "Epoch 0, Loss(train/val) 69.90946/71.01564. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.036155076303109365\n",
      "Epoch 0, Loss(train/val) 71.54291/71.20454. Took 0.35 sec\n",
      "ACC: 0.46875, MCC: -0.07803322775472506\n",
      "Epoch 0, Loss(train/val) 70.47281/70.08223. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.10902649807579674\n",
      "Epoch 0, Loss(train/val) 70.68106/70.78785. Took 0.34 sec\n",
      "ACC: 0.578125, MCC: 0.10275246654751793\n",
      "Epoch 0, Loss(train/val) 70.03703/70.18024. Took 0.34 sec\n",
      "ACC: 0.40625, MCC: -0.05945004526603802\n",
      "Epoch 0, Loss(train/val) 70.74056/70.49023. Took 0.34 sec\n",
      "ACC: 0.390625, MCC: -0.20168187964479709\n",
      "Epoch 0, Loss(train/val) 70.47743/69.71938. Took 0.33 sec\n",
      "ACC: 0.40625, MCC: -0.04684519931585006\n",
      "Epoch 0, Loss(train/val) 70.66913/72.24052. Took 0.33 sec\n",
      "ACC: 0.5, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) 70.69943/69.95262. Took 0.34 sec\n",
      "ACC: 0.390625, MCC: -0.17612240316572622\n",
      "Epoch 0, Loss(train/val) 70.60765/69.79167. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: -0.006424925662032356\n",
      "Epoch 0, Loss(train/val) 70.39731/70.40285. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.08727977857199909\n",
      "Epoch 0, Loss(train/val) 70.48462/68.59911. Took 0.35 sec\n",
      "ACC: 0.5, MCC: -0.08571428571428572\n",
      "Epoch 0, Loss(train/val) 70.54432/70.34185. Took 0.36 sec\n",
      "ACC: 0.5, MCC: -0.027597827557262634\n",
      "Epoch 0, Loss(train/val) 70.65180/70.83398. Took 0.35 sec\n",
      "ACC: 0.578125, MCC: 0.18442777839082938\n",
      "Epoch 0, Loss(train/val) 70.79192/70.44810. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: 0.06816708894454176\n",
      "Epoch 0, Loss(train/val) 71.46453/69.67032. Took 0.37 sec\n",
      "ACC: 0.515625, MCC: 0.08512187667886854\n",
      "Epoch 0, Loss(train/val) 70.67369/69.59940. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.08606629658238704\n",
      "Epoch 0, Loss(train/val) 69.81320/69.37690. Took 0.35 sec\n",
      "ACC: 0.484375, MCC: 0.004232389556904849\n",
      "Epoch 0, Loss(train/val) 70.73702/70.63012. Took 0.36 sec\n",
      "ACC: 0.578125, MCC: 0.22034498977496858\n",
      "Epoch 0, Loss(train/val) 71.06289/71.02304. Took 0.37 sec\n",
      "ACC: 0.390625, MCC: -0.2393949488198693\n",
      "Epoch 0, Loss(train/val) 70.56540/70.74364. Took 0.40 sec\n",
      "ACC: 0.546875, MCC: 0.13064015512799124\n",
      "Epoch 0, Loss(train/val) 70.15828/71.07651. Took 0.34 sec\n",
      "ACC: 0.421875, MCC: -0.17485381766873062\n",
      "Epoch 0, Loss(train/val) 70.48430/70.19641. Took 0.35 sec\n",
      "ACC: 0.4375, MCC: -0.099230849433283\n",
      "Epoch 0, Loss(train/val) 71.64301/72.56007. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.16637976944997757\n",
      "Epoch 0, Loss(train/val) 69.78908/69.71387. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.11382681986840493\n",
      "Epoch 0, Loss(train/val) 70.09101/69.83369. Took 0.35 sec\n",
      "ACC: 0.375, MCC: -0.16151457061744964\n",
      "Epoch 0, Loss(train/val) 70.43903/70.45103. Took 0.34 sec\n",
      "ACC: 0.421875, MCC: -0.00826898230594723\n",
      "Epoch 0, Loss(train/val) 71.13280/70.23930. Took 0.35 sec\n",
      "ACC: 0.609375, MCC: 0.23865721224648745\n",
      "Epoch 0, Loss(train/val) 71.14825/70.77848. Took 0.37 sec\n",
      "ACC: 0.46875, MCC: -0.11500161355436699\n",
      "Epoch 0, Loss(train/val) 70.49108/69.65382. Took 0.35 sec\n",
      "ACC: 0.46875, MCC: -0.055997550008062294\n",
      "Epoch 0, Loss(train/val) 71.04512/70.80794. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.11006439012669275\n",
      "Epoch 0, Loss(train/val) 70.88195/71.49431. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: -0.10202730382030911\n",
      "Epoch 0, Loss(train/val) 71.22853/71.25435. Took 0.35 sec\n",
      "ACC: 0.484375, MCC: -0.2205128205128205\n",
      "Epoch 0, Loss(train/val) 69.99738/69.76759. Took 0.36 sec\n",
      "ACC: 0.53125, MCC: 0.016169041669088866\n",
      "Epoch 0, Loss(train/val) 71.04099/71.45707. Took 0.35 sec\n",
      "ACC: 0.453125, MCC: -0.04011426554254583\n",
      "Epoch 0, Loss(train/val) 70.91772/70.57751. Took 0.36 sec\n",
      "ACC: 0.5625, MCC: 0.12296371230092627\n",
      "Epoch 0, Loss(train/val) 70.92535/72.72953. Took 0.36 sec\n",
      "ACC: 0.5, MCC: -0.023070606931102022\n",
      "Epoch 0, Loss(train/val) 68.81352/67.20403. Took 0.36 sec\n",
      "ACC: 0.546875, MCC: 0.10902649807579674\n",
      "Epoch 0, Loss(train/val) 69.64991/70.03175. Took 0.35 sec\n",
      "ACC: 0.421875, MCC: -0.16638958140993043\n",
      "Epoch 0, Loss(train/val) 70.21393/70.39155. Took 0.36 sec\n",
      "ACC: 0.53125, MCC: 0.10846522890932808\n",
      "Epoch 0, Loss(train/val) 71.17478/70.43595. Took 0.35 sec\n",
      "ACC: 0.40625, MCC: -0.08214400968169071\n",
      "Epoch 0, Loss(train/val) 70.80466/72.85224. Took 0.33 sec\n",
      "ACC: 0.703125, MCC: 0.3971160402518228\n",
      "Epoch 0, Loss(train/val) 69.79604/70.64812. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.011953709238683663\n",
      "Epoch 0, Loss(train/val) 71.00835/71.15660. Took 0.34 sec\n",
      "ACC: 0.53125, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) 69.93687/70.12743. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: 0.1211560890116727\n",
      "Epoch 0, Loss(train/val) 70.41013/70.31500. Took 0.35 sec\n",
      "ACC: 0.546875, MCC: 0.03253000243161777\n",
      "Epoch 0, Loss(train/val) 70.34428/69.62726. Took 0.34 sec\n",
      "ACC: 0.578125, MCC: 0.08370786705565378\n",
      "Epoch 0, Loss(train/val) 70.48709/69.92027. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.09287218116773731\n",
      "Epoch 0, Loss(train/val) 71.29851/70.61898. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: 0.018049705127885604\n",
      "Epoch 0, Loss(train/val) 70.61690/71.01229. Took 0.35 sec\n",
      "ACC: 0.546875, MCC: 0.12156613477096616\n",
      "Epoch 0, Loss(train/val) 70.76890/71.60482. Took 0.35 sec\n",
      "ACC: 0.5625, MCC: -0.13840913308956662\n",
      "Epoch 0, Loss(train/val) 70.96875/71.93420. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: 0.08539151954760196\n",
      "Epoch 0, Loss(train/val) 69.38168/69.18198. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.07622548215427608\n",
      "Epoch 0, Loss(train/val) 70.08903/70.17921. Took 0.35 sec\n",
      "ACC: 0.59375, MCC: 0.21650635094610968\n",
      "Epoch 0, Loss(train/val) 70.74448/71.55199. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.0885319710087594\n",
      "Epoch 0, Loss(train/val) 70.76444/71.86694. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: 0.03688555567816588\n",
      "Epoch 0, Loss(train/val) 69.85818/69.59701. Took 0.34 sec\n",
      "ACC: 0.375, MCC: -0.30429566682085646\n",
      "Epoch 0, Loss(train/val) 70.41016/70.32013. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.06950480468569159\n",
      "Epoch 0, Loss(train/val) 70.72950/69.26976. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: 0.09245003270420486\n",
      "Epoch 0, Loss(train/val) 70.97754/70.64874. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: 0.11008838664532174\n",
      "Epoch 0, Loss(train/val) 70.77244/71.58480. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.16294759249954838\n",
      "Epoch 0, Loss(train/val) 70.66994/69.55360. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.13315005718713654\n",
      "Epoch 0, Loss(train/val) 69.89714/69.99866. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.06362847629757777\n",
      "Epoch 0, Loss(train/val) 70.41742/70.58078. Took 0.34 sec\n",
      "ACC: 0.578125, MCC: 0.18442777839082938\n",
      "Epoch 0, Loss(train/val) 70.54789/71.22855. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.049980989108788364\n",
      "Epoch 0, Loss(train/val) 70.83271/72.14520. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.018266554145039696\n",
      "Epoch 0, Loss(train/val) 71.30441/70.34793. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: 0.02154352039804115\n",
      "Epoch 0, Loss(train/val) 70.39631/70.99281. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.05790766725522051\n",
      "Epoch 0, Loss(train/val) 71.67157/71.63579. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: 0.046373889576016826\n",
      "Epoch 0, Loss(train/val) 71.27631/71.72647. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: 0.16265001215808886\n",
      "Epoch 0, Loss(train/val) 70.80672/71.35607. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.0452352697840582\n",
      "Epoch 0, Loss(train/val) 70.24036/69.79793. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.026836379837912434\n",
      "Epoch 0, Loss(train/val) 70.81434/70.58492. Took 0.33 sec\n",
      "ACC: 0.59375, MCC: 0.07453559924999299\n",
      "Epoch 0, Loss(train/val) 70.51758/69.92683. Took 0.33 sec\n",
      "ACC: 0.4375, MCC: -0.23175626392360707\n",
      "Epoch 0, Loss(train/val) 70.48694/70.53461. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.04982728791224399\n",
      "Epoch 0, Loss(train/val) 69.64976/70.87297. Took 0.34 sec\n",
      "ACC: 0.53125, MCC: -0.02450715406979359\n",
      "Epoch 0, Loss(train/val) 70.53630/69.42877. Took 0.35 sec\n",
      "ACC: 0.515625, MCC: -0.019702682109634957\n",
      "Epoch 0, Loss(train/val) 70.12774/69.56407. Took 0.35 sec\n",
      "ACC: 0.46875, MCC: -0.08738077349703083\n",
      "Epoch 0, Loss(train/val) 70.95745/71.14060. Took 0.35 sec\n",
      "ACC: 0.515625, MCC: 0.010419719766238846\n",
      "Epoch 0, Loss(train/val) 70.40286/69.87854. Took 0.35 sec\n",
      "ACC: 0.453125, MCC: -0.19053287138518982\n",
      "Epoch 0, Loss(train/val) 70.55578/70.31671. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: -0.041344911529736156\n",
      "Epoch 0, Loss(train/val) 70.46935/70.75591. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.09061004703659373\n",
      "Epoch 0, Loss(train/val) 70.87366/70.83926. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: 0.047619047619047616\n",
      "Epoch 0, Loss(train/val) 70.32457/70.81764. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.1268540658512312\n",
      "Epoch 0, Loss(train/val) 70.33216/71.30951. Took 0.81 sec\n",
      "ACC: 0.53125, MCC: 0.048507125007266595\n",
      "Epoch 0, Loss(train/val) 69.49873/68.98100. Took 0.34 sec\n",
      "ACC: 0.53125, MCC: -0.08582029808977935\n",
      "Epoch 0, Loss(train/val) 70.68802/70.27524. Took 0.34 sec\n",
      "ACC: 0.40625, MCC: -0.09169839395065688\n",
      "Epoch 0, Loss(train/val) 71.21849/70.80634. Took 0.34 sec\n",
      "ACC: 0.609375, MCC: 0.24873268045318114\n",
      "Epoch 0, Loss(train/val) 70.51097/71.90678. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: 0.0023098630955841236\n",
      "Epoch 0, Loss(train/val) 69.90263/69.64368. Took 0.35 sec\n",
      "ACC: 0.5, MCC: 0.0991956236158312\n",
      "Epoch 0, Loss(train/val) 71.42354/71.32909. Took 0.34 sec\n",
      "ACC: 0.53125, MCC: 0.05420213225174926\n",
      "Epoch 0, Loss(train/val) 70.20520/69.94511. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.026836379837912434\n",
      "Epoch 0, Loss(train/val) 70.62313/70.62602. Took 0.33 sec\n",
      "ACC: 0.640625, MCC: 0.20339007194925068\n",
      "Epoch 0, Loss(train/val) 69.82081/70.75768. Took 0.33 sec\n",
      "ACC: 0.40625, MCC: -0.27146025103791244\n",
      "Epoch 0, Loss(train/val) 69.93399/70.60848. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.13314386189201055\n",
      "Epoch 0, Loss(train/val) 70.76425/69.89735. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.11896346399976723\n",
      "Epoch 0, Loss(train/val) 69.38260/69.99210. Took 0.36 sec\n",
      "ACC: 0.578125, MCC: 0.11142851539596063\n",
      "Epoch 0, Loss(train/val) 70.01529/69.92129. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: -0.11215076988808788\n",
      "Epoch 0, Loss(train/val) 70.49727/70.77789. Took 0.35 sec\n",
      "ACC: 0.546875, MCC: 0.12156613477096616\n",
      "Epoch 0, Loss(train/val) 71.75526/71.74519. Took 0.35 sec\n",
      "ACC: 0.578125, MCC: 0.17485381766873062\n",
      "Epoch 0, Loss(train/val) 70.80722/68.44025. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.015051045257357716\n",
      "Epoch 0, Loss(train/val) 71.48932/70.05446. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.0820624619694061\n",
      "Epoch 0, Loss(train/val) 70.73596/71.43620. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.02938413738897565\n",
      "Epoch 0, Loss(train/val) 70.53681/70.03252. Took 0.33 sec\n",
      "ACC: 0.390625, MCC: -0.19282872818393804\n",
      "Epoch 0, Loss(train/val) 71.03610/70.21238. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.05718335949618505\n",
      "Epoch 0, Loss(train/val) 70.17058/69.93682. Took 0.33 sec\n",
      "ACC: 0.390625, MCC: -0.20032387995050754\n",
      "Epoch 0, Loss(train/val) 70.11549/71.06345. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.03313667478318056\n",
      "Epoch 0, Loss(train/val) 70.74060/71.39155. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.15196169394189366\n",
      "Epoch 0, Loss(train/val) 69.93051/69.59946. Took 0.33 sec\n",
      "ACC: 0.609375, MCC: 0.18274276524937544\n",
      "Epoch 0, Loss(train/val) 69.81525/69.88601. Took 0.34 sec\n",
      "ACC: 0.609375, MCC: 0.19770766067180878\n",
      "Epoch 0, Loss(train/val) 70.33174/70.49795. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: 0.012967780080514722\n",
      "Epoch 0, Loss(train/val) 70.47923/71.56420. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.18149475129798115\n",
      "Epoch 0, Loss(train/val) 70.98049/70.09978. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.05420213225174926\n",
      "Epoch 0, Loss(train/val) 70.83902/71.06529. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.1007821250148141\n",
      "Epoch 0, Loss(train/val) 71.03547/69.96394. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.10259783520851541\n",
      "Epoch 0, Loss(train/val) 69.03852/68.97028. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: 0.08512187667886854\n",
      "Epoch 0, Loss(train/val) 71.50598/72.47768. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: -0.035182987609823045\n",
      "Epoch 0, Loss(train/val) 70.49583/70.65929. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.027392713453777272\n",
      "Epoch 0, Loss(train/val) 70.88191/69.71478. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.09983374884595826\n",
      "Epoch 0, Loss(train/val) 71.75369/70.29900. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.07710592627016746\n",
      "Epoch 0, Loss(train/val) 71.07907/70.91000. Took 0.33 sec\n",
      "ACC: 0.390625, MCC: -0.15114173098063566\n",
      "Epoch 0, Loss(train/val) 69.48247/69.70080. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.06348584335357274\n",
      "Epoch 0, Loss(train/val) 70.75757/71.87171. Took 0.34 sec\n",
      "ACC: 0.625, MCC: 0.2886751345948129\n",
      "Epoch 0, Loss(train/val) 69.91651/69.47377. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.14433756729740646\n",
      "Epoch 0, Loss(train/val) 70.93643/70.23502. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.04222003309207491\n",
      "Epoch 0, Loss(train/val) 70.84147/71.03179. Took 0.34 sec\n",
      "ACC: 0.4375, MCC: -0.20140599270554796\n",
      "Epoch 0, Loss(train/val) 70.05326/69.50858. Took 0.34 sec\n",
      "ACC: 0.53125, MCC: 0.10010887319501069\n",
      "Epoch 0, Loss(train/val) 70.36078/70.06219. Took 0.34 sec\n",
      "ACC: 0.4375, MCC: -0.22721652007844526\n",
      "Epoch 0, Loss(train/val) 70.30789/70.78556. Took 0.34 sec\n",
      "ACC: 0.4375, MCC: -0.15231225557722924\n",
      "Epoch 0, Loss(train/val) 71.17706/69.55719. Took 0.34 sec\n",
      "ACC: 0.578125, MCC: 0.15428278029593878\n",
      "Epoch 0, Loss(train/val) 71.08546/70.74036. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.10494455393423795\n",
      "Epoch 0, Loss(train/val) 69.83916/69.02560. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: 0.0911835340720322\n",
      "Epoch 0, Loss(train/val) 71.07351/70.19424. Took 0.34 sec\n",
      "ACC: 0.59375, MCC: 0.2100639473200342\n",
      "Epoch 0, Loss(train/val) 70.33932/70.04137. Took 0.35 sec\n",
      "ACC: 0.453125, MCC: -0.10635445160305\n",
      "Epoch 0, Loss(train/val) 70.56897/70.53339. Took 0.35 sec\n",
      "ACC: 0.53125, MCC: 0.13314386189201055\n",
      "Epoch 0, Loss(train/val) 71.02332/71.72646. Took 0.35 sec\n",
      "ACC: 0.390625, MCC: -0.1993421034805062\n",
      "Epoch 0, Loss(train/val) 70.88983/69.69489. Took 0.34 sec\n",
      "ACC: 0.390625, MCC: -0.12912588943720443\n",
      "Epoch 0, Loss(train/val) 71.02076/71.66457. Took 0.34 sec\n",
      "ACC: 0.6875, MCC: 0.33188038846827844\n",
      "Epoch 0, Loss(train/val) 70.19332/70.09493. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.13010726223589664\n",
      "Epoch 0, Loss(train/val) 70.91816/69.73823. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.008866995073891626\n",
      "Epoch 0, Loss(train/val) 69.92245/71.13465. Took 0.34 sec\n",
      "ACC: 0.609375, MCC: 0.16727642548310923\n",
      "Epoch 0, Loss(train/val) 70.68854/69.82675. Took 0.34 sec\n",
      "ACC: 0.375, MCC: -0.24253562503633297\n",
      "Epoch 0, Loss(train/val) 70.25358/71.25815. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.020601266687222692\n",
      "Epoch 0, Loss(train/val) 70.26806/71.37536. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: -0.09061004703659373\n",
      "Epoch 0, Loss(train/val) 70.47924/68.99094. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.06348584335357274\n",
      "Epoch 0, Loss(train/val) 70.62183/70.77540. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.08571428571428572\n",
      "Epoch 0, Loss(train/val) 70.41044/70.14066. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.03917303733717809\n",
      "Epoch 0, Loss(train/val) 70.59664/70.13091. Took 0.35 sec\n",
      "ACC: 0.5, MCC: -0.06279669574154817\n",
      "Epoch 0, Loss(train/val) 69.80133/69.05759. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: 0.09759000729485331\n",
      "Epoch 0, Loss(train/val) 71.10684/70.50787. Took 0.34 sec\n",
      "ACC: 0.578125, MCC: 0.17485381766873062\n",
      "Epoch 0, Loss(train/val) 70.32439/70.06912. Took 0.34 sec\n",
      "ACC: 0.625, MCC: 0.1978273656162033\n",
      "Epoch 0, Loss(train/val) 70.50914/71.34238. Took 0.34 sec\n",
      "ACC: 0.421875, MCC: -0.1287163801655757\n",
      "Epoch 0, Loss(train/val) 70.28078/69.69473. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.05908580644613889\n",
      "Epoch 0, Loss(train/val) 70.44200/70.94303. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: 0.028215384400198253\n",
      "Epoch 0, Loss(train/val) 70.84605/70.42928. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: -0.0686780908582235\n",
      "Epoch 0, Loss(train/val) 69.71988/69.34158. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: 0.13900960937138318\n",
      "Epoch 0, Loss(train/val) 71.41559/71.11961. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: 0.08914849883204184\n",
      "Epoch 0, Loss(train/val) 70.37821/70.87336. Took 0.35 sec\n",
      "ACC: 0.53125, MCC: 0.026836379837912434\n",
      "Epoch 0, Loss(train/val) 70.64583/70.64714. Took 0.34 sec\n",
      "ACC: 0.421875, MCC: -0.1268540658512312\n",
      "Epoch 0, Loss(train/val) 71.02737/71.70264. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: -0.031199984310868976\n",
      "Epoch 0, Loss(train/val) 69.94032/69.47533. Took 0.34 sec\n",
      "ACC: 0.34375, MCC: -0.229461336019767\n",
      "Epoch 0, Loss(train/val) 71.30954/71.44054. Took 0.33 sec\n",
      "ACC: 0.59375, MCC: 0.1773241389867146\n",
      "Epoch 0, Loss(train/val) 70.36867/69.66763. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.05420213225174926\n",
      "Epoch 0, Loss(train/val) 71.29046/70.89079. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.026058663542806157\n",
      "Epoch 0, Loss(train/val) 70.83960/71.42880. Took 0.34 sec\n",
      "ACC: 0.4375, MCC: -0.09216619992325613\n",
      "Epoch 0, Loss(train/val) 70.16947/70.23196. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: -0.09245003270420486\n",
      "Epoch 0, Loss(train/val) 70.42603/70.02042. Took 0.34 sec\n",
      "ACC: 0.421875, MCC: -0.08370786705565378\n",
      "Epoch 0, Loss(train/val) 70.88249/71.28795. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: 0.0022154222857491456\n",
      "Epoch 0, Loss(train/val) 71.19247/70.42092. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.07803322775472506\n",
      "Epoch 0, Loss(train/val) 70.61655/70.99509. Took 0.34 sec\n",
      "ACC: 0.59375, MCC: 0.18523864848892105\n",
      "Epoch 0, Loss(train/val) 71.00003/71.10857. Took 0.34 sec\n",
      "ACC: 0.609375, MCC: 0.10476190476190476\n",
      "Epoch 0, Loss(train/val) 70.54114/70.79494. Took 0.36 sec\n",
      "ACC: 0.5625, MCC: 0.15118578920369088\n",
      "Epoch 0, Loss(train/val) 70.18134/69.71982. Took 0.35 sec\n",
      "ACC: 0.5625, MCC: 0.1807753815155468\n",
      "Epoch 0, Loss(train/val) 71.43351/72.22215. Took 0.35 sec\n",
      "ACC: 0.4375, MCC: -0.23175626392360707\n",
      "Epoch 0, Loss(train/val) 70.61304/70.73473. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: 0.0022154222857491456\n",
      "Epoch 0, Loss(train/val) 71.23487/71.31161. Took 0.35 sec\n",
      "ACC: 0.390625, MCC: -0.23294541397390262\n",
      "Epoch 0, Loss(train/val) 70.77349/70.22100. Took 0.35 sec\n",
      "ACC: 0.5625, MCC: 0.13235242923632212\n",
      "Epoch 0, Loss(train/val) 70.99383/70.15846. Took 0.36 sec\n",
      "ACC: 0.546875, MCC: 0.018266554145039696\n",
      "Epoch 0, Loss(train/val) 70.62004/71.65462. Took 0.35 sec\n",
      "ACC: 0.484375, MCC: 0.02154352039804115\n",
      "Epoch 0, Loss(train/val) 70.65688/71.03162. Took 0.35 sec\n",
      "ACC: 0.546875, MCC: -0.0022259352109805924\n",
      "Epoch 0, Loss(train/val) 70.30325/70.22763. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.13471563869719666\n",
      "Epoch 0, Loss(train/val) 70.18394/70.12716. Took 0.33 sec\n",
      "ACC: 0.40625, MCC: -0.09956709956709957\n",
      "Epoch 0, Loss(train/val) 70.54552/70.55726. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.025861699363244256\n",
      "Epoch 0, Loss(train/val) 69.98611/69.36074. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: -0.012312225225925604\n",
      "Epoch 0, Loss(train/val) 70.52300/69.77431. Took 0.33 sec\n",
      "ACC: 0.5, MCC: 0.03546361409014303\n",
      "Epoch 0, Loss(train/val) 70.94054/69.67155. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.08222643447147887\n",
      "Epoch 0, Loss(train/val) 69.18899/68.45107. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.12498768867296815\n",
      "Epoch 0, Loss(train/val) 70.96630/71.72395. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.17448048290289417\n",
      "Epoch 0, Loss(train/val) 70.59317/69.33083. Took 0.33 sec\n",
      "ACC: 0.609375, MCC: 0.20959097296420087\n",
      "Epoch 0, Loss(train/val) 70.25244/70.50260. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.10500815676649744\n",
      "Epoch 0, Loss(train/val) 70.16068/69.76520. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.012955005512625914\n",
      "Epoch 0, Loss(train/val) 70.01284/69.48868. Took 0.33 sec\n",
      "ACC: 0.625, MCC: 0.24309494690922778\n",
      "Epoch 0, Loss(train/val) 70.73393/71.73465. Took 0.34 sec\n",
      "ACC: 0.4375, MCC: -0.13900960937138318\n",
      "Epoch 0, Loss(train/val) 69.54930/70.27761. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.17795459968658567\n",
      "Epoch 0, Loss(train/val) 70.76760/70.62836. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.04982728791224399\n",
      "Epoch 0, Loss(train/val) 70.15061/69.71134. Took 0.34 sec\n",
      "ACC: 0.578125, MCC: 0.04115547222147856\n",
      "Epoch 0, Loss(train/val) 70.56983/69.92931. Took 0.95 sec\n",
      "ACC: 0.46875, MCC: -0.1636319382479181\n",
      "Epoch 0, Loss(train/val) 70.78569/70.79710. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.0416070055112537\n",
      "Epoch 0, Loss(train/val) 70.09084/70.20593. Took 0.35 sec\n",
      "ACC: 0.53125, MCC: 0.07570682517832987\n",
      "Epoch 0, Loss(train/val) 70.40763/69.88625. Took 0.36 sec\n",
      "ACC: 0.546875, MCC: 0.06859245370246428\n",
      "Epoch 0, Loss(train/val) 70.57760/71.13091. Took 0.35 sec\n",
      "ACC: 0.515625, MCC: 0.046373889576016826\n",
      "Epoch 0, Loss(train/val) 70.32922/69.80036. Took 0.32 sec\n",
      "ACC: 0.40625, MCC: -0.13815273063140598\n",
      "Epoch 0, Loss(train/val) 70.95026/70.36159. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.06262242910851495\n",
      "Epoch 0, Loss(train/val) 71.13401/71.60411. Took 0.33 sec\n",
      "ACC: 0.578125, MCC: 0.17688728441930626\n",
      "Epoch 0, Loss(train/val) 70.45187/71.06197. Took 0.96 sec\n",
      "ACC: 0.484375, MCC: -0.02421797398482414\n",
      "Epoch 0, Loss(train/val) 70.42489/69.82439. Took 0.33 sec\n",
      "ACC: 0.5, MCC: 0.009163235455864739\n",
      "Epoch 0, Loss(train/val) 70.62874/71.80702. Took 0.34 sec\n",
      "ACC: 0.4375, MCC: -0.07881104062391008\n",
      "Epoch 0, Loss(train/val) 70.06714/70.49994. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.027597827557262634\n",
      "Epoch 0, Loss(train/val) 71.05303/70.93071. Took 0.34 sec\n",
      "ACC: 0.421875, MCC: -0.16150120428611295\n",
      "Epoch 0, Loss(train/val) 70.65405/71.67271. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.011953709238683663\n",
      "Epoch 0, Loss(train/val) 70.45057/69.88338. Took 0.34 sec\n",
      "ACC: 0.609375, MCC: 0.14606945763083234\n",
      "Epoch 0, Loss(train/val) 70.56199/70.69743. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.19210545285208808\n",
      "Epoch 0, Loss(train/val) 69.74274/69.82513. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.09734495980881153\n",
      "Epoch 0, Loss(train/val) 71.35151/70.93837. Took 0.97 sec\n",
      "ACC: 0.484375, MCC: 0.012967780080514722\n",
      "Epoch 0, Loss(train/val) 71.26933/71.40820. Took 0.33 sec\n",
      "ACC: 0.625, MCC: 0.22084711628963774\n",
      "Epoch 0, Loss(train/val) 70.20527/68.97739. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.10275246654751793\n",
      "Epoch 0, Loss(train/val) 68.92471/68.90295. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.19425252799436668\n",
      "Epoch 0, Loss(train/val) 71.39005/70.79469. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: 0.06210761473297944\n",
      "Epoch 0, Loss(train/val) 69.74532/69.44605. Took 0.35 sec\n",
      "ACC: 0.578125, MCC: 0.22529024816220128\n",
      "Epoch 0, Loss(train/val) 69.63413/70.69137. Took 0.36 sec\n",
      "ACC: 0.484375, MCC: -0.11617858011292062\n",
      "Epoch 0, Loss(train/val) 69.95656/69.13802. Took 0.34 sec\n",
      "ACC: 0.375, MCC: -0.20127931918348624\n",
      "Epoch 0, Loss(train/val) 70.89820/70.71371. Took 0.35 sec\n",
      "ACC: 0.59375, MCC: 0.1807753815155468\n",
      "Epoch 0, Loss(train/val) 70.88135/70.54263. Took 0.34 sec\n",
      "ACC: 0.375, MCC: -0.17108079108537955\n",
      "Epoch 0, Loss(train/val) 69.96190/70.93861. Took 0.34 sec\n",
      "ACC: 0.5, MCC: -0.03913053124059665\n",
      "Epoch 0, Loss(train/val) 70.53937/68.79128. Took 0.35 sec\n",
      "ACC: 0.375, MCC: -0.19955825456831924\n",
      "Epoch 0, Loss(train/val) 70.80733/70.17830. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: -0.07265392195447241\n",
      "Epoch 0, Loss(train/val) 69.86762/70.13593. Took 0.34 sec\n",
      "ACC: 0.421875, MCC: -0.20089174191687223\n",
      "Epoch 0, Loss(train/val) 71.40868/70.90096. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.09341218537003596\n",
      "Epoch 0, Loss(train/val) 70.07534/70.04087. Took 0.34 sec\n",
      "ACC: 0.53125, MCC: 0.03917303733717809\n",
      "Epoch 0, Loss(train/val) 70.08482/69.88963. Took 0.36 sec\n",
      "ACC: 0.46875, MCC: -0.10010887319501069\n",
      "Epoch 0, Loss(train/val) 69.71154/69.70713. Took 0.35 sec\n",
      "ACC: 0.546875, MCC: 0.07036672182012485\n",
      "Epoch 0, Loss(train/val) 71.42371/71.02290. Took 0.34 sec\n",
      "ACC: 0.4375, MCC: -0.18071682129971953\n",
      "Epoch 0, Loss(train/val) 70.41906/71.14178. Took 0.33 sec\n",
      "ACC: 0.59375, MCC: 0.19487030513625772\n",
      "Epoch 0, Loss(train/val) 71.31695/70.66431. Took 0.33 sec\n",
      "ACC: 0.59375, MCC: 0.20181644987353448\n",
      "Epoch 0, Loss(train/val) 70.68994/70.51113. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.07273929674533079\n",
      "Epoch 0, Loss(train/val) 69.41163/68.72552. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.030467917928916295\n",
      "Epoch 0, Loss(train/val) 69.87903/69.56159. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.10846522890932808\n",
      "Epoch 0, Loss(train/val) 70.22541/70.93790. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: -0.04178165937007196\n",
      "Epoch 0, Loss(train/val) 70.81502/70.68203. Took 0.35 sec\n",
      "ACC: 0.421875, MCC: -0.16314545558893145\n",
      "Epoch 0, Loss(train/val) 69.48903/70.70807. Took 0.34 sec\n",
      "ACC: 0.5, MCC: -0.036155076303109365\n",
      "Epoch 0, Loss(train/val) 69.96319/69.98569. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.06104362873533078\n",
      "Epoch 0, Loss(train/val) 70.68076/71.24971. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.0902550601789804\n",
      "Epoch 0, Loss(train/val) 70.53152/70.86767. Took 0.34 sec\n",
      "ACC: 0.5, MCC: -0.1405726992011029\n",
      "Epoch 0, Loss(train/val) 70.58053/69.98734. Took 0.33 sec\n",
      "ACC: 0.640625, MCC: 0.12879797345315208\n",
      "Epoch 0, Loss(train/val) 70.58106/71.46347. Took 0.35 sec\n",
      "ACC: 0.609375, MCC: 0.21796176586341726\n",
      "Epoch 0, Loss(train/val) 70.85871/71.47173. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: 0.12173183529737108\n",
      "Epoch 0, Loss(train/val) 69.34765/69.85085. Took 0.35 sec\n",
      "ACC: 0.515625, MCC: 0.013454429991568964\n",
      "Epoch 0, Loss(train/val) 69.53796/69.40797. Took 1.03 sec\n",
      "ACC: 0.375, MCC: -0.20259206962659404\n",
      "Epoch 0, Loss(train/val) 70.81636/70.03724. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.1229526932416184\n",
      "Epoch 0, Loss(train/val) 70.42619/70.27448. Took 0.34 sec\n",
      "ACC: 0.640625, MCC: 0.18974358974358974\n",
      "Epoch 0, Loss(train/val) 71.70216/72.84369. Took 0.34 sec\n",
      "ACC: 0.421875, MCC: -0.08370786705565378\n",
      "Epoch 0, Loss(train/val) 71.41553/71.14583. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.19619349067317748\n",
      "Epoch 0, Loss(train/val) 70.84264/71.56271. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.010419719766238846\n",
      "Epoch 0, Loss(train/val) 70.43671/70.05122. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.10251423416428378\n",
      "Epoch 0, Loss(train/val) 70.67628/71.51648. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.07845331985520247\n",
      "Epoch 0, Loss(train/val) 70.85300/70.09786. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: 0.05098167171291605\n",
      "Epoch 0, Loss(train/val) 70.81781/70.79351. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: -0.015019349877480085\n",
      "Epoch 0, Loss(train/val) 70.44877/70.93823. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: -0.05382272057250939\n",
      "Epoch 0, Loss(train/val) 70.57536/69.88297. Took 0.34 sec\n",
      "ACC: 0.5, MCC: -0.050256410256410255\n",
      "Epoch 0, Loss(train/val) 71.55602/71.15365. Took 0.35 sec\n",
      "ACC: 0.46875, MCC: -0.058823529411764705\n",
      "Epoch 0, Loss(train/val) 69.75110/67.97965. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.12575458377852053\n",
      "Epoch 0, Loss(train/val) 71.50370/69.89727. Took 0.34 sec\n",
      "ACC: 0.53125, MCC: 0.02938413738897565\n",
      "Epoch 0, Loss(train/val) 70.11351/70.26534. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: -0.04003550427859755\n",
      "Epoch 0, Loss(train/val) 71.25337/70.44846. Took 0.35 sec\n",
      "ACC: 0.421875, MCC: -0.08370786705565378\n",
      "Epoch 0, Loss(train/val) 71.39352/71.78550. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.08606629658238704\n",
      "Epoch 0, Loss(train/val) 70.33603/69.72118. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: -0.0022154222857491456\n",
      "Epoch 0, Loss(train/val) 70.55574/70.42375. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: 0.14462158210542375\n",
      "Epoch 0, Loss(train/val) 70.49555/70.43470. Took 0.35 sec\n",
      "ACC: 0.46875, MCC: -0.0629940788348712\n",
      "Epoch 0, Loss(train/val) 70.74387/70.02723. Took 0.35 sec\n",
      "ACC: 0.46875, MCC: -0.0710915894200724\n",
      "Epoch 0, Loss(train/val) 70.74081/71.21424. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: 0.008104408984731078\n",
      "Epoch 0, Loss(train/val) 70.48562/69.84113. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: 0.03688555567816588\n",
      "Epoch 0, Loss(train/val) 70.43751/69.60719. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.08233222475801151\n",
      "Epoch 0, Loss(train/val) 69.74071/68.91373. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.07965984390565167\n",
      "Epoch 0, Loss(train/val) 70.87257/70.13508. Took 0.33 sec\n",
      "ACC: 0.4375, MCC: -0.012250499062972714\n",
      "Epoch 0, Loss(train/val) 71.00079/70.26292. Took 0.34 sec\n",
      "ACC: 0.40625, MCC: -0.1883201896480698\n",
      "Epoch 0, Loss(train/val) 70.08549/69.78162. Took 0.35 sec\n",
      "ACC: 0.5625, MCC: 0.16974982846110506\n",
      "Epoch 0, Loss(train/val) 71.13595/70.96198. Took 0.35 sec\n",
      "ACC: 0.671875, MCC: 0.24595062420801728\n",
      "Epoch 0, Loss(train/val) 70.26396/71.75926. Took 0.33 sec\n",
      "ACC: 0.5, MCC: 0.01659128610703117\n",
      "Epoch 0, Loss(train/val) 69.62842/70.15476. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.0778902520624173\n",
      "Epoch 0, Loss(train/val) 70.55469/70.47629. Took 0.34 sec\n",
      "ACC: 0.4375, MCC: -0.15244937348544793\n",
      "Epoch 0, Loss(train/val) 70.70403/70.48162. Took 0.34 sec\n",
      "ACC: 0.4375, MCC: -0.08655029717602476\n",
      "Epoch 0, Loss(train/val) 70.41433/70.83089. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.021079040716371285\n",
      "Epoch 0, Loss(train/val) 70.10410/69.64037. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.11834526708278773\n",
      "Epoch 0, Loss(train/val) 69.56421/69.80682. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: 0.012967780080514722\n",
      "Epoch 0, Loss(train/val) 70.40808/71.22353. Took 0.34 sec\n",
      "ACC: 0.40625, MCC: -0.014920941939059814\n",
      "Epoch 0, Loss(train/val) 70.26665/70.79510. Took 0.35 sec\n",
      "ACC: 0.578125, MCC: 0.1287163801655757\n",
      "Epoch 0, Loss(train/val) 70.24835/69.75878. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.02446487298750427\n",
      "Epoch 0, Loss(train/val) 71.71624/71.31628. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: -0.010908167810642008\n",
      "Epoch 0, Loss(train/val) 70.49638/69.75001. Took 0.35 sec\n",
      "ACC: 0.515625, MCC: 0.11968263863870991\n",
      "Epoch 0, Loss(train/val) 70.76603/71.07925. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.07273929674533079\n",
      "Epoch 0, Loss(train/val) 70.56134/71.90282. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: 0.03253000243161777\n",
      "Epoch 0, Loss(train/val) 70.55343/71.28786. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.018049705127885604\n",
      "Epoch 0, Loss(train/val) 71.10157/71.58291. Took 0.33 sec\n",
      "ACC: 0.625, MCC: 0.2482845429325592\n",
      "Epoch 0, Loss(train/val) 71.00513/70.25504. Took 0.34 sec\n",
      "ACC: 0.484375, MCC: -0.03202563076101743\n",
      "Epoch 0, Loss(train/val) 70.32507/70.24662. Took 0.34 sec\n",
      "ACC: 0.578125, MCC: 0.1536230967599611\n",
      "Epoch 0, Loss(train/val) 71.34417/70.54591. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.07570682517832987\n",
      "Epoch 0, Loss(train/val) 70.05600/69.67759. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.07570682517832987\n",
      "Epoch 0, Loss(train/val) 69.49612/69.60945. Took 0.34 sec\n",
      "ACC: 0.53125, MCC: 0.06158357771260997\n",
      "Epoch 0, Loss(train/val) 71.19725/70.84193. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: 0.13945994111797608\n",
      "Epoch 0, Loss(train/val) 70.27252/68.90160. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.0710915894200724\n",
      "Epoch 0, Loss(train/val) 70.94277/69.40152. Took 0.36 sec\n",
      "ACC: 0.578125, MCC: 0.07499049287944097\n",
      "Epoch 0, Loss(train/val) 69.35737/70.34220. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.0731089354297218\n",
      "Epoch 0, Loss(train/val) 70.85779/71.87331. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.07265392195447241\n",
      "Epoch 0, Loss(train/val) 70.28920/69.44386. Took 0.34 sec\n",
      "ACC: 0.5625, MCC: 0.12498768867296815\n",
      "Epoch 0, Loss(train/val) 70.26402/70.84884. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.12682630177432805\n",
      "Epoch 0, Loss(train/val) 71.20960/70.43394. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.09983374884595826\n",
      "Epoch 0, Loss(train/val) 70.61074/71.28159. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.15283065658442813\n",
      "Epoch 0, Loss(train/val) 70.77480/70.44450. Took 0.34 sec\n",
      "ACC: 0.375, MCC: -0.16183579655925293\n",
      "Epoch 0, Loss(train/val) 70.57777/70.96999. Took 0.34 sec\n",
      "ACC: 0.578125, MCC: 0.14349000645205595\n",
      "Epoch 0, Loss(train/val) 70.53340/70.83755. Took 0.34 sec\n",
      "ACC: 0.40625, MCC: -0.16324595240672599\n",
      "Epoch 0, Loss(train/val) 70.85535/71.40771. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.03917303733717809\n",
      "Epoch 0, Loss(train/val) 70.41565/71.66233. Took 0.34 sec\n",
      "ACC: 0.46875, MCC: -0.08652532008633532\n",
      "Epoch 0, Loss(train/val) 70.64297/71.51787. Took 0.34 sec\n",
      "ACC: 0.34375, MCC: -0.24370871833797697\n",
      "Epoch 0, Loss(train/val) 70.47155/69.82036. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.03688555567816588\n",
      "Epoch 0, Loss(train/val) 70.49825/69.81360. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.02486823656509969\n",
      "Epoch 0, Loss(train/val) 70.08039/71.49803. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.007174960033341752\n",
      "Epoch 0, Loss(train/val) 71.10549/72.10654. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.1007821250148141\n",
      "Epoch 0, Loss(train/val) 69.92713/70.86978. Took 0.34 sec\n",
      "ACC: 0.453125, MCC: -0.10259783520851541\n",
      "Epoch 0, Loss(train/val) 70.87600/70.91899. Took 0.34 sec\n",
      "ACC: 0.578125, MCC: 0.14349000645205595\n",
      "Epoch 0, Loss(train/val) 71.02801/71.49353. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.00392156862745098\n",
      "Epoch 0, Loss(train/val) 71.34308/70.87357. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.1630980846658687\n",
      "Epoch 0, Loss(train/val) 70.49919/70.91190. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: -0.05382272057250939\n",
      "Epoch 0, Loss(train/val) 70.12194/70.10411. Took 0.35 sec\n",
      "ACC: 0.375, MCC: -0.27074557691828405\n",
      "Epoch 0, Loss(train/val) 70.07718/70.20840. Took 0.33 sec\n",
      "ACC: 0.578125, MCC: 0.14400244857369446\n",
      "Epoch 0, Loss(train/val) 71.62439/69.85674. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.10846522890932808\n",
      "Epoch 0, Loss(train/val) 70.14801/71.09177. Took 0.34 sec\n",
      "ACC: 0.65625, MCC: 0.2721190148800421\n",
      "Epoch 0, Loss(train/val) 70.76250/70.27687. Took 0.35 sec\n",
      "ACC: 0.453125, MCC: 0.019061119832061685\n",
      "Epoch 0, Loss(train/val) 70.20886/70.24277. Took 0.35 sec\n",
      "ACC: 0.640625, MCC: 0.25575002517077644\n",
      "Epoch 0, Loss(train/val) 70.34604/70.92918. Took 0.35 sec\n",
      "ACC: 0.5625, MCC: 0.0911835340720322\n",
      "Epoch 0, Loss(train/val) 70.65253/72.04617. Took 0.35 sec\n",
      "ACC: 0.53125, MCC: -0.02450715406979359\n",
      "Epoch 0, Loss(train/val) 69.82575/69.52623. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.07495746605704415\n",
      "Epoch 0, Loss(train/val) 70.76368/70.25816. Took 0.34 sec\n",
      "ACC: 0.5, MCC: 0.0820624619694061\n",
      "Epoch 0, Loss(train/val) 70.69721/69.93259. Took 0.35 sec\n",
      "ACC: 0.5, MCC: -0.030467917928916295\n",
      "Epoch 0, Loss(train/val) 70.75232/70.11873. Took 0.34 sec\n",
      "ACC: 0.609375, MCC: 0.20168187964479709\n",
      "Epoch 0, Loss(train/val) 70.62053/70.83076. Took 0.34 sec\n",
      "ACC: 0.546875, MCC: 0.25123605173384456\n",
      "Epoch 0, Loss(train/val) 70.89114/69.73035. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.07033112351420975\n",
      "Epoch 0, Loss(train/val) 70.79073/70.34283. Took 0.35 sec\n",
      "ACC: 0.546875, MCC: 0.10613237065158375\n",
      "Epoch 0, Loss(train/val) 70.57717/71.05492. Took 0.34 sec\n",
      "ACC: 0.4375, MCC: -0.06666666666666667\n",
      "Epoch 0, Loss(train/val) 71.51381/72.10840. Took 0.34 sec\n",
      "ACC: 0.40625, MCC: -0.21019754169815524\n",
      "Epoch 0, Loss(train/val) 70.06830/71.18349. Took 0.34 sec\n",
      "ACC: 0.53125, MCC: 0.09288407280256479\n",
      "Epoch 0, Loss(train/val) 70.63762/70.95157. Took 0.34 sec\n",
      "ACC: 0.5, MCC: -0.049969626464415974\n"
     ]
    }
   ],
   "source": [
    "## 실행 파일\n",
    "args.data_list = os.listdir(\"C:\\\\Users\\\\USER\\\\JupyterProjects\\\\AdvLSTM\\\\data\\\\kdd17\\\\ourpped\")\n",
    "\n",
    "\n",
    "with open(args.save_file_path + '\\\\' + 'AdvLSTM_result_t.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerow([\"model\", \"stock\", \"entire_exp_time\",  \"avg_test_ACC\", \"avg_test_ACC_std\", \"avg_test_MCC\"])\n",
    "\n",
    "    for data in args.data_list:\n",
    "        \n",
    "        stock = data.split('.')[0]\n",
    "\n",
    "        est = time.time()\n",
    "        setattr(args, 'symbol', stock)\n",
    "        args.new_file_path = args.save_file_path + '\\\\' + \"AdvLSTM_\" + args.symbol\n",
    "        os.makedirs(args.new_file_path)\n",
    "        \n",
    "        \n",
    "        csv_read = stock_csv_read(data,args.x_frames,args.y_frames)\n",
    "        split_data_list = csv_read.cv_split()\n",
    "        \n",
    "        ACC_cv = []\n",
    "        for i, data in enumerate(split_data_list):\n",
    "            args.split_file_path = args.new_file_path + \"\\\\\" + str(i) +\"th_iter\"\n",
    "            os.makedirs(args.split_file_path)\n",
    "            # 0번째에 index 1번째에 stock 1개가 input으로 들어감\n",
    "            trainset = StockDataset(data[0])\n",
    "            valset = StockDataset(data[1])\n",
    "            testset = StockDataset(data[2])\n",
    "        \n",
    "\n",
    "            partition = {'train': trainset, 'val': valset, 'test': testset}\n",
    "\n",
    "\n",
    "            setting, result = experiment(partition, args)\n",
    "            eet = time.time()\n",
    "            entire_exp_time = eet - est\n",
    "\n",
    "            fig = plt.figure()\n",
    "            plt.plot(result['train_losses'])\n",
    "            plt.plot(result['val_losses'])\n",
    "            plt.legend(['train_losses', 'val_losses'], fontsize=15)\n",
    "            plt.xlabel('epoch', fontsize=15)\n",
    "            plt.ylabel('loss', fontsize=15)\n",
    "            plt.grid()\n",
    "            plt.savefig(args.split_file_path + '\\\\' + str(args.symbol) + '_fig' + '.png')\n",
    "            plt.close(fig)\n",
    "            ACC_cv.append(result['ACC'])\n",
    "            # csv파일에 기록하기\n",
    "        ACC_cv_ar = np.array(ACC_cv)\n",
    "        acc_avg = np.mean(ACC_cv_ar)\n",
    "        acc_std = np.std(ACC_cv_ar)\n",
    "\n",
    "        wr.writerow([\"AdvLSTM\", args.symbol, entire_exp_time, acc_avg, acc_std, result['MCC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py38_64",
   "language": "python",
   "name": "py38_64"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
