{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Stock_Dataset.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\USER\\\\JupyterProjects\\\\AdvLSTM')\n",
    "from Stock_Dataset import StockDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Att_LSTM.ipynb\n",
      "importing Jupyter notebook from attention.ipynb\n",
      "importing Jupyter notebook from metric.ipynb\n",
      "importing Jupyter notebook from loss_fn1.ipynb\n",
      "importing Jupyter notebook from adv.ipynb\n",
      "importing Jupyter notebook from Stock_datasets_csv.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "from Att_LSTM import attLSTM\n",
    "import numpy as np\n",
    "import time\n",
    "from metric import metric_acc as ACC\n",
    "from metric import metric_mcc as MCC\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "from loss_fn1 import adv_loss\n",
    "from adv import adversarial\n",
    "from Stock_datasets_csv import stock_csv_read\n",
    "\n",
    "def train(attLSTM,adversarial ,lstm_optimizer,Partition, args): ## Data, loss function, argument\n",
    "    trainloader = DataLoader(Partition['train'],\n",
    "                             batch_size = args.batch_size,\n",
    "                             shuffle=False, drop_last=True)\n",
    "    attLSTM.train()\n",
    "    adversarial.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    for i, (x,y) in enumerate(trainloader):\n",
    "        \n",
    "        lstm_optimizer.zero_grad()\n",
    "        \n",
    "        true_y = y.squeeze().float().to(args.device)\n",
    "        x = x.to(args.device)\n",
    "        attLSTM.hidden = [hidden.to(args.device) for hidden in attLSTM.init_hidden()]\n",
    "        es, attention_weight, attn_applied = attLSTM(x)\n",
    "        # print(es.size()) [128, 20]\n",
    "\n",
    "        y_hat, y_hat_adv = adversarial(es, true_y)\n",
    "        \n",
    "        loss = args.loss_fn(y_hat, y_hat_adv, true_y)\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        lstm_optimizer.step()## parameter 갱신\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    return attLSTM, adversarial, train_loss\n",
    "\n",
    "\n",
    "def validation(attLSTM,adversarial, partition, args):\n",
    "    valloader = DataLoader(partition['val'],\n",
    "                           batch_size=args.batch_size,\n",
    "                           shuffle=False, drop_last=True)\n",
    "    attLSTM.eval()\n",
    "    adversarial.eval()\n",
    "    \n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(valloader):\n",
    "\n",
    "            true_y = y.squeeze().float().to(args.device)\n",
    "            x = x.to(args.device)\n",
    "\n",
    "            attLSTM.hidden = [attLSTM.to(args.device) for hidden in attLSTM.init_hidden()]\n",
    "\n",
    "            es, attention_weight, attn_applied = attLSTM(x)\n",
    "\n",
    "            y_hat, y_hat_adv = adversarial(es, true_y)\n",
    "\n",
    "            # output_ = torch.where(output1 >= 0.5, 1.0, 0.0)\n",
    "            # output_.requires_grad=True\n",
    "\n",
    "            loss = args.loss_fn(y_hat, y_hat_adv, true_y)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_loss = val_loss / len(valloader)\n",
    "        return attLSTM, adversarial, val_loss\n",
    "\n",
    "\n",
    "def test(attLSTM,adversarial,partition, args):\n",
    "    testloader = DataLoader(partition['test'],\n",
    "                           batch_size=args.batch_size,\n",
    "                           shuffle=False, drop_last=True)\n",
    "    attLSTM.eval()\n",
    "\n",
    "    ACC_metric = 0.0\n",
    "    MCC_metric = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(testloader):\n",
    "\n",
    "            # feature transform\n",
    "            true_y = y.squeeze().float().to(args.device)\n",
    "            x = x.to(args.device)\n",
    "\n",
    "            attLSTM.hidden = [hidden.to(args.device) for hidden in attLSTM.init_hidden()]\n",
    "\n",
    "            es, attention_weight, attn_applied = attLSTM(x)\n",
    "\n",
    "            y_hat, y_hat_adv = adversarial(es, true_y)\n",
    "\n",
    "            output_ = torch.where(y_hat >= 0.0, 1.0, 0.0)\n",
    "\n",
    "            output_.requires_grad = True\n",
    "\n",
    "            ACC_metric += ACC(output_, true_y)\n",
    "            MCC_metric += MCC(output_, true_y)\n",
    "\n",
    "        ACC_metric = ACC_metric / len(testloader)\n",
    "        MCC_metric = MCC_metric / len(testloader)\n",
    "\n",
    "        return ACC_metric, MCC_metric\n",
    "\n",
    "\n",
    "\n",
    "def experiment(partition, args):\n",
    "    attLSTM = args.attLSTM(args.input_dim, args.hid_dim, args.output_dim, args.num_layers, args.batch_size,\n",
    "                           args.dropout, args.use_bn, args.attention_head, args.attn_size,\n",
    "                           activation=\"ReLU\")\n",
    "    adversarial = args.adversarial(args.batch_size, args.hid_dim, args.attn_size)\n",
    "\n",
    "    attLSTM.to(args.device)\n",
    "    adversarial.to(args.device)\n",
    "\n",
    "    if args.optim == 'SGD':\n",
    "        lstm_optimizer = optim.SGD(attLSTM.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'RMSprop':\n",
    "        lstm_optimizer = optim.RMSprop(attLSTM.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'Adam':\n",
    "        lstm_optimizer = optim.Adam(attLSTM.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    else:\n",
    "        raise ValueError('In-valid optimizer choice')\n",
    "\n",
    "    # ===== List for epoch-wise data ====== #\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    # ===================================== #\n",
    "    for epoch in range(args.epoch):\n",
    "        ts = time.time()\n",
    "        attLSTM, adversarial, train_loss = train(attLSTM, adversarial, lstm_optimizer, partition, args)\n",
    "\n",
    "        attLSTM, adversarial, val_loss = validation(attLSTM, adversarial, partition, args)\n",
    "\n",
    "        te = time.time()\n",
    "\n",
    "        ## 각 에폭마다 모델을 저장하기 위한 코드\n",
    "        torch.save(attLSTM.state_dict(), args.split_file_path + '\\\\' + str(epoch) +'_attLSTM' +'.pt')\n",
    "        torch.save(adversarial.state_dict(), args.split_file_path + '\\\\' + str(epoch) +'_adversarial' +'.pt')\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print('Epoch {}, Loss(train/val) {:2.5f}/{:2.5f}. Took {:2.2f} sec'\n",
    "              .format(epoch, train_loss, val_loss, te - ts))\n",
    "\n",
    "    ## val_losses에서 가장 값이 최소인 위치를 저장함\n",
    "    site_val_losses = val_losses.index(min(val_losses)) ## 10 epoch일 경우 0번째~9번째 까지로 나옴\n",
    "    attLSTM = args.attLSTM(args.input_dim, args.hid_dim, args.output_dim, args.num_layers, args.batch_size,\n",
    "                           args.dropout, args.use_bn, args.attention_head, args.attn_size,\n",
    "                           activation=\"ReLU\")\n",
    "    adversarial = args.adversarial(args.batch_size, args.hid_dim, args.attn_size)\n",
    "\n",
    "    attLSTM.to(args.device)\n",
    "    adversarial.to(args.device)\n",
    "\n",
    "\n",
    "    attLSTM.load_state_dict(torch.load(args.split_file_path + '\\\\' + str(site_val_losses) +'_attLSTM'+ '.pt'))\n",
    "    adversarial.load_state_dict(torch.load(args.split_file_path + '\\\\' + str(site_val_losses) +'_adversarial'+ '.pt'))\n",
    "\n",
    "    ACC, MCC = test(attLSTM, adversarial, partition, args)\n",
    "    print('ACC: {}, MCC: {}'.format(ACC, MCC))\n",
    "\n",
    "    with open(args.split_file_path + '\\\\'+ str(site_val_losses)+'Epoch_test_metric' +'.csv', 'w') as fd:\n",
    "        print('ACC: {}, MCC: {}'.format(ACC, MCC), file=fd)\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    result['train_losses'] = train_losses\n",
    "    result['val_losses'] = val_losses\n",
    "    result['ACC'] = ACC\n",
    "    result['MCC'] = MCC\n",
    "\n",
    "    return vars(args), result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====== Random Seed Initialization ====== #\n",
    "seed = 666\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# ========= experiment setting ========== #\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "args.save_file_path = \"C:\\\\Users\\\\USER\\\\JupyterProjects\\\\AdvLSTM\\\\results\"\n",
    "\n",
    "# ====== hyperparameter ======= #\n",
    "args.batch_size = 64\n",
    "\n",
    "args.dropout = 0.15\n",
    "args.use_bn = True\n",
    "args.loss_fn = adv_loss  ## loss function for classification : cross entropy\n",
    "args.optim = 'Adam'\n",
    "args.lr = 0.0005\n",
    "args.l2 = 0.00001 #?\n",
    "args.epoch = 100\n",
    "# ============= model ================== #\n",
    "args.attLSTM = attLSTM\n",
    "args.adversarial = adversarial\n",
    "# ====== att_lstm hyperparameter ======= #\n",
    "\n",
    "args.x_frames = 10\n",
    "args.y_frames = 1\n",
    "args.input_dim = 10\n",
    "args.hid_dim = 10\n",
    "args.output_dim = 1\n",
    "args.attention_head = 1\n",
    "args.attn_size = 10\n",
    "args.num_layers = 1\n",
    "args.attLSTM_x_frames = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss(train/val) 70.93964/69.29726. Took 0.55 sec\n",
      "Epoch 1, Loss(train/val) 70.77098/69.20193. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.57455/69.10251. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.37078/69.00876. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.19193/68.91489. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.02987/68.82022. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.82286/68.72392. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.64463/68.62774. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.47192/68.53207. Took 0.34 sec\n",
      "Epoch 9, Loss(train/val) 69.29696/68.43465. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.09783/68.33858. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.90454/68.25152. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.77487/68.17127. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.51983/68.10105. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.48486/68.03644. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.35212/67.97826. Took 0.34 sec\n",
      "Epoch 16, Loss(train/val) 68.20467/67.92469. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 68.02042/67.88271. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.90396/67.85230. Took 0.34 sec\n",
      "Epoch 19, Loss(train/val) 67.83434/67.83104. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.66456/67.82916. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.50359/67.84438. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 67.31643/67.87284. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 67.22498/67.91911. Took 0.34 sec\n",
      "Epoch 24, Loss(train/val) 67.00336/67.97662. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 66.91618/68.03570. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 66.73313/68.09722. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 66.54799/68.15845. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 66.36184/68.21304. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.37490/68.25726. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.23187/68.30341. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 66.09039/68.34589. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 66.01961/68.38596. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 65.85580/68.41734. Took 0.34 sec\n",
      "Epoch 34, Loss(train/val) 65.75490/68.43556. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 65.78883/68.44442. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.60820/68.44160. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 65.33854/68.42203. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 65.40603/68.38651. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 65.30508/68.33065. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 64.97384/68.25797. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 64.97779/68.16436. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 64.94959/68.05503. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.86265/67.94279. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 64.71558/67.83215. Took 0.34 sec\n",
      "Epoch 45, Loss(train/val) 64.80165/67.72203. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 64.47764/67.61798. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 64.48011/67.51281. Took 0.35 sec\n",
      "Epoch 48, Loss(train/val) 64.23663/67.38532. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.19214/67.23573. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 64.03743/67.08895. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.92438/66.96686. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.82193/66.81120. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.71418/66.70021. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.63865/66.61873. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.64369/66.51292. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.46298/66.44904. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 63.38070/66.45441. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 63.46117/66.37265. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 63.32300/66.35979. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 63.14557/66.30946. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 63.28650/66.28601. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.18526/66.26349. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.15896/66.27878. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 63.14213/66.20606. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 63.03333/66.21043. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 63.02878/66.11250. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.93628/66.21657. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 62.94890/66.13662. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 63.11305/66.11337. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 62.86925/66.12670. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 62.91782/66.10700. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.76676/66.15395. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.79284/66.17859. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 62.72711/66.22393. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 62.55559/66.23637. Took 0.34 sec\n",
      "Epoch 76, Loss(train/val) 62.65281/66.26060. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 62.59866/66.26562. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 62.47438/66.27186. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 62.51962/66.25688. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 62.53389/66.32563. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 62.28432/66.34149. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 62.39038/66.33971. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 62.37315/66.39317. Took 0.34 sec\n",
      "Epoch 84, Loss(train/val) 62.30523/66.40050. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 62.17000/66.40476. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 62.13661/66.43318. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 62.17764/66.49802. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 62.10592/66.47937. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 62.07214/66.53202. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 62.02742/66.52161. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 62.04313/66.56347. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 62.07541/66.58459. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.95770/66.56391. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.85334/66.66614. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.70913/66.64051. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 61.90241/66.64001. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.84703/66.67385. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.77603/66.66187. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.71086/66.70660. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.10010887319501069\n",
      "Epoch 0, Loss(train/val) 70.82435/70.57677. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.64526/70.38238. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.49805/70.16219. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.28044/69.92426. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.14488/69.66908. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.86322/69.38361. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.63697/69.06079. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.42813/68.70626. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.10475/68.31786. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.83644/67.90904. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.56078/67.50552. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.32500/67.10477. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.99609/66.70178. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.74900/66.30413. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.49586/65.97173. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.16147/65.67081. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.98803/65.40852. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.63499/65.17570. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.44575/64.97401. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.26851/64.80168. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.24582/64.64633. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.95886/64.51472. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.88008/64.40156. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.65146/64.30312. Took 0.34 sec\n",
      "Epoch 24, Loss(train/val) 65.56040/64.22823. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.37121/64.17315. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.33327/64.13734. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.24035/64.09849. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.00103/64.06222. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.89841/64.02151. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.80668/63.96905. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.71638/63.91163. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.58978/63.83986. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.56092/63.76663. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 64.46590/63.68757. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.33454/63.60765. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 64.35431/63.53117. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.20118/63.45261. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.23195/63.37216. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.02875/63.29177. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 64.13310/63.21838. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.98147/63.15722. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.92811/63.11843. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.85745/63.08285. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.04843/63.02884. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.73616/62.97446. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.61790/62.92448. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 63.69916/62.90028. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 63.72774/62.85815. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.72599/62.84706. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.55530/62.82363. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.65469/62.80036. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.48827/62.76897. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 63.53893/62.74334. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.60596/62.72955. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 63.46895/62.69161. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.43450/62.67016. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.41186/62.65018. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 63.33992/62.64523. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.31396/62.63226. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.27497/62.62295. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 63.18887/62.61559. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.14952/62.59829. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.22947/62.59072. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.14021/62.57061. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.08435/62.53698. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 63.09205/62.55501. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 63.12762/62.50366. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 63.13976/62.57237. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 63.02956/62.47451. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 63.07161/62.59232. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.99198/62.38871. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 62.98124/62.61315. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.87412/62.30482. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 62.86402/62.58500. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 63.02821/62.36399. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 62.99571/62.47254. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.78172/62.51992. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 62.95194/62.56178. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.99746/62.21235. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.69700/62.49495. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.91224/62.31409. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 62.77507/62.46876. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 62.89408/62.52122. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.91474/62.30721. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.63526/62.42500. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 62.76637/62.26738. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 62.77063/62.49947. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 62.74772/62.22506. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 62.52275/62.22887. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 62.64942/62.38876. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 62.58561/62.15150. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 62.66896/62.45634. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 62.72205/62.18258. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 62.49398/62.21068. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 62.60531/62.36005. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 62.53614/62.22538. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 62.56926/62.25786. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 62.50749/62.26983. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 62.41414/62.37906. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.1229526932416184\n",
      "Epoch 0, Loss(train/val) 71.20957/70.07448. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.93866/69.75893. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.65959/69.42959. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.38901/69.08122. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.02628/68.70532. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.71960/68.28126. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.26859/67.79633. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.82841/67.25362. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.30382/66.67664. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.95256/66.08694. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.57986/65.52690. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.18023/65.00198. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.75156/64.52148. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.40228/64.08608. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.10089/63.69753. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.84778/63.34934. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.59293/63.03363. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.29832/62.72491. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.01235/62.41500. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.94269/62.11887. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.67066/61.82757. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.44614/61.51751. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.36347/61.19442. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.91600/60.85550. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.71076/60.50935. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.55167/60.18727. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.23621/59.88602. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.03313/59.58023. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.78319/59.26398. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.41982/58.89160. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.04012/58.42239. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 61.55117/57.87774. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.06932/57.33650. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.69986/56.92855. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.12877/56.60225. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.99267/56.35411. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.69949/56.18163. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 59.45662/56.08236. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.07574/56.01743. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.99528/55.95692. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.98285/55.90658. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 58.84902/55.85104. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 58.71629/55.81995. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.63813/55.76899. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.58024/55.73459. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.38545/55.78361. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.40732/55.68356. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.31984/55.68597. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.28633/55.67217. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.04247/55.65606. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.20019/55.63832. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.10112/55.56134. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.88872/55.56443. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 57.95602/55.55177. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.81509/55.53320. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 57.71588/55.53764. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.64018/55.50697. Took 0.34 sec\n",
      "Epoch 57, Loss(train/val) 57.74393/55.45619. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.55016/55.41611. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.56740/55.40849. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 57.46307/55.42501. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.44686/55.40676. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.41650/55.42918. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 57.38038/55.34642. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.32876/55.39391. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.28835/55.34327. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.32165/55.38084. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.20879/55.37392. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.15411/55.31619. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.24178/55.33070. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.09737/55.27307. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.09145/55.29180. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.07707/55.27893. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.89146/55.28669. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.16362/55.18013. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.92436/55.12069. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.05901/55.08980. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.84998/55.16183. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 56.89330/55.17051. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.68285/55.13923. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.87687/55.06204. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.77392/55.18966. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.69676/55.04976. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.69057/55.10325. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.77811/55.05548. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.61731/55.07448. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.62546/54.99694. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.58482/55.11824. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.63764/54.99375. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 56.60348/55.05062. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.49861/54.99677. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.47062/55.01930. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 56.49802/55.00478. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.30130/54.95358. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.31275/54.92793. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.42081/54.95114. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 56.37890/54.93005. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.45542/54.95018. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.21564/54.89122. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.37176/54.86009. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.0905982365507463\n",
      "Epoch 0, Loss(train/val) 70.72403/69.72995. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.28477/69.59214. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.84272/69.47566. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.35722/69.36544. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.85850/69.23061. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.33267/69.00589. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.78403/68.73205. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.11908/68.42203. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 66.48635/68.09242. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 65.85498/67.75266. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 65.13587/67.41173. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 64.40020/67.07094. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 63.73815/66.72620. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 62.99008/66.37273. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 62.31872/65.98251. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 61.82907/65.56750. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 61.30069/65.14194. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 60.77270/64.71275. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 60.22362/64.26419. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 59.92019/63.79139. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 59.51733/63.32479. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 59.10222/62.89054. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 58.69766/62.51326. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 58.11485/62.15382. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 57.69711/61.78999. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 57.52859/61.43714. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 57.33284/61.12360. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 56.93774/60.83161. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 56.95342/60.58035. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 56.71408/60.34077. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 56.58677/60.12334. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 56.47308/59.93707. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 56.44052/59.78031. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 56.26498/59.63990. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 56.24152/59.51854. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 56.15866/59.41370. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 56.07658/59.31873. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 55.91791/59.22948. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 55.97593/59.13615. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 55.80797/59.05441. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 55.79902/58.97495. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 55.74839/58.91472. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 55.68635/58.84541. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 55.68573/58.77093. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 55.51899/58.69668. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 55.40495/58.62592. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 55.47378/58.54090. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 55.35353/58.47005. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 55.21833/58.42434. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 55.15316/58.39613. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 55.12055/58.34639. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 55.12722/58.28193. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 54.92271/58.24337. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 55.01948/58.21167. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 54.74798/58.18399. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 54.80814/58.12291. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 54.67659/58.08324. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 54.68856/58.04323. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 54.53496/57.97042. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 54.47998/57.91332. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 54.45467/57.83116. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 54.25955/57.73768. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 54.20808/57.64494. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 54.11468/57.56711. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 54.12675/57.47524. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 53.99415/57.39360. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 53.89563/57.32326. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 53.96846/57.23302. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 53.75328/57.22256. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 53.58590/57.15556. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 53.60709/57.13142. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 53.49390/57.07628. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 53.32979/57.05773. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 53.42093/57.01002. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 53.37143/56.94472. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 53.17974/56.89965. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 53.20134/56.88964. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 52.95168/56.83634. Took 0.34 sec\n",
      "Epoch 78, Loss(train/val) 53.12769/56.78292. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 53.09122/56.74402. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 52.78594/56.66837. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 52.86241/56.58789. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 52.77968/56.50455. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 52.82533/56.44209. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 52.62722/56.34721. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 52.45806/56.28471. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 52.73846/56.43408. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 52.40016/56.20662. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 52.37311/56.28915. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 52.29361/56.13346. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 52.30808/56.06627. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 52.36245/56.25401. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 52.25613/56.14068. Took 0.35 sec\n",
      "Epoch 93, Loss(train/val) 52.11486/56.06873. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 52.16496/56.09353. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 52.06167/56.21133. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 52.28119/55.90226. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 52.01751/55.86345. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 52.07434/56.19947. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 51.93731/56.13054. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.013900245738365579\n",
      "Epoch 0, Loss(train/val) 69.92203/69.29330. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.63671/69.17348. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.36657/69.01254. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.02653/68.79833. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.65235/68.52151. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.17817/68.20187. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.63265/67.86449. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 67.03630/67.54274. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 66.61338/67.25871. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.24630/67.00340. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.03336/66.78004. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 65.84782/66.60365. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.52101/66.43935. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.43783/66.31277. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.23413/66.20545. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.18294/66.12704. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.92910/66.06158. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.86761/66.00975. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.79545/65.96646. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.68535/65.93275. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.54070/65.90772. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.51541/65.88680. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.43629/65.87254. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.11590/65.86146. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 64.30415/65.85091. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.97894/65.83434. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.04190/65.80931. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.96937/65.78162. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.84523/65.75366. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.99034/65.72717. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.85021/65.69415. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.65460/65.66545. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.64058/65.64065. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.47271/65.61757. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.50969/65.59456. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.44518/65.57572. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.44931/65.56253. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.36127/65.55161. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.54193/65.54179. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.15792/65.52718. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 63.27413/65.50340. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.04631/65.44799. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.03893/65.37460. Took 0.35 sec\n",
      "Epoch 43, Loss(train/val) 63.02429/65.33863. Took 0.35 sec\n",
      "Epoch 44, Loss(train/val) 63.17430/65.33302. Took 0.35 sec\n",
      "Epoch 45, Loss(train/val) 63.06860/65.33592. Took 0.34 sec\n",
      "Epoch 46, Loss(train/val) 62.89515/65.34335. Took 0.34 sec\n",
      "Epoch 47, Loss(train/val) 62.96514/65.35362. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 62.84168/65.36617. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.68219/65.37307. Took 0.34 sec\n",
      "Epoch 50, Loss(train/val) 62.90187/65.34894. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.71624/65.32767. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.68577/65.29806. Took 0.34 sec\n",
      "Epoch 53, Loss(train/val) 62.71690/65.23827. Took 0.34 sec\n",
      "Epoch 54, Loss(train/val) 62.52004/65.18471. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 62.46388/65.14407. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 62.50603/65.13848. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 62.55513/65.14331. Took 0.34 sec\n",
      "Epoch 58, Loss(train/val) 62.33299/65.16017. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 62.56235/65.18405. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 62.28856/65.19934. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.32537/65.19779. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 62.26811/65.18762. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 62.17829/65.17215. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 62.04478/65.16508. Took 0.34 sec\n",
      "Epoch 65, Loss(train/val) 61.94537/65.12934. Took 0.34 sec\n",
      "Epoch 66, Loss(train/val) 62.05098/65.14574. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.94152/65.11124. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 62.05935/65.11878. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 61.81089/65.09144. Took 0.34 sec\n",
      "Epoch 70, Loss(train/val) 61.91845/65.08504. Took 0.34 sec\n",
      "Epoch 71, Loss(train/val) 61.98192/65.09820. Took 0.34 sec\n",
      "Epoch 72, Loss(train/val) 61.89595/65.09771. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 61.78226/65.11070. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.48954/65.08969. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 61.73704/65.08365. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.58287/65.08880. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 61.64165/65.05816. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.45149/65.08914. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.49542/65.05515. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.43168/65.03454. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.47290/65.02217. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.37347/65.03088. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.35015/65.01855. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 61.30093/64.98451. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 61.17830/64.98347. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.11603/64.98874. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.08802/64.96231. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.15967/64.93731. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.02571/64.93346. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.99079/64.91740. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.77392/64.92390. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.94263/64.89096. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.89822/64.90383. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.65260/64.90714. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.65995/64.86685. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.56771/64.89909. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.49004/64.86620. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.47336/64.86232. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.48052/64.84982. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.13244804941089508\n",
      "Epoch 0, Loss(train/val) 70.26158/69.97195. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.01900/69.67924. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.69496/69.33154. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.31554/68.91356. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 68.94605/68.41253. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.41026/67.80737. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.83519/67.11548. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.27529/66.34359. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 66.52553/65.52366. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 65.92647/64.72517. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.23399/64.03773. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 64.75967/63.45847. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 64.24775/63.00719. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 63.94814/62.60684. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 63.64372/62.25993. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.25605/61.96530. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 62.97798/61.70963. Took 0.34 sec\n",
      "Epoch 17, Loss(train/val) 62.74216/61.46852. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 62.48594/61.26269. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.46882/61.09525. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.37970/60.96717. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.01560/60.85815. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.89562/60.76910. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.86358/60.71187. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.80242/60.69540. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.83893/60.70913. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.65452/60.77297. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.57089/60.83378. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 61.38910/60.90408. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.44243/60.99175. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 61.32154/61.04416. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.13121/61.06516. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.08659/61.09790. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.12231/61.15690. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.97217/61.21401. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.97664/61.24896. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.03713/61.28516. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.82505/61.35467. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.77293/61.38288. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.82686/61.42035. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.55210/61.48519. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.65467/61.56271. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.51302/61.63407. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.56841/61.66320. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 60.56377/61.67019. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.38846/61.69946. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.33881/61.76966. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.33133/61.80095. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.07611/61.81618. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.24794/61.83601. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.17542/61.87859. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.21206/61.89560. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.15530/61.91215. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.06028/61.90932. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.08796/61.90217. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.03808/61.92767. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.01491/61.93200. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.92136/61.94120. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.92548/61.93824. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.80586/61.95702. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.77984/61.98863. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.92612/62.00386. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.78184/62.00550. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.67765/61.98990. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.61710/61.98957. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.60457/61.96693. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.62669/61.94469. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.56928/61.95658. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.64298/61.94384. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.48750/61.93445. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.54214/61.93938. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.31812/61.93091. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.50035/61.89889. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.39806/61.89186. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.31782/61.87027. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.21601/61.86447. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.33279/61.83709. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.20204/61.81005. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.16179/61.79345. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.09801/61.75384. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 59.02148/61.73205. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.95970/61.67406. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.94668/61.63327. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.78004/61.60666. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.85061/61.55156. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.64315/61.47872. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.48796/61.40540. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.59062/61.33680. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.56134/61.24892. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.37956/61.19794. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.23548/61.09311. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.25315/61.02018. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.20956/60.93134. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.11004/60.91478. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.05489/60.79344. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.09059/60.73419. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 57.92138/60.65116. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.96275/60.56604. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.72149/60.51820. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.82317/60.50624. Took 0.32 sec\n",
      "ACC: 0.421875, MCC: -0.19856113239375686\n",
      "Epoch 0, Loss(train/val) 70.73644/71.39594. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.55842/71.35023. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.45450/71.30072. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.27782/71.24699. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.08242/71.19192. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.95524/71.13359. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.83395/71.06334. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.59504/70.98434. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.42449/70.90505. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.25961/70.80614. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.13239/70.70037. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.02290/70.58601. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.82862/70.45650. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.69461/70.32058. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.48933/70.17352. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.36116/70.01496. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.21294/69.83644. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.05188/69.63733. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.87229/69.42760. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.66507/69.21306. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.55220/69.00760. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 67.34473/68.81318. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.26849/68.63101. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.09054/68.45529. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.97893/68.28387. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.85381/68.12254. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.80694/67.96803. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.64141/67.82455. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 66.45229/67.68286. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.49911/67.54356. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.30772/67.39313. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 66.15862/67.24994. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 65.96186/67.10404. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.83754/66.97021. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.86690/66.84217. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.60309/66.71851. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.58820/66.60875. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 65.52919/66.50991. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 65.49621/66.41261. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 65.41740/66.33267. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 65.15735/66.25793. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 65.31245/66.18533. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 65.18870/66.11751. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 65.32997/66.05135. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 65.02612/65.98727. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 65.05761/65.92565. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.86021/65.86103. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 64.90437/65.80961. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.89197/65.75343. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.77982/65.70519. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 64.89909/65.66003. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 64.80378/65.61429. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 64.66129/65.58434. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 64.62196/65.56696. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 64.60130/65.54845. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 64.52361/65.53313. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 64.38358/65.52200. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 64.46941/65.51945. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 64.41256/65.52748. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 64.38105/65.53953. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 64.43624/65.54196. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 64.28063/65.56445. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 64.18931/65.55965. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 64.09784/65.57531. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 64.06519/65.63159. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 64.17424/65.70036. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 63.91723/65.80376. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 63.96674/65.85963. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 63.84466/65.94784. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 63.85211/65.94294. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 63.87213/65.93002. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 63.70652/65.94308. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 63.64730/65.96431. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 63.61666/65.94339. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 63.52141/65.91990. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 63.59229/65.88493. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 63.45355/65.89614. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 63.30594/65.87505. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 63.44156/65.85965. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 63.43291/65.88149. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 63.26286/65.84566. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 63.24637/65.84922. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 63.23146/65.84408. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 63.09316/65.80412. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 63.20827/65.76563. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 63.10563/65.74471. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 63.11205/65.76714. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 63.01332/65.78010. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 62.80161/65.79176. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 62.91020/65.81751. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 62.65063/65.81873. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 62.67551/65.75081. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 62.84613/65.77653. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 62.67311/65.79364. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 62.57871/65.79121. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 62.78922/65.82787. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 62.71079/65.80264. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 62.52046/65.85056. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 62.58441/65.82391. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 62.52782/65.97013. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.05790766725522051\n",
      "Epoch 0, Loss(train/val) 70.62489/69.77111. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.34669/69.61868. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.16666/69.46941. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 69.80854/69.32545. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.63009/69.16201. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.30512/68.97327. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.02597/68.78309. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.79241/68.58804. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.52947/68.40423. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.24099/68.23346. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.99871/68.09450. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.67918/68.00843. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.34184/67.92201. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.00465/67.79927. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.76705/67.66677. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.40517/67.50064. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.18971/67.35230. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.73637/67.21776. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.51314/67.06478. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 65.05596/66.94543. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.71528/66.79488. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.50818/66.56119. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.21137/66.37228. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.96378/66.09989. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.72436/65.81792. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 63.39452/65.56950. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.17461/65.37769. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.89861/65.22870. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 62.65230/65.02852. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.66518/64.83520. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.33983/64.71822. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 61.99988/64.69422. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.79729/64.56232. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.58941/64.35683. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.39835/64.46172. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 61.30926/64.28057. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 61.05061/64.18211. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 60.82021/64.17349. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.63218/63.95360. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.54814/64.08587. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.34079/63.95506. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.12370/63.79827. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.04037/63.82139. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.98543/63.74229. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.63386/63.61436. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.55422/63.58843. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.40366/63.57688. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.13214/63.59518. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.13316/63.48943. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.02728/63.52776. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.84201/63.48481. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.78001/63.49412. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.56225/63.48637. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 58.49176/63.45366. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.21642/63.43524. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 58.12917/63.40171. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.17882/63.35919. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.88030/63.32143. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 57.85511/63.23927. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 57.76180/63.23095. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 57.69661/63.14305. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.67398/63.17695. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 57.55364/63.11213. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 57.55383/63.08020. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 57.51824/63.05941. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.39181/63.03678. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.26957/63.07787. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.28069/62.95881. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.16594/62.98705. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.10854/63.01080. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.11414/62.96449. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.00703/62.95484. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.80220/63.01737. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.82794/62.93237. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.88736/63.03836. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.79265/63.00070. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 56.70578/62.97651. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.78308/63.00352. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.64341/63.05770. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 56.42956/63.08816. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.42824/63.07547. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.37903/63.06159. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.44859/63.09142. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.24241/63.11411. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.28360/63.10983. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.15352/63.13314. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.29553/63.21309. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.00747/63.24335. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.02457/63.27974. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.03870/63.28076. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.11763/63.36058. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 55.90985/63.39346. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.99122/63.38374. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.81231/63.43105. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.82210/63.49646. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 55.78783/63.55301. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.71165/63.55675. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.74187/63.53493. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.63053/63.65478. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.58006/63.61291. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.048507125007266595\n",
      "Epoch 0, Loss(train/val) 70.81981/72.00800. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.48824/71.76368. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.09787/71.50043. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.74528/71.21920. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.36987/70.91766. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.91474/70.59809. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.51194/70.26614. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.13342/69.93124. Took 0.34 sec\n",
      "Epoch 8, Loss(train/val) 67.67500/69.59547. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.25670/69.25944. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.89912/68.91859. Took 0.34 sec\n",
      "Epoch 11, Loss(train/val) 66.46378/68.57964. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.10709/68.21456. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.79006/67.81300. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.25275/67.36461. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.95585/66.85383. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.47691/66.30044. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.03020/65.78999. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.57701/65.30396. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.15297/64.85851. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.86046/64.45238. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 62.38971/64.10098. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.00186/63.73176. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.65177/63.39684. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.37676/63.12707. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 61.05745/62.86753. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.90544/62.66936. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.54980/62.56100. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.43301/62.48392. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.29322/62.39240. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.16644/62.32594. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.01032/62.30079. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.82654/62.26116. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 59.95653/62.22371. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.73096/62.18137. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.44910/62.13552. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.41851/62.08389. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 59.37300/62.04084. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.28727/62.02420. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.30825/61.99443. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.01152/61.99440. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.05673/61.96852. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.87644/61.95460. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 58.99674/61.93245. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 58.79840/61.98160. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 58.80493/61.94230. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.74940/61.97280. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.66559/61.94467. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 58.61775/61.99201. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 58.45745/61.99343. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.49320/62.00928. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.31931/61.92925. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.30128/61.98714. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.22644/61.89715. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.19315/61.90988. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.01140/61.96799. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.95784/61.97416. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.89013/62.04186. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.05611/61.80806. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 57.97637/61.99823. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.81927/62.01519. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.79422/62.01594. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 57.77214/61.86946. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 57.65313/61.97113. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.67472/61.97480. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.52060/61.95359. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.60946/61.93788. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.54073/61.94368. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 57.37447/61.90075. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.31337/61.86666. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.34934/61.92641. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.24131/61.86963. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.35168/61.84904. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 57.38144/61.87769. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.10703/61.88720. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.21463/61.91046. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 57.12826/61.83902. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.97618/61.81446. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.98803/61.82809. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.16390/61.81110. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.02240/61.80981. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.92705/61.78977. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.12199/61.79046. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.84093/61.77747. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.90596/61.75943. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.72014/61.72898. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.80592/61.71978. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.81602/61.69345. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.73360/61.69384. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.64915/61.68965. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.57190/61.67463. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.62910/61.63921. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.49090/61.64424. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.42476/61.58718. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.48786/61.62434. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 56.33392/61.58292. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.32152/61.52732. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.41667/61.49833. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.22667/61.50667. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 56.22909/61.42369. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.038395331411533284\n",
      "Epoch 0, Loss(train/val) 71.07448/71.16270. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.83485/70.99165. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.64618/70.82030. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.41185/70.63818. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.17306/70.43970. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.93345/70.21359. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.65698/69.95319. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.32157/69.65380. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.05152/69.31628. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.72448/68.95502. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.39347/68.58725. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.98648/68.19537. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.50489/67.78541. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.13038/67.38630. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.72605/67.01501. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.37499/66.67364. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.82620/66.35226. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.38353/66.02620. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.02780/65.67027. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.55528/65.24500. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.02475/64.70848. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.35233/64.04929. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.81959/63.39460. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 62.40815/62.86864. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 61.86646/62.49946. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.55368/62.26058. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.33751/62.07819. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.20259/61.91901. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.91849/61.80533. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 60.81006/61.71223. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 60.63802/61.63235. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.60467/61.55531. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.32269/61.47559. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.28702/61.40358. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.08190/61.32496. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.03445/61.23447. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.78918/61.11826. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.62437/61.05577. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.56620/60.99646. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.36530/60.95196. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.36564/60.89306. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.08152/60.76718. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.13820/60.61342. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.99886/60.58670. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.91882/60.44028. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 58.84357/60.32891. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.55057/60.07895. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.42411/60.05054. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.37536/59.75705. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.43477/59.55061. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.20013/59.51431. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 58.10711/59.32449. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 58.04787/59.48961. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.00897/58.97168. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 57.88798/59.09225. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 57.79165/58.96738. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 57.87561/58.71438. Took 0.34 sec\n",
      "Epoch 57, Loss(train/val) 57.75106/58.73102. Took 0.34 sec\n",
      "Epoch 58, Loss(train/val) 57.68157/58.86394. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 57.47169/58.64419. Took 0.34 sec\n",
      "Epoch 60, Loss(train/val) 57.48091/58.87432. Took 0.34 sec\n",
      "Epoch 61, Loss(train/val) 57.46381/58.54073. Took 0.34 sec\n",
      "Epoch 62, Loss(train/val) 57.27141/58.69160. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.30886/58.37134. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.32113/58.41266. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.23919/58.37813. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.13189/58.37870. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.06266/58.40085. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.13021/58.37606. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 56.90942/58.45243. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.09773/58.33945. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 56.89746/58.39983. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.87582/58.39272. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.80081/58.43898. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.71088/58.45108. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.74920/58.42107. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 56.61065/58.47076. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.66737/58.60793. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.63018/58.40434. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.60311/58.46578. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.65501/58.46895. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.38880/58.44249. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.33788/58.40111. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.37845/58.36361. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 56.28411/58.47211. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.36672/58.48860. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 56.27757/58.34567. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 56.19293/58.47887. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.12875/58.39581. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.04351/58.36422. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.18295/58.30024. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.96940/58.23378. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.92193/58.26544. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.98413/58.41396. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.78718/58.14760. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.93102/57.99483. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.67458/58.48347. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.72319/58.78807. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.64993/57.64627. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.80324/58.28653. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.17688728441930626\n",
      "Epoch 0, Loss(train/val) 70.57208/70.96427. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.40950/70.78690. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.20358/70.60946. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.02822/70.42686. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.84406/70.24168. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.65690/70.05414. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.44225/69.85836. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.32425/69.65799. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.09599/69.45101. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.91595/69.23117. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 68.68757/68.99612. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.47089/68.74149. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.22632/68.47142. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 67.92905/68.18571. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 67.74301/67.88541. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 67.56825/67.57954. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.29568/67.25931. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 67.01013/66.91925. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 66.74648/66.55785. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.44103/66.16750. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.12996/65.75247. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.76106/65.32827. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.64358/64.93640. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.33015/64.59336. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.01621/64.29627. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 64.89300/64.04406. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 64.67002/63.82900. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.55179/63.63836. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 64.46885/63.46152. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 64.28727/63.29754. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 64.04159/63.13812. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.10015/63.00497. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.00461/62.88612. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.97485/62.77855. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 63.73678/62.67708. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.61841/62.57009. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.56739/62.46832. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.46485/62.37301. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.30451/62.29102. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 63.26330/62.21502. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.01390/62.14199. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.11434/62.08702. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 62.95760/62.01701. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.87964/61.89585. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.66124/61.79131. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 62.53830/61.65553. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 62.50097/61.57648. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.33337/61.45795. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.28011/61.36977. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 62.05988/61.34244. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.09284/61.28100. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 62.05314/61.15750. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 61.94286/61.11953. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.83647/61.15245. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.91447/61.04320. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.75645/61.01427. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.53860/60.91508. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 61.62164/60.88305. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.48519/60.85570. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.49249/60.78860. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.52208/60.73234. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 61.41456/60.64608. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 61.38915/60.64767. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.21012/60.65997. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.27747/60.53116. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 61.23266/60.45528. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 61.08891/60.46331. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.07338/60.38836. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.10911/60.39589. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.00100/60.30017. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.93475/60.29626. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.86681/60.23434. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.82202/60.21352. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.89140/60.15998. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.87514/60.10031. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.83047/60.11467. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.83640/59.99426. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.77610/60.00286. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.64064/59.95894. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.64005/59.83590. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.60704/59.83685. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.54404/59.72686. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.37697/59.61433. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.56249/59.60869. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.40584/59.56809. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.52657/59.50282. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.51586/59.47076. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.35957/59.40324. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 60.43494/59.44841. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 60.45113/59.37606. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.21839/59.33046. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 60.30748/59.29278. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 60.15891/59.28094. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 60.19892/59.31569. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 60.08411/59.21164. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.08143/59.23952. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.13675/59.20559. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 60.14787/59.26996. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.11840/59.18130. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 60.06161/59.20762. Took 0.31 sec\n",
      "ACC: 0.578125, MCC: 0.1536230967599611\n",
      "Epoch 0, Loss(train/val) 70.44169/70.26891. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.32163/70.19759. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.20764/70.12614. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.11002/70.05971. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.98894/70.00539. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.86949/69.94935. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.77134/69.89742. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.60953/69.83875. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.48591/69.76987. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 69.30362/69.69009. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 69.22731/69.60487. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.02127/69.52010. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 68.87403/69.43436. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.65335/69.35064. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.45899/69.26672. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.28994/69.18787. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 68.01462/69.12204. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.84029/69.07195. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 67.60080/69.03086. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.37783/68.99386. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.25269/68.96111. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 66.97869/68.92657. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 66.81176/68.89938. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.61340/68.88200. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 66.48534/68.86427. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.32105/68.84844. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 66.31264/68.81992. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.18378/68.77889. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 65.99534/68.74448. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.84395/68.72107. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.78721/68.69962. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 65.61743/68.65422. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.54987/68.61407. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 65.51678/68.58099. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 65.37664/68.54939. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.39512/68.50119. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.26577/68.46452. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 65.10149/68.44465. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 65.09224/68.41103. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 65.13304/68.36886. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 64.89918/68.29304. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.86902/68.22738. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.89631/68.22223. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 64.82218/68.18905. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.61984/68.12386. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.53389/68.03935. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 64.55049/67.93678. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 64.41797/67.85886. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.46322/67.81801. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 64.38802/67.80350. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 64.34363/67.73624. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 64.15183/67.72211. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 64.13851/67.66044. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 64.12862/67.62084. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 64.09093/67.53383. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 64.00105/67.44853. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 63.82097/67.46043. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 63.69688/67.41310. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.84890/67.30484. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.70163/67.28643. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 63.56622/67.15875. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 63.44858/66.98769. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 63.50547/66.91779. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 63.40960/66.88797. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 63.33479/66.76833. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 63.08651/66.70346. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 63.11635/66.67343. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 63.05268/66.60319. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 62.98130/66.65758. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.79906/66.49160. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 62.79095/66.55278. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.70228/66.44301. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.61844/66.35658. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.62273/66.34786. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 62.47870/66.32413. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.57607/66.19250. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.33181/66.13182. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.38693/66.12482. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 62.33006/66.06803. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 62.21117/66.07069. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 62.14637/65.99443. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.06684/65.93221. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 61.97882/65.92822. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.97093/65.89667. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 61.92016/65.85499. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.85428/65.85286. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.58564/65.80393. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.45865/65.79343. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.61521/65.78452. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 61.51439/65.75885. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 61.36448/65.74286. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.36730/65.77007. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 61.43728/65.76031. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 61.09100/65.71719. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.31219/65.73995. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 61.09083/65.74831. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.99724/65.76601. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.92103/65.70818. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.78777/65.65482. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 60.75020/65.70868. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.02757337634153148\n",
      "Epoch 0, Loss(train/val) 70.06408/70.32841. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.92355/70.24673. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.79069/70.16272. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.62288/70.07720. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.50828/69.98534. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.36232/69.88937. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.23253/69.78291. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.08037/69.67206. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.95072/69.55640. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.74073/69.42672. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.58579/69.28138. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.39723/69.12073. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.20634/68.94160. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.96954/68.75015. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.73614/68.54033. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.50255/68.30479. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.16323/68.04374. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 66.84407/67.74761. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 66.50978/67.41872. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.09304/67.08995. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.83741/66.75923. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.59284/66.44492. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.19091/66.17136. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 65.05419/65.94537. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.80894/65.79071. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.63130/65.66293. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.51667/65.56040. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 64.34466/65.47295. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.17344/65.40472. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.89990/65.34433. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 63.87921/65.29253. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 63.74620/65.24489. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.66214/65.20734. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.59792/65.17719. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.48411/65.15156. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.56630/65.12158. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.32151/65.09442. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.30394/65.06875. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.07928/65.04252. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.09170/65.02582. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.19231/65.00944. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 62.96798/65.00895. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.99231/65.01665. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.97000/65.02115. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.94733/65.02319. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.76568/65.03313. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.88570/65.04281. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.66011/65.05058. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.75314/65.05983. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 62.69104/65.07008. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.64542/65.08558. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.66840/65.10685. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.45262/65.15210. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.46504/65.20113. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.59496/65.22568. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 62.38833/65.23220. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.13372/65.24586. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.14172/65.26944. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.25829/65.29000. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.21036/65.30510. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.16369/65.32477. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.16048/65.32362. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.16250/65.32556. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.00548/65.34874. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.03605/65.36742. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.93941/65.37913. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.85507/65.39306. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.80438/65.44092. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 61.78559/65.46162. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.80347/65.44018. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.78599/65.44019. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 61.88974/65.47109. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.73567/65.49220. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 61.73807/65.49239. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.79783/65.48724. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 61.69122/65.48721. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 61.67206/65.47467. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.79151/65.48381. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 61.44310/65.47936. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 61.65336/65.47271. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 61.38192/65.49085. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.32210/65.49466. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 61.51706/65.50560. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 61.52538/65.52821. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 61.53702/65.54165. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 61.38560/65.52257. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.43796/65.51579. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.39697/65.49670. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.36369/65.50631. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 61.39825/65.51730. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 61.19945/65.51588. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.28531/65.51849. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 61.24979/65.53949. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.19829/65.54189. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.31636/65.52955. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.21476/65.52255. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.17694/65.51965. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.09497/65.51356. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.21653/65.50086. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.01227/65.51319. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.1559849013011475\n",
      "Epoch 0, Loss(train/val) 71.50506/72.50310. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.23685/72.42677. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.94221/72.35686. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.71273/72.29316. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.44284/72.23788. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.18181/72.18114. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.87057/72.10955. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 69.61759/72.02224. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.28362/71.91542. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.98654/71.78409. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 68.73835/71.62711. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.32275/71.43929. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.94779/71.20238. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 67.53603/70.90121. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 67.11738/70.52980. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.53199/70.09651. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.11274/69.65804. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 65.62807/69.26167. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 65.14850/68.91949. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 64.85277/68.60778. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 64.53583/68.34660. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.14303/68.14724. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.98115/67.97127. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 63.65063/67.80347. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.44185/67.64165. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 63.16917/67.51552. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 62.93218/67.39980. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.86965/67.29636. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 62.58833/67.18723. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.37579/67.08133. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.26769/66.98350. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.17496/66.89791. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.82256/66.82829. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.74433/66.77057. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.51579/66.71962. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 61.46259/66.67828. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.49174/66.64046. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.26486/66.60336. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.12821/66.56460. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 60.98414/66.51361. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 60.84452/66.45769. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 60.66912/66.40479. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.51896/66.31870. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.43029/66.17770. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 60.11731/65.98840. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 60.03319/65.74931. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.82693/65.48169. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 59.53831/65.19401. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 59.41337/64.90854. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 59.41392/64.63570. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.17147/64.34700. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.20079/64.10666. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.88695/63.95672. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.91610/63.79189. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 58.78388/63.68209. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 58.87328/63.54974. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.83817/63.50218. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 58.68082/63.36190. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 58.69479/63.26361. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 58.74248/63.23458. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.64769/63.15128. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.58571/63.17431. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.46366/63.08673. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 58.40609/63.08923. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.51888/63.00446. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 58.32246/63.01222. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.39680/62.94144. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 58.31658/62.88248. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 58.39920/62.76212. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.28945/62.75511. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 58.08747/62.71486. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.15025/62.67061. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.16981/62.58062. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 58.12686/62.56190. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 58.13884/62.49929. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.05693/62.37561. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.89152/62.24394. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 57.89138/62.20566. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.80969/62.06704. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 57.98196/62.08685. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 57.78257/62.00708. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.88194/62.04212. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.68777/61.98415. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.69105/62.08707. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.65442/62.08058. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.59734/62.11143. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 57.55739/62.08606. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.52131/62.10699. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 57.45824/62.03871. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 57.43349/62.11036. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.41297/62.09330. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.28282/62.12912. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.37044/62.09219. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.32344/62.15662. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.23741/62.12072. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 57.35563/62.07095. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 57.31440/62.15225. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.17029/62.15484. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.04875/62.12969. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.14804/62.13571. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.014274868079616495\n",
      "Epoch 0, Loss(train/val) 71.05899/70.49101. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.87653/70.29482. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.73648/70.08351. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.55735/69.86143. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.41041/69.63857. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.23813/69.41181. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.06558/69.18427. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 69.95339/68.95366. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.74084/68.71695. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.56488/68.46804. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.33490/68.21271. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.10621/67.94305. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.87987/67.66248. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.59071/67.38351. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.27285/67.09657. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 68.00209/66.81964. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.77506/66.57382. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 67.49093/66.35822. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.26673/66.18814. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 67.05344/66.06982. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 66.71371/65.95844. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.52575/65.85053. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.30845/65.74886. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 65.99702/65.65059. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.83941/65.54008. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 65.65332/65.43096. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 65.37798/65.33168. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.16425/65.23307. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 64.88994/65.13167. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.70210/65.01884. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 64.60702/64.90637. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.36207/64.79974. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.25830/64.70202. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.03882/64.64085. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.84188/64.59928. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.67214/64.55445. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.69399/64.53535. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.59574/64.51496. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.51390/64.49303. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.49677/64.46723. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.27479/64.44946. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.22644/64.43608. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.25598/64.41900. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 63.07400/64.41883. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.77364/64.42159. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.86805/64.41495. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.83940/64.40974. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.70612/64.40773. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 62.47354/64.41327. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.55322/64.40995. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 62.51469/64.38567. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 62.32699/64.33879. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.26396/64.31063. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.28281/64.30187. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.30643/64.23885. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 62.31930/64.19306. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 62.21647/64.14792. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.07317/64.14525. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.04492/64.15346. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.90894/64.04903. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.77512/63.98993. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.76054/64.06329. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.69754/63.96488. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.72232/63.93538. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.59614/63.87116. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 61.58193/63.74407. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 61.43924/63.75577. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.49611/63.81024. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 61.41827/63.73142. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.17137/63.73333. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.27574/63.62111. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.18602/63.62574. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.98180/63.57800. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 61.02039/63.49425. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.88366/63.45172. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 60.96359/63.46276. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.80900/63.40544. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.79154/63.43434. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.79451/63.28109. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.64136/63.33944. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.65523/63.23354. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.47416/63.25546. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 60.56298/63.20779. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.29774/63.20168. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 60.46507/63.19840. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.34035/63.11853. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.22165/63.05783. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 60.09025/63.05238. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.23179/62.99029. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.99611/62.98305. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 59.85514/62.98373. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.79118/62.98054. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.78511/62.92790. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 59.73025/62.90194. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.83019/62.88605. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.74618/62.87608. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.56903/62.85846. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.43740/62.84663. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.54499/62.81337. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 59.43284/62.82102. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.09288407280256479\n",
      "Epoch 0, Loss(train/val) 70.15339/70.01034. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.97508/69.91615. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 69.71530/69.81118. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.57575/69.67896. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.36712/69.51018. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.12521/69.31258. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.90516/69.07611. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.65395/68.79957. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.29773/68.47449. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.00741/68.11246. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.62551/67.70398. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.28105/67.25594. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 66.84856/66.78924. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.52494/66.33353. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.13506/65.91151. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.84753/65.54381. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.41859/65.25013. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.19956/65.02673. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.97764/64.84197. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.69931/64.68845. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 64.34927/64.58922. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.10780/64.54092. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.01503/64.50744. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.03390/64.49792. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.79242/64.49049. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 63.57231/64.47180. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.49761/64.45319. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.35484/64.43008. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.08799/64.40005. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.07579/64.35858. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.98862/64.32230. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 62.93538/64.28638. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.74338/64.26151. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.76970/64.24871. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.63684/64.24104. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.59785/64.21561. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.32224/64.17828. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.41625/64.14865. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 62.42427/64.12183. Took 0.35 sec\n",
      "Epoch 39, Loss(train/val) 62.18219/64.09610. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.02274/64.05901. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.03974/64.01617. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 61.97353/63.98574. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.87634/63.94025. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.74085/63.89125. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.89727/63.82388. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.68191/63.76761. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.79984/63.70560. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.54454/63.64286. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.54489/63.58838. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.41165/63.53264. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.44562/63.48491. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.12639/63.44648. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.29484/63.39508. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 61.11050/63.36521. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.05155/63.34573. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.98410/63.30189. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.98602/63.26324. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.85364/63.25907. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.93072/63.24556. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.78429/63.22538. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.70795/63.19683. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.68093/63.18779. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.54513/63.12242. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.49629/63.08105. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 60.42509/63.06112. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.28579/63.00695. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.37889/62.97805. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.26431/62.98759. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.10501/62.93063. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.97806/62.90324. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.05094/62.86366. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.90827/62.79709. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.84173/62.72558. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 59.80333/62.70283. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.81563/62.60955. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 59.72800/62.57833. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.67503/62.48252. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.69465/62.45620. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.59518/62.40689. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 59.38227/62.38392. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.48851/62.19233. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.20599/62.19649. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 59.29103/62.11990. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.16962/62.05087. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.26914/62.03295. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 58.99538/62.01714. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.05548/61.96897. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 58.91356/61.88711. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 58.95715/61.90875. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.80466/61.85026. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 58.79314/61.78907. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 58.75045/61.76786. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.79068/61.79845. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.54010/61.79210. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.60013/61.69558. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.55157/61.73355. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 58.40594/61.70951. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.49472/61.66364. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 58.35331/61.72667. Took 0.31 sec\n",
      "ACC: 0.53125, MCC: 0.05514348094667237\n",
      "Epoch 0, Loss(train/val) 70.79231/70.63142. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.61574/70.56998. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.49327/70.50938. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.28259/70.44446. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.14219/70.37615. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.98409/70.29860. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.76990/70.21130. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.53854/70.11024. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.35876/70.00176. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.16477/69.88913. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.90330/69.77593. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.70984/69.66901. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.52417/69.57817. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.25333/69.49514. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.06867/69.41774. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.84753/69.34462. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.65602/69.27748. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.43408/69.23594. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.18791/69.21091. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.95167/69.17471. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.68406/69.11705. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.39753/69.03265. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 66.05192/68.92181. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.81001/68.76252. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.47112/68.55145. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 65.25376/68.30701. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.83158/68.01608. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.55811/67.71651. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.24082/67.42830. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.94660/67.15604. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.75500/66.88988. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 63.52848/66.61974. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.27863/66.34820. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.05744/66.09297. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.86461/65.87416. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.72839/65.70643. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.67859/65.57799. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.50312/65.47051. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.44399/65.37685. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.37717/65.31950. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.24624/65.27618. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.31972/65.23808. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 62.11905/65.21556. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.88802/65.19176. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.95084/65.15630. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 61.90354/65.14085. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 61.87582/65.10912. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 61.76221/65.07807. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.73389/65.07810. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.73679/65.06851. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 61.69236/65.04881. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.58543/65.05417. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.58956/65.05740. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.45027/65.05512. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.39386/65.08985. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.43908/65.12939. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 61.36509/65.03608. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 61.29818/65.03854. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.27715/64.98816. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 61.08874/65.05247. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 61.16897/64.98489. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.06506/64.87769. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.97968/64.93948. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.89218/64.68304. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 60.77199/64.84346. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 60.79398/64.32667. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.65703/64.74493. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 60.60274/64.20542. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.49293/64.63709. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 60.39297/64.06647. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.40817/64.33897. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.24475/63.98885. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.15602/64.17500. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.25476/63.99286. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 59.94534/63.99567. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.06706/63.96085. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.94053/63.83667. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 59.89605/63.82368. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.75930/63.84414. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.84606/63.74041. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.74130/63.85384. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.71011/63.72419. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 59.65814/63.93371. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.67362/63.87310. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.42778/63.90314. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.59332/63.81020. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.30300/63.96254. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.29142/63.74833. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.12970/63.93766. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 59.21406/63.78436. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.20886/63.91224. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.18111/63.75604. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 59.05930/63.90017. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 58.92020/63.82379. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.97249/63.91316. Took 0.34 sec\n",
      "Epoch 95, Loss(train/val) 58.88728/63.89994. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.90208/63.94762. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.93553/63.92053. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.92301/63.90531. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.76934/63.89994. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: 0.012577870090366055\n",
      "Epoch 0, Loss(train/val) 71.29820/70.19663. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 71.03162/70.03826. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.78675/69.85640. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.53130/69.66178. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 70.25350/69.43518. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.99660/69.16228. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.67337/68.83379. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.36729/68.44419. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.96863/67.95923. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.57004/67.37146. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.93237/66.67056. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.49135/65.91771. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.79238/65.16487. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.12619/64.46314. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.52117/63.82951. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.92506/63.27822. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.14751/62.79455. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 63.56472/62.37331. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 63.12385/62.00952. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.52672/61.73264. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.34455/61.57051. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 62.12022/61.46239. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 61.60809/61.38023. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.45968/61.30409. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 61.27080/61.22398. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.13191/61.16430. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.83861/61.13433. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 60.78684/61.10091. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.66941/61.09005. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.62691/61.05687. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.63603/61.04293. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.38819/61.03162. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.39246/61.03781. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.50073/61.04126. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.28118/61.03210. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.20580/61.02634. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.26353/61.03544. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.19253/61.04364. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.10703/61.04971. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.01861/61.06107. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.02652/61.05994. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.94879/61.06311. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.79986/61.07850. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.98724/61.08792. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.85455/61.11889. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.87859/61.14261. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 59.67602/61.14196. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 59.82917/61.14261. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.63791/61.16909. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 59.69352/61.18504. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 59.62506/61.19120. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.62386/61.18967. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.65852/61.20433. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.54050/61.21793. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.67171/61.25196. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.46255/61.25911. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.61139/61.26949. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 59.41633/61.33683. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.49203/61.39649. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.30529/61.40196. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 59.40678/61.45149. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 59.46850/61.49718. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.38951/61.49298. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.31276/61.54000. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.23707/61.57133. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.11267/61.59428. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.22538/61.56094. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.15257/61.51884. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.96580/61.54451. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.24841/61.61499. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.98091/61.50940. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.94736/61.19489. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.91886/61.27943. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.07011/61.26886. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.79085/61.02803. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.77888/61.33688. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.80439/61.66011. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.80315/61.51014. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.63655/61.23309. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.65631/61.71421. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.70471/61.24993. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.72284/61.64830. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.72688/61.30362. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.65225/61.21500. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.57812/61.17275. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.51640/61.30173. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.50975/61.33398. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.25279/60.98732. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.39132/61.01979. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.53509/61.01160. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.23979/61.06804. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.40154/60.97772. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.35315/60.90718. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.25380/60.97361. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.91830/61.04261. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 58.29335/61.04307. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 58.35044/61.07002. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.35085/61.06559. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.12376/61.13306. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.10734/61.16354. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.048647332992624304\n",
      "Epoch 0, Loss(train/val) 71.19966/70.74803. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.98111/70.42206. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.76892/70.09484. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.55986/69.77104. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.32902/69.44806. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.15197/69.12837. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.91872/68.82946. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.66319/68.53889. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.49886/68.26015. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.27658/67.99888. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 69.03260/67.74221. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.79781/67.48534. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.58796/67.22752. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.41040/66.97395. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.12099/66.70855. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.85749/66.42239. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 67.66636/66.11874. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 67.45099/65.79236. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.19608/65.44150. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.91994/65.08302. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.67007/64.72539. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.38132/64.37930. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.16969/64.05981. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.94244/63.77744. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.70486/63.53066. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.59962/63.32043. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.40447/63.14633. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.15431/63.01199. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.01653/62.91401. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.80591/62.84337. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 64.67633/62.80554. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.38849/62.80106. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.28521/62.82304. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.89520/62.85458. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.65711/62.89578. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.51989/62.91988. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.31427/62.92213. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.06521/62.85720. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.66573/62.67968. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.44519/62.39587. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.13517/62.03271. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.81736/61.65311. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.51017/61.30854. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.42407/61.01600. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.90855/60.76775. Took 0.34 sec\n",
      "Epoch 45, Loss(train/val) 60.78927/60.56100. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.81715/60.40500. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.50702/60.29575. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.23345/60.16686. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.19079/60.05619. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.03503/59.97407. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.96908/59.86166. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.64485/59.75600. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.42472/59.60525. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.39699/59.49467. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 59.28883/59.32635. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.98666/59.18750. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.09832/59.11026. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.90401/58.92315. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.59236/58.81996. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.69006/58.65118. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.41438/58.51271. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.17717/58.36321. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.26746/58.18058. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.19449/58.06340. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.93905/57.88910. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.85652/57.74810. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.91439/57.62583. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.49309/57.51589. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.44672/57.36921. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.39212/57.22035. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.34269/57.08449. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.25816/56.94602. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.30256/56.82928. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 57.08600/56.75641. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.84390/56.69786. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.94513/56.57009. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.97868/56.46911. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.90797/56.35482. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.81708/56.23783. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 56.58308/56.15354. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.63356/56.12949. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.53196/56.01550. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.44436/55.92057. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.30282/55.85662. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.13877/55.80054. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.33572/55.69246. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.03948/55.64413. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.17775/55.58759. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.30794/55.53860. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 56.06542/55.48822. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.05549/55.43305. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.17579/55.38212. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.07392/55.35519. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.84869/55.37468. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.00755/55.30146. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.89481/55.29648. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 55.81633/55.14978. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.59969/55.10489. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.84887/55.06129. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.06815142307594586\n",
      "Epoch 0, Loss(train/val) 71.27238/71.12098. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 71.09322/70.96931. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.84184/70.82616. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.62435/70.69514. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.43669/70.57448. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.29280/70.45998. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.12197/70.35217. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.89404/70.25144. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 69.72988/70.14882. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.55999/70.04484. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.41141/69.94618. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.19677/69.84139. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.04739/69.73364. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.90137/69.62260. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.77045/69.50576. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.51796/69.38396. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.40276/69.25634. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.22637/69.12065. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.05059/68.97968. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.92628/68.83143. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.77096/68.66801. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.53265/68.49648. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.32532/68.31478. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 67.14608/68.12795. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.78502/67.92506. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 66.54157/67.69418. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 66.27833/67.41351. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.94592/67.06287. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 65.61186/66.65550. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.24746/66.22104. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.80243/65.75754. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.42159/65.26539. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.09211/64.74679. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.99616/64.23165. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.78930/63.75403. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.55934/63.31543. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.41037/62.97342. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.24046/62.69555. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.16654/62.51182. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.90133/62.33223. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.92636/62.23307. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.88729/62.18079. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.80789/62.13395. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.71898/62.14045. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.56864/62.15823. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 62.50033/62.20755. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.40479/62.27066. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.32495/62.30803. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.35666/62.35793. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.00466/62.38968. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.97165/62.43664. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.84727/62.47072. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 61.76941/62.55237. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.71258/62.60379. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.69816/62.66991. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.70581/62.67829. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.47503/62.62316. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.41242/62.57781. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.35026/62.51801. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.20810/62.46442. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.18350/62.39137. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 61.20269/62.30485. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.02978/62.25162. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.99228/62.13479. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.00605/62.17891. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.90072/62.10580. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.81810/62.12175. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.80420/62.12503. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.78593/62.18131. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.66507/62.25308. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.42711/62.18786. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.52463/62.29362. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.34602/62.35080. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.33910/62.39749. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.32981/62.50822. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.23331/62.62053. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.17230/62.62306. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.06550/62.75199. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.04874/62.77627. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.85604/62.95152. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.75774/63.04266. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.84873/62.97823. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.62298/63.14090. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.51389/63.11835. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.55250/63.25409. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.57428/63.07642. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.40194/63.17734. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.36158/63.00729. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.26977/63.33750. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.31719/62.94763. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.15950/63.01313. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.08229/63.16989. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.04327/62.77412. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.92838/63.08329. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.97985/63.07849. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.82510/62.60881. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.79933/63.21900. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.86552/62.92562. Took 0.34 sec\n",
      "Epoch 98, Loss(train/val) 58.73606/62.68209. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 58.67775/62.96594. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: -0.02450715406979359\n",
      "Epoch 0, Loss(train/val) 70.30783/70.04250. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.14963/69.89063. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.94680/69.72797. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.78179/69.54888. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.61096/69.35016. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.36682/69.12167. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.09088/68.85670. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.78030/68.55557. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.42860/68.21082. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.01396/67.83040. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.69738/67.43079. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.30696/66.99134. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.92762/66.50969. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.53731/65.97620. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.21871/65.41487. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.84286/64.84290. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.48921/64.30077. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 65.07336/63.78932. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.82397/63.31905. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.57626/62.89859. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.35431/62.52849. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 64.05325/62.19522. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.90026/61.88022. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.76688/61.60467. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.62260/61.37148. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.36629/61.17519. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.43352/60.99903. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.08807/60.83923. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.09662/60.71754. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.07002/60.61700. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 63.02085/60.52417. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.92924/60.43344. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.60490/60.35608. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.83734/60.29055. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.66478/60.23080. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.76811/60.17482. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.60014/60.12321. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.53881/60.07889. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.58213/60.03698. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.32019/59.99948. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.50411/59.96559. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.39793/59.93716. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.16783/59.91175. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.26694/59.87670. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.15161/59.84182. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.31045/59.81802. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.25293/59.80000. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.32181/59.78470. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.06084/59.78481. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.12171/59.77174. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 62.20505/59.75821. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.06926/59.74390. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.03429/59.73163. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.05042/59.71949. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.99160/59.70893. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.98993/59.71242. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 62.02729/59.71349. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.91421/59.70994. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.98395/59.70261. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.90422/59.68849. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.81943/59.68145. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.76168/59.68261. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.58885/59.67479. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.74883/59.65324. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.73241/59.66125. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.81438/59.66431. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.67975/59.66150. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.84294/59.66578. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.67824/59.66282. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.82541/59.66222. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.65771/59.66919. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.64279/59.66447. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.53190/59.65057. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 61.63814/59.65191. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.67554/59.65291. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.57483/59.64727. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.61003/59.64904. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.71448/59.64758. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.47998/59.65806. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.27812/59.67594. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.38925/59.69263. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.44516/59.68801. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.45561/59.69314. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.40275/59.70835. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 61.32817/59.73592. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 61.44365/59.74878. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 61.19811/59.74910. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 61.29022/59.75157. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.45981/59.77185. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.25959/59.78577. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.29523/59.79809. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.25887/59.79742. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.07670/59.81722. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.09890/59.84187. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.07354/59.84238. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.13025/59.85706. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.06378/59.86951. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.06712/59.88605. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.97473/59.90864. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.90307/59.91825. Took 0.32 sec\n",
      "ACC: 0.59375, MCC: 0.20851441405707474\n",
      "Epoch 0, Loss(train/val) 70.79897/71.60298. Took 0.35 sec\n",
      "Epoch 1, Loss(train/val) 70.68210/71.54676. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.68632/71.49569. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.54221/71.44835. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.50725/71.40391. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.43029/71.35889. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.39390/71.30221. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 70.30595/71.24952. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.28478/71.19016. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 70.16679/71.14120. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 70.12837/71.09068. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.99699/71.04324. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.96346/70.99487. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.90057/70.94353. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 69.84535/70.88805. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.78800/70.83319. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 69.79779/70.76512. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 69.64694/70.70006. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 69.59677/70.63567. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 69.50311/70.56831. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 69.49342/70.48872. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 69.33848/70.40711. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 69.23127/70.32345. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 69.16128/70.24088. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 69.07522/70.15071. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 69.01412/70.05841. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 68.91355/69.95148. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 68.81632/69.83463. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 68.67081/69.71704. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 68.57110/69.57887. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 68.48849/69.44312. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 68.39449/69.31116. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 68.33312/69.16058. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 68.27765/69.01649. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 68.19548/68.87515. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 67.95084/68.72456. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 67.94973/68.58261. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 67.84915/68.44084. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 67.81485/68.30174. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 67.66595/68.16884. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 67.61806/68.04598. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 67.42841/67.92334. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 67.36072/67.81152. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 67.26991/67.70584. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 67.20128/67.59511. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 67.05879/67.50314. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 66.94223/67.39266. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 66.95278/67.29846. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 66.85306/67.20103. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 66.83748/67.10146. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 66.59327/67.01907. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 66.59640/66.93499. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 66.42564/66.84959. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 66.41801/66.78606. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 66.25488/66.70399. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 66.24082/66.60954. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 66.19886/66.53651. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 66.06290/66.48328. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 66.11871/66.43601. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 65.98584/66.36938. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 65.85005/66.31512. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 65.94170/66.25690. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 65.81064/66.21625. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 65.61165/66.16550. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 65.59404/66.11769. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 65.49855/66.08058. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 65.36043/66.01991. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 65.37629/65.96337. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 65.25642/65.94698. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 65.22988/65.89996. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 65.09979/65.85422. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 64.92331/65.81538. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 64.91132/65.79160. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 64.84186/65.74231. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 64.77037/65.67258. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 64.64909/65.61647. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 64.58595/65.56164. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 64.48848/65.51601. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 64.45856/65.45397. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 64.29786/65.36260. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 64.21681/65.28944. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 64.22141/65.19898. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 64.03737/65.13356. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 64.05250/65.06665. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 64.07399/64.93800. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 64.07333/64.88581. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 63.93953/64.79446. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 63.67067/64.69630. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 63.73899/64.58907. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 63.78797/64.54795. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 63.59117/64.48831. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 63.64481/64.33585. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 63.55005/64.33727. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 63.49247/64.20284. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 63.55586/64.24979. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 63.29405/64.08616. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 63.43622/64.17379. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 63.12836/64.04367. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 63.23970/64.10344. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 63.25496/64.02406. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.15244937348544793\n",
      "Epoch 0, Loss(train/val) 69.96039/69.97716. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.82184/69.90347. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.67699/69.82384. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.51481/69.74034. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.37164/69.64771. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.13552/69.53455. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.97560/69.40017. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.71847/69.24325. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.49557/69.04604. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.22497/68.81058. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.84267/68.52843. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.42322/68.22141. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.99018/67.93946. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.57850/67.68644. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.16575/67.46040. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.87388/67.24963. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.51872/67.04800. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.13181/66.85477. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.87154/66.68018. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 64.80866/66.53149. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.40690/66.39441. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.23439/66.26972. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.06652/66.15714. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.96143/66.05482. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.69263/65.96346. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.70644/65.87845. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.55156/65.79803. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.55183/65.72322. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 63.57031/65.65015. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.48099/65.58512. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 63.32337/65.52509. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.28733/65.46864. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.29220/65.41463. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 63.21586/65.36765. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.08221/65.33202. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.08833/65.29357. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.10882/65.25899. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.85741/65.23279. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 62.89800/65.20626. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.94351/65.17754. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.83083/65.15226. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.76941/65.13020. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.64234/65.10926. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.74838/65.07993. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.66493/65.05077. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.74086/65.03235. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.63058/65.00363. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.49339/64.98001. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.53065/64.95818. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.47874/64.93592. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.52769/64.90570. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.35774/64.87527. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 62.40240/64.84561. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.25223/64.81586. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.30575/64.79237. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 62.35749/64.75726. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.24669/64.71947. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.22686/64.62720. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 62.09241/64.48148. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.08489/64.42981. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.04170/64.29559. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.00196/64.23935. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.88163/64.15443. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.73534/64.04760. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.81272/63.97659. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 61.94379/63.88217. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.75840/63.79813. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.72746/63.75899. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.67194/63.69189. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.47468/63.64002. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.39722/63.59593. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.37456/63.54965. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.42702/63.52711. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.41233/63.50043. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.35856/63.47591. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.33472/63.45648. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.32296/63.43662. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.27580/63.43065. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 61.20764/63.40370. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.24018/63.40971. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.10430/63.40021. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.11009/63.39860. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.94695/63.39371. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.02888/63.40197. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 61.03201/63.40151. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.98017/63.40139. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.91518/63.41095. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 61.08158/63.40559. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.79872/63.41339. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 60.76504/63.42260. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.83079/63.41965. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 60.82334/63.41393. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.59461/63.42627. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.64404/63.43581. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.60183/63.44768. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.57925/63.46027. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.52190/63.47913. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.39417/63.48228. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.23446/63.48933. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.35741/63.49933. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: -0.11378277614173485\n",
      "Epoch 0, Loss(train/val) 70.52086/69.11542. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.34931/68.98650. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.24154/68.85090. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.12179/68.70564. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.00750/68.54460. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.82005/68.35469. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.70592/68.13203. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.51280/67.86652. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.33791/67.54185. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.13082/67.15406. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.82313/66.67440. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.55874/66.11120. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 68.26817/65.45910. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.92959/64.74241. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.54154/64.04428. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.13415/63.38363. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.78521/62.80915. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.48458/62.35804. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.25798/62.04345. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.03941/61.77308. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.94813/61.54335. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.81485/61.32914. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.61980/61.13039. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 65.36896/60.93730. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.31324/60.75491. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.20215/60.58271. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.10925/60.41393. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.05516/60.26409. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.91479/60.13274. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.76187/59.99825. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 64.69404/59.86745. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 64.49408/59.73004. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.46121/59.60363. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.40431/59.48749. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.36984/59.39383. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.11480/59.32731. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 64.07289/59.33419. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.03759/59.43602. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 63.81425/59.56568. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.81743/59.56140. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.65134/59.54042. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.38324/59.50409. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.46089/59.42212. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 63.30169/59.29688. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 63.15274/59.22546. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.13055/59.10137. Took 0.34 sec\n",
      "Epoch 46, Loss(train/val) 62.96052/58.95933. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.90466/58.84610. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 62.67817/58.71995. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 62.74224/58.55160. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.54346/58.40571. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.36772/58.22136. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.21494/58.03347. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.10247/57.93702. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 62.12341/57.81061. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 61.97619/57.67456. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.85405/57.57052. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.77393/57.48490. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.65339/57.39114. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.52588/57.28309. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 61.42485/57.21733. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.28594/57.15701. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 61.33946/57.12225. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.29739/57.06616. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 61.03842/57.03230. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 61.12604/56.95317. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.99631/56.90837. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.81296/56.90590. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.81740/56.78398. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 60.72317/56.79954. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.67015/56.80066. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.66403/56.69831. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.61389/56.50528. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.24251/56.53030. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 60.37763/56.48167. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.46049/56.56134. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.12483/56.52643. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.13729/56.45224. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 60.17790/56.35200. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.08320/56.41359. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.00897/56.03682. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 60.05775/56.08528. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.94953/56.41553. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.80448/56.33221. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.87544/56.19321. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.59629/56.09865. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.77311/55.74434. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 59.70823/55.84280. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.56408/56.22488. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.50949/56.25070. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.47737/56.12262. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 59.41144/56.25635. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.45272/56.15599. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.38424/55.63174. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.45895/55.53070. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.16473/55.85444. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.30367/56.06790. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.36987/55.54042. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 59.14053/55.49167. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.04605/55.57681. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.014274868079616495\n",
      "Epoch 0, Loss(train/val) 70.54093/69.85367. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.37161/69.61567. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.19294/69.36071. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.99571/69.09721. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.85711/68.82500. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.67302/68.54440. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.48633/68.26607. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.27853/67.99031. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.07646/67.71389. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.93374/67.45140. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.74936/67.20442. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.57755/66.97092. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.39077/66.74706. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.22415/66.53770. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.05965/66.33828. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.90315/66.14947. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.63090/65.95976. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.50683/65.77255. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.27152/65.57418. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.95415/65.35648. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.79502/65.10550. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.41875/64.81180. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.11822/64.47706. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.69779/64.11805. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.25453/63.77007. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.85940/63.46540. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.54533/63.21901. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.25627/63.02722. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.04695/62.87053. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.92713/62.74477. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.71856/62.64410. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.61901/62.56112. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.61246/62.48999. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 63.40424/62.43240. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.30547/62.38136. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 63.20441/62.33181. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.21714/62.27938. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.06920/62.23666. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.01503/62.20098. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.99892/62.17379. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.01288/62.13823. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.94396/62.09342. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.83400/62.06364. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.74478/62.03759. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.78836/62.01793. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.57606/61.99498. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.61125/61.98136. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.67316/61.97449. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.55462/61.95758. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.51289/61.93887. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.51635/61.92373. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.42268/61.91571. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.44539/61.91048. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.23595/61.90386. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.30356/61.87539. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.11111/61.83987. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 62.20737/61.80532. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 62.06453/61.76719. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.03892/61.73288. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.21134/61.73973. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.74672/61.72958. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.89671/61.69725. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.86757/61.67122. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.69653/61.65789. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 61.55097/61.66016. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 61.74004/61.61917. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.56710/61.59794. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.62631/61.57244. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 61.44686/61.54048. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.44709/61.52500. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.44258/61.49689. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 61.31783/61.48759. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.31911/61.44273. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 61.31125/61.36866. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.11029/61.37045. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.04240/61.28482. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.04051/61.25321. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 60.99028/61.19960. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.84255/61.12377. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.80030/61.08476. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.76997/61.04207. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.76866/60.97853. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 60.70549/60.95201. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 60.68372/60.89256. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.61299/60.89089. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.48181/60.79889. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.65894/60.76498. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.56116/60.75707. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.44345/60.68962. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.41865/60.66600. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 60.44058/60.61998. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.46074/60.62695. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 60.39973/60.61513. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 60.09512/60.52361. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.31828/60.53466. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.21346/60.55716. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.13943/60.44167. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.24302/60.46156. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 60.08569/60.45460. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.04783/60.34430. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.046373889576016826\n",
      "Epoch 0, Loss(train/val) 71.00184/70.89161. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.78523/70.73170. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.66055/70.57550. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.43610/70.41610. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.18799/70.25676. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.99156/70.09771. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.78159/69.94278. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.59065/69.78751. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.37860/69.63235. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.11913/69.47685. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.91047/69.31927. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.72015/69.16171. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.54386/69.00384. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.29943/68.84698. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.10180/68.69900. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.86398/68.55728. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 67.68325/68.41936. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.54877/68.29345. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.30884/68.17203. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.12235/68.05530. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 66.98983/67.93789. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.93445/67.81357. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 66.75689/67.69933. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.53006/67.57993. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.37148/67.46629. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 66.36714/67.35859. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.21528/67.26021. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.00763/67.15606. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 65.81564/67.04774. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 65.79599/66.97495. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.65539/66.90121. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.58776/66.80727. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.39528/66.71889. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.24334/66.62952. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 65.03103/66.56723. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.91282/66.52872. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.85802/66.44628. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 64.72934/66.41092. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.53736/66.36748. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.50166/66.33789. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.43723/66.28897. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.31047/66.26624. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.15880/66.23180. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.07808/66.16916. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 64.02611/66.16814. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.89879/66.16164. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.69975/66.08195. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.68646/66.07848. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 63.56475/65.95464. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.43495/66.02158. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.40611/65.99039. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.20437/65.96917. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.21864/65.96304. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.07588/65.90974. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.95970/65.86938. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.91436/65.85364. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.89186/65.82055. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.69195/65.75719. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 62.94520/65.77584. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 62.70345/65.72053. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.71015/65.68150. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.59955/65.64044. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.51626/65.62240. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.47343/65.58762. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.34316/65.56799. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.36821/65.53599. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.19157/65.50206. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.22313/65.46960. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.13778/65.46409. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.02614/65.43698. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.05343/65.41594. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.86606/65.39478. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.77192/65.39919. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.71273/65.41065. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.54351/65.43498. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.70812/65.42024. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 61.55675/65.35985. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.57164/65.42654. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.31955/65.37967. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.38879/65.40598. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.39969/65.28176. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.08078/65.36240. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.15214/65.29831. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.09208/65.31459. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.93175/65.25278. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.85022/65.23808. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.80102/65.21214. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.53521/65.15695. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.55455/65.13007. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 60.55541/65.06592. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.30213/65.01216. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.45529/64.97065. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 60.26788/64.92434. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 60.34005/64.87489. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 60.21699/64.81802. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.19024/64.75867. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.04794/64.70171. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.14588/64.65308. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 60.04787/64.61272. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.13498/64.59895. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.047395744875690524\n",
      "Epoch 0, Loss(train/val) 70.93775/71.16024. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.70318/71.12968. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.50530/71.10065. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.34402/71.06386. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.03518/71.01350. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.88990/70.95801. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.64167/70.88845. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.47539/70.80865. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.24993/70.71572. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.99862/70.60753. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.73273/70.48875. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.53627/70.37042. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.18878/70.23887. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.86264/70.10336. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.62085/69.98186. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.28888/69.88711. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.98262/69.79438. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.59493/69.68192. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.17844/69.52616. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.09983/69.32144. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.83376/69.09666. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 65.26693/68.85480. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.26882/68.65402. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.94269/68.52214. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.61063/68.46776. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.36131/68.43128. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.13899/68.38029. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.10643/68.35274. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.78348/68.33548. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.72055/68.31509. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 63.56295/68.31001. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.44584/68.34102. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.44906/68.27094. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.44827/68.20055. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.06117/68.12086. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.07339/68.05508. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.09101/68.02342. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.97801/67.98891. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.82676/67.95329. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 62.77015/67.85634. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.65739/67.68850. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.67770/67.52348. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.34939/67.36590. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.48329/67.16881. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.30341/67.07103. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.16513/66.95824. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 62.00304/66.86856. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.10937/66.89608. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.98577/66.92568. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.98409/66.89104. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.86946/66.86742. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.79112/66.81881. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.80184/66.75898. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.55756/66.79330. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.62546/66.75059. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.76345/66.69498. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.53256/66.61980. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.33410/66.67605. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.44732/66.69455. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 61.27628/66.49271. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.25883/66.60398. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.16123/66.53810. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.17486/66.48000. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.09875/66.31853. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.10956/66.37815. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.13014/66.36854. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.95089/66.32762. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.95581/66.20369. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.04754/66.26989. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.71280/66.16327. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.73219/66.19948. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.81134/66.20889. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.58856/66.30853. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.48978/66.04221. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 60.62227/66.25882. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.48546/66.03754. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.57867/66.09394. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.42345/66.05698. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.47585/65.88808. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.32810/66.02758. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.34220/65.97624. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.44092/66.06310. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 60.30430/65.99560. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.29056/65.84601. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.27042/65.76070. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.14938/65.74789. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.05688/65.70537. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.07125/65.75754. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.14196/65.60915. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.01458/65.62853. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.07254/65.57950. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.04618/65.51106. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.95480/65.56701. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.83912/65.30917. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.89553/65.42931. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.99641/65.42751. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.74810/65.20235. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 59.90668/65.31696. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 59.72635/65.00509. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.69097/65.16507. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.19147452777105392\n",
      "Epoch 0, Loss(train/val) 70.74866/70.02734. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.52177/69.87753. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.32028/69.73435. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.10775/69.58780. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.88329/69.43524. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.66647/69.27444. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.42624/69.08841. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 69.12429/68.89132. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.83479/68.66666. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.59371/68.42153. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.24239/68.14932. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.82049/67.82832. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.47470/67.46295. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.04942/67.04910. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.71776/66.58304. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.23086/66.07217. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.86351/65.55830. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.40511/65.07480. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.15145/64.64041. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.83876/64.25837. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 64.45863/63.92218. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.17117/63.60392. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.95354/63.28391. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.68852/62.98115. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.49730/62.65978. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.30649/62.35853. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.02510/62.01231. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.83990/61.69809. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.64019/61.45768. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.61812/61.25023. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.33400/61.06951. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.22724/60.91212. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 61.96997/60.79994. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.79214/60.72112. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.54626/60.55117. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.33712/60.52747. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.28934/60.49568. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.09313/60.56571. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 61.11275/60.40756. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.95448/60.34632. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 60.99604/60.39972. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 60.92423/60.32172. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.70266/60.50882. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.73170/60.43396. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.53772/60.44096. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.65274/60.39829. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 60.42520/60.38728. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.49411/60.52053. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.46259/60.65564. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.28069/60.56943. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.37969/60.51516. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.16655/60.45357. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.22612/60.54282. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.00760/60.55965. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 59.99405/60.58469. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.87602/60.70328. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.84328/60.69369. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.91468/60.78165. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.81173/60.62328. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.70328/60.69093. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.75958/60.91228. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.71450/60.82203. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 59.55366/61.04076. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.60913/60.63721. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.56831/60.83294. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.49791/61.12329. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.27198/61.00585. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.30828/60.78077. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.23952/60.89153. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.98009/60.76506. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.12260/61.06931. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.94603/60.94582. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.24140/61.07734. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.89655/61.07139. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.86561/61.04137. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.73435/61.28989. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.58656/61.17464. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.67156/61.20510. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.53737/61.25154. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.43618/61.43839. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.68109/61.27599. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.47260/61.35352. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.44383/61.44984. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 58.34593/61.31822. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.09307/61.26691. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.21718/61.34595. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.05552/61.32769. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 58.19303/61.38503. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.99886/61.46625. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.97005/61.56961. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.88421/61.58439. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.96145/61.46777. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.72046/61.51878. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.92126/61.75941. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.79580/61.53581. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.93575/61.58126. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.72629/61.62355. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 57.60498/61.62610. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.34948/61.89234. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.54802/61.29569. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.00700902994282404\n",
      "Epoch 0, Loss(train/val) 70.45702/70.35159. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.18300/70.17204. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.99279/69.99131. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.75344/69.81081. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.52780/69.63338. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.29600/69.45168. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.01950/69.26635. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.78082/69.07883. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.42159/68.88425. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.19509/68.68056. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.87786/68.46236. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.48331/68.22446. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.12279/67.95737. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.66828/67.63975. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.05568/67.25112. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.45697/66.79199. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.94502/66.27485. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.27999/65.72058. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.58184/65.14538. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.03741/64.55919. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.77553/63.99655. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.47347/63.51210. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.21533/63.14790. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.10452/62.86086. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.71914/62.65194. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.60077/62.49640. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.46588/62.38335. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.34428/62.28453. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.20140/62.19685. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.23291/62.12561. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.89861/62.06300. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.99936/61.99226. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.00370/61.94446. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.77985/61.89848. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.73505/61.83840. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 60.70829/61.76480. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 60.70487/61.69618. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.50084/61.62585. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.55955/61.54460. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.32211/61.44919. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.35420/61.34637. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.25087/61.24770. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.27518/61.14639. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.08694/61.06320. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.11711/60.93895. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.98982/60.83936. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 59.93231/60.75283. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.77753/60.66752. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.80690/60.56683. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.74581/60.46563. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.68254/60.39078. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.51240/60.29775. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.55065/60.20277. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.40425/60.14697. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.49698/60.06542. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 59.50986/59.98007. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.41419/59.91498. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.27831/59.86010. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.17661/59.77183. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 59.34131/59.68979. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.26416/59.65894. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 59.18155/59.64605. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.10410/59.62031. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.03442/59.59390. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.97944/59.55680. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.83770/59.49663. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 59.07912/59.49800. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.96396/59.51675. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.89957/59.50275. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.84146/59.44476. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 58.80263/59.43526. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.73164/59.45605. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.65151/59.45053. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.63845/59.42186. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 58.57853/59.38816. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.52709/59.38639. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.65825/59.39341. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.52306/59.40031. Took 0.34 sec\n",
      "Epoch 78, Loss(train/val) 58.47526/59.44138. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.50296/59.44769. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.44438/59.42730. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.43051/59.43993. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.38317/59.44837. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.25919/59.43015. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.18898/59.47450. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 58.18053/59.46123. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.32537/59.46551. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.35324/59.44122. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.22379/59.44286. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.08397/59.45346. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.24080/59.47974. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.22897/59.47657. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.90861/59.50154. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.99858/59.51486. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.07508/59.51658. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.03197/59.58383. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.04023/59.58412. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.98827/59.56952. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.88232/59.54398. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.75598/59.55565. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.008592321037107784\n",
      "Epoch 0, Loss(train/val) 70.31538/71.27274. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.09716/70.99204. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.76007/70.68700. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.52435/70.35885. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.20570/70.02154. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.90850/69.67380. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.52925/69.30741. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.15625/68.91720. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.81923/68.50568. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.32150/68.05846. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.99244/67.58130. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.58632/67.08861. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.06405/66.60307. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.76018/66.14196. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.32838/65.71263. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.96336/65.33102. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.70169/64.96663. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.34002/64.58897. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 63.97333/64.18028. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.64944/63.72334. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.13339/63.25470. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.81393/62.82754. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 62.21513/62.44411. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.77931/62.03461. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.42284/61.64861. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.12517/61.43663. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.94016/61.29501. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.82321/61.22084. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.43845/61.16881. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.49985/61.12341. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.43204/61.10112. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.40128/61.07230. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 60.26933/61.07834. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.18224/61.10522. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.05910/61.09683. Took 0.34 sec\n",
      "Epoch 35, Loss(train/val) 60.27281/61.08978. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 60.00348/61.15488. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.05477/61.16410. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.10440/61.20399. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.89717/61.20240. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.76508/61.25766. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.71400/61.29784. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.71007/61.35441. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.79077/61.36113. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.58138/61.41534. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.61537/61.43179. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.57273/61.39914. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.53248/61.50189. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.23954/61.68570. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.40244/61.58487. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.27933/61.55036. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.44448/61.57503. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.31884/61.77925. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.37446/62.08958. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.22234/61.94823. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.15658/61.68438. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.10798/61.91891. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.11589/61.78119. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.24812/62.05965. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.96603/61.66288. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.11430/60.78684. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.85004/61.87881. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.81741/61.76405. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.76219/61.45648. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 58.80666/61.46899. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.65359/62.32899. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 58.70484/60.96627. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.69788/62.01192. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 58.41261/62.51999. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.57777/61.68700. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.48175/62.03673. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.44770/62.40146. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.54472/61.58931. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.38549/62.38370. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.36405/62.34646. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.40354/61.96489. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.28251/61.16788. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.36498/61.17821. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.21887/62.61314. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.27713/61.07668. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.34970/61.07454. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.04365/61.02309. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.86278/61.26617. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.10781/60.87320. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.80406/60.15452. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.85819/60.48210. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.76946/59.81376. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.68145/59.88089. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.60103/59.54797. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.36075/59.80515. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 57.28600/59.81962. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.19714/59.45583. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.31961/59.38919. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.04544/59.93542. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.19346/59.36991. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.17424/59.40414. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.03688/59.13700. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.90864/59.29224. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.82126/59.28101. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.84907/58.58510. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.10251423416428378\n",
      "Epoch 0, Loss(train/val) 70.57229/69.05448. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.27235/68.68847. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.99718/68.31434. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.73396/67.93423. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.44925/67.54781. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.17161/67.15192. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.87494/66.73365. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.65691/66.29086. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.30751/65.83183. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.01971/65.35456. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.62867/64.86557. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.39629/64.34678. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.00142/63.81530. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.56785/63.29468. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.16925/62.80323. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.73624/62.36274. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 65.35742/61.95175. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.89641/61.58501. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.42810/61.25459. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 64.01777/60.95837. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.55559/60.69393. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.12180/60.45209. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.57097/60.23423. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.13528/60.03688. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.80357/59.83028. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.37293/59.62146. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 61.03021/59.40355. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.68934/59.22248. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.37431/59.04092. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.21322/58.86602. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.94892/58.66451. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.84170/58.41920. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 59.58414/58.12935. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.29680/57.82904. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.21788/57.58570. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.22271/57.42596. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.07388/57.30688. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.86427/57.20874. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 58.83415/57.11882. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.62633/57.04538. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.58498/56.97784. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.57101/56.92175. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.41150/56.87165. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 58.27552/56.82486. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.25174/56.78058. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.23068/56.74183. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.14767/56.70971. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.97562/56.68309. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 58.12647/56.65448. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.03792/56.63036. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.97120/56.60849. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.86129/56.57876. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.89006/56.54087. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.71586/56.50031. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.81772/56.47044. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.65334/56.45977. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.69330/56.45168. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.61932/56.47585. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.60339/56.53183. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 57.50293/56.53072. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.47138/56.56413. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.43680/56.53653. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.43599/56.52616. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.27430/56.53230. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.42042/56.52340. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.33626/56.54591. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 57.28580/56.42625. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.17530/56.46845. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 57.10574/56.55978. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.29950/56.53146. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 57.24555/56.48889. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.22421/56.45586. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.99644/56.53367. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 56.98917/56.56726. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 56.99637/56.55973. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.04040/56.54488. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.18105/56.56531. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.96321/56.46375. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 57.04927/56.49885. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.08131/56.52361. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.95395/56.56752. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.94334/56.57706. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 56.93680/56.59763. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.80737/56.57948. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.83073/56.61541. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.71594/56.63166. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.67919/56.65826. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.70061/56.67390. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 56.76267/56.71880. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 56.64080/56.76939. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.68137/56.86474. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.51370/56.85416. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.50849/56.90622. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.42130/56.90882. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.45870/56.97149. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.33049/56.98965. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.30650/56.99430. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.30117/56.90248. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.36162/56.81944. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.16368/56.66337. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.051799406700962544\n",
      "Epoch 0, Loss(train/val) 70.83468/71.90083. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.73200/71.83359. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.66487/71.75372. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.56459/71.64378. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.48625/71.53626. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 70.38970/71.44046. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 70.27616/71.33867. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 70.18415/71.23284. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 70.11495/71.12126. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 70.00819/71.00727. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.91400/70.89767. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 69.80531/70.80791. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.72426/70.74174. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 69.61643/70.67834. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.53033/70.61951. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.41605/70.55754. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 69.32558/70.49216. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 69.17256/70.41589. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 69.12095/70.33763. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 68.95826/70.26041. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 68.86758/70.17525. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 68.83661/70.08882. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 68.69083/69.99165. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 68.69954/69.89172. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 68.46806/69.78770. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 68.42133/69.67782. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 68.27708/69.55247. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 68.15944/69.42645. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 68.02037/69.28871. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 67.95099/69.13521. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 67.76054/68.96894. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 67.56700/68.81412. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 67.44716/68.66544. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 67.28454/68.52325. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 67.12155/68.39027. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 67.11488/68.28535. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 66.95940/68.20525. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 66.85593/68.11698. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 66.80400/68.03957. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 66.77746/67.99484. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 66.57381/67.91301. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 66.62770/67.82758. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 66.36971/67.77060. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 66.24715/67.68380. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 66.10002/67.65086. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 66.10191/67.62532. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 66.03039/67.65063. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 65.93607/67.52377. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 65.90774/67.58669. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 65.83181/67.49034. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 65.67515/67.40896. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 65.62303/67.33096. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 65.63221/67.39679. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 65.36603/67.47082. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 65.60662/67.32517. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 65.45244/67.55824. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 65.44578/67.49640. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 65.34588/67.49183. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 65.39051/67.38831. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 65.15037/67.57860. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 65.27266/67.73241. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 65.17949/67.61157. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 65.26239/67.86546. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 65.11369/67.67090. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 64.97769/67.88463. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 65.07066/67.60374. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 64.87437/67.93890. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 64.94367/67.66175. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 64.80477/67.98899. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 64.74157/67.65623. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 64.74910/67.48655. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 64.74667/67.81483. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 64.63993/67.44782. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 64.66533/67.43604. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 64.80250/67.49622. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 64.59686/67.38878. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 64.65628/67.78487. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 64.43258/67.32322. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 64.50537/67.28573. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 64.38481/67.34660. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 64.59812/67.30283. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 64.22982/67.52481. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 64.29661/67.27422. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 64.41834/67.47101. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 64.24270/67.21635. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 64.24665/67.50724. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 64.14707/67.25401. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 64.17669/67.78558. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 64.18279/67.22766. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 63.94932/67.24745. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 64.17008/67.26997. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 63.90608/67.23588. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 63.81742/67.22245. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 63.92634/67.23963. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 63.82062/67.25035. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 63.88457/67.23969. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 63.87598/67.28684. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 63.74903/67.23849. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 63.71719/67.22501. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 63.71300/67.19096. Took 0.31 sec\n",
      "ACC: 0.578125, MCC: 0.15318083468998522\n",
      "Epoch 0, Loss(train/val) 70.63921/69.77336. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.40353/69.53593. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.18181/69.29676. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 69.94256/69.05674. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.78761/68.81340. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.51941/68.57243. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.30285/68.32844. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 69.00756/68.08439. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.78268/67.83689. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.49549/67.59133. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.24035/67.34203. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.97234/67.10049. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.56357/66.82893. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 67.22482/66.46499. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 67.01135/66.07310. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.61948/65.65831. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 66.30085/65.25138. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.97974/64.86282. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.60264/64.52003. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 65.37908/64.20909. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.07033/63.89442. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.88451/63.59946. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 64.66110/63.29549. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.49237/63.00701. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.20316/62.73573. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 64.08167/62.48246. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 63.73570/62.24841. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 63.60349/62.03979. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.49104/61.86485. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.43671/61.73604. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.30111/61.63397. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.25660/61.54178. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 63.03551/61.44623. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.96960/61.36494. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.97780/61.29234. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.90874/61.23042. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 62.84582/61.17696. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 62.62258/61.13319. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.64198/61.09408. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.57299/61.05354. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.57291/61.01936. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 62.41693/60.98606. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 62.36478/60.93927. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.25633/60.87549. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.27554/60.80074. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 62.13740/60.73425. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.09117/60.68850. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 62.03120/60.64812. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 62.02741/60.63561. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.89952/60.63541. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 61.83847/60.62965. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 61.78707/60.63320. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.73926/60.61665. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.90583/60.64081. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.69260/60.63993. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.67793/60.65921. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 61.76064/60.63515. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.67658/60.62440. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.42492/60.59413. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 61.59269/60.58341. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 61.59052/60.55455. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 61.27881/60.52998. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.49896/60.49710. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.33676/60.52272. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.34504/60.46852. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.26783/60.45490. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 61.29335/60.43052. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.36109/60.41392. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.33823/60.35347. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.13665/60.32380. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 61.00115/60.29474. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.14601/60.23516. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.98305/60.19377. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 61.07535/60.18035. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.02557/60.10367. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 60.98171/60.13416. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 60.98063/60.06345. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 60.95324/60.00623. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.84633/59.97241. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 60.69428/59.97212. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.75016/59.93899. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 60.76062/59.94392. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.82149/59.89095. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.72968/59.83244. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.64931/59.81042. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.54962/59.72989. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.53596/59.75050. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 60.58494/59.62246. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 60.59108/59.67743. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.39064/59.67640. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 60.46862/59.60637. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 60.45257/59.50824. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.48566/59.51793. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.48398/59.47633. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 60.31150/59.64262. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.30678/59.36166. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 60.22090/59.45704. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.36174/59.24717. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.18766/59.35352. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 60.22025/59.28322. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.013980301652228746\n",
      "Epoch 0, Loss(train/val) 70.51468/70.72515. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.31615/70.58307. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.15332/70.44041. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.95065/70.30260. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.71053/70.16883. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.54655/70.03487. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.43037/69.90223. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.21524/69.77219. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 69.05750/69.64038. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.85449/69.50642. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.75753/69.36594. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.59975/69.22179. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.39812/69.07515. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 68.26417/68.92525. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 68.13701/68.77427. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 68.01559/68.63050. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.84971/68.48389. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.69930/68.34924. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 67.60217/68.21529. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.49459/68.08131. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.26805/67.94601. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 67.17222/67.81608. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 67.02523/67.68509. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 66.89693/67.54450. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 66.73371/67.40497. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 66.65682/67.26268. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 66.44431/67.11453. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 66.32234/66.96289. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 66.27094/66.80972. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.05547/66.65112. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 65.89406/66.48698. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.72324/66.32647. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.69308/66.17381. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 65.54594/66.01450. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.42005/65.85456. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 65.38974/65.68997. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.22104/65.53592. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.11634/65.38271. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 64.86217/65.22760. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 64.78122/65.06862. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.73749/64.89537. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 64.51068/64.70673. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.31706/64.49695. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.07104/64.27152. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.02575/64.03404. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.93393/63.78170. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.59368/63.53880. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 63.40521/63.30886. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 63.40499/63.11999. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.21501/62.95270. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 63.06480/62.77520. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.91730/62.63680. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 62.68872/62.48373. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.77454/62.40355. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.68368/62.28510. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.47741/62.17260. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 62.38356/62.06929. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.24313/61.95766. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 62.22631/61.85912. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.17358/61.76852. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.05171/61.67431. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.86069/61.58687. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 61.98063/61.49346. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.80583/61.41278. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 61.77413/61.30188. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.73043/61.19056. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.48600/61.12139. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.77066/61.03328. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.63588/60.95833. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 61.42693/60.88393. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.40230/60.77319. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.29180/60.71854. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.22793/60.67671. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.47011/60.61155. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.09119/60.61978. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 61.47382/60.56637. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.35704/60.46002. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.89234/60.46843. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 61.10979/60.41943. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 60.97091/60.37929. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.82384/60.33252. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.91467/60.31240. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.88425/60.27063. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.74690/60.24795. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.76378/60.20919. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 60.73536/60.17663. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.72718/60.15595. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.46363/60.13838. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.43803/60.10759. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.56606/60.07814. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 60.49962/60.04782. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.54860/60.03469. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.40623/60.02193. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.40641/59.99992. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 60.31812/59.99309. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.30448/59.95501. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.21764/59.96029. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.25233/59.96863. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 60.06054/59.96007. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.07436/59.91334. Took 0.31 sec\n",
      "ACC: 0.625, MCC: 0.22392739182633167\n",
      "Epoch 0, Loss(train/val) 70.24851/70.76428. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.08490/70.75333. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.95330/70.74208. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.87004/70.73298. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.74924/70.72789. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.61208/70.71816. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.45737/70.71188. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.34762/70.70383. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.18362/70.69574. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.03356/70.68117. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.88751/70.64096. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.65374/70.57619. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.56557/70.48840. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 68.40385/70.37540. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.25039/70.23744. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.13172/70.10202. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 68.01399/69.95990. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.91305/69.80833. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.75130/69.65977. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.61340/69.49611. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 67.53040/69.33371. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.29374/69.16360. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 67.15949/68.97059. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 67.04864/68.78838. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.84137/68.60606. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.77124/68.41705. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.61328/68.22494. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.47375/68.03632. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 66.30098/67.85196. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.16730/67.66335. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.09515/67.48435. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.81480/67.31710. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.74771/67.15798. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.68823/66.99420. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 65.58331/66.84545. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.26286/66.69556. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.12894/66.53790. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.16239/66.39291. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.95236/66.25226. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 64.86878/66.11985. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.71087/65.98693. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.64446/65.87611. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.45814/65.77925. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 64.39469/65.70158. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.33761/65.61256. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.20479/65.54264. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.13958/65.48827. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 64.17950/65.44203. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.99111/65.40253. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.90157/65.37472. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.79743/65.36746. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 63.81716/65.35564. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.75554/65.32762. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 63.60885/65.31730. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.56792/65.31987. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.52833/65.38142. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.38601/65.39408. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.47383/65.42402. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.28036/65.51643. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.30207/65.62219. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.19168/65.64487. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 63.11541/65.77345. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.05735/65.85770. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 63.08551/65.84560. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 62.93556/65.96675. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.87179/66.08366. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 62.75646/66.16316. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.83184/66.15710. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 62.78833/66.11739. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.58248/65.99223. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.46605/66.15309. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.45723/66.08922. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 62.40013/65.99887. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.24178/66.23589. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 62.33172/65.80733. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.19915/66.19273. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.07872/65.70573. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.04023/66.21124. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.99789/65.63049. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 61.86769/66.25702. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 61.94991/65.65099. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 61.90670/66.35802. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.78031/65.68562. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 61.72655/66.18416. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.73451/65.85329. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 61.44658/66.23914. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.42089/65.89532. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 61.45074/66.20433. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 61.47663/65.80928. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.38113/66.27597. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.30581/65.90230. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 61.31545/66.41860. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 61.16743/65.84499. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 61.06053/66.47292. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.14199/65.86041. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.94224/66.35194. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 61.02639/65.88177. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 60.89031/66.37149. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.84204/65.88639. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.95724/66.27560. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.08072044179875086\n",
      "Epoch 0, Loss(train/val) 70.56750/71.09736. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.40606/71.10499. Took 0.34 sec\n",
      "Epoch 2, Loss(train/val) 70.29800/71.11571. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.21234/71.12827. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.02240/71.14386. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.91397/71.15695. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.73707/71.16805. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.58532/71.17596. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.43820/71.18398. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.31969/71.19059. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.12268/71.19244. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.96316/71.18875. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.79265/71.17486. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.68110/71.14774. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.44808/71.10709. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.25574/71.04669. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.17009/70.95430. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.02103/70.82809. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.78282/70.66672. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.62674/70.46210. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.37673/70.20519. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.26117/69.91380. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.01877/69.61453. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.87748/69.31860. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.71817/69.03738. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.64050/68.77276. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 66.48036/68.52279. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.44967/68.31610. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.37475/68.15135. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.14087/67.97112. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.25284/67.79997. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 66.12321/67.64159. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 65.98060/67.45705. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.92130/67.28210. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.78329/67.13499. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 65.81979/67.00651. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 65.73855/66.93261. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 65.58030/66.89631. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 65.73198/66.74114. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 65.52098/66.65025. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 65.50588/66.66238. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 65.49494/66.50719. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 65.24897/66.43073. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 65.33244/66.37389. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 65.29164/66.23531. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 65.10939/66.22702. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 65.11712/66.16022. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 64.95589/66.07359. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 64.91782/65.99126. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.69089/65.92164. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 64.71571/65.83539. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 64.67273/65.72170. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 64.58616/65.72547. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 64.47811/65.63378. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 64.49118/65.51068. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 64.42727/65.39989. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 64.31402/65.28991. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 64.23868/65.22152. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 64.23434/65.08113. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 64.29466/65.06924. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 64.00830/64.86964. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 63.95884/64.73553. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 64.06307/64.62298. Took 0.34 sec\n",
      "Epoch 63, Loss(train/val) 63.88324/64.57975. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.82829/64.57356. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.73106/64.53091. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 63.81430/64.41311. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 63.76027/64.36369. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 63.66596/64.39906. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 63.74652/64.40612. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 63.65893/64.31904. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 63.56944/64.23959. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 63.49924/64.30968. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 63.56004/64.40129. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 63.39364/64.38424. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 63.43061/64.51035. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 63.38515/64.30643. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 63.30333/64.44710. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 63.29267/64.43124. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 63.27569/64.41672. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 63.31991/64.35445. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 63.24683/64.33095. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 63.15494/64.35422. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 63.09361/64.34734. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.98790/64.02702. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.89940/64.17206. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.95460/64.25095. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 62.84228/64.11665. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 62.77519/63.90933. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 62.67663/64.25135. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 62.71054/64.20937. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 62.66014/64.12521. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 62.73476/64.16183. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 62.65784/64.23185. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 62.82596/64.16542. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 62.79346/64.29575. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 62.69277/64.35015. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 62.64331/64.19342. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 62.32835/64.18254. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 62.49641/64.22308. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.11124684011100254\n",
      "Epoch 0, Loss(train/val) 70.91024/70.62612. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.70992/70.40092. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.56045/70.17722. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.44257/69.94658. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.27448/69.70345. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 70.12404/69.45419. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.99943/69.19155. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.83959/68.90956. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.64370/68.60194. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.48067/68.27908. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.35102/67.94893. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.15019/67.59538. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.95777/67.22369. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.75015/66.83047. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.52252/66.41833. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.29446/65.99062. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.06155/65.55196. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.81410/65.10813. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 67.64888/64.66054. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.41081/64.21773. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 67.05136/63.76937. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.90546/63.32303. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.53959/62.86222. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.45006/62.41768. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 66.17874/61.99202. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.88187/61.59751. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 65.62931/61.21932. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.37122/60.87117. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.16207/60.56417. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.71140/60.28195. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.60970/60.01978. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.27884/59.77616. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 64.13831/59.57814. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.06331/59.45939. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.93931/59.36779. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.89192/59.28637. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.65763/59.21179. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.59713/59.14598. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.44432/59.09312. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 63.33914/59.05296. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.43227/59.00891. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.32129/58.97776. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.32294/58.94987. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 63.13938/58.92390. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.07846/58.90579. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.00739/58.89426. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 62.96303/58.88287. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.84273/58.87520. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.90812/58.86240. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.94221/58.84258. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.77684/58.84254. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 62.70647/58.84151. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 62.64356/58.84576. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.51614/58.83548. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.60153/58.83123. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.56832/58.83032. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.53624/58.82896. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 62.40683/58.80984. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.45144/58.78870. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 62.35209/58.78735. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.36582/58.78270. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.20150/58.77695. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.27712/58.76371. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.16622/58.76123. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.32296/58.73797. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.10747/58.72372. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.17420/58.71762. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.01050/58.71666. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.05421/58.69436. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 62.11681/58.68015. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.95285/58.66875. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.89596/58.64177. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.89056/58.62791. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.97091/58.61069. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.70005/58.59388. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.88393/58.58863. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.80140/58.56642. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.67539/58.54315. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.57061/58.50914. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.62866/58.49559. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.62174/58.47327. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 61.53802/58.46123. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.58147/58.42023. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.54789/58.41799. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.42616/58.40128. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.57066/58.36642. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.45056/58.32463. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 61.36180/58.31081. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.27090/58.28468. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.34209/58.25090. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 61.35702/58.23540. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.26264/58.20900. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.26830/58.19271. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.20263/58.16442. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.12720/58.12108. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.11482/58.08421. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.99591/58.05155. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.05963/58.02559. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.02753/57.99809. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.96907/57.96397. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.048507125007266595\n",
      "Epoch 0, Loss(train/val) 70.71147/70.55183. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.48390/70.38831. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.23200/70.23626. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.97159/70.08546. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.77164/69.93126. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.51243/69.77756. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.20676/69.61549. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.90988/69.44056. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.62084/69.25101. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.30609/69.03799. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.01205/68.79946. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.56669/68.53445. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.30915/68.24146. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.96115/67.93338. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.55607/67.62106. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.21554/67.31191. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.78055/67.00767. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.51731/66.70444. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.07672/66.40253. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.69055/66.10565. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.40532/65.82840. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.93466/65.54832. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 63.55699/65.26478. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.20692/64.97916. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.99192/64.71026. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.62773/64.46664. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.38764/64.22588. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.09126/63.99072. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 61.82853/63.76142. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.57528/63.53360. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.45700/63.32823. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.23859/63.13079. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.06399/62.93579. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.91674/62.76634. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.82582/62.61422. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.56337/62.48063. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.51547/62.33342. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.40192/62.17746. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.32669/62.02834. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.22312/61.89331. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.03122/61.76385. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.05898/61.64034. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.04713/61.50115. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.75578/61.37080. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.84007/61.29242. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.65716/61.18241. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.46290/61.06586. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 59.42574/60.92679. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.43174/60.83920. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.34455/60.73059. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.16449/60.65958. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.28861/60.64109. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.14600/60.67644. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.94877/60.55056. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.90559/60.48217. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.79942/60.43283. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 58.68505/60.36103. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 58.62914/60.26895. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 58.61037/60.22176. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.62743/60.14314. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.53550/60.11542. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.57254/60.06940. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.47622/59.97935. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.37953/59.93362. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 58.21040/59.82657. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.30651/59.76082. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 58.37661/59.67355. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.15702/59.52605. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.21745/59.53438. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.05721/59.45510. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.11786/59.43042. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.87073/59.29240. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.88256/59.27332. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.88674/59.19892. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.97120/59.17064. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.76461/59.05209. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.87013/59.00458. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 57.72951/58.93216. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.62754/58.88965. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.63162/58.79344. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.75648/58.74580. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.55585/58.73794. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 57.69049/58.67974. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.46598/58.57737. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.40586/58.57360. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.45916/58.47285. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.41308/58.55988. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.28248/58.36250. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.23157/58.53387. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.20454/58.27932. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 57.03783/58.47193. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.13829/58.25465. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.22296/58.37577. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.18583/58.29649. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.97324/58.34756. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.87826/58.42212. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.87480/58.25623. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.80525/58.40315. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 56.93328/58.24976. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.88635/58.31852. Took 0.32 sec\n",
      "ACC: 0.359375, MCC: -0.3323218506999783\n",
      "Epoch 0, Loss(train/val) 70.55288/70.59689. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.36747/70.51675. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.21630/70.44361. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.01372/70.37378. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.84883/70.30370. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.62348/70.23539. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.42288/70.16131. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.20970/70.07307. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.95001/69.96819. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.68563/69.84419. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.46726/69.69186. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.19050/69.51424. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.87271/69.30497. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.47778/69.06332. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.09850/68.78362. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.65170/68.47776. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.33124/68.17123. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 65.81578/67.87353. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.33690/67.58757. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.90893/67.33559. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 64.57130/67.12424. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.28806/66.94946. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.90335/66.79726. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.68646/66.67224. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.29624/66.57983. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.07567/66.50518. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 63.07876/66.45824. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.89889/66.41843. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.76010/66.36700. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.36435/66.30521. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 62.41882/66.23250. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.32402/66.17513. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 62.25241/66.13049. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.06202/66.09177. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.98085/66.04892. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.95094/65.99947. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.86645/65.94294. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.65630/65.87963. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.66659/65.81722. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 61.55944/65.76302. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.46109/65.68645. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.42946/65.60427. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.48142/65.50116. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.44116/65.38793. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.20413/65.28930. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.09973/65.18485. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.08307/65.08474. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.19858/64.97754. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.03481/64.84188. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.94095/64.67456. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.95835/64.55492. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.98362/64.40124. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 60.88336/64.25280. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.79089/64.09974. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 60.58155/63.95454. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.69589/63.80783. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.65611/63.68903. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.47736/63.56485. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.45954/63.48544. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.28823/63.40680. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.36593/63.20889. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.29058/63.05056. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.07005/62.97355. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.02414/62.86220. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.14308/62.81710. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.89784/62.72183. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.93584/62.65819. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.83663/62.57769. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.74780/62.56013. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.73767/62.45568. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.58938/62.37078. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.73147/62.32735. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.63598/62.30476. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.67188/62.22201. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 59.51628/62.11788. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.35369/62.16262. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.53205/61.99985. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.29542/62.01067. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.32415/61.93564. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.30350/61.83770. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.30252/61.81803. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 59.14076/61.72850. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 59.22228/61.69348. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.04304/61.67553. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.02716/61.57709. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.07377/61.58489. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.90636/61.54277. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.94600/61.45206. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.92674/61.53227. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 58.75704/61.37606. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.62410/61.44334. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.69407/61.31843. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.77636/61.43347. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.71295/61.25160. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.59734/61.46057. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.56574/61.25827. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.47719/61.43852. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.43000/61.18261. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.36402/61.36529. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.35844/61.12083. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.08222643447147887\n",
      "Epoch 0, Loss(train/val) 69.63554/70.83281. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.33187/70.65311. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.05658/70.47650. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 68.71665/70.32068. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.41511/70.17076. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.08266/70.03120. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.77185/69.90205. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 67.44492/69.78201. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 66.99519/69.66051. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.72355/69.53492. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.34589/69.40153. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.06663/69.25550. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.69725/69.09785. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.39771/68.93202. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 64.98869/68.75054. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.66963/68.55210. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.33020/68.31937. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.03252/68.03191. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 63.66652/67.75118. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.44807/67.46568. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.12362/67.14042. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.87548/66.77345. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.40520/66.43818. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 62.16054/66.15115. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.96862/65.88438. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.73983/65.62943. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.41053/65.39127. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.36991/65.21581. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.07250/65.05891. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.95941/64.95529. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 60.64561/64.83603. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.63736/64.74165. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.52581/64.64194. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.41135/64.57822. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.27221/64.56611. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.24225/64.49667. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.13219/64.43295. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.93885/64.36196. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.77080/64.31567. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.81795/64.26869. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 59.51570/64.23190. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.56439/64.20017. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.42911/64.14617. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.41860/64.13470. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.26950/64.10078. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.21305/64.08487. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 59.29802/64.05762. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.01193/64.06895. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.03141/64.07529. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.90666/64.04890. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.84503/64.03659. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 58.82387/64.04026. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.62625/63.98949. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.68380/63.86871. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.53840/63.80861. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.41236/63.76387. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.31275/63.82170. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.25227/63.73298. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.27361/63.67478. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.77522/63.73705. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.74768/63.52767. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.58292/63.70029. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.68658/63.86469. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 57.66318/63.46526. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 57.50725/63.70214. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.33018/63.75914. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.38956/63.65593. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.25698/63.81631. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.14786/63.83009. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.17795/63.63795. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.95710/63.62410. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.10070/63.41598. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.77147/63.70688. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.89174/63.65790. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 56.84627/63.30885. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.80349/63.47573. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.74773/63.62873. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.75295/63.43159. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.75935/63.23251. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.61803/63.45138. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 56.43558/63.12912. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 56.62971/63.81718. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.59927/63.24372. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.33400/63.71973. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.55351/63.23343. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.32037/63.34455. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.23012/63.40504. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.13280/63.27422. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.18479/63.30683. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 55.95902/63.22487. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.15215/63.32066. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.29717/63.66190. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.14821/63.36226. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.81576/63.36781. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.89235/63.26665. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.88096/63.45819. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 55.80899/63.44260. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.04013/64.03059. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 55.82896/63.66941. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.64324/63.92466. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: -0.012312225225925604\n",
      "Epoch 0, Loss(train/val) 70.52827/70.79715. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.28461/70.64545. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.07030/70.48378. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.87988/70.31992. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.68326/70.13853. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.45199/69.93153. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.24698/69.70711. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.95064/69.45711. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.69569/69.20433. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.41925/68.96709. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.15655/68.75699. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 67.84028/68.57964. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.49488/68.42924. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.17042/68.31518. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.88863/68.22789. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.52942/68.15726. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.24257/68.10136. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 66.06172/68.06712. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.83058/68.03819. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.58581/68.01290. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.37860/67.98476. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.23557/67.95384. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.99736/67.93399. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.86804/67.91917. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 64.77230/67.88669. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.56217/67.85110. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.51076/67.79361. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.42018/67.73414. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.27964/67.62370. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 64.23477/67.51168. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.06143/67.44721. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.99707/67.35447. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.96322/67.26771. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.75984/67.17362. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 63.72580/67.08239. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.64030/67.01487. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.59022/66.92986. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.54985/66.82906. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.50162/66.71816. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 63.30555/66.63030. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.25746/66.57736. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.25161/66.49208. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.20946/66.40376. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.00771/66.38554. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.89370/66.35464. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.85719/66.31184. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.78880/66.23731. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.63875/66.20257. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.73113/66.12173. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.68470/66.05712. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.49818/66.03552. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.48065/66.03905. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.37557/65.95403. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.37463/66.00993. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.24167/65.98804. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 62.19056/65.93031. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.09236/65.84470. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.04356/65.84248. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.98825/65.82988. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.87129/65.81149. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.80551/65.69513. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 61.84485/65.79879. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.71272/65.64804. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.68074/65.82872. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.64245/65.71836. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.56112/65.89243. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.60868/65.73368. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 61.44187/65.89722. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.24364/65.67305. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.37142/65.90177. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.29134/65.72054. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.36872/65.96269. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.12533/65.69048. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.21393/66.03996. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.01430/65.58075. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.16023/65.86407. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.95246/65.53193. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.95845/65.91621. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.74570/65.41447. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.00852/65.73994. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.67856/65.32719. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 60.84747/65.71844. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 60.72664/65.21030. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.67068/65.65151. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.69193/65.21252. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.52227/65.46402. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.52883/65.22297. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.55904/65.28326. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 60.53282/65.27752. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.42361/65.12577. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.47485/65.30405. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.44505/65.10194. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.31469/65.08847. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 60.22939/65.02275. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.26713/65.00243. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.27226/64.90290. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.14180/64.97025. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 60.20857/64.95872. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.14111/64.93612. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.15811/64.91151. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.1388738730621637\n",
      "Epoch 0, Loss(train/val) 69.61178/70.27690. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.34113/69.98611. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.03135/69.68427. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 68.74072/69.37965. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.45180/69.07228. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.12635/68.75749. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.82163/68.43298. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.56281/68.10095. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 67.25611/67.74676. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 66.93482/67.37392. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.57123/66.98196. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.21807/66.58339. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 65.92057/66.19399. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.55193/65.81960. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.13533/65.45601. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.93407/65.10826. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.66192/64.78928. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.46514/64.51192. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.21310/64.25950. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.98393/64.04095. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.77082/63.83971. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.74123/63.67360. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.51880/63.51666. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.43454/63.38317. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.34248/63.26104. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.18954/63.12721. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.08384/62.99943. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.97354/62.87531. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.83611/62.75359. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.87146/62.63065. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.52901/62.50447. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.54168/62.37302. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.42010/62.24669. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.41881/62.13261. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.12124/62.02807. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.03886/61.92139. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.99681/61.82981. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.88183/61.74704. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.90192/61.67122. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.79108/61.60527. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 61.80244/61.54491. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.82273/61.47729. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.79079/61.41737. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.56107/61.35802. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.57115/61.30786. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.44820/61.25302. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.52596/61.19623. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.60630/61.15766. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.35834/61.11295. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.32215/61.07154. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.33218/61.02356. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.23675/60.95958. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.26683/60.90375. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.16650/60.85109. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 61.22371/60.82937. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.20562/60.82524. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.95234/60.78749. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.09392/60.75261. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.04411/60.70084. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.06816/60.64224. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 60.94453/60.58955. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.98422/60.52960. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.84936/60.52787. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.80929/60.50192. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.72141/60.43945. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.83108/60.45150. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.64768/60.47011. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.58201/60.54795. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.64328/60.53307. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.52744/60.48125. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.50963/60.46476. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.50067/60.50485. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.36636/60.41712. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 60.39197/60.34351. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.34930/60.34732. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 60.30403/60.31425. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.40311/60.38616. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.21105/60.28512. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 60.33153/60.40049. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.11897/60.31715. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.33980/60.46166. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.25568/60.36363. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.20142/60.37766. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.00377/60.24625. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.08814/60.35813. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.99228/60.32314. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.93440/60.42808. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.85195/60.35387. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.86739/60.35766. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.83117/60.31757. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.68063/60.29782. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.68081/60.28353. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.62534/60.36950. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.61877/60.18988. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 59.53990/60.36622. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.63798/60.23783. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.70716/60.41968. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.55820/60.26544. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.56568/60.32558. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.49115/60.18262. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.06643282473893375\n",
      "Epoch 0, Loss(train/val) 71.34631/71.75444. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.12972/71.60041. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.94902/71.45041. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.75579/71.30913. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.55079/71.16632. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.38296/71.02855. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.17513/70.89120. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.99404/70.75292. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.78311/70.61131. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.58343/70.46246. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.39831/70.31488. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.20601/70.16773. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.96262/70.01603. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.80340/69.86531. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.57966/69.71427. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.38518/69.55797. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.23636/69.40086. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.01724/69.24802. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.80473/69.08704. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.62331/68.90939. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.46819/68.72479. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 67.31240/68.53420. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.09244/68.36544. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.00624/68.19054. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 66.76278/67.99337. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.53042/67.78262. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 66.57520/67.55629. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.38005/67.32066. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 66.00540/67.07150. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.00162/66.81888. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.75086/66.57786. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.62131/66.37671. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 65.36765/66.22976. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.22018/66.08986. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.90753/65.95358. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.79389/65.82399. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.64434/65.70095. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.63226/65.59058. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.36317/65.48137. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.17431/65.37706. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.98781/65.28684. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.85655/65.19476. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.87900/65.11126. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.76465/65.03455. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.60823/64.97366. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.53166/64.92219. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.35013/64.88320. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.30800/64.86077. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.10546/64.85190. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 63.06094/64.91141. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.92014/64.95008. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.91182/65.02226. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.77941/65.08754. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.74982/65.19254. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.63983/65.26630. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.31147/65.33840. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 62.39129/65.43559. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.18630/65.57381. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.98881/65.48475. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.05554/65.83984. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.27932/65.74501. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.99455/65.94659. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 61.74307/65.84203. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.85701/66.02703. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.68947/65.96336. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.76278/66.04039. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.58938/66.06859. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.53648/66.07339. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.54882/66.07523. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.48776/66.12639. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.33765/66.17839. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.46193/66.13294. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.38012/66.16101. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.41179/66.20373. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.31567/66.23216. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.47307/66.32463. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.32878/66.22565. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.43822/66.36416. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.15779/66.18345. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 61.25205/66.44604. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.28199/66.12123. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.20844/66.49984. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.11894/65.99905. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.15832/66.64153. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.09055/65.95687. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.95883/66.56065. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 61.07193/66.09345. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.07304/66.33496. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.99872/65.97871. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.16037/66.67842. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.92300/66.10397. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.88535/66.12363. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.99304/66.15359. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.96939/66.15221. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.82653/66.25879. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.07246/66.07202. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.70912/66.22321. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.91779/65.98812. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.08974/66.28250. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.84803/65.88326. Took 0.31 sec\n",
      "ACC: 0.515625, MCC: 0.09061004703659373\n",
      "Epoch 0, Loss(train/val) 71.18811/71.41831. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.01124/71.32031. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.81510/71.23284. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.62486/71.15125. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.43793/71.07730. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.22157/71.01646. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.03048/70.96378. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.87706/70.92270. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.63130/70.88377. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 69.43466/70.84475. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.18343/70.80037. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.01180/70.75002. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.78451/70.68966. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.64945/70.62554. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.56209/70.55913. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.38750/70.49501. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.25174/70.43481. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.07919/70.37550. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.09205/70.32125. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.93256/70.26649. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 67.79782/70.21592. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 67.66751/70.16127. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.55477/70.10339. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.53345/70.04243. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 67.32298/69.98123. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 67.26232/69.91959. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 67.09607/69.85763. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 67.13248/69.78781. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 67.04698/69.71617. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.88290/69.64544. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.89319/69.58060. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 66.69219/69.51245. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 66.61432/69.44743. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 66.61176/69.38786. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 66.50742/69.33120. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 66.41622/69.27624. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 66.27215/69.21688. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 66.16063/69.15596. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 66.15700/69.10161. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 66.11431/69.04110. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 65.97879/68.97348. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 66.01140/68.90772. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 65.95196/68.83969. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 65.87762/68.77125. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 65.75076/68.69411. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 65.79840/68.60728. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 65.58202/68.51362. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 65.58934/68.41165. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 65.50356/68.29784. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 65.45901/68.16998. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 65.36345/68.01801. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 65.07971/67.84533. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 65.04156/67.64425. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 65.07818/67.40612. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 64.95538/67.14592. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 64.79793/66.85942. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 64.72825/66.57841. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 64.65706/66.31197. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 64.46731/66.07891. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 64.40791/65.88458. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 64.28677/65.70689. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 64.14716/65.53833. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.90907/65.36346. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.68145/65.17897. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.77447/64.99849. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.41003/64.82299. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 63.31122/64.64777. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 63.08247/64.49394. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.76755/64.35041. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.78255/64.21811. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.66937/64.10863. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.48081/64.00703. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.17168/63.91861. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.17457/63.84405. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.01841/63.78252. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 61.86778/63.73413. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.76797/63.69264. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 61.74493/63.65659. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.80994/63.62474. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.67313/63.59014. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.59864/63.55959. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.49174/63.52027. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.50995/63.49453. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.33703/63.47050. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.36753/63.44605. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.33907/63.41941. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.07598/63.39213. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.11953/63.36297. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.99559/63.33784. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.08648/63.29535. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.13954/63.25857. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.97915/63.24900. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.87647/63.23380. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.99953/63.22610. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 60.70965/63.19818. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.76474/63.18369. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.81734/63.14676. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.82455/63.10204. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.78615/63.07758. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 60.46377/63.06132. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.021109792565893827\n",
      "Epoch 0, Loss(train/val) 70.48166/70.35679. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.31443/70.23907. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.09264/70.11741. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.92764/69.98770. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.67014/69.83849. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.49551/69.66682. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.22040/69.48151. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.95903/69.26875. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.76233/69.04620. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.45082/68.81053. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.19236/68.56634. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.83101/68.31417. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.65525/68.07477. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.43994/67.85017. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.13010/67.64544. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.81889/67.46447. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.51881/67.31647. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.26507/67.22357. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 66.05038/67.15399. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.87957/67.10187. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.69514/67.06444. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.61575/67.03981. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.53891/67.03048. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.33088/67.03146. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.17468/67.03551. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 65.00928/67.04192. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.85691/67.06402. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.92575/67.09047. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.57326/67.12241. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.60050/67.16270. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.44857/67.19955. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.51845/67.23632. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.42479/67.26801. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.30060/67.30423. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 64.20054/67.33638. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.92019/67.36709. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.97299/67.39040. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.87147/67.41122. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 63.68260/67.43252. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 63.81080/67.44296. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.67357/67.45518. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.52673/67.45536. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.46709/67.44941. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.33418/67.44433. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.26772/67.43187. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.10159/67.41862. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.03677/67.39093. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.94958/67.34750. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.06357/67.29637. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.76607/67.23506. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.61933/67.16728. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.73168/67.09395. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.41109/67.01897. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.39106/66.93632. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.19631/66.86406. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.07160/66.79535. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.97850/66.71556. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.09059/66.62997. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.93800/66.55013. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.84651/66.47165. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.84077/66.41463. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.80147/66.35068. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.60558/66.29836. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.62206/66.25652. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.51827/66.21156. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 61.51882/66.17008. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.46612/66.14487. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.31378/66.12722. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 61.31320/66.10881. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.17875/66.07912. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.42290/66.05608. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.25119/66.02140. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.92673/65.98992. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 61.12776/65.97569. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.17866/65.94971. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.25234/65.91373. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.07156/65.89548. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.07515/65.87743. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.75230/65.85577. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.04858/65.84431. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.89591/65.82179. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.90175/65.79774. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.01604/65.77831. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.76422/65.76350. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.87303/65.74596. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.74292/65.72157. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.74501/65.69250. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.84898/65.67164. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.85181/65.64989. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.67423/65.65039. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.72328/65.63180. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.76196/65.60235. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.73395/65.57198. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 60.53707/65.56751. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.44971/65.56564. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.50105/65.55146. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.55340/65.53378. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 60.62943/65.51228. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.50745/65.49277. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.42113/65.46396. Took 0.32 sec\n",
      "ACC: 0.5, MCC: -0.049286405809014416\n",
      "Epoch 0, Loss(train/val) 71.21255/69.26438. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.97398/69.31567. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.61812/69.37548. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.41702/69.44866. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.12181/69.52950. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.85697/69.61785. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.55887/69.70711. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.23654/69.78430. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.02653/69.84754. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.69792/69.89102. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.35265/69.91440. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.96925/69.90998. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 67.66414/69.89606. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.25761/69.84402. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.91373/69.74606. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.57184/69.62885. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.28291/69.47287. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.91023/69.29102. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.78756/69.08795. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.39421/68.88142. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.27164/68.67643. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 64.83905/68.45911. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.64827/68.25883. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.49054/68.08217. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.21893/67.92673. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.99982/67.79848. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.92067/67.68263. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 63.85523/67.58441. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.53771/67.49690. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.31461/67.41037. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.23695/67.32277. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.09641/67.24538. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.08185/67.17532. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.82883/67.11321. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.81084/67.06125. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.70429/67.01555. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.56902/66.98364. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.56354/66.95605. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.33689/66.94244. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.30191/66.94627. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.16864/66.96113. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.07224/66.99355. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.03680/67.03321. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 61.87215/67.08578. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.79086/67.17024. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.66741/67.25974. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.51549/67.33416. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.49332/67.39780. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.35311/67.42282. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.36112/67.46591. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.37275/67.58719. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.26819/67.73785. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.04847/67.75260. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.91625/67.75279. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.86129/67.85101. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.78343/67.92026. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.65098/68.07220. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.81552/68.11705. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.67854/68.12467. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.59323/68.20659. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 60.38239/68.39236. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.41473/68.39568. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.37284/68.44898. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.21668/68.60777. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.13518/68.68849. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.17252/68.68643. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.94013/68.81349. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.00482/68.81837. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.72801/68.87967. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.85559/68.96868. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.76477/69.02386. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.69681/69.02371. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.54641/69.14336. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.62310/69.15827. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.43076/69.35576. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.40971/69.29000. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 59.27010/69.50298. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.48276/69.26221. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.40664/69.55476. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.28618/69.38284. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.28107/69.66463. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.09503/69.38682. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.03506/69.68529. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.95213/69.46124. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.99614/69.66819. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.83656/69.50196. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.97285/69.66260. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.94435/69.47266. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 58.79500/69.74688. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.90163/69.59349. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.77708/69.75132. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 58.58608/69.55661. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.79270/69.77331. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.68120/69.49439. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 58.52804/69.81393. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.56771/69.58663. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.56872/69.85534. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.38177/69.68330. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.79510/69.78296. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.43089/69.71861. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.06348584335357274\n",
      "Epoch 0, Loss(train/val) 70.31328/71.27611. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.00675/71.31682. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.79539/71.33397. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 69.57554/71.34438. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.34171/71.35279. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.13432/71.35764. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.89440/71.37146. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.71070/71.38786. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.50384/71.40493. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.24930/71.42441. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.91555/71.44159. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.69122/71.44444. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.52650/71.42500. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.26402/71.38348. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.95698/71.31328. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.67682/71.21900. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 66.45584/71.11768. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 66.07811/71.03238. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.89358/70.97705. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.66989/70.93765. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.41955/70.91519. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.30651/70.90388. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.93898/70.90437. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.79944/70.91393. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.64997/70.92478. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.43335/70.93710. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 64.31030/70.94795. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.20173/70.96532. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.93503/70.97478. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.80995/70.98731. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.63617/71.00212. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.41465/71.01516. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.51579/71.02474. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.28972/71.00929. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.23034/70.98714. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.07835/70.96780. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.06098/70.94944. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.88776/70.92177. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.74122/70.86723. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.65638/70.80837. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.41926/70.73048. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.58094/70.67285. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.38865/70.58615. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.38474/70.53135. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.20581/70.42282. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.95635/70.32845. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.93567/70.25806. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.97699/70.19547. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.94370/70.10551. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.74960/70.02561. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.69400/69.91588. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.77981/69.78987. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 61.46262/69.63325. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.51913/69.51199. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.51294/69.39449. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.34924/69.25353. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.33558/69.20380. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.98912/69.09626. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.12811/69.02180. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.10303/68.96678. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.06121/68.86192. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.96298/68.81690. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.91088/68.78893. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.91304/68.58311. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.79382/68.52158. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 60.77110/68.42223. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.87492/68.35574. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.79087/68.30286. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.76683/68.13524. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.51723/68.06168. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.55555/68.04681. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.56138/67.98665. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.39285/67.94073. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.30842/67.91700. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.37650/67.75900. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.35476/67.76041. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.33620/67.73763. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.33269/67.70534. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.21323/67.71733. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.10278/67.55149. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 60.23479/67.57275. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.03272/67.55473. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.12217/67.57304. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.96787/67.58865. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.92678/67.47369. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.86173/67.52547. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.89373/67.58651. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.63324/67.64790. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.70701/67.65356. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.75692/67.64881. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.68212/67.70346. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.60167/67.69996. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.57834/67.76901. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.60721/67.76954. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.59355/67.75327. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.35478/67.77623. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.52823/67.81081. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.46345/67.79002. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.25286/67.80135. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.13571/67.85925. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.11559657831495045\n",
      "Epoch 0, Loss(train/val) 71.50297/71.73347. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.32786/71.56052. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 71.14876/71.38509. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.99256/71.21396. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.82092/71.04343. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.66899/70.86971. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.46572/70.70176. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.30090/70.53288. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 70.08281/70.36090. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.87204/70.18130. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.66675/69.98048. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.36472/69.74866. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 69.09722/69.48853. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.75547/69.18716. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.44485/68.83382. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.99037/68.42416. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.66406/67.98312. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.27660/67.53130. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.89255/67.09044. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.50104/66.68513. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.15910/66.32646. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.79735/66.02263. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.43532/65.81095. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.09738/65.65503. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.90454/65.53723. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.65942/65.46621. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.44932/65.56817. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.07403/65.47037. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.95873/65.26933. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.77290/65.01682. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.60973/64.73940. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.40023/64.44075. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.13905/64.05886. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.88423/63.87979. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.76321/63.53584. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.54643/63.20618. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.47458/63.19711. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.22126/63.21260. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.26036/63.20413. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.01887/63.32667. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 61.91014/63.51526. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.72387/63.70273. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.69418/63.89964. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.57223/64.10447. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.39802/64.21859. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.27608/64.48698. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.22574/64.66138. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.09944/64.53926. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.87848/64.73595. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.82971/64.82513. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.84878/64.79528. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.70158/64.68528. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 60.58002/65.10371. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.53998/64.67928. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.46257/64.54408. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.44690/64.96872. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.27640/64.83789. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.16716/64.76707. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.10262/64.74707. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 60.16533/65.03360. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.94951/64.59061. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.93895/64.55276. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 59.83712/64.81831. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.75669/64.34082. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.75083/64.41030. Took 0.34 sec\n",
      "Epoch 65, Loss(train/val) 59.72547/64.44129. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.82090/64.84646. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 59.58411/64.51144. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.64942/64.68642. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.41987/64.08572. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.57892/64.32995. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 59.44098/64.61758. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.37515/64.16061. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.32763/64.18062. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.33497/64.22225. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.21882/64.27475. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.05377/64.14116. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.22642/64.60706. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.02829/64.05678. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.02136/64.35463. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.99719/64.11796. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.77830/63.77178. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.83409/64.30137. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.77043/63.82188. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.96510/64.11850. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.65423/63.81846. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.59326/63.62579. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 58.47435/63.79815. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 58.71283/64.14291. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.55504/63.86391. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.50079/63.08531. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 58.43666/63.75508. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.46948/64.09359. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.11386/63.60057. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 58.07980/63.13410. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.13959/63.91288. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.05596/63.53386. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.04447/62.83147. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 58.14565/63.43518. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.87258/64.02002. Took 0.32 sec\n",
      "ACC: 0.40625, MCC: -0.19136555680572745\n",
      "Epoch 0, Loss(train/val) 70.86819/70.54246. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.66751/70.36896. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.52733/70.19482. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.32931/70.02277. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.18556/69.85246. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.96327/69.68152. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.78155/69.51553. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.56017/69.35871. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.37853/69.20841. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.17705/69.06707. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.97591/68.93194. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.77045/68.80883. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.52211/68.69112. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.32590/68.57812. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.13276/68.46747. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 67.83969/68.36282. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 67.69245/68.25561. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.42042/68.14062. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.32700/68.01912. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.00360/67.89266. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.82190/67.75793. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.64492/67.61412. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 66.47275/67.46435. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 66.35391/67.30756. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.16344/67.14248. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.09763/66.97495. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.86806/66.80177. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.83648/66.62905. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.67164/66.45236. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 65.50196/66.27207. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.45425/66.10592. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 65.33609/65.94144. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 65.16624/65.77774. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 65.11929/65.60714. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.05878/65.44694. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.86749/65.27733. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.80526/65.10997. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.59203/64.94344. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.59526/64.76517. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.28029/64.57340. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.18734/64.34400. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.00403/64.08948. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.66990/63.80581. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.45755/63.50188. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.36503/63.19429. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 63.07181/62.91203. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.03848/62.66442. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 62.90352/62.42384. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.62557/62.21924. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.58521/62.03345. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.53167/61.87106. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.30247/61.73029. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.14191/61.61286. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.07936/61.51937. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.86562/61.42863. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 61.77591/61.34812. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.67712/61.27829. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.61436/61.21095. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.49291/61.15316. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.55856/61.11025. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.37604/61.07613. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.47822/61.03508. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.22204/60.99906. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.10700/60.99610. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.89132/60.97563. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.06445/60.95592. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.91041/60.94637. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.83538/60.94886. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 60.87517/60.95446. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.68676/60.95086. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.55954/60.93624. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.65793/60.91612. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.51227/60.91658. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.48414/60.89993. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.50004/60.89389. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.56164/60.85830. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.46926/60.83796. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 60.26449/60.78290. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.25583/60.78436. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.18591/60.75999. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.20085/60.76943. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.08155/60.77199. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 60.04706/60.73737. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.98845/60.72479. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 59.91169/60.69688. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 59.86815/60.67624. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.97342/60.65834. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.92846/60.65892. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.81007/60.68746. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.94508/60.66461. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 59.54555/60.67936. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 59.63333/60.67579. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.77081/60.72287. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.72400/60.74849. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.59705/60.75636. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.53143/60.77322. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.61002/60.81490. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 59.60064/60.85112. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.42068/60.88086. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.37868/60.89077. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.11555252264060875\n",
      "Epoch 0, Loss(train/val) 71.42370/71.32458. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.22153/71.21702. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.12635/71.12309. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.98139/71.04135. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.86695/70.97048. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 70.76048/70.90306. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.61725/70.83778. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.51415/70.77216. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.36631/70.70134. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 70.24453/70.62677. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 70.06811/70.54372. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.92371/70.45400. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.74322/70.35534. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 69.64956/70.24875. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.39795/70.13016. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.23788/70.00625. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 69.08376/69.87715. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.89954/69.74100. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.75852/69.60326. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.54191/69.46808. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 68.43271/69.34221. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 68.20093/69.22339. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 68.10994/69.11428. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.87526/69.00711. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 67.75481/68.90334. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 67.58160/68.79762. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 67.48885/68.69023. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 67.29897/68.57650. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 67.17967/68.46499. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.99872/68.34654. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.81384/68.22282. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 66.60456/68.09584. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 66.33723/67.95409. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 66.11076/67.79704. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.86031/67.64009. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.66950/67.49478. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.53517/67.36673. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.38646/67.27450. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 65.25434/67.19087. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 65.15526/67.11009. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.99469/67.02956. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.92711/66.94684. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.91794/66.85932. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.67956/66.77352. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 64.68779/66.68056. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 64.51341/66.58298. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.47271/66.48216. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 64.37967/66.37379. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.37482/66.27051. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.21446/66.16278. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 64.18657/66.04287. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 64.13282/65.92141. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.98858/65.80679. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.91710/65.68592. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 63.86356/65.56887. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.63054/65.45552. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.64713/65.33142. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.74949/65.22562. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.56704/65.12793. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.42399/65.03145. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.36194/64.94228. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 63.35162/64.86021. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.41520/64.79771. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 63.38089/64.73853. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.10544/64.69726. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.17957/64.66700. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 63.11818/64.62883. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.97560/64.58971. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 63.00786/64.55393. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 63.06800/64.54051. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 63.02912/64.53156. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.85967/64.52242. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 63.01370/64.51096. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.86371/64.50853. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.69641/64.50406. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.90601/64.50966. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.66069/64.51884. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.79747/64.51792. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.65014/64.51860. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.61168/64.54644. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.59610/64.55876. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.42439/64.54762. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 62.55505/64.56027. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 62.49890/64.58224. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.49817/64.58183. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 62.47287/64.57401. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 62.30504/64.57519. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 62.35151/64.59522. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 62.27138/64.58315. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 62.23915/64.58768. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 62.19419/64.57760. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 62.20189/64.59781. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 62.11613/64.60548. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 62.06370/64.59474. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 62.26916/64.59854. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 62.07894/64.60146. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 62.15124/64.61113. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 62.07925/64.61098. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.84636/64.62787. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.77496/64.58564. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.0890972157191321\n",
      "Epoch 0, Loss(train/val) 70.84033/70.75523. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.64812/70.62336. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.50942/70.49123. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.31794/70.35706. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.14927/70.21992. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.94352/70.07971. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.79841/69.93352. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.58400/69.78088. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.42591/69.61475. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.15785/69.43710. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.90848/69.24288. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.70706/69.03211. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.40693/68.80116. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.14390/68.55182. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.93426/68.28523. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.58746/68.00889. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.17993/67.72263. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.84199/67.43483. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.51231/67.16189. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.11976/66.91469. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.83916/66.69295. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.40036/66.49525. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.20561/66.31797. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.82768/66.15860. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.72743/66.02241. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.36203/65.89857. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.19738/65.78307. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.10912/65.68591. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.01038/65.61069. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.62503/65.54276. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.68528/65.47187. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.45671/65.39339. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.40713/65.31491. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.20956/65.23736. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.16740/65.15852. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.04983/65.08122. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.93716/64.99867. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.77253/64.91765. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.57327/64.83978. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.57737/64.76367. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 62.50210/64.68567. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.21590/64.60915. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 62.22296/64.52739. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.10643/64.43851. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.02937/64.37011. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.87960/64.30489. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 61.86263/64.22794. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.55732/64.15569. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 61.61517/64.08796. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.62901/64.00890. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.50119/63.92567. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.46883/63.85348. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.33888/63.77443. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.12421/63.69228. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.15062/63.62013. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.01595/63.54902. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.96983/63.47935. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 60.93481/63.42236. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.91426/63.37159. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.97582/63.32233. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.79540/63.28471. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.69290/63.24538. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.59762/63.20739. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.76114/63.16161. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.58768/63.12538. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.61366/63.08487. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.44061/63.06573. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.40015/63.04880. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.33098/63.01998. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.17379/63.00001. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.12493/62.98118. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.16541/62.96811. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.14501/62.95363. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.99751/62.93328. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.02887/62.92365. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.90306/62.90187. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 59.77558/62.89041. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.79321/62.86302. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.58157/62.84284. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.55908/62.81825. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.65574/62.78576. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.48829/62.74234. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.46727/62.70207. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.43550/62.65968. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.42081/62.62796. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.46302/62.58130. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.47974/62.57268. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.41264/62.53639. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.20705/62.49023. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.31245/62.45930. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 59.14895/62.42240. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.17971/62.39502. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.10899/62.39737. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.19974/62.38782. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.95470/62.34896. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.10137/62.33379. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.94597/62.30773. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.92610/62.28897. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.98800/62.25889. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.95246/62.24406. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.10902649807579674\n",
      "Epoch 0, Loss(train/val) 69.77458/69.76941. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.56263/69.51474. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 69.38124/69.27148. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.19612/69.03474. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.00779/68.79605. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.84426/68.55458. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.61458/68.30164. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.35593/68.03079. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.04818/67.74091. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.83908/67.43252. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.56188/67.09943. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.27326/66.74168. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.94188/66.35119. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.63114/65.92284. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 66.17888/65.55966. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 65.85681/65.18971. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.43061/64.80892. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.06748/64.41105. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.76785/64.00713. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 64.23547/63.60345. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.01758/63.20635. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.59785/62.85894. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.40168/62.57806. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.16133/62.39326. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.86814/62.23009. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.84630/62.08470. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.62328/61.96363. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.67426/61.85799. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.43835/61.77438. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.37771/61.68156. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.20807/61.57616. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.14759/61.48683. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.09901/61.38461. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.03890/61.28398. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.82244/61.18231. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.64196/61.08541. Took 0.34 sec\n",
      "Epoch 36, Loss(train/val) 61.66021/60.98711. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 61.63423/60.88510. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.56054/60.78838. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 61.55274/60.70188. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.44200/60.61298. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.35025/60.51524. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.20302/60.44732. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 61.17763/60.39295. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.27518/60.34462. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.05810/60.29472. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.87715/60.25306. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.86058/60.22125. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.89597/60.18461. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.78467/60.17275. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.81172/60.14626. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.75660/60.12154. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.76586/60.08239. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.61505/60.05259. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 60.45051/60.03996. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.50499/60.01923. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.35322/60.01773. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.50203/59.97791. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.33254/59.96393. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.33255/59.93268. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.26964/59.94267. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.34676/59.89547. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.18046/59.90055. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.37997/59.85942. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.21642/59.88504. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.11554/59.83994. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.28465/59.84043. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.17158/59.80608. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 59.94206/59.79710. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.95236/59.77245. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.97587/59.75728. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.01008/59.75190. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.06425/59.74261. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.09681/59.72218. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.93340/59.72323. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.77716/59.70672. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.84159/59.70605. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.76221/59.68089. Took 0.35 sec\n",
      "Epoch 78, Loss(train/val) 59.92977/59.68470. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.79490/59.65492. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.74952/59.65257. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.82792/59.63067. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.65259/59.62931. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.71073/59.59619. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.70165/59.61766. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.80214/59.54418. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.60789/59.59956. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.64517/59.49413. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.52336/59.59799. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.57575/59.44780. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.60410/59.55837. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.50767/59.39250. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.53755/59.56002. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 59.55584/59.34918. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.39096/59.52989. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.39330/59.31387. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.53466/59.49969. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.42483/59.28926. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.38938/59.46669. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.49981/59.27713. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.09553751222296826\n",
      "Epoch 0, Loss(train/val) 70.84623/71.09349. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.70368/70.99435. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.50597/70.89816. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.36162/70.80231. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.26075/70.70741. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.12767/70.61332. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.95816/70.51840. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 69.81556/70.42169. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.64228/70.32548. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.43430/70.22757. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.24726/70.12199. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.04647/70.00989. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.79809/69.88597. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.51882/69.75142. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.29708/69.60709. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 67.98138/69.45658. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.75463/69.30214. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.47034/69.13986. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.22962/68.97221. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.90745/68.80127. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.61125/68.61819. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.36420/68.42661. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.08776/68.22997. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.94227/68.02213. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.71868/67.80315. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.63791/67.57579. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.34209/67.37157. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.15183/67.16335. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 64.97940/66.94653. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.84349/66.72920. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.74885/66.50816. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 64.63476/66.29700. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 64.46165/66.09627. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 64.21703/65.90337. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.13036/65.71627. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.02392/65.54401. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.71440/65.38211. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.72008/65.23450. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.60254/65.09847. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.60746/64.96134. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.35165/64.82085. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.27673/64.69781. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 63.27651/64.57152. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.26132/64.45828. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.22832/64.34409. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.03652/64.22005. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.90366/64.10645. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.95062/64.01213. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.07521/63.92399. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.83740/63.81955. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.84103/63.76553. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.87716/63.71200. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.62212/63.63098. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.77958/63.54702. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.69062/63.47588. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.65259/63.42314. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.53286/63.35415. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.51438/63.31017. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 62.35767/63.24610. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.54094/63.17331. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.44935/63.08937. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.21675/63.01940. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.20490/62.97170. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.26191/62.93600. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.16255/62.90158. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.09775/62.87171. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.32385/62.84218. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.19788/62.81583. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.14335/62.78498. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.16989/62.76215. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.99548/62.74138. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.07999/62.72537. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.96585/62.70253. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.95353/62.68727. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.00074/62.65142. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.02959/62.62698. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.02623/62.61012. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.83405/62.59260. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.79044/62.58972. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 61.74531/62.58100. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.84635/62.58044. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.87199/62.56831. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.77188/62.55132. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.70338/62.53281. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.64936/62.50554. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.74833/62.47965. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 61.73497/62.45735. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.61824/62.42938. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.58028/62.40259. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.64985/62.39762. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.61082/62.34197. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.37677/62.30421. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 61.40695/62.32586. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.41388/62.27966. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 61.36853/62.26955. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.36423/62.24860. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.29566/62.24747. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.37625/62.22772. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.24266/62.22429. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.12968/62.21629. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.1656833739159028\n",
      "Epoch 0, Loss(train/val) 70.04064/69.44911. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.74584/69.13607. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.50269/68.82813. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.22293/68.52884. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.93139/68.24251. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.63681/67.96536. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.36340/67.69630. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 67.98385/67.43298. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 67.71008/67.16940. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.35950/66.90245. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.04476/66.62054. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.73550/66.32025. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.45863/66.00644. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.14711/65.69382. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.81003/65.38260. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.56488/65.08189. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.17226/64.78212. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 64.94943/64.50210. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.62125/64.22693. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 64.50362/63.95475. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.23310/63.66935. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.84494/63.36238. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.70121/63.03218. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 63.53069/62.68507. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 63.23185/62.32890. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.05996/61.95132. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.96113/61.58445. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.70003/61.24030. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.67237/60.93738. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.51024/60.69274. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.30288/60.48326. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.30495/60.30891. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.24845/60.16070. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.19920/60.02845. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.11500/59.90087. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.05362/59.78714. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.00719/59.68637. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.93774/59.59015. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.96712/59.49393. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.73312/59.39376. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.79583/59.28483. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.59973/59.15461. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 61.57706/58.99579. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.45204/58.82274. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.36899/58.66055. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.24180/58.51597. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.07359/58.40627. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.04815/58.31599. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 61.05441/58.23433. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.95592/58.16233. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.98882/58.10034. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.77951/58.05287. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.72797/58.00204. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.72962/57.94622. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.67295/57.90282. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.61417/57.86432. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 60.62072/57.82170. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.51146/57.77995. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.53904/57.74659. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.41094/57.71486. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.33607/57.68780. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.27998/57.64441. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.34951/57.61754. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 60.46058/57.58704. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.39216/57.56006. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.26253/57.55688. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.30294/57.54098. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.25745/57.52129. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.15618/57.49197. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.14891/57.46909. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.20896/57.46148. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.15953/57.46278. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.07734/57.46010. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.92927/57.46689. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.96314/57.44422. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.00069/57.45759. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.85074/57.45195. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.94192/57.47409. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.96613/57.46482. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.92444/57.46243. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.78979/57.45316. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.59756/57.44854. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.70442/57.48222. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.57218/57.49941. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.43171/57.49311. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.68591/57.52014. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.50434/57.55539. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 59.61811/57.57209. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.51535/57.52081. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 59.46815/57.55973. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.59831/57.56817. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.32018/57.58286. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.14860/57.58790. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.27654/57.58824. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.31497/57.57637. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.30523/57.56846. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.31284/57.59065. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.22560/57.60835. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.22938/57.63814. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.06975/57.61816. Took 0.32 sec\n",
      "ACC: 0.421875, MCC: -0.12158607754020519\n",
      "Epoch 0, Loss(train/val) 70.62070/69.38882. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.38477/69.33286. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.20875/69.25982. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.07029/69.17224. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.92929/69.07323. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.68828/68.95452. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.42978/68.81461. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.20096/68.65698. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.97472/68.49191. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.67133/68.30658. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.29072/68.09784. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.90550/67.86152. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.62506/67.60870. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.13081/67.33996. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.67965/67.06956. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.19113/66.81289. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.88689/66.57674. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.44651/66.36707. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.07587/66.18182. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.59388/66.01039. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.36320/65.84095. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.97659/65.67063. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.79031/65.50500. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.53501/65.34627. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.16736/65.19507. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.17357/65.06252. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.92811/64.94926. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.93609/64.85749. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.72776/64.79900. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.61320/64.76606. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.41223/64.74249. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.36472/64.71511. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.46499/64.67018. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.14861/64.61154. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.06084/64.52641. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.18991/64.42526. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.90863/64.29033. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.86779/64.09315. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.77199/63.80735. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.83044/63.80033. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.69179/63.71341. Took 0.34 sec\n",
      "Epoch 41, Loss(train/val) 61.70800/63.71865. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.58137/63.71802. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.50874/63.62863. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 61.46216/63.56493. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.37540/63.69655. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.35358/63.51441. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.34091/63.61864. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.18182/63.41900. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.20245/63.67137. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.88350/63.40181. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.95676/63.65592. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.77340/63.44279. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.95258/63.59964. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.85715/63.43379. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.95359/63.55679. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.86543/63.41082. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.94148/63.50919. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.73195/63.41379. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.73051/63.40593. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.64187/63.37783. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.60744/63.37701. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.50098/63.26035. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.51681/63.34792. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 60.38036/63.21593. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.35745/63.25924. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.18623/63.23075. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.22063/63.15286. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.96953/63.20643. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.07087/63.14390. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.04109/63.13290. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.11555/63.14470. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.89714/63.17329. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.89073/63.17257. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.77153/63.19299. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.74391/63.11333. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.55361/63.03925. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.57424/63.07215. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.51084/62.95819. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.41967/62.92373. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.36364/62.98831. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.40796/62.91343. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.28034/62.84950. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.15653/62.84951. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.29500/62.76744. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.86810/62.75853. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.96013/62.76122. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.84896/62.75673. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.89895/62.70920. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.80729/62.71590. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.64712/62.71111. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.64527/62.60526. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.66201/62.63876. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.52935/62.64566. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.51427/62.59513. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.68473/62.57334. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.60758/62.62566. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.40386/62.57020. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.44663/62.58114. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.33604/62.57526. Took 0.33 sec\n",
      "ACC: 0.59375, MCC: 0.18461861664914886\n",
      "Epoch 0, Loss(train/val) 70.95088/70.03303. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.64992/69.76432. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.38035/69.48365. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.06204/69.18822. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.77771/68.87590. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.49099/68.54494. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.11634/68.17597. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.79787/67.77277. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.35768/67.31454. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.05562/66.79561. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.59665/66.21835. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.05123/65.59733. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.62836/64.96416. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.05694/64.34042. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.48284/63.71291. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.01770/63.07178. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.65907/62.40765. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.07972/61.73385. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.69097/61.06633. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.18845/60.45199. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.94159/59.90601. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.52980/59.45919. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.30587/59.09238. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.19280/58.79071. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.02249/58.53422. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.97206/58.31475. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.85312/58.12499. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.76145/57.95624. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.81240/57.81934. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.60569/57.70770. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.56957/57.60038. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.57034/57.51031. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.44258/57.41404. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.38099/57.34823. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.36363/57.29006. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 61.30388/57.23734. Took 0.34 sec\n",
      "Epoch 36, Loss(train/val) 61.28449/57.18195. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.35071/57.14371. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 61.30773/57.09916. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.31496/57.07335. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.00824/57.05193. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.14720/57.02531. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 61.02511/56.99568. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.11478/56.95726. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.11251/56.93370. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.16802/56.90694. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.94500/56.87903. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.11920/56.86344. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.95635/56.83865. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.08248/56.82372. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.93626/56.80127. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.98959/56.77651. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.79570/56.76820. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.81799/56.76121. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.85527/56.73722. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.91290/56.71252. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.65728/56.69396. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.83870/56.67273. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.77110/56.65618. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.59949/56.64482. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.64814/56.64441. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.68046/56.63158. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.57957/56.61401. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.65509/56.59119. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.69937/56.56670. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.59836/56.54479. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.63611/56.52977. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.61472/56.50561. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.39681/56.50475. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.39615/56.50332. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.45305/56.49091. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.47820/56.46595. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.46106/56.46529. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.42185/56.45249. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.21158/56.41888. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.25844/56.42039. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.20552/56.38611. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.00420/56.36485. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 60.06694/56.36077. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.20264/56.33047. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.12283/56.30047. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.13467/56.27827. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 60.02545/56.23828. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.97354/56.19991. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.06045/56.18720. Took 0.34 sec\n",
      "Epoch 85, Loss(train/val) 59.92509/56.16549. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.74039/56.13896. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.71199/56.10798. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.74792/56.08575. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.94878/56.03497. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.64473/56.00642. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.62913/55.99054. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.63269/55.95107. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 59.42266/55.92924. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.46931/55.87683. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.59041/55.84707. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.55615/55.81917. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 59.47015/55.77011. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.36959/55.73796. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.43298/55.71770. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.08449792771373392\n",
      "Epoch 0, Loss(train/val) 70.35555/70.53558. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.11566/70.20635. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.84309/69.84872. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.57209/69.46367. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.27007/69.04266. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.92567/68.57294. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.57962/68.06577. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.26855/67.54401. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.83610/67.01529. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.45650/66.48396. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.00559/65.95192. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.61413/65.43222. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.28730/64.94350. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.94756/64.48901. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.57617/64.06309. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.25857/63.67192. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.12525/63.31378. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.88681/62.99291. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.67002/62.70367. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.53059/62.44831. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.17976/62.23676. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.03592/62.04724. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.87933/61.87514. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.80630/61.72023. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.69843/61.57485. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.62862/61.43359. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.44679/61.29521. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.31336/61.16296. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.13489/61.04310. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.18022/60.93279. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.23489/60.83041. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.02727/60.73325. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.95590/60.64094. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.82412/60.57209. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.93926/60.50433. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.76105/60.44012. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.65791/60.37991. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.62046/60.32564. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.62734/60.26398. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.69615/60.19259. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.37279/60.13339. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.33070/60.07703. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.37637/60.01993. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.44857/59.96090. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.22905/59.89227. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.30366/59.82591. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.33681/59.79163. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.14359/59.74726. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.17207/59.65595. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.05746/59.58157. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.09268/59.54490. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.91543/59.48603. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.79693/59.41354. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.69655/59.33181. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.60198/59.30262. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.64633/59.25715. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.64822/59.21756. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.48099/59.18692. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.40086/59.07936. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.34847/59.03144. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.26620/59.02553. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.19357/58.92852. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.18644/58.90984. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.21298/58.81644. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.91172/58.71083. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.03393/58.70259. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.87333/58.60510. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.88837/58.54347. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.86539/58.47181. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.82200/58.37449. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.83002/58.32402. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.60714/58.28756. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.65479/58.28342. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.64446/58.16735. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.55889/58.21054. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.61672/58.03151. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.36787/58.22734. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.51707/58.02921. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.33437/58.10672. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.45235/57.98643. Took 0.34 sec\n",
      "Epoch 80, Loss(train/val) 60.33936/58.13062. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.43639/57.90482. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.30347/58.08391. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 60.37424/57.78517. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.30900/58.07968. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.36431/57.75659. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 60.33400/58.02351. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.40207/57.81376. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.21041/57.97296. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.11346/57.81028. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.05808/57.91847. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.17802/57.84553. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.08364/57.86398. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.16687/57.88130. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 60.08074/57.83322. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 59.79070/57.83595. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.00459/57.77289. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.94607/57.78321. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.97239/57.74080. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.84652/57.67702. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.018049705127885604\n",
      "Epoch 0, Loss(train/val) 70.20965/70.31333. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.03222/70.19392. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.87472/70.07535. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.67560/69.95262. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.46432/69.82521. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.22795/69.68591. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.03926/69.53596. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.76081/69.37546. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.44334/69.19795. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.18089/68.99697. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.86389/68.76492. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.35396/68.49260. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.96014/68.18416. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.46688/67.85225. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.97358/67.51127. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.40441/67.17039. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.19752/66.83547. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.76830/66.56210. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.51462/66.30170. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.33495/66.05589. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.06353/65.82669. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.81953/65.60398. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.71831/65.39628. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.49163/65.19370. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.34131/64.99000. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.15330/64.78327. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.92336/64.56637. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.66846/64.35175. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.53577/64.16060. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.45165/64.00352. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.13529/63.87334. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.93949/63.73322. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.83940/63.60810. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.51783/63.52037. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.50483/63.41339. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.27499/63.31414. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.15064/63.24154. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.05321/63.16044. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.92917/63.08109. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.83043/63.02243. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.82024/62.97424. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.55739/62.92351. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.42429/62.82952. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.25835/62.80494. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.27317/62.77426. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.23666/62.76814. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.08399/62.68417. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.92622/62.63071. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.80050/62.66768. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 59.68522/62.57257. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.50229/62.58932. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.38206/62.47737. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.37960/62.46704. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.35046/62.47172. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.23708/62.42955. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.30633/62.38802. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.96133/62.44526. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.05800/62.34524. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.88857/62.32093. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.86687/62.39724. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.58899/62.18736. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.40544/62.08544. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.32928/62.20274. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.24687/62.01683. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.14271/62.11537. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.06431/61.82119. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.90463/62.10969. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.93284/61.98305. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.75843/62.26889. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.56484/61.84511. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.48981/62.09875. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.45634/62.01043. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.19112/61.98032. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 57.03123/61.99273. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 56.97261/61.96735. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.76215/61.84135. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.67409/61.96342. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.57984/61.85313. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 56.29735/61.95914. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.25240/61.75548. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 55.87168/61.83129. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 55.66525/61.63441. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 55.58303/61.57569. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 55.38007/61.52010. Took 0.34 sec\n",
      "Epoch 84, Loss(train/val) 55.19308/61.08179. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.12920/61.59954. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 54.93496/61.27818. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 54.98539/61.12886. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 54.72708/61.11654. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 54.94163/61.14978. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.07620/61.38554. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.25461/61.93393. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 54.72928/60.98476. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 54.22089/61.32439. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 54.08532/61.26868. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 54.17109/60.76974. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 54.12285/60.68687. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 54.51862/61.23688. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 54.87784/61.28553. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 54.33307/60.83011. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: -0.0010820172848339962\n",
      "Epoch 0, Loss(train/val) 72.00787/70.91629. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 71.71516/70.79021. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.49338/70.67247. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 71.29035/70.55870. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 71.02010/70.44160. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.81506/70.31550. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.56596/70.18314. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.30631/70.03990. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.10788/69.88035. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.80919/69.70081. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.52429/69.49873. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.16986/69.25549. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.82547/68.98186. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.40042/68.68098. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.99192/68.36447. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.58269/68.04285. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.11975/67.72557. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.72437/67.40900. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.33303/67.10240. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 65.63356/66.81382. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.09794/66.55641. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.57947/66.31688. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.07530/66.07938. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.63518/65.79089. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.06900/65.40655. Took 0.34 sec\n",
      "Epoch 25, Loss(train/val) 62.66247/64.88847. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.08635/64.26578. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.66748/63.63772. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.39595/63.09958. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.90567/62.69174. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.54075/62.37706. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.47435/62.14518. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.02680/61.94685. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.90243/61.78751. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.82321/61.64215. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.67644/61.50997. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.66068/61.39176. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.42900/61.27863. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.29875/61.16959. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.32932/61.06419. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.31137/60.95471. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.16206/60.83335. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.09605/60.71615. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.05819/60.60366. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.85491/60.50617. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.12484/60.36815. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.87644/60.26970. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.69008/60.25089. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.62971/60.19017. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.50298/60.13033. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.44566/60.04379. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.32763/59.96222. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.54979/59.87501. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.25112/59.75802. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.34624/59.65847. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.34184/59.59890. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.12592/59.49365. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.08569/59.41901. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.93738/59.29847. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.97336/59.21933. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.87627/59.17841. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.86771/59.07388. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.66176/58.91788. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.58336/58.87379. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.73467/58.74255. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.55408/58.67060. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.62738/58.61621. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.28002/58.55066. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.50482/58.46669. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.40540/58.44761. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.48474/58.32072. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.29725/58.35863. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.18761/58.24173. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.27456/58.24807. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.20377/58.19321. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.15674/58.23189. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.10183/58.08005. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 57.15690/58.20970. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.99847/58.05759. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.94404/58.00681. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.90229/58.01508. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.98735/57.99673. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.02807/58.01027. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.76740/57.99090. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.86133/57.92302. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.84424/57.89315. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.68718/57.87441. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.75508/57.90365. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.62512/57.83587. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.64227/57.81968. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.54757/57.79390. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.62124/57.74979. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.63124/57.75023. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.61771/57.73235. Took 0.34 sec\n",
      "Epoch 94, Loss(train/val) 56.53197/57.69352. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.38442/57.66076. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.38101/57.72663. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 56.56923/57.66817. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.30734/57.63666. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.55916/57.63758. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: 0.038252504425632605\n",
      "Epoch 0, Loss(train/val) 71.19957/72.05342. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.97082/71.73930. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.71600/71.42997. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.50120/71.12872. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.24635/70.81609. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.02714/70.48627. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.76807/70.13767. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.46112/69.76270. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.15365/69.35831. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.89072/68.92671. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.51545/68.46503. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.18281/67.98392. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.75823/67.47661. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.29431/66.94098. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.87868/66.38512. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.35095/65.79205. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.81721/65.15175. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.24612/64.60024. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.65667/64.07058. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.23599/63.57214. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.61898/63.21299. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.16796/62.88461. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.90224/62.60785. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 62.34532/62.37835. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.12741/62.22765. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 61.65116/62.14896. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.25478/62.13728. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 61.19784/62.16194. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.93427/62.20042. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.72603/62.22855. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.57988/62.24588. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 60.42569/62.25325. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.22018/62.26726. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.14768/62.26874. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.04621/62.27508. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.18555/62.26733. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.02134/62.25788. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.04963/62.24611. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 59.77639/62.22688. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 59.79145/62.21238. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 59.69903/62.19552. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.63834/62.17476. Took 0.34 sec\n",
      "Epoch 42, Loss(train/val) 59.63360/62.16245. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.52303/62.13943. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.52977/62.11093. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 59.39768/62.08294. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 59.24556/62.04478. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 59.29947/62.00529. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.21857/61.95818. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 59.01793/61.90089. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.04132/61.82111. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 58.92234/61.73344. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 58.70539/61.61669. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.86912/61.51133. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 58.58404/61.39795. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.69904/61.28192. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 58.50484/61.21656. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.30628/61.11112. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.28304/61.03880. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.26142/60.95130. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.12253/60.88310. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.05828/60.81479. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.13106/60.73953. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 57.89116/60.68363. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.03936/60.60406. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.79056/60.52422. Took 0.34 sec\n",
      "Epoch 66, Loss(train/val) 57.76943/60.46534. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.67019/60.41714. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 57.56164/60.34624. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.44607/60.29930. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.47739/60.23360. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.30884/60.19130. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 57.55443/60.13220. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 57.54474/60.10251. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.39952/60.02737. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.11935/59.95940. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 57.57068/59.90887. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 57.51934/59.87852. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.20937/59.82425. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.15380/59.73854. Took 0.34 sec\n",
      "Epoch 80, Loss(train/val) 57.22936/59.69566. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 57.10768/59.67894. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.84537/59.59573. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 57.17918/59.58010. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.81348/59.50189. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.91264/59.49699. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.95966/59.43218. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.93743/59.41188. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 56.65787/59.37239. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 57.04144/59.31921. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.82535/59.30796. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.56971/59.23880. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.64653/59.28188. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.44668/59.19912. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 56.35694/59.19340. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.61837/59.12668. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.56283/59.16864. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.29914/59.14639. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 56.31342/59.11868. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.39603/59.08907. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: -0.04750168687962835\n",
      "Epoch 0, Loss(train/val) 70.87695/71.03058. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.73454/70.92614. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.56636/70.82207. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.43740/70.71788. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.32780/70.61464. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.16784/70.51103. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 70.06043/70.40453. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.89424/70.29417. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.73250/70.18046. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.55570/70.06164. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 69.36159/69.93859. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.24236/69.80276. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.02198/69.65419. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.87947/69.49322. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.60011/69.31192. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.41357/69.11298. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.16167/68.88972. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.91115/68.64327. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.54234/68.35713. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.20286/68.01202. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.72502/67.60080. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.22745/67.10072. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.80963/66.49513. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.14754/65.80968. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.62609/65.19019. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.09039/64.68134. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.82643/64.31850. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.46858/64.02287. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.06627/63.76968. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.93800/63.55609. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.72013/63.37727. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.55748/63.23314. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.49664/63.11206. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.41998/63.00840. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.23995/62.92089. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.24431/62.85815. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.05943/62.80719. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.08237/62.76640. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.79335/62.73046. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.74001/62.70105. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.88140/62.67600. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.67368/62.65776. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.55520/62.64016. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.67627/62.62405. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.61215/62.60956. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.41284/62.59747. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.50326/62.58916. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.45963/62.57996. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.42934/62.56678. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.34466/62.55071. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.24369/62.53735. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.31803/62.52876. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.24201/62.51916. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.10355/62.51521. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.16570/62.50336. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.11642/62.49652. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.06898/62.49445. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.03387/62.49526. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.91448/62.48462. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.96151/62.48660. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.02516/62.48235. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.85326/62.48212. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.88963/62.48677. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.91512/62.47909. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.78525/62.45945. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.86721/62.45152. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.68633/62.45765. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.88307/62.46687. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.78122/62.46382. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.66007/62.45847. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.72183/62.45075. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.61075/62.45579. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.82821/62.44772. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.56628/62.44707. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.53665/62.43639. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.48170/62.43884. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.60218/62.43390. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.45697/62.43264. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.55013/62.43834. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.74289/62.44175. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.50437/62.43889. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.50890/62.43472. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.57141/62.44007. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.32558/62.42502. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.34204/62.41839. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.33212/62.42435. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.43421/62.42412. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.34819/62.41458. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.40168/62.41827. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.34545/62.42249. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.23589/62.39570. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.21910/62.40084. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.19638/62.41721. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.27074/62.42178. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.37633/62.40534. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.09124/62.39039. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.08174/62.40083. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 60.07730/62.39946. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 60.13774/62.38259. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.98864/62.39112. Took 0.32 sec\n",
      "ACC: 0.390625, MCC: -0.21202254684706773\n",
      "Epoch 0, Loss(train/val) 71.13388/70.40105. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 71.03324/70.38042. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.95583/70.36231. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.86969/70.34490. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.80877/70.32621. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.70843/70.31133. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.62248/70.29435. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 70.56680/70.27077. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.48480/70.24815. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 70.39034/70.22057. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 70.35455/70.19187. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 70.21797/70.15662. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 70.18075/70.12482. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 70.07933/70.08769. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 70.02004/70.04888. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.91078/70.00325. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 69.77235/69.95317. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 69.65670/69.89034. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 69.54890/69.82807. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 69.43261/69.75251. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 69.28037/69.65524. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 69.19848/69.54430. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 69.01272/69.41902. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 68.83173/69.27644. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 68.70294/69.11556. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 68.40609/68.94083. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 68.17043/68.75148. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 67.95402/68.56006. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 67.83588/68.36093. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 67.54333/68.16226. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 67.25690/67.99006. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 67.05965/67.87080. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 66.96435/67.75938. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 66.65468/67.66180. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 66.49343/67.56838. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 66.35899/67.46393. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 66.20316/67.35885. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 66.03820/67.23972. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 65.81486/67.13516. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 65.71289/67.03315. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 65.57651/66.93087. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 65.43589/66.84181. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 65.43077/66.75172. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 65.09992/66.66781. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 65.16932/66.58236. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 65.01377/66.50826. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.84207/66.45225. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 64.83538/66.39902. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.73179/66.34775. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.69429/66.21581. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 64.48229/66.19769. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 64.61967/66.04783. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 64.37748/66.11288. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 64.21660/66.03450. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 64.06740/66.11282. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 64.03162/66.01710. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.79140/66.00321. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.70402/65.94216. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.68064/65.83249. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 63.54857/65.91052. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.52622/65.91838. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 63.55409/65.65110. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.31253/65.83448. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.25056/65.78835. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.25655/65.75957. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.11434/65.69656. Took 0.34 sec\n",
      "Epoch 66, Loss(train/val) 63.28251/65.77636. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 63.09837/65.09721. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.94901/65.26120. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 63.10521/65.74913. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 63.17139/65.81591. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.88448/65.49374. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.71541/65.77679. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.66688/65.64797. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.61401/65.78365. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.54980/65.54681. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 62.52197/65.73795. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.40851/65.72112. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 62.36492/65.67605. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.23022/65.58096. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.20047/65.06682. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.39192/65.08799. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 62.07766/64.89327. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.84745/65.30563. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 61.87581/65.07248. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.05581/65.52229. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.08382/65.50515. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.91816/64.93920. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 61.62379/65.74265. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.85790/65.50217. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 62.05219/65.54613. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.65084/65.54345. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 61.71171/65.56988. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.40659/65.72054. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.55796/65.46511. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.18398/65.59042. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.42113/64.91285. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.60997/65.41615. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.20927/65.81254. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 61.19745/65.60910. Took 0.32 sec\n",
      "ACC: 0.40625, MCC: -0.17845494786936686\n",
      "Epoch 0, Loss(train/val) 71.26474/70.14260. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.10592/70.22015. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.92333/70.28397. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.77127/70.35540. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.65470/70.42690. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.47106/70.49532. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.29967/70.55842. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 70.17745/70.62133. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.97434/70.67652. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.84558/70.73184. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.67304/70.77815. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.47093/70.81877. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 69.38291/70.85007. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.17394/70.87798. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.97424/70.89283. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 68.79407/70.89566. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.67215/70.88817. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 68.46808/70.87466. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.31196/70.85581. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.14264/70.83217. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 68.00412/70.80589. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.89436/70.77466. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.78408/70.74397. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.63682/70.70891. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 67.51361/70.67439. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 67.38650/70.63829. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 67.19866/70.59743. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 67.18351/70.54699. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 67.02392/70.49249. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.88921/70.43273. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.79504/70.35651. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 66.71894/70.28515. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 66.55185/70.20002. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 66.41741/70.11111. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 66.28527/70.00561. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 66.20578/69.89668. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.99911/69.77732. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.90120/69.65121. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 65.69501/69.52837. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 65.67261/69.39706. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 65.45902/69.27473. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 65.36742/69.17374. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 65.28897/69.07814. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 65.08803/68.97070. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.81815/68.85008. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.94805/68.74035. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 64.76028/68.63322. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 64.68943/68.54054. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 64.41556/68.43822. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.28230/68.32119. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 64.16662/68.17645. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.96707/68.03869. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 64.16092/67.94283. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.92874/67.83555. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.90081/67.73286. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 63.74918/67.62749. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.58842/67.52711. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.55474/67.45572. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.48092/67.38660. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 63.33383/67.29812. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.21135/67.21855. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 63.12726/67.15376. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.12905/67.08381. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.89206/67.01582. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.86809/66.96784. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.71578/66.93120. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.70802/66.88393. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.67775/66.84496. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.60609/66.83675. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.48512/66.78665. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 62.47168/66.77649. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.29023/66.72834. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.20476/66.71056. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 62.08179/66.69473. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.10630/66.65457. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.97411/66.67178. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.92001/66.59904. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.89526/66.59707. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 61.81853/66.55180. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.83413/66.62904. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.61687/66.49859. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.47773/66.62126. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.59812/66.45297. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.56577/66.65262. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.57009/66.57576. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.53979/66.72551. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.48376/66.58624. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.46882/66.69975. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.36505/66.62222. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.34020/66.70244. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.20995/66.79534. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.15114/66.74881. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.13968/66.76448. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.09431/66.91018. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.01882/66.70148. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.09814/66.98909. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.23106/66.72743. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.99237/66.93034. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.95325/66.87310. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.99763/66.93521. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.05514348094667237\n",
      "Epoch 0, Loss(train/val) 70.36004/70.35146. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.15916/70.15381. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 69.95679/69.94984. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.73727/69.73633. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.51171/69.50879. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.24217/69.25403. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.92729/68.95428. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.57475/68.58944. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.12999/68.14502. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.60413/67.59998. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 66.89909/66.96159. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 66.07870/66.29782. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.31883/65.70000. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 64.64090/65.30867. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.15000/65.02349. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.71449/64.81215. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.48518/64.65176. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.36159/64.52212. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.05452/64.41996. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.08510/64.33307. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.97716/64.27599. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.86578/64.21490. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.75124/64.15897. Took 0.34 sec\n",
      "Epoch 23, Loss(train/val) 62.80390/64.09814. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.40758/64.03824. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.65123/63.98911. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.58073/63.92519. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.47936/63.85343. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.31994/63.79407. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.28227/63.71162. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.17196/63.65593. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.15144/63.57663. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.05327/63.50190. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.95990/63.46509. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.87430/63.44817. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.77344/63.40562. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.65244/63.39988. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.59306/63.41341. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.51088/63.37986. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.44313/63.36643. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.33838/63.35173. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.20793/63.34436. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.10652/63.31207. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.11848/63.30577. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.02321/63.28328. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.92799/63.24023. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.82159/63.20461. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.76854/63.19920. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.73032/63.15288. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.81657/63.09271. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.52292/63.02377. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.61310/62.94419. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.59556/62.85188. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.60418/62.81240. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.47277/62.69876. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.35617/62.67128. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.25230/62.54947. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.31158/62.51572. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.24128/62.38353. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.17786/62.43074. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.96818/62.29647. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.08912/62.30453. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.98668/62.20210. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.84559/62.18695. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.96720/62.15722. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.86282/62.12549. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.80519/62.09079. Took 0.34 sec\n",
      "Epoch 67, Loss(train/val) 59.82497/62.12166. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 59.52358/62.08326. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.69951/62.03230. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.61690/62.00189. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.45715/61.97874. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.42093/61.98014. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.33734/61.96438. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.45665/62.00223. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.30599/61.97861. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.16230/62.00709. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.28029/61.91530. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.31994/61.92345. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.21574/61.93676. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.18496/61.92097. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.09497/61.85791. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.95639/61.93734. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.02008/61.84888. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.06648/61.85387. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.84506/61.87317. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.80301/61.85679. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.73601/61.84539. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.68501/61.86582. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.83267/61.83078. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.68129/61.80816. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.78527/61.76140. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.51449/61.72769. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.62116/61.74822. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.56405/61.73479. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.59600/61.71697. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.36011/61.71141. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.33436/61.70302. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.51639/61.68430. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.47105/61.60088. Took 0.32 sec\n",
      "ACC: 0.640625, MCC: 0.25575002517077644\n",
      "Epoch 0, Loss(train/val) 71.04830/70.74812. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.79617/70.63962. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.60478/70.53663. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.42190/70.43748. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.19232/70.33914. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.00024/70.22968. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.75699/70.10733. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.54192/69.97272. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.30784/69.82775. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.02838/69.66515. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.74471/69.49327. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.41359/69.29747. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.03022/69.09128. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.62970/68.88461. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.19941/68.67000. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.76000/68.45062. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.32030/68.23610. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.77441/68.02241. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.27089/67.80592. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.83521/67.59040. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.36434/67.37275. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.84308/67.15652. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.44132/66.93827. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.18199/66.74230. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.93065/66.57095. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.57978/66.40489. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.23546/66.24432. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.06352/66.08919. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.83654/65.94308. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.53829/65.79785. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.28986/65.65167. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.09864/65.50108. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.05700/65.35345. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.78259/65.22390. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.50771/65.12137. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.45553/65.03565. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.24722/64.95423. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.04029/64.87969. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.96677/64.82244. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.69387/64.77789. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.69987/64.72518. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.66814/64.67501. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.53508/64.62730. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.56222/64.58702. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.33164/64.54819. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.12707/64.50395. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.18635/64.46751. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.04859/64.43063. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.07911/64.41441. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.01494/64.39642. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.98843/64.37997. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.01723/64.33798. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.76516/64.29069. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 58.70901/64.26347. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.80955/64.21218. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.66568/64.16492. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.47045/64.14795. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.57599/64.12173. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.54030/64.08042. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.42205/64.05321. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.44833/64.00381. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.38529/63.98617. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.34769/63.98570. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.14190/63.98915. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.28467/63.92187. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.23419/63.94636. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.17053/63.87247. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.20790/63.88005. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.07863/63.90147. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.87468/63.80643. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.00908/63.84705. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.92130/63.72470. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.97625/63.80148. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.92816/63.69558. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.75280/63.86799. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.90187/63.69983. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.82706/63.86181. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.65034/63.63858. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.78250/63.92176. Took 0.34 sec\n",
      "Epoch 79, Loss(train/val) 57.74130/63.62799. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.48166/63.81906. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.67915/63.69633. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.60157/63.72837. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.51473/63.65722. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.59603/63.76609. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.34349/63.84519. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.46844/63.77785. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.55716/63.83836. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 57.56494/63.72033. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.49801/63.95584. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.35693/63.73196. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.35422/63.84911. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.37217/63.91946. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.22206/63.79632. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.18427/64.03436. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.17095/63.84803. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.17374/64.12859. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.29114/63.90089. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.07134/64.20058. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.23863/63.92475. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.1229526932416184\n",
      "Epoch 0, Loss(train/val) 70.48284/70.20644. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.32454/70.03043. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.17404/69.84041. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.97354/69.63539. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.81419/69.42630. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.53636/69.21117. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.39358/69.00185. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.16771/68.79728. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.90643/68.58344. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.71665/68.35458. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.48079/68.11481. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.22286/67.86263. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.97220/67.61250. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.70294/67.38123. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.41493/67.17923. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 67.07592/66.99735. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.85710/66.82278. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.59471/66.65578. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.28026/66.49507. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.07917/66.33567. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.79369/66.17758. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.66593/66.02761. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.37055/65.88229. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.16363/65.73956. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.00726/65.59473. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.70955/65.44302. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.60460/65.28543. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.44886/65.12739. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.31795/64.95960. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.04724/64.79020. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 63.94368/64.61636. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.80716/64.46299. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.72363/64.31278. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.73639/64.16985. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.40271/64.05286. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.46681/63.96409. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.34473/63.88188. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.25340/63.80904. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 63.09078/63.75782. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.98746/63.69009. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.76222/63.63282. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.74463/63.57238. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.69997/63.53211. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.58394/63.49963. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.46373/63.47210. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.40782/63.45961. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.40180/63.44093. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.28485/63.42932. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.11238/63.41809. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.04484/63.40496. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.04545/63.38895. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.91203/63.37556. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.90893/63.36334. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.78561/63.32363. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.65026/63.23121. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.62779/63.19253. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.50461/63.18616. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.46829/63.20066. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.38551/63.20688. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.29193/63.23502. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.28399/63.25325. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.09463/63.29961. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.14876/63.32419. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.99324/63.39823. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.96417/63.41024. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.92390/63.49621. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.91120/63.52855. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.85704/63.59755. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.70987/63.60547. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.55818/63.68995. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.61073/63.70017. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.35966/63.76706. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.37326/63.79309. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.34270/63.85426. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.38948/63.87415. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.24532/63.89715. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.04250/63.89537. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.06621/63.85903. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.99407/63.84389. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.05995/63.74263. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.95865/63.68017. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.84578/63.65649. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.83126/63.61310. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.65929/63.58062. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.57762/63.56744. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.42554/63.51950. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.58153/63.57943. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.35710/63.42027. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.37861/63.59340. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.41998/63.37779. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.20390/63.49303. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.19201/63.40870. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.15077/63.48269. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.93460/63.41142. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.91428/63.46659. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.89374/63.36385. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.88229/63.50270. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.79001/63.35278. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.65744/63.51902. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.62532/63.39428. Took 0.32 sec\n",
      "ACC: 0.5, MCC: -0.03232119576510264\n",
      "Epoch 0, Loss(train/val) 70.25132/71.34232. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.99538/71.23236. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.74851/71.12502. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.49750/71.01476. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.20849/70.90318. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.88573/70.78614. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.61055/70.66386. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.29392/70.52284. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.98125/70.36031. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.55381/70.15690. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.17899/69.87498. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.65594/69.40261. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.02979/68.43900. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.47841/67.19185. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.94388/66.35471. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.50110/65.82806. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.12240/65.42682. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.89187/65.15273. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 63.61331/64.91546. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.26147/64.69656. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.90828/64.48591. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.75392/64.29678. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.48669/64.13387. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 62.55687/64.00168. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.08387/63.88261. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.22462/63.79037. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.00718/63.70557. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.81741/63.61371. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.88598/63.53552. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.77946/63.46360. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.64923/63.37835. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.55828/63.30931. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.38571/63.26270. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.43989/63.23068. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.39532/63.19236. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.22297/63.15400. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.30910/63.10704. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.17951/63.07001. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 61.07344/63.01702. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.26356/62.97469. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.17347/62.95528. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.14976/62.91616. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.04684/62.87924. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.10268/62.85570. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.94667/62.81242. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.00463/62.78918. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.95081/62.76775. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.14927/62.75113. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.09529/62.72057. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.81128/62.70192. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.06847/62.67588. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.78447/62.64929. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.77681/62.63505. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.96497/62.63336. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.71558/62.62283. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.63026/62.61324. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.79134/62.61262. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.81113/62.60007. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.67340/62.59539. Took 0.34 sec\n",
      "Epoch 59, Loss(train/val) 60.62659/62.57729. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.75904/62.56863. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.51621/62.56278. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.77031/62.55174. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.72215/62.55119. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.62635/62.54807. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.67508/62.54626. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.63438/62.54006. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.56786/62.53122. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.70239/62.50660. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.73257/62.50385. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.54636/62.50595. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.67824/62.51066. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.66438/62.50098. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.50787/62.49096. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.56275/62.50874. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.44401/62.50788. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.27420/62.49170. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.49535/62.47201. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.47396/62.43515. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.58238/62.43365. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.50724/62.42394. Took 0.34 sec\n",
      "Epoch 81, Loss(train/val) 60.40316/62.40157. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 60.48167/62.41782. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.30850/62.39973. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.39525/62.36560. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.38991/62.36177. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.36057/62.36548. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.31071/62.37499. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.45920/62.35402. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.32627/62.31905. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.32835/62.30360. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.35206/62.31681. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.11422/62.28782. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.14029/62.26166. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.11327/62.26700. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 60.09148/62.24777. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.25154/62.23801. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.14999/62.21327. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 60.30874/62.21114. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.02643/62.16156. Took 0.32 sec\n",
      "ACC: 0.59375, MCC: 0.1686533906277161\n",
      "Epoch 0, Loss(train/val) 71.07950/70.53694. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.74839/70.41576. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.51695/70.27998. Took 0.34 sec\n",
      "Epoch 3, Loss(train/val) 70.27247/70.13671. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.99383/69.98108. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.74423/69.82658. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.41068/69.67052. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.11253/69.50372. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.74855/69.32933. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.41707/69.13483. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.07810/68.92706. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.77361/68.70655. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.42069/68.47894. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.09986/68.24313. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.87482/68.00221. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.55078/67.74825. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.25021/67.48996. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.85738/67.21218. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.60857/66.92062. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.20139/66.62302. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 64.84602/66.29901. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.41657/65.94305. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.99481/65.57011. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.70761/65.20040. Took 0.34 sec\n",
      "Epoch 24, Loss(train/val) 63.36110/64.84269. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.98775/64.51801. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.69817/64.21539. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.35314/63.92580. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.16074/63.65305. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.83765/63.40737. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 61.65236/63.17915. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.48735/62.97889. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.36748/62.79125. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.07170/62.60699. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 60.99905/62.43565. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.84069/62.29420. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.68018/62.17078. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.50367/62.04136. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.51379/61.94319. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.41781/61.86072. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.05147/61.78292. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.98683/61.70722. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.94080/61.64514. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.74839/61.57454. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.76936/61.52898. Took 0.34 sec\n",
      "Epoch 45, Loss(train/val) 59.59042/61.48261. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.55949/61.43319. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.34040/61.37733. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.25130/61.31241. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.18643/61.22512. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.22290/61.14538. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.04794/61.08344. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.94504/60.98638. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.77984/60.85773. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.78984/60.78003. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.67055/60.62270. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.49283/60.52278. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.42199/60.43930. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 58.50888/60.31681. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.31381/60.36975. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.34715/60.19624. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.43799/60.06629. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.27654/60.08559. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.21115/60.02769. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.15448/59.99422. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.93370/59.97103. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 58.04881/59.88069. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.86037/59.88662. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 58.00729/59.90830. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.83473/59.76865. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.74761/59.71803. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.73107/59.70261. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.60296/59.61836. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 57.64096/59.69601. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.60631/59.55334. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.62889/59.50138. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.47595/59.51262. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.43947/59.44909. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.53098/59.45519. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.46772/59.40329. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.39288/59.35041. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 57.29740/59.30434. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.36837/59.31726. Took 0.34 sec\n",
      "Epoch 83, Loss(train/val) 57.19941/59.30569. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.28152/59.29879. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.14432/59.25832. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 57.10596/59.24842. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.18152/59.20563. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.09503/59.17941. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 57.08671/59.13892. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.15289/59.15749. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.98034/59.15559. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.03011/59.13540. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.95046/59.13125. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.00559/59.11039. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.77235/59.10156. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.91682/59.11481. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.98119/59.07390. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 56.78307/59.07330. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.85451/59.03212. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.015384615384615385\n",
      "Epoch 0, Loss(train/val) 71.50456/71.44516. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.31536/71.41570. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.15492/71.39136. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.97763/71.37230. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.81029/71.35199. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.65708/71.32638. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.46074/71.30297. Took 0.34 sec\n",
      "Epoch 7, Loss(train/val) 70.29195/71.27682. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.09662/71.25173. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.91887/71.23133. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.78028/71.20565. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.56853/71.17750. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.41814/71.14692. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.24021/71.11514. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.03697/71.09097. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.92103/71.06985. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 68.70341/71.05424. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.45639/71.03449. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.30527/71.00939. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.03235/70.97260. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.93151/70.92182. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.73501/70.83765. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.49913/70.70012. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.32977/70.54070. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 67.04875/70.36358. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.84078/70.19519. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 66.63342/70.05494. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.51622/69.94574. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.31368/69.89281. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.21292/69.84692. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.14410/69.78338. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.76902/69.73280. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.64600/69.69044. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.41386/69.70229. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.17691/69.63725. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 64.93158/69.55569. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.72841/69.49708. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.65007/69.43620. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.30514/69.36553. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.20874/69.29940. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 64.00206/69.25565. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.78671/69.23228. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.67068/69.21505. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 63.64343/69.17184. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 63.43747/69.15744. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 63.35519/69.12566. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 63.25509/69.10982. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.13110/69.09343. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.91894/69.12653. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 62.87608/69.12358. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.75988/69.12785. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.61934/69.15302. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.55868/69.15667. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.59847/69.18172. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.35495/69.13966. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.13077/69.10387. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.18930/69.09389. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.96201/69.10758. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.80365/69.06200. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.71311/69.08004. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.63661/69.03482. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.46789/69.01398. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.45955/69.00237. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.19286/69.00684. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.15103/68.97446. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.04995/68.96281. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.04426/68.96233. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.96093/68.94262. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.81691/68.87750. Took 0.34 sec\n",
      "Epoch 69, Loss(train/val) 60.79561/68.81172. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.69340/68.81065. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.51270/68.71616. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.50480/68.64179. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.37281/68.55106. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.26797/68.42757. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.12188/68.37716. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.05856/68.22062. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.81931/68.12599. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.70756/68.10197. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.63539/67.98117. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.62407/67.92323. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 59.53666/67.85006. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.29128/67.74694. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.38708/67.64343. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.18211/67.64204. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.22119/67.63462. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.00013/67.54079. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.01648/67.51984. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.03303/67.46487. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.91996/67.37273. Took 0.34 sec\n",
      "Epoch 90, Loss(train/val) 58.82679/67.32166. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.75145/67.28497. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.73526/67.21156. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.63363/67.12128. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.52508/67.11011. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.48491/67.08041. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.40317/67.05643. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.45499/66.96930. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 58.38813/66.94816. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.30267/66.92764. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.1353903836185097\n",
      "Epoch 0, Loss(train/val) 70.03662/69.88012. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.74475/69.64235. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.49853/69.38739. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.23130/69.12326. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.91079/68.83912. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.60129/68.55466. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.30175/68.25516. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.01014/67.95229. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.64505/67.64725. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.37196/67.35040. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.94589/67.06891. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.54211/66.80139. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.12312/66.56251. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.73923/66.34667. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.35277/66.15357. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.91576/65.97490. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.45042/65.81973. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.08550/65.65816. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.78067/65.51254. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.28032/65.36785. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.11065/65.22587. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.93264/65.06889. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.71179/64.86880. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.48078/64.65911. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.34002/64.45058. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.02582/64.22274. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 62.02699/63.99179. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.84614/63.77435. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.55504/63.54865. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.60075/63.32423. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.37661/63.10474. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.47265/62.89893. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.30232/62.69750. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.09091/62.49953. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.00378/62.30868. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.97494/62.13470. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.98942/61.97456. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.68184/61.84197. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.68798/61.72062. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.48187/61.60209. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.56102/61.48724. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 60.44110/61.39283. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.55320/61.29554. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.23396/61.21260. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.27457/61.14088. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.14472/61.04902. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.11713/60.96199. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.10896/60.89931. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.93203/60.87698. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.06629/60.81838. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.82947/60.74700. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.96351/60.69896. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.54141/60.64589. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.74095/60.54871. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.74317/60.47314. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.62693/60.42822. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.66617/60.37851. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.50824/60.34192. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.62601/60.30127. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.49238/60.23344. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.49106/60.14680. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.36402/60.08262. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.39497/60.05682. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.15660/59.99789. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.32358/59.91650. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.23731/59.83580. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 59.12990/59.81666. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.17390/59.73708. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.10311/59.69284. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.01275/59.66910. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.10954/59.53537. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.10309/59.49103. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.95504/59.45039. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.90677/59.38397. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.93787/59.34819. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 58.97468/59.37276. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.75488/59.31419. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.55162/59.23779. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.69161/59.24564. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.54961/59.15335. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.74107/59.15215. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.59682/59.10464. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.52636/59.07610. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.43675/59.05941. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.47829/59.06205. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.39158/59.05378. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.45605/58.93746. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.53202/58.92717. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.29760/58.96282. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.15497/58.90240. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.35692/58.87733. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.30799/58.82320. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.22709/58.82038. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.23619/58.73926. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.25983/58.69278. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.20600/58.64453. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.00253/58.58597. Took 0.34 sec\n",
      "Epoch 97, Loss(train/val) 57.96822/58.49139. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.06471/58.43599. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.96877/58.34417. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: -0.02154352039804115\n",
      "Epoch 0, Loss(train/val) 70.89083/71.01589. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.72588/70.93081. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.58518/70.84847. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.41870/70.76868. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.24850/70.68238. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.17664/70.60168. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.02819/70.51987. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.84527/70.42941. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.73165/70.32812. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.53932/70.22403. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.33627/70.11322. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.06670/69.99924. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.94013/69.90524. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.66140/69.83997. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.42322/69.78869. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.22877/69.75527. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.93556/69.73203. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.73603/69.72021. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.48998/69.72651. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.24264/69.75669. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.08504/69.75283. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.83980/69.74681. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 66.63390/69.74768. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.48435/69.74666. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.26486/69.74286. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 66.01850/69.74331. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.80594/69.71329. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.68228/69.69849. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.43764/69.67032. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.29816/69.69244. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.01754/69.73440. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.81698/69.72217. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.76843/69.71844. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.62087/69.69334. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 64.52537/69.67255. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.40754/69.67784. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.35947/69.69737. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.28104/69.72699. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.26631/69.72574. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.05869/69.71922. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.05074/69.71490. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.87429/69.72558. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.90476/69.74519. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.83491/69.76035. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.76510/69.74998. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.76884/69.74020. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.65090/69.72617. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.46931/69.69144. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.38833/69.67721. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 63.55383/69.65841. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.24585/69.63955. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.41281/69.61098. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 63.37370/69.55360. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.21487/69.52815. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.18816/69.47916. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 63.12386/69.39225. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.95480/69.25639. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.04124/69.15916. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.78098/69.08981. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.66742/69.00243. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.58692/68.92262. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.50520/68.82724. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.61194/68.73656. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.51539/68.68040. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 62.46235/68.54520. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.30587/68.41895. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.32090/68.31472. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.26032/68.21046. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.12859/68.20188. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.05785/68.08958. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.88511/68.00412. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 62.08657/67.98871. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.91113/67.99453. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.85193/67.83699. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.79970/67.79424. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.87234/67.73407. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.74572/67.68132. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 61.62194/67.69250. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.50746/67.61946. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.37512/67.55132. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 61.46478/67.56610. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.44645/67.44303. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.32876/67.40292. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.21401/67.37720. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 61.33053/67.29462. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.11368/67.40003. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 61.18287/67.19368. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.09070/67.27245. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.17108/67.25278. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 60.85631/67.08613. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 61.02920/67.05365. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.94850/67.10121. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.90636/66.99306. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.80175/67.01700. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 60.84185/66.94693. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.67372/66.90504. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.66461/66.80415. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.60809/66.81584. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.57863/66.78374. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.57112/66.79442. Took 0.32 sec\n",
      "ACC: 0.40625, MCC: -0.08623367261916397\n",
      "Epoch 0, Loss(train/val) 69.66729/68.83620. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.37533/68.44148. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.06050/68.02727. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 68.70902/67.57188. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.31505/67.06779. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 67.86669/66.52583. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.46830/65.95647. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 66.99335/65.35370. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 66.36181/64.68836. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 65.75552/63.94969. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.07534/63.23173. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 64.43655/62.61679. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 63.94893/62.09324. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 63.48569/61.65533. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 63.44512/61.30193. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.10034/61.00819. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 62.97755/60.74067. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.83872/60.57555. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.57602/60.44670. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.44981/60.33881. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.52320/60.25688. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.38068/60.18612. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.39650/60.12171. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.33883/60.06625. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.26410/60.00560. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.38571/59.94603. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.24503/59.88902. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.24039/59.82952. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.14820/59.78319. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.93633/59.73855. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.02484/59.70319. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.96140/59.66851. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.96459/59.62956. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.00480/59.58441. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.91494/59.53906. Took 0.34 sec\n",
      "Epoch 35, Loss(train/val) 61.97251/59.50179. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.00316/59.46756. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.84100/59.43849. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.83524/59.39912. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 61.77105/59.36524. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.73717/59.33147. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.73630/59.30301. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.73838/59.26370. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.61750/59.22146. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.80917/59.18151. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.66593/59.13543. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.58738/59.11347. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.46906/59.06997. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.62398/59.01818. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.49427/58.98275. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 61.55276/58.94094. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.46366/58.89690. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 61.45705/58.87971. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.45497/58.86060. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.45233/58.83728. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.33728/58.81131. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.44943/58.77437. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.34188/58.73916. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.36929/58.71416. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.26805/58.67831. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.34497/58.66106. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.23519/58.63981. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.15379/58.61973. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.11869/58.60886. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.15664/58.61352. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.18937/58.59293. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.14467/58.54597. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 61.15943/58.52090. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 61.09032/58.52456. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.05174/58.51838. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.14631/58.49747. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.98415/58.47271. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.97300/58.44355. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.97651/58.44212. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 61.02952/58.42261. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 61.11110/58.42488. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.83697/58.42988. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.93085/58.41381. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.87950/58.40881. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.71920/58.39924. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.78439/58.41208. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.78831/58.43820. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.78231/58.43520. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.78394/58.41257. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 60.59361/58.39297. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.67118/58.37631. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.60613/58.38932. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.63672/58.39550. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.74518/58.39893. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.37379/58.40430. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.50096/58.38714. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.61547/58.37854. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.43845/58.39958. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 60.57350/58.37293. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 60.48307/58.38708. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 60.51114/58.36068. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 60.43661/58.38845. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.32147/58.41814. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.31437/58.36901. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.27840/58.39401. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.07273929674533079\n",
      "Epoch 0, Loss(train/val) 69.77159/70.34257. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.58257/70.12230. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 69.40842/69.88811. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.20380/69.62847. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.04789/69.35912. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.82122/69.07082. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.68438/68.78746. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.46304/68.49599. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.31915/68.20304. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.06841/67.92023. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.92370/67.67771. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 67.69754/67.47433. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.44509/67.24941. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.29936/67.05083. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.12338/66.87453. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.86655/66.71599. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.71209/66.56281. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.50831/66.40498. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.30161/66.23404. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.21438/66.13987. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.05367/66.05583. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 65.99666/65.98184. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.70467/65.86961. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.56484/65.81203. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.33234/65.73976. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.21074/65.56342. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.16345/65.41499. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.04998/65.38165. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.91649/65.22498. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.74289/65.12905. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.64785/65.03187. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.45210/64.82115. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.18386/64.68434. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.08383/64.55720. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.88529/64.47625. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.61068/64.30118. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.57745/64.17694. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.48410/64.07159. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.29690/63.97686. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.11114/63.87812. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.93884/63.76801. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 62.95154/63.75258. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.81147/63.69495. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.73552/63.67551. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.65039/63.64904. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.59304/63.59516. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.40812/63.57969. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.48267/63.59464. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.48919/63.64631. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.25049/63.60275. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.18244/63.54938. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.28055/63.46633. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.10253/63.49808. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.10841/63.46859. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.22911/63.46007. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.99102/63.47149. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.95288/63.43058. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 61.84974/63.28851. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.86678/63.19982. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.88195/63.32873. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.46139/63.16623. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.79213/63.19650. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.82353/63.09969. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.53007/63.00704. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.45880/63.06437. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.27798/63.04457. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.50696/63.01900. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.46795/62.82925. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.51002/62.83208. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.19352/62.89394. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.23756/62.49459. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.32823/62.61578. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.26586/62.31876. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.16760/62.58047. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.23983/62.59055. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.09248/62.75690. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.86574/62.59615. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.81803/62.45801. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.94751/62.63911. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.74998/62.59953. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.84270/62.57999. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.72984/62.48961. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.81837/62.53864. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.66964/62.50614. Took 0.34 sec\n",
      "Epoch 84, Loss(train/val) 60.58640/62.49021. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 60.69458/62.46908. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.46711/62.41031. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.56427/62.44996. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.41755/62.39219. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.45638/62.35518. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.34787/62.29911. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.56683/62.30195. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 60.41558/61.95853. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.55292/61.29988. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.41871/62.20511. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.40904/62.23503. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.23651/62.28638. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.22607/62.05522. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.21978/61.98998. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.33806/62.14971. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.0902550601789804\n",
      "Epoch 0, Loss(train/val) 70.85846/71.28149. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.48641/71.10252. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.19288/70.93794. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.86757/70.78603. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.49851/70.64384. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.14788/70.50673. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.77926/70.37498. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.44551/70.25577. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.07071/70.15488. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.77634/70.06496. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.41713/69.98546. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.08968/69.90848. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 66.77646/69.81419. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.46251/69.68990. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 66.16275/69.54491. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.92368/69.39468. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.65394/69.24361. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.43664/69.09139. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 65.27786/68.93675. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.96075/68.77573. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.78072/68.61003. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.58835/68.42764. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.37880/68.22867. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.19309/68.00623. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.02043/67.77263. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.84460/67.51733. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 63.45773/67.24749. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.33001/66.98383. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.20758/66.74075. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.91437/66.50261. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.79717/66.26419. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.45470/66.05200. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.23185/65.86129. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.26199/65.67573. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.90574/65.48817. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.85605/65.32166. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.82599/65.19008. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 61.43636/65.09615. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 61.40567/64.98627. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.33652/64.89243. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.09782/64.79208. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.07310/64.70800. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.88968/64.60639. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.74537/64.47210. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.53350/64.34436. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.52994/64.19225. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.52974/64.07259. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 60.33801/64.04342. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.38022/63.85569. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.17255/63.83278. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.03046/63.65977. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.94208/63.55146. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.92509/63.49881. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 59.72999/63.32881. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.76245/63.33952. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.56774/63.17641. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.34435/63.02400. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.38239/63.01374. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.31953/62.79971. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.25626/62.71176. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.19580/62.62567. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.93599/62.47174. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.82163/62.40833. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.68454/62.16955. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.73142/62.23823. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.60598/61.97367. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.68700/62.19160. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.59182/61.81597. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.36235/62.08764. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.14129/61.80812. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.16757/61.85598. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.10357/61.72573. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.93228/61.69741. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.86380/61.75023. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.71681/61.59852. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 57.59492/61.74325. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.58914/61.61109. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.44272/61.62346. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.26361/61.60155. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.22969/61.51360. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.22127/61.57803. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.11420/61.51751. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.99109/61.38878. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.05531/61.55903. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.92191/61.22129. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.83430/61.50785. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.77856/61.19884. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.77392/61.41522. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.48646/61.11763. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.68649/61.37426. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.49025/61.11609. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.56318/61.28414. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 56.40911/61.04599. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.33047/61.13564. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.18955/60.92122. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.19919/61.13943. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.25190/61.19334. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.89407/60.81422. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.91127/61.06110. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.86527/60.90219. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.022628141110071023\n",
      "Epoch 0, Loss(train/val) 70.48211/70.16048. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.30088/70.12202. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.18503/70.09936. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.97647/70.09420. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.77658/70.10423. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.58966/70.13034. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.32054/70.17380. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.09029/70.22105. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.89175/70.27567. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.55981/70.32217. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.23764/70.33079. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.99692/70.29406. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.53702/70.21045. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.41367/70.10397. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.09092/69.98879. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.91455/69.86877. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.66141/69.73282. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.46171/69.59069. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.26487/69.44300. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.95416/69.30698. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.87751/69.18117. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.65970/69.08018. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.48014/68.98850. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.47544/68.89983. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.45431/68.81387. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.28295/68.74506. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 65.23227/68.67793. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 64.97090/68.62278. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.07589/68.56413. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 64.96986/68.51823. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.83061/68.46874. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.76756/68.41890. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.79232/68.37333. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.61439/68.33286. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.67152/68.31673. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.52261/68.29379. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.56422/68.26762. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.64574/68.25880. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.42309/68.24210. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.34547/68.22526. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.43119/68.20404. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.22035/68.19476. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 64.25992/68.18056. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.22334/68.18524. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.02717/68.19717. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.06705/68.20351. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.07310/68.18079. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 63.86515/68.16601. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.89419/68.15453. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.82790/68.14616. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.79356/68.13890. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.76761/68.11662. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.75892/68.09856. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 63.75562/68.08778. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.64654/68.08203. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.51217/68.06255. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.53915/68.04672. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 63.45889/68.01819. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.41978/68.09557. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.37385/67.95728. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 63.21799/67.90794. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 63.22345/67.83735. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.09484/67.79066. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.04884/67.74494. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 63.28849/67.71564. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.08762/67.68931. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.98523/67.64389. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.94793/67.61704. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.92037/67.61086. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 62.98673/67.63422. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 62.84578/67.62375. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.82188/67.57957. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 62.70070/67.55683. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.64279/67.51920. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.78973/67.48297. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.71914/67.46339. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.57555/67.42004. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.63503/67.37140. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.33268/67.33439. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 62.48815/67.30912. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.57219/67.28160. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 62.40892/67.19513. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 62.28201/67.13349. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 62.28836/67.11583. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.19469/67.05266. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.26221/66.95040. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.14157/66.89182. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 62.13578/66.85788. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 62.02012/66.80337. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.95378/66.71342. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 62.02387/66.64529. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 62.11651/66.55676. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.86326/66.48746. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.83948/66.39981. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.85636/66.44958. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.73915/66.41988. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.68865/66.33336. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.71309/66.35883. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.68592/66.31183. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 61.51384/66.23372. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.054366028221956235\n",
      "Epoch 0, Loss(train/val) 70.54371/70.90616. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.35429/70.87453. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.14979/70.83749. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.99660/70.80328. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.84569/70.77718. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.62515/70.75273. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.47298/70.74178. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.27928/70.73521. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.09271/70.73278. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.86741/70.73933. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.58423/70.74687. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.33107/70.76406. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.03316/70.78462. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.70669/70.80383. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.46252/70.81572. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.28501/70.81522. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.96620/70.80386. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.88440/70.79778. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.68146/70.79489. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.43793/70.79931. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.27451/70.80563. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.08174/70.81899. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.86653/70.84421. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.71470/70.87290. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.57726/70.89337. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.37413/70.93394. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.18983/70.95213. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.04418/70.94032. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.97269/70.87270. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.78862/70.79968. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.64387/70.72594. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.43731/70.67506. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.12424/70.51914. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.12127/70.32472. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 64.01043/70.08919. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.75450/69.82294. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.61518/69.52348. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 63.45940/69.23266. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.35326/69.08413. Took 0.34 sec\n",
      "Epoch 39, Loss(train/val) 63.17822/68.89694. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.01762/68.70566. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.92407/68.58968. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.74817/68.51699. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.70233/68.37621. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.51970/68.26946. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.41356/68.24931. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.36794/68.20316. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.16264/68.10401. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.94000/68.05433. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.80809/67.97636. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.87194/67.77806. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.76105/67.81731. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.61442/67.85760. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.48924/67.77220. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.39763/67.73584. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.13122/67.81862. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.11256/67.71795. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.04837/67.59497. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.81180/67.72728. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 60.80123/67.46071. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.60828/67.49289. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.49420/67.61488. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 60.30559/67.30764. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.24208/67.71031. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.32379/67.51974. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.03373/67.40105. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.00613/67.41889. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.02076/67.31138. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.88758/67.47778. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.72584/67.37219. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.76866/67.48354. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.53270/67.29780. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 59.66685/67.46106. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.37081/67.24825. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.31063/67.34470. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.17800/67.25590. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.16671/67.30960. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.10568/67.20450. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.10620/67.28225. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.83191/67.10748. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.92357/67.14216. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.69289/67.20819. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.76444/67.08978. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.69290/67.04711. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.74060/67.05170. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 58.69326/67.16100. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.75133/67.18944. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.51131/66.94463. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.50588/67.05888. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.46304/67.08425. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.26847/66.88752. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.33649/67.06612. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.22048/67.19147. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.13171/66.95335. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 58.01296/67.13931. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.13808/67.19659. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.00188/67.15422. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.03739/67.04557. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.00390/66.95833. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.94944/66.84782. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.15131899415399777\n",
      "Epoch 0, Loss(train/val) 70.64409/70.81841. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.46012/70.71836. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.24044/70.61069. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.06427/70.49215. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.82150/70.35915. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.53390/70.21060. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.31177/70.03974. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.08943/69.84579. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.78991/69.62289. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.50373/69.36754. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.20923/69.08598. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.91867/68.77821. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.60789/68.46358. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.28527/68.16216. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.95440/67.88598. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.80636/67.63393. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.54676/67.40114. Took 0.34 sec\n",
      "Epoch 17, Loss(train/val) 66.29980/67.18882. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.17897/66.98921. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.86090/66.79748. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.73886/66.59368. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.65794/66.39339. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.47927/66.21072. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.25419/66.03314. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.21712/65.86513. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.16576/65.70140. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.96118/65.56651. Took 0.34 sec\n",
      "Epoch 27, Loss(train/val) 64.85185/65.44193. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.73890/65.31684. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.67850/65.21576. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.71479/65.13503. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.55024/65.04636. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.45301/64.96530. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.40275/64.88532. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 64.22042/64.79079. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.31166/64.71568. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.18423/64.63155. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.07491/64.57282. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 64.00419/64.49989. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.92217/64.42498. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 63.87939/64.35499. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.82516/64.31469. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.70384/64.26832. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.62049/64.24492. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.52771/64.20309. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.43183/64.22593. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.16479/64.26575. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 63.04659/64.27754. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.02814/64.27689. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 62.67991/64.26738. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 62.72751/64.29414. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.63425/64.32629. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.45453/64.33498. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.24563/64.35117. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.29373/64.36855. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.10482/64.47446. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.89633/64.49046. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 61.89646/64.51295. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.82472/64.53200. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.82009/64.51977. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.70393/64.51505. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.65525/64.49946. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 61.62592/64.49435. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.36710/64.47911. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.39399/64.43030. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.46725/64.39385. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.22404/64.37868. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.00979/64.32887. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.11291/64.25716. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.98875/64.23503. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.95033/64.21230. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.84789/64.19389. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.86502/64.12589. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.84245/64.07769. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.62707/64.00970. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.64984/63.97529. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.64442/63.88485. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.55011/63.83282. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.38550/63.76225. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.35430/63.66254. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.35810/63.60991. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.04857/63.53734. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.09699/63.51966. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.94354/63.48195. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.91158/63.47657. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.86986/63.39514. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.72442/63.48158. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.78100/63.26756. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.66921/63.39229. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.59372/63.22235. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.47574/63.33543. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.36497/63.18166. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.33950/63.20991. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.36649/63.14017. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.32737/63.17226. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.14555/63.10174. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.24208/63.10101. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.04150/63.07846. Took 0.34 sec\n",
      "Epoch 98, Loss(train/val) 59.03442/63.11071. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.93419/63.10268. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.006753041030410036\n",
      "Epoch 0, Loss(train/val) 71.87805/71.40575. Took 0.35 sec\n",
      "Epoch 1, Loss(train/val) 71.60944/71.15887. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.35114/70.91046. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 71.07546/70.66118. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.80130/70.40386. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.49471/70.12577. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.15691/69.82910. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.78584/69.50932. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.38605/69.17651. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.96938/68.83264. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.56280/68.48331. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.16673/68.12988. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.76583/67.76402. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.36251/67.38135. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.01393/66.98610. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.55647/66.57360. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.19405/66.14805. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.79404/65.71567. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.41601/65.28941. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.99818/64.88215. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.58722/64.50290. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.22107/64.14149. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.97130/63.79835. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.75140/63.47377. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.36144/63.15402. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.12396/62.83504. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.92344/62.52768. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.71521/62.22510. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.35513/61.93169. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.16329/61.63143. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.77053/61.38448. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 61.51219/61.15150. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.31855/60.94160. Took 0.34 sec\n",
      "Epoch 33, Loss(train/val) 61.05962/60.70698. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.63001/60.42876. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.52474/60.15558. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.28096/59.88808. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.14123/59.61755. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.97440/59.42210. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.90486/59.28130. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.69474/59.16590. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.75695/59.07084. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.72892/58.99852. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.67421/58.93391. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.63948/58.90018. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 59.41673/58.87418. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 59.40447/58.84843. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.43600/58.80885. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.37627/58.78306. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.25786/58.75276. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.21964/58.72561. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.09378/58.72784. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.14907/58.71859. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.35316/58.70946. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.13779/58.70462. Took 0.34 sec\n",
      "Epoch 55, Loss(train/val) 59.04354/58.68552. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.90493/58.66455. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.04016/58.65489. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.92132/58.64907. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 59.01673/58.65407. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.79962/58.65821. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.81489/58.65828. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.81879/58.67585. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.97101/58.69612. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.84949/58.68239. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.87638/58.66969. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.80236/58.64051. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.70487/58.63791. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.66521/58.64820. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.83124/58.67531. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.73992/58.69225. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.70213/58.68432. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.76923/58.72511. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.84364/58.75773. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.79775/58.72608. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.64424/58.68213. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.63721/58.67327. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.63081/58.73318. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.30571/58.72680. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.41956/58.76958. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.42969/58.78870. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.45644/58.75065. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.54973/58.72744. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.53859/58.75869. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.44436/58.75446. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.55004/58.78374. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.43839/58.78977. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.42651/58.81224. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.34498/58.78989. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.37169/58.77100. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.24605/58.78290. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.17921/58.73288. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.33690/58.71112. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.25270/58.74639. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.20640/58.74944. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.22460/58.77902. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 58.18683/58.71240. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.05247/58.71632. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.15914/58.72884. Took 0.34 sec\n",
      "Epoch 99, Loss(train/val) 58.03390/58.75066. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.17407765595569785\n",
      "Epoch 0, Loss(train/val) 69.80850/72.10509. Took 0.35 sec\n",
      "Epoch 1, Loss(train/val) 69.58504/72.02926. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.44044/71.95728. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.16261/71.88087. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.02296/71.80773. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.84586/71.73140. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.61847/71.64066. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.41124/71.53194. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.25743/71.41257. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.94392/71.27541. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.73373/71.12408. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.61105/70.95504. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.27353/70.77040. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.06564/70.55964. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.79651/70.33514. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.46750/70.09253. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.33523/69.82387. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 66.16103/69.53804. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.84661/69.24201. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 65.67888/68.95703. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.46576/68.68365. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.28813/68.41737. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.15188/68.17471. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.00056/67.97027. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.92006/67.83888. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.67048/67.76289. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.58506/67.72212. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.32356/67.65050. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.21415/67.56948. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.19456/67.44309. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.02135/67.31792. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.92310/67.14777. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.77601/66.93790. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.61627/66.78351. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.61860/66.63457. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.47903/66.47586. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.28448/66.33795. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.28206/66.22734. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.18442/66.12044. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 63.02155/65.98470. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.86708/65.92329. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.96447/65.95020. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.67426/65.93244. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.54918/65.81467. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.51229/65.84102. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.32331/65.81341. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.29421/65.81276. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.29406/65.73007. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 62.02627/65.78391. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.10063/65.73870. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.02606/65.76288. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.91040/65.88801. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.95568/65.84282. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.91170/65.92735. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.78441/65.87473. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.65018/65.81653. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.55633/66.13005. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.65769/65.98327. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.49185/66.12929. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.36384/66.04757. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.38765/66.22421. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.22491/66.20977. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.10098/66.40372. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.88937/66.35718. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.07547/66.37988. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.83080/66.57408. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.94734/66.54599. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.68112/66.67088. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 60.63196/66.72942. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.64661/66.73391. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.45456/66.72640. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.53034/66.85070. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.29428/66.83530. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.28647/66.88142. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.24555/67.21556. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.34344/66.99032. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.03794/67.03655. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.11486/67.02057. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.08587/67.03420. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.92275/66.84634. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.77921/67.05409. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.59095/66.92735. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.54975/66.94524. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.38458/66.91041. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.09492/67.04372. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.05947/66.95836. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.97429/66.82939. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.00380/67.03978. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.75555/66.75677. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.62224/66.68855. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.54346/66.89781. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.31138/66.44807. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.18656/66.24183. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.95740/66.02275. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.79418/65.42805. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.50229/65.96732. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.58638/65.25058. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.18083/65.51704. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.25368/64.41065. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 56.90367/65.24557. Took 0.33 sec\n",
      "ACC: 0.4375, MCC: -0.06816708894454176\n",
      "Epoch 0, Loss(train/val) 71.06657/71.87051. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.88023/71.56682. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.73345/71.26837. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.55608/70.96974. Took 0.34 sec\n",
      "Epoch 4, Loss(train/val) 70.30691/70.66048. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.14746/70.34111. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.99517/70.02388. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.73168/69.69813. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.50745/69.35439. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.32471/69.00575. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.11102/68.65832. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.94297/68.32243. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.79586/67.99862. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.53462/67.68479. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.39683/67.39112. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.16414/67.11405. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.03203/66.85923. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.78425/66.63089. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.60233/66.42966. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.52265/66.25845. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.27373/66.10567. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 67.16403/65.97197. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 67.02237/65.84822. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.05429/65.74429. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.83885/65.65150. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 66.77620/65.56710. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.59449/65.48950. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.48768/65.41637. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.44261/65.34900. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.30661/65.28640. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.32382/65.23158. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 66.31221/65.17667. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 66.14056/65.12373. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 66.03624/65.06805. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.95958/65.01405. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.96290/64.95756. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 65.79036/64.90402. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.78476/64.84218. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 65.79882/64.77309. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 65.58681/64.69528. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 65.49313/64.61594. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 65.43317/64.53786. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 65.30615/64.47144. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 65.32082/64.40500. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 65.11793/64.33493. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 65.12518/64.26829. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 65.00484/64.19772. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 65.01601/64.11862. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.75060/64.03267. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.72326/63.95718. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 64.73780/63.89214. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 64.42616/63.79150. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 64.35163/63.74556. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 64.41062/63.68430. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 64.42227/63.55363. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 64.13539/63.43271. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 64.06183/63.35076. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 64.00272/63.25599. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.92543/63.14431. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 63.89286/63.03827. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 63.54359/62.94611. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 63.68000/62.84763. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.50465/62.66899. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.38684/62.57708. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 63.21981/62.36934. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.20646/62.26343. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 63.02081/62.01886. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.84478/61.82983. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 62.64232/61.61308. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 62.44336/61.42734. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.58021/61.20478. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.45693/61.06870. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.41435/60.89611. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 62.20802/60.76878. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.27392/60.56993. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 62.08501/60.43744. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.98938/60.24434. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.94072/60.18180. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.93149/60.00654. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 61.99997/59.91953. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.66531/59.75897. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.67063/59.78024. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.65593/59.64201. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.55160/59.58673. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.64606/59.44810. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.47436/59.59415. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 61.33538/59.32410. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 61.25340/59.42887. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.37250/59.25641. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.19056/59.31402. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.18460/59.17828. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.03134/59.22359. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 61.18962/59.10652. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.18092/59.13277. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.76921/59.06477. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 60.99609/58.91684. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.90059/58.87409. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 60.75465/58.87493. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.94638/58.79028. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.79715/58.64202. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.015653689050413564\n",
      "Epoch 0, Loss(train/val) 71.00072/70.67838. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.66530/70.55586. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.37334/70.45792. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.05154/70.37988. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.72649/70.30817. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.43372/70.23631. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.05370/70.16267. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.70924/70.08708. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.40766/70.00243. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.01565/69.88531. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.68432/69.74604. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.36990/69.56497. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.07385/69.34511. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.72268/69.07758. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.27518/68.75591. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.05480/68.40969. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.67757/68.04340. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.30539/67.67300. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.95142/67.28826. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.58309/66.92509. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.24126/66.56315. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.74230/66.19056. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.52542/65.84995. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.15564/65.49274. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.97015/65.19698. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.58903/64.90173. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 62.38193/64.62812. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.19492/64.49293. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.92020/64.17471. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.74852/64.18641. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.51271/63.80601. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.30575/63.93472. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.10942/63.68427. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.95240/63.80402. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.91448/63.60390. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.90990/63.73363. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.66260/63.49160. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.74815/63.74777. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.65600/63.64373. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.44854/63.80357. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.47303/63.67204. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.32069/63.77565. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.45745/63.48749. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.43293/63.77995. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.20154/63.65031. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 60.14462/63.84912. Took 0.34 sec\n",
      "Epoch 46, Loss(train/val) 60.17707/63.79482. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.12978/63.97523. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.11338/63.85088. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.12202/64.03391. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.94430/63.86991. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.00537/64.06979. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.08262/63.81127. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.95626/64.08910. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.91823/63.87626. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.89684/64.04135. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.72813/63.92216. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.85627/64.10989. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.74394/63.98619. Took 0.34 sec\n",
      "Epoch 59, Loss(train/val) 59.92111/64.22685. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.64312/63.98529. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.74568/64.26085. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.53584/63.97161. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.46352/64.25400. Took 0.34 sec\n",
      "Epoch 64, Loss(train/val) 59.50439/64.13776. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.42554/64.32031. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.54013/64.21878. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.37736/64.32832. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.38318/64.26534. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.31583/64.37743. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.27100/64.30571. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.17109/64.38960. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.34830/64.33711. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.26963/64.40748. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.13149/64.37917. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.32014/64.41594. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.08235/64.35793. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.92077/64.34017. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.97232/64.32597. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.74139/64.33367. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.94956/64.34315. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.88219/64.39432. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.86861/64.36002. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.67702/64.32498. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.68119/64.32601. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.67578/64.36708. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.55330/64.37640. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.47595/64.37079. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.53354/64.32703. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.38572/64.35087. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.40782/64.41078. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.27687/64.37389. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.17400/64.37052. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.24653/64.32882. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.10427/64.27729. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.07313/64.24985. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.93223/64.22509. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.72519/64.20795. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.71756/64.24175. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.66897/64.18203. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.0677883717457337\n",
      "Epoch 0, Loss(train/val) 71.73412/71.23591. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 71.48432/71.08667. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 71.29867/70.93533. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 71.09966/70.78542. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.88217/70.62141. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.69683/70.44453. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.47053/70.25415. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 70.26884/70.05786. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 70.02434/69.85433. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 69.76844/69.64404. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.49295/69.41701. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.20429/69.17661. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.92926/68.93137. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.66369/68.68400. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.24496/68.42947. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.88835/68.16032. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.60899/67.88142. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.16256/67.58211. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.78313/67.25877. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.41262/66.90704. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.94285/66.51683. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.59923/66.07602. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.27685/65.58151. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.69086/65.01212. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.19280/64.38354. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.87741/63.77842. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.39285/63.23318. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.97108/62.76455. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.35539/62.34400. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.86344/61.98723. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.24297/61.67839. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.69444/61.41470. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.23742/61.21765. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.89199/61.11000. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.35679/61.05546. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.10347/61.02564. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.85315/61.01076. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 58.78329/61.00237. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.58442/60.99109. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.56290/60.98211. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.31451/60.97844. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.52825/60.96557. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.33876/60.96222. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.30970/60.96251. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.26180/60.96817. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.26727/60.96585. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.23167/60.97034. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.10045/60.97631. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.97596/60.98474. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.98309/60.99952. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.89608/61.02586. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.82837/61.02784. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.91972/61.00984. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.80311/61.01827. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.83673/61.03210. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.71708/61.05610. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 57.73497/60.94410. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.54487/60.94601. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.84643/61.02954. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.78555/60.99266. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.74176/60.94762. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.66839/60.95705. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.49643/60.93452. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.57544/60.92475. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.45268/60.91386. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.51627/60.92188. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.41315/60.92658. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.41507/60.92144. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.44417/60.93478. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.47938/60.93011. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.23769/60.96456. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.30046/60.96400. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.37821/60.97776. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.14526/61.00332. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.12734/61.00350. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.09061/60.98376. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 57.06000/61.01365. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.98303/60.94051. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.95329/60.95488. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.84712/60.93757. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.78566/60.93830. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.69132/60.97738. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.94169/61.04377. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.81145/61.08948. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.73156/61.08020. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.85188/60.96186. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.55048/61.00051. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.65516/61.11014. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.35627/61.08619. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.49338/61.10236. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.44609/61.04773. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.31520/61.16885. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.52728/61.03601. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.54308/61.15221. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.39728/61.08485. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.48407/61.18349. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.14998/61.11944. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 56.31879/61.14642. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 56.30010/61.15947. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.14583/61.14472. Took 0.33 sec\n",
      "ACC: 0.5, MCC: 0.013900245738365579\n",
      "Epoch 0, Loss(train/val) 71.08103/71.18017. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 71.00788/71.16226. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.88920/71.14058. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.78634/71.11854. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.72102/71.09540. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.57526/71.07681. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.55709/71.05473. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.46090/71.02876. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 70.30830/71.00630. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 70.24182/70.98458. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 70.12283/70.96711. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.95565/70.95511. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.79552/70.94676. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.65809/70.94870. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.56552/70.94551. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.44128/70.95026. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 69.26848/70.95262. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 69.06237/70.94400. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.97354/70.92964. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.86400/70.90691. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 68.68662/70.88731. Took 0.34 sec\n",
      "Epoch 21, Loss(train/val) 68.52162/70.85558. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 68.31137/70.81002. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 68.23113/70.75668. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 68.04484/70.70699. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 67.97555/70.65477. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 67.87715/70.59964. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 67.81754/70.55736. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 67.65626/70.50167. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 67.57185/70.44423. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 67.50026/70.39727. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 67.43938/70.35397. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 67.24188/70.28311. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 67.13669/70.24101. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 67.11124/70.23122. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 66.95153/70.21043. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 66.87915/70.17061. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 66.79165/70.13473. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 66.69714/70.12146. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 66.55076/70.15256. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 66.61938/70.15485. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 66.38405/70.13232. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 66.35770/70.24408. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 66.29198/70.33654. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 66.27019/70.29380. Took 0.34 sec\n",
      "Epoch 45, Loss(train/val) 65.94140/70.35162. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 66.02650/70.37890. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 65.96114/70.44423. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 65.98628/70.54968. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 65.75587/70.58830. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 65.77129/70.53715. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 65.77250/70.51964. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 65.70653/70.57345. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 65.56026/70.70068. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 65.41143/70.75881. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 65.41636/70.84858. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 65.29173/70.89944. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 65.36989/70.95161. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 65.11438/71.01749. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 65.12150/71.01233. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 65.08340/71.05912. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 64.91547/71.13638. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 64.99823/71.22044. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 64.86571/71.10753. Took 0.34 sec\n",
      "Epoch 64, Loss(train/val) 64.90226/71.15492. Took 0.34 sec\n",
      "Epoch 65, Loss(train/val) 64.84354/71.21266. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 64.65892/71.24529. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 64.61849/71.29816. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 64.65086/71.40586. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 64.48547/71.45408. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 64.53326/71.46461. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 64.39580/71.44826. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 64.37437/71.42157. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 64.32138/71.38035. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 64.23630/71.44409. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 64.26937/71.54502. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 64.10610/71.44696. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 64.04201/71.44783. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 63.99655/71.48854. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 63.83399/71.44134. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 63.80157/71.33704. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 63.77951/71.42072. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 63.82759/71.43594. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 63.60935/71.52374. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 63.49679/71.50481. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 63.37877/71.57388. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 63.41102/71.52257. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 63.24765/71.60953. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 63.36271/71.52410. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 63.28664/71.59981. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 63.13046/71.63627. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 63.25861/71.64171. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 63.14183/71.65760. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 62.97801/71.73038. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 62.93949/71.81701. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 62.78625/71.86518. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 62.79115/71.87566. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 62.78181/71.91326. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 62.68969/71.93664. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 62.69795/71.97957. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.07160575596310784\n",
      "Epoch 0, Loss(train/val) 71.15375/70.66707. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.93876/70.56534. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.74151/70.47898. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.51430/70.39521. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.31882/70.31908. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.07164/70.24776. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.94164/70.17662. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.62425/70.10004. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.53818/70.02243. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.26919/69.93833. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.96639/69.84090. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.74031/69.72484. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.47151/69.56686. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.19060/69.36143. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.80293/69.10175. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.20584/68.80234. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.83392/68.52980. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.39744/68.31293. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.07265/68.20854. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.73772/68.12453. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.45757/68.04277. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.21406/67.94608. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.87097/67.84173. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.76432/67.73967. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.52279/67.64405. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.26506/67.54601. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.00337/67.44496. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.04595/67.34055. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.75144/67.26200. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.68560/67.17850. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.51090/67.08783. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.38076/66.99081. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.16529/66.88833. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.97445/66.78873. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.03140/66.68807. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.84484/66.58862. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.79388/66.48769. Took 0.34 sec\n",
      "Epoch 37, Loss(train/val) 62.64377/66.39329. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.45086/66.29842. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.31726/66.20713. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.42093/66.11836. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 62.34688/66.03157. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.17850/65.93742. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.02471/65.84975. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.10758/65.76887. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.02778/65.69434. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.93868/65.62324. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.80462/65.56566. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.83851/65.50500. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.69308/65.44442. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.64075/65.37953. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.55879/65.30541. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.52359/65.22972. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.66038/65.16112. Took 0.34 sec\n",
      "Epoch 54, Loss(train/val) 61.45439/65.09251. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.35211/65.00611. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.38536/64.94059. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.28929/64.84956. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.19801/64.77188. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.35461/64.67970. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.14481/64.59756. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.02811/64.48135. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.92497/64.37209. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.98735/64.23819. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.98254/64.09250. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.89573/63.92794. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.82797/63.74510. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 60.69640/63.56101. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 60.41319/63.39384. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.41048/63.20478. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.21447/63.06528. Took 0.34 sec\n",
      "Epoch 71, Loss(train/val) 60.17159/62.93211. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.03956/62.81399. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.89746/62.67849. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.85505/62.54331. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.84168/62.42873. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 59.65516/62.35672. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.39566/62.28469. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.40163/62.17271. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.30249/62.07635. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.06483/61.95813. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.18391/61.90808. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.94133/61.75409. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.85796/61.69109. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.71435/61.60027. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.64590/61.59157. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.53846/61.48455. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.39144/61.32445. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.34188/61.46012. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 58.30132/61.24944. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.11927/61.15948. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 57.99105/61.10999. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.98667/61.31848. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.95145/60.99813. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.82512/61.24107. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.70518/60.91039. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.43631/61.02632. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.51001/61.16450. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.40650/60.82569. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.33125/60.92894. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.13483997249264842\n",
      "Epoch 0, Loss(train/val) 70.78610/70.78305. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.74399/70.73003. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.64445/70.67447. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.52317/70.61169. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.43800/70.54264. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.36061/70.46362. Took 0.34 sec\n",
      "Epoch 6, Loss(train/val) 70.29013/70.37497. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.17049/70.27715. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.04781/70.15981. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.94646/70.03126. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.84235/69.89055. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.70108/69.73696. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 69.52150/69.57079. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.34487/69.39908. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.19503/69.21832. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.00631/69.02405. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.78703/68.84184. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.57141/68.66179. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.46124/68.48863. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.25834/68.30564. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 68.01823/68.11668. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 67.77184/67.91521. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 67.53774/67.68827. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.21252/67.42290. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.97970/67.10669. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 66.58258/66.73218. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.24263/66.31991. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.81868/65.96944. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.53284/65.56417. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 65.20977/65.22378. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.92824/64.89255. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.69663/64.59890. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 64.35785/64.32040. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.20496/64.03219. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.90487/63.79514. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.74260/63.54952. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.55301/63.28101. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.45618/63.04952. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.13940/62.78638. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.12108/62.52626. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.83381/62.29885. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.72836/62.00995. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.36046/61.74069. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.33190/61.45367. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.21896/61.15071. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.96775/60.87140. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.70519/60.54753. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.49542/60.24103. Took 0.34 sec\n",
      "Epoch 48, Loss(train/val) 61.39126/59.92910. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.30554/59.64691. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.07254/59.37530. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.94603/59.09212. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.72237/58.83680. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.54894/58.62803. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.54702/58.46703. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.22821/58.29379. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.14594/58.17460. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.93179/58.04700. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.00425/58.02573. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.96262/57.74171. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.71581/57.74311. Took 0.34 sec\n",
      "Epoch 61, Loss(train/val) 59.77380/57.52608. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.62927/57.52974. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.43799/57.35635. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.41371/57.35936. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 59.31701/57.17245. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.17802/57.29148. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.05545/57.00361. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.17062/57.19416. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.02586/57.02016. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.90075/56.88862. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.01601/56.99554. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.64386/56.68275. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.61158/56.77698. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.69916/56.64326. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.48509/56.71071. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.35603/56.52532. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.33327/56.41756. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.27516/56.31376. Took 0.34 sec\n",
      "Epoch 79, Loss(train/val) 58.44870/56.36057. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.24218/56.29352. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.32534/56.15199. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.14527/56.21838. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.08952/56.18728. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.06506/56.12282. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.82492/56.01230. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.83060/55.63639. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.97777/55.86497. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 57.58290/56.05708. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 57.62593/55.67002. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.69368/55.61680. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.53125/55.75297. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.64196/55.93206. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.49542/55.82579. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.51321/55.65889. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.42293/55.30588. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.49282/55.77715. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.72545/54.55582. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.53356/55.66048. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.12766/54.62484. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.11056588493219922\n",
      "Epoch 0, Loss(train/val) 71.74236/71.19477. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 71.50068/71.09743. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.28222/70.99680. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 71.02480/70.89828. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.78244/70.79433. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.51249/70.68228. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 70.23220/70.56931. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.92879/70.44772. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.61857/70.31674. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.28075/70.16724. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.93988/69.99183. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.53831/69.77885. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.11020/69.52747. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.71498/69.24986. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.33972/68.95812. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.81949/68.67410. Took 0.34 sec\n",
      "Epoch 16, Loss(train/val) 66.43244/68.39231. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.07389/68.12072. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.80333/67.85654. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.34794/67.58632. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.08083/67.32468. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.79257/67.06473. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.46406/66.80909. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.13835/66.56296. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.94080/66.34277. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.71679/66.15361. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.63828/65.98087. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.42229/65.82787. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.45322/65.69561. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.25304/65.57976. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.13461/65.48401. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.07986/65.38355. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.96308/65.31213. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.89030/65.28104. Took 0.34 sec\n",
      "Epoch 34, Loss(train/val) 62.66908/65.28434. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.68049/65.27017. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.62636/65.27789. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.46704/65.29977. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.50658/65.32920. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.40063/65.34969. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.38550/65.39135. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.32259/65.42363. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.16667/65.42855. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.28621/65.44716. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.03392/65.45590. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.07018/65.45393. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.94935/65.45357. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.93570/65.46870. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.82222/65.47163. Took 0.34 sec\n",
      "Epoch 49, Loss(train/val) 61.77878/65.46870. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.61947/65.44287. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.67555/65.43665. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.58342/65.41759. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.53500/65.39722. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.44942/65.35638. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.46547/65.31001. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.43371/65.23338. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.27760/65.17393. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.30183/65.15431. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.04331/65.09149. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.11486/65.03815. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.07054/64.93891. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.88387/64.86333. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.71317/64.73288. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.76053/64.60251. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.54911/64.50472. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.59891/64.39337. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.38565/64.37134. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.26707/64.25400. Took 0.34 sec\n",
      "Epoch 69, Loss(train/val) 60.07400/64.19134. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.14613/64.12053. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.85878/64.08125. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.89181/64.04402. Took 0.34 sec\n",
      "Epoch 73, Loss(train/val) 59.61560/63.98013. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.54676/63.93589. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.43977/63.85506. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.43498/63.81602. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.28219/63.79576. Took 0.34 sec\n",
      "Epoch 78, Loss(train/val) 59.25287/63.72371. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.16166/63.65551. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.09798/63.63791. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.88278/63.58238. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.64464/63.46825. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.70949/63.31670. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.74801/63.28241. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.52613/63.14147. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.62350/63.03501. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.47431/63.00341. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.33771/62.87403. Took 0.34 sec\n",
      "Epoch 89, Loss(train/val) 58.37705/62.90487. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.14879/62.81002. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.18779/62.70962. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.12963/62.76466. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.07430/62.73402. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.83291/62.60389. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 57.81755/62.62406. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.88746/62.59476. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.74134/62.47830. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.55903/62.39307. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.74689/62.36187. Took 0.32 sec\n",
      "ACC: 0.5, MCC: -0.01659128610703117\n",
      "Epoch 0, Loss(train/val) 71.00607/70.34972. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.62305/70.07408. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.22648/69.82155. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.86158/69.59505. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.50685/69.39019. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.09847/69.19061. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.72985/68.98340. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.21097/68.75224. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.74102/68.48109. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.26231/68.16553. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.69924/67.81366. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.98426/67.43498. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.59987/67.05276. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.02428/66.68472. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.54827/66.33652. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.14499/66.00977. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.88922/65.77553. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.45365/65.57486. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.21449/65.38761. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.00386/65.21402. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.69821/65.04505. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 62.50253/64.90021. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.26538/64.76847. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.12626/64.64144. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.84021/64.50996. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.75293/64.37299. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 61.50524/64.22704. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.25215/64.03610. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.89883/63.76552. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.77337/63.43013. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.49921/63.07877. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.07229/62.87128. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.83074/62.75144. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 59.62614/62.67356. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.51857/62.60939. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.35705/62.55127. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.51187/62.50243. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.23891/62.45499. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.22302/62.41660. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.25899/62.37703. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.16092/62.33598. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.16134/62.29603. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.28660/62.25994. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.10311/62.23012. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.07302/62.20334. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.94992/62.18237. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.93282/62.16746. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.93010/62.16082. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.00452/62.14368. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.76474/62.12851. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.83468/62.11252. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.75743/62.10213. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.78923/62.08306. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.70752/62.07263. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 58.59797/62.06852. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.72529/62.05792. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.60731/62.04425. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.79731/62.04001. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.63659/62.03577. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.61351/62.02377. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 58.61001/62.01277. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.60621/62.00881. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.60312/62.00134. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.40452/61.99421. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 58.56881/61.98768. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.55577/61.97855. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.41583/61.97316. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.57814/61.96530. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.31367/61.94369. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.41899/61.92917. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.40303/61.91409. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.56625/61.90939. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.53862/61.89879. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.29517/61.88448. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.28728/61.86976. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.30385/61.85026. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.42464/61.81968. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 58.26506/61.80082. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.33190/61.77009. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.44373/61.75394. Took 0.34 sec\n",
      "Epoch 80, Loss(train/val) 58.19458/61.74981. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.34296/61.68360. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.26704/61.59190. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.27068/61.52748. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.14543/61.48014. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.19861/61.46166. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.10753/61.38354. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.20862/61.28579. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.00054/61.24453. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.07373/61.17963. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 57.92677/61.19233. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.96718/61.26968. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.75729/61.36246. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.72145/61.32070. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.68523/61.51827. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.65373/61.51908. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.76771/61.52278. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.53476/61.57857. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.56754/61.51427. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.50747/61.48737. Took 0.33 sec\n",
      "ACC: 0.40625, MCC: -0.20464559184764586\n",
      "Epoch 0, Loss(train/val) 70.48687/71.33191. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.15339/71.01123. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.82315/70.69028. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.47193/70.34496. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.20534/69.99847. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.88395/69.65591. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.52483/69.31489. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.24249/68.98794. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.82592/68.66726. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.46214/68.35845. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.07594/68.04351. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.76613/67.71776. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.34773/67.37588. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.91277/67.01640. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.40519/66.64335. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.90901/66.26094. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.42035/65.87083. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.88532/65.48982. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.44629/65.12267. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.02184/64.78413. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.66834/64.46921. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 62.22456/64.18925. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.99852/63.93685. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.65426/63.70359. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 61.49843/63.49322. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.37781/63.30537. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 61.14583/63.14018. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 61.00956/62.97729. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.73851/62.79829. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.67593/62.61555. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.18948/62.41158. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 60.26609/62.17586. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.06515/61.89966. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.76920/61.61240. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.68551/61.34953. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.46656/61.12493. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.48932/60.93052. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 59.40024/60.76746. Took 0.34 sec\n",
      "Epoch 38, Loss(train/val) 59.16526/60.61242. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.27944/60.46757. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.00622/60.33118. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.93457/60.21049. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.85476/60.09662. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.62146/59.99591. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.64880/59.90697. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.38456/59.82748. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.33061/59.75219. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.22091/59.68167. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.32095/59.62334. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.04580/59.57846. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 57.89309/59.53526. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.92806/59.49651. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 57.81363/59.46650. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 57.75346/59.43984. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.49533/59.41189. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.65215/59.38475. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.33846/59.35423. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.39123/59.31990. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.31291/59.27357. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.33147/59.23749. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.34296/59.19937. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 57.14052/59.15847. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 57.11178/59.12296. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 56.99234/59.07836. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.27794/59.04656. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.07138/59.01950. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.05041/58.98332. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 56.73841/58.94924. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 56.78193/58.92574. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.05719/58.89619. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.65681/58.88081. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.65462/58.85983. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.64657/58.83601. Took 0.34 sec\n",
      "Epoch 73, Loss(train/val) 56.74630/58.82461. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.52987/58.81730. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.66950/58.79271. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 56.65429/58.78899. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.45715/58.77328. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.62552/58.75742. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.60539/58.73575. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.47778/58.72040. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.66049/58.70763. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.64597/58.68359. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.37899/58.66437. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.44618/58.65037. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.48591/58.61866. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.59075/58.61593. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.47248/58.59470. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.44703/58.57486. Took 0.34 sec\n",
      "Epoch 89, Loss(train/val) 56.53511/58.54248. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.29440/58.52488. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.32795/58.49081. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 56.30190/58.47928. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.40994/58.47325. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 56.35139/58.43716. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.28327/58.41773. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 56.23741/58.40776. Took 0.34 sec\n",
      "Epoch 97, Loss(train/val) 56.30662/58.40348. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.34154/58.37122. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.13555/58.35787. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: -0.02480694691784169\n",
      "Epoch 0, Loss(train/val) 70.43853/69.92724. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.19635/69.72758. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.99517/69.52896. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.78923/69.33207. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.51686/69.12139. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.30956/68.88130. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.05999/68.61127. Took 0.34 sec\n",
      "Epoch 7, Loss(train/val) 68.79458/68.29574. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.57615/67.94043. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.24211/67.52168. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.02091/67.01844. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.70018/66.45788. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.34276/65.79901. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.99164/65.05019. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.59126/64.19713. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.11582/63.25922. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.79697/62.28188. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.46170/61.35554. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.03613/60.57541. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.56908/59.96242. Took 0.34 sec\n",
      "Epoch 20, Loss(train/val) 64.28913/59.53767. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.03483/59.22094. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.75626/58.97565. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.66710/58.78911. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.49179/58.63511. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.29881/58.51228. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.17577/58.40092. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.32374/58.29900. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.03026/58.20021. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.95466/58.10986. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.86957/58.01308. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.90975/57.92069. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.94850/57.83509. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.67227/57.75002. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.56060/57.66916. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.55756/57.60040. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.41541/57.52596. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.31559/57.45061. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.29613/57.38038. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.14491/57.30816. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.06643/57.23858. Took 0.34 sec\n",
      "Epoch 41, Loss(train/val) 62.27385/57.16787. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.85867/57.09502. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.83224/57.04512. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.71007/56.99718. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.65120/56.95489. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.73752/56.92749. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.41698/56.91366. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.46634/56.89029. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.29721/56.86405. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.26498/56.83331. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.17267/56.82624. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.23985/56.80555. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.09817/56.79078. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.98055/56.79744. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.91713/56.78109. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.87848/56.77406. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.86793/56.75715. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.80811/56.74664. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.66608/56.74155. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.57304/56.73787. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.54829/56.74260. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.58866/56.74996. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.56428/56.74931. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.46340/56.73355. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.33283/56.73222. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.33070/56.71197. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.17127/56.70655. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.35178/56.69896. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.96839/56.70021. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.97229/56.68417. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.98554/56.64521. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.89452/56.61356. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.91452/56.58704. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.01047/56.58065. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.74503/56.56812. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.80398/56.54288. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.83162/56.50149. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.54688/56.46878. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.68248/56.41556. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.71374/56.39928. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.48656/56.38554. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.33434/56.33656. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.49201/56.31353. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.21697/56.27401. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.44546/56.26586. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.12431/56.21196. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.26261/56.17561. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.10527/56.15236. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 59.24645/56.12082. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 59.01750/56.12045. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.96890/56.09674. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.14729/56.07738. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 59.07337/56.05601. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.09445/56.04458. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.01852/55.97599. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 58.84543/55.91293. Took 0.34 sec\n",
      "Epoch 97, Loss(train/val) 58.89932/55.91854. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.95865/55.88787. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.93986/55.87020. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.12682630177432805\n",
      "Epoch 0, Loss(train/val) 71.92608/71.04520. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.71312/70.90749. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.47914/70.76816. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 71.30422/70.62968. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 71.05243/70.48974. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.84507/70.34419. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.66243/70.20216. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 70.41023/70.06372. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.25891/69.92989. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 70.02270/69.80329. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.72650/69.68362. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.47236/69.56758. Took 0.34 sec\n",
      "Epoch 12, Loss(train/val) 69.26893/69.44901. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.97682/69.32726. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.76431/69.20415. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.43235/69.07339. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 68.16616/68.92841. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.86130/68.77180. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.51803/68.59787. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.16086/68.40859. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.72574/68.19575. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.27922/67.97322. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.89816/67.74611. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.57929/67.52591. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.04566/67.29611. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.50633/67.07669. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.16218/66.86160. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.85793/66.66422. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.38920/66.50188. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.30514/66.37708. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.96633/66.27679. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.66634/66.20812. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.38161/66.17258. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.07315/66.15308. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.16112/66.15044. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.10476/66.15382. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.69163/66.20366. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.70258/66.26860. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.56310/66.26761. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.38284/66.30335. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.24904/66.34303. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.08562/66.36650. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.88955/66.40510. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.06844/66.52116. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.85615/66.47613. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.83584/66.52152. Took 0.34 sec\n",
      "Epoch 46, Loss(train/val) 60.68759/66.46611. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.60332/66.58733. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.62680/66.51362. Took 0.34 sec\n",
      "Epoch 49, Loss(train/val) 60.42620/66.60756. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.38075/66.62727. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.24619/66.68559. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.30432/66.68245. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.12840/66.76845. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.11371/66.69974. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.93746/66.77753. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.89374/66.82532. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.84415/66.89956. Took 0.34 sec\n",
      "Epoch 58, Loss(train/val) 59.83408/66.89875. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.63600/66.93084. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.64826/66.95338. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.58613/66.95222. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.48115/66.98145. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 59.35445/66.92102. Took 0.34 sec\n",
      "Epoch 64, Loss(train/val) 59.35247/66.97916. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.35970/66.89896. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.29553/66.98558. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.27629/66.92168. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.14914/66.95802. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.32071/66.90558. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.20647/66.90533. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.03065/66.85985. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.96218/66.90024. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.99268/66.83955. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.91403/66.83849. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 58.85615/66.73685. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.88745/66.79678. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.68274/66.78068. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.93238/66.74329. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.83358/66.67556. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.65300/66.64702. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.53239/66.59418. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.56184/66.58733. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.65880/66.45341. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.51072/66.54668. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.46498/66.54851. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 58.55149/66.53336. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.41192/66.53413. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.24456/66.49188. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.27626/66.54243. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.24891/66.45818. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.23372/66.42345. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.98814/66.40566. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 58.18326/66.27065. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.14117/66.24644. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.21116/66.25809. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.88384/66.16058. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.07839/65.93897. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.83516/65.93124. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.93317/65.79491. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.04115547222147856\n",
      "Epoch 0, Loss(train/val) 70.90088/71.28603. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.61778/70.92638. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.37147/70.58915. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.11747/70.26759. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.87734/69.95421. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.67724/69.65967. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.40764/69.37871. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.15818/69.11059. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.91698/68.85002. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.70691/68.58048. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.41928/68.29869. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.16153/67.99988. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.81852/67.67075. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.47695/67.31564. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.17092/66.94547. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.82893/66.55162. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.42171/66.14104. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.98404/65.70905. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.58351/65.25499. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.21743/64.77467. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.79091/64.28998. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.43673/63.83579. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.10268/63.43042. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.70463/63.08910. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.47225/62.80906. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.11107/62.57325. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.06449/62.37644. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.70557/62.21558. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.64595/62.08481. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.48161/61.97063. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.32561/61.87115. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.30131/61.77239. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.26653/61.67470. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.11869/61.59026. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.99942/61.50784. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.03005/61.44018. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.94918/61.37947. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.75108/61.32462. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.85255/61.27357. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 61.68355/61.22314. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 61.61050/61.18615. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.68737/61.15641. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.52027/61.13181. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.62871/61.10390. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.43435/61.07356. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.61319/61.04322. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.54158/61.02123. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.50514/61.00242. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.28340/60.98286. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.35230/60.95929. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.30871/60.93856. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.20696/60.91769. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.24088/60.89762. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.24540/60.88297. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.18099/60.88219. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.18281/60.87344. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.27403/60.86753. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.18686/60.86226. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.10169/60.85242. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.09874/60.84299. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.08559/60.84428. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.18878/60.84602. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.95420/60.83865. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.04563/60.83325. Took 0.34 sec\n",
      "Epoch 64, Loss(train/val) 60.95190/60.83265. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.20014/60.83085. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.03644/60.83085. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.03390/60.83309. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 60.95252/60.82923. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.98666/60.83021. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.92916/60.82881. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.92515/60.82484. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.97696/60.82833. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.96751/60.83340. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.84296/60.82838. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.81710/60.83224. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.77256/60.83508. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.74766/60.83896. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 60.86586/60.84113. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.80750/60.85016. Took 0.34 sec\n",
      "Epoch 80, Loss(train/val) 60.81164/60.85548. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.58186/60.85677. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.77061/60.85975. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 60.61752/60.85865. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.73135/60.86353. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.54155/60.86822. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.55818/60.86459. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.58431/60.86974. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 60.58201/60.89693. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.59224/60.92520. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.54970/60.93932. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.47688/60.94946. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.44100/60.95460. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.59106/60.96725. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 60.40701/60.98193. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.41572/60.98414. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.41870/60.99681. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.33307/61.00880. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 60.19434/61.03183. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 60.22123/61.05224. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) 70.56849/70.16920. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.23176/69.97305. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.98212/69.76911. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.66905/69.54842. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.31642/69.30650. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.04707/69.03530. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.72594/68.73782. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.32035/68.40516. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.96418/68.03474. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.52467/67.62802. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.17417/67.18494. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.56768/66.71609. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.10484/66.22852. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.68864/65.73788. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.21932/65.25182. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.67831/64.77395. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.29853/64.31556. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.87941/63.87016. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.49109/63.44145. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.12183/63.00320. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.73782/62.56961. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 62.54191/62.13569. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.99704/61.69202. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.65753/61.29388. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.33373/60.96500. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.02273/60.69751. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.68945/60.42611. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.39939/60.17088. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.15658/59.94335. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 59.99792/59.71545. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.71345/59.47621. Took 0.34 sec\n",
      "Epoch 31, Loss(train/val) 59.39486/59.27657. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.27730/59.03278. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.07033/58.79087. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.06590/58.67464. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 58.83671/58.48806. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.59607/58.35021. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.47215/58.17603. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.50029/58.03851. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.29469/57.88430. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 58.27679/57.76225. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.11261/57.65862. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 58.08473/57.53646. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 57.71901/57.44879. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 57.72737/57.31546. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 57.70719/57.23562. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 57.38911/57.11948. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.32638/57.06281. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.24288/56.96011. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.18067/56.87395. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 56.94101/56.80371. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 56.90075/56.70651. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 56.70450/56.63202. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 56.65279/56.56202. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 56.55957/56.48947. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 56.34473/56.45566. Took 0.34 sec\n",
      "Epoch 56, Loss(train/val) 56.25174/56.39894. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 56.11820/56.33418. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 55.90592/56.34365. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 55.66521/56.42550. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 55.74077/56.24828. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 55.35456/56.24870. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 55.29816/56.35130. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 55.39232/56.26003. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 55.16704/56.24858. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 55.06566/56.21851. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 54.88592/56.12088. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 54.71017/56.01824. Took 0.34 sec\n",
      "Epoch 68, Loss(train/val) 54.67937/55.78823. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 54.55115/55.86021. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 54.38671/55.69873. Took 0.34 sec\n",
      "Epoch 71, Loss(train/val) 54.40856/55.60985. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 54.35429/55.48668. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 54.19255/55.40791. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 54.12960/55.37063. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 54.22817/55.18731. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 53.91243/55.05692. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 53.79364/54.90348. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 53.63538/54.82401. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 53.67038/54.76390. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 53.61620/54.83035. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 53.53296/54.99342. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 53.80814/54.90422. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 53.57451/54.77479. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 53.47384/54.54310. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 53.45574/54.40918. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 53.35368/54.42319. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 53.20686/54.45352. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 53.05647/54.57111. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 53.08468/54.66393. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 53.26666/54.59345. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 53.15936/54.52562. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 53.06065/54.43061. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 52.98048/54.25527. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 52.93704/54.13083. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 53.02521/54.06705. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 52.91874/54.11497. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 52.76834/54.49881. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 52.81549/54.40850. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 52.81206/54.25232. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.13235242923632212\n",
      "Epoch 0, Loss(train/val) 70.76714/71.52485. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.48625/71.22247. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.21380/70.91473. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.94374/70.59995. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.63992/70.26747. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.27222/69.91241. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.94539/69.53806. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.59556/69.15087. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.18535/68.75616. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.83217/68.36193. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.49714/67.97718. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.11680/67.60641. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.70079/67.24463. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.29910/66.89015. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.87641/66.53906. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.51762/66.19086. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.10520/65.85023. Took 0.34 sec\n",
      "Epoch 17, Loss(train/val) 64.73547/65.52617. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.41487/65.23058. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.95336/64.96597. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.64036/64.72137. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.26320/64.49289. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.96026/64.25985. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.64774/64.01437. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.49158/63.74714. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.06826/63.48102. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.98128/63.24116. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.67720/63.04527. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.59011/62.89648. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.36956/62.75940. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.25626/62.63303. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.08401/62.52222. Took 0.34 sec\n",
      "Epoch 32, Loss(train/val) 60.79629/62.42030. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.05223/62.32535. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.76051/62.23583. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.58318/62.14856. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 60.55619/62.06356. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.51382/61.97409. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.29663/61.88958. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.32737/61.80627. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.34219/61.71302. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.98855/61.61760. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 59.83838/61.54125. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.86288/61.49460. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.77385/61.48505. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 59.47888/61.43866. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.52873/61.41184. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.56820/61.41979. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.40808/61.30736. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.32830/61.34269. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.26809/61.28886. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.16975/61.23754. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.02872/61.21225. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.00933/61.16619. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.94068/61.16936. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 58.99298/61.08017. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 58.84491/61.04672. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.99974/61.06145. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.70853/60.99695. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.68320/60.95971. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 58.63095/60.97054. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.68873/60.89228. Took 0.34 sec\n",
      "Epoch 62, Loss(train/val) 58.63767/60.92119. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.58152/60.85586. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.52310/60.80864. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.38926/60.79660. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 58.33760/60.75093. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.44496/60.70664. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 58.19475/60.70767. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.34202/60.62490. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 58.11960/60.59654. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.35962/60.59016. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.22979/60.57393. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.11896/60.58487. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.14726/60.47265. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.18659/60.46342. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.01486/60.43882. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 57.94858/60.42592. Took 0.34 sec\n",
      "Epoch 78, Loss(train/val) 58.15137/60.35551. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 57.82670/60.32083. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 57.99615/60.36902. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 57.84152/60.30592. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.71519/60.25029. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 57.84784/60.26793. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.65540/60.15106. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.60656/60.22371. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.53081/60.08794. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.49551/60.15472. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.51217/60.08274. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 57.22339/59.95560. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 57.33422/60.10146. Took 0.34 sec\n",
      "Epoch 91, Loss(train/val) 57.40887/59.96186. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.26079/59.95439. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.23818/59.85569. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.23697/59.85442. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 57.14042/59.85498. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.07278/59.84857. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.14666/59.65983. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.06509/59.83878. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.10730/59.65277. Took 0.32 sec\n",
      "ACC: 0.390625, MCC: -0.11786009846708258\n",
      "Epoch 0, Loss(train/val) 70.30512/70.52361. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.06344/70.29827. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.98065/70.06673. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.78135/69.82143. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.59885/69.56483. Took 0.34 sec\n",
      "Epoch 5, Loss(train/val) 69.37605/69.27740. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.15783/68.95866. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.99694/68.62322. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.63733/68.25729. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.49533/67.85453. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.19901/67.42898. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.78496/66.97818. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.48161/66.50570. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.22177/66.02791. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.94690/65.53713. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.61407/65.03452. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.32556/64.51313. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.12175/63.97079. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.63869/63.40097. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 65.35456/62.82115. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.12503/62.23762. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.79321/61.66537. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.39562/61.11570. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.12301/60.65192. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.94981/60.27723. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.67190/59.95924. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.50676/59.68766. Took 0.34 sec\n",
      "Epoch 27, Loss(train/val) 63.37097/59.45277. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.27891/59.27638. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.00520/59.11179. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 63.07800/58.98477. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.92626/58.87655. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.91048/58.77198. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.73584/58.68121. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.65094/58.61255. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.61085/58.56122. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.57933/58.51925. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.43731/58.47045. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.44873/58.44445. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.26741/58.43294. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.20694/58.43549. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.11328/58.44618. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.97003/58.49474. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.01935/58.53744. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.97485/58.58834. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.88906/58.57837. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.76923/58.62925. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.50405/58.66583. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.63719/58.62292. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.65937/58.62838. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.49856/58.61288. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.31012/58.68077. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.24688/58.62817. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.33223/58.69148. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.13013/58.78691. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.80429/58.51453. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.88948/58.73140. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.99278/58.56928. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.90993/58.69484. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.71106/58.67642. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.76921/58.62176. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.71263/58.85156. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.55133/58.65311. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.52563/58.85945. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.54882/58.94394. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.45399/58.90559. Took 0.34 sec\n",
      "Epoch 66, Loss(train/val) 60.32956/59.19094. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.12725/59.19014. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.15923/59.13213. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.02475/59.08918. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.12262/59.27157. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.87280/58.96359. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.92431/59.17458. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.64455/59.10440. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.68991/59.22613. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.69107/58.72577. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.65795/59.28444. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.44940/58.98301. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.25423/59.25135. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.21945/58.76640. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.34182/58.99867. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 59.22041/59.02359. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.17900/58.75518. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.90475/59.19542. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.81861/58.94985. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.82587/58.74881. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.82979/58.91717. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.66123/59.09434. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.62546/58.93761. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.48035/58.90311. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.15557/58.71133. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.23882/58.93729. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.26856/58.77887. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 58.01273/58.67529. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.79316/58.84725. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.74079/58.69211. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.67930/58.92121. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.63590/58.80849. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.46001/58.91207. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.50266/58.87788. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.054366028221956235\n",
      "Epoch 0, Loss(train/val) 70.00273/69.93504. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.70929/69.70007. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.39687/69.43033. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.04117/69.13184. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.62345/68.78479. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.24086/68.38680. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.70760/67.92860. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.05191/67.39485. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.23272/66.79939. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 65.62628/66.17689. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 64.80948/65.72412. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 64.24978/65.36752. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 63.48092/65.03530. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 62.97687/64.73647. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 62.41239/64.52492. Took 0.34 sec\n",
      "Epoch 15, Loss(train/val) 62.13734/64.33708. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 61.67794/64.14992. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 61.29101/63.96924. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 61.25535/63.80768. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 61.00566/63.66940. Took 0.34 sec\n",
      "Epoch 20, Loss(train/val) 60.88415/63.53875. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 60.79496/63.41194. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 60.79935/63.31683. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 60.40543/63.24180. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.67110/63.18184. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 60.33469/63.12724. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.15902/63.10200. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 59.93420/63.07070. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.13721/63.03402. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.04146/63.00181. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.81577/63.00449. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 59.71700/63.00086. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.63926/63.00481. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 59.69033/62.97364. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.39140/63.00604. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.38530/63.00948. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.07847/62.95843. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.05711/62.91373. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.82773/62.86562. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.67517/62.85828. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.77316/62.79518. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.55592/62.76897. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.25976/62.74816. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 58.28485/62.68542. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.18619/62.67074. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.18324/62.61690. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 57.96825/62.64724. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.90421/62.51891. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 57.89007/62.54277. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.77230/62.47341. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 57.70307/62.44093. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.71282/62.30748. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.46020/62.30743. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 57.53018/62.31392. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.40630/62.22908. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 57.48190/62.26937. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.50471/62.10133. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.43096/62.07701. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 56.99762/62.12084. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 57.12133/62.02774. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 56.92617/62.06844. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 56.91161/61.94324. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 56.77958/61.95105. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 56.72841/61.86718. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 56.69566/61.78879. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.59422/61.76684. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 56.68031/61.71153. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 56.50131/61.73183. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 56.70004/61.63172. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 56.42996/61.58474. Took 0.34 sec\n",
      "Epoch 70, Loss(train/val) 56.52953/61.56135. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.40759/61.50864. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.36204/61.52537. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.36962/61.45717. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.13353/61.40698. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.27226/61.44408. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.25516/61.36985. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.34650/61.33252. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 56.05521/61.33703. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.04828/61.29181. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 55.90047/61.27150. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.08256/61.21261. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 55.97669/61.22382. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 55.91240/61.17148. Took 0.34 sec\n",
      "Epoch 84, Loss(train/val) 55.90031/61.16233. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 55.97501/61.20498. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 55.94709/61.17267. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 55.66489/61.11978. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.85026/61.13144. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.16424/61.04845. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.76758/61.05888. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.79975/61.05167. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 55.76480/61.00216. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.66074/61.02622. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.60375/61.04958. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.60302/60.98777. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 55.60388/60.94221. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.56951/60.91177. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.61401/60.92102. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.60367/60.85535. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: 0.11378277614173485\n",
      "Epoch 0, Loss(train/val) 69.97113/69.43341. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.47313/68.90269. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 68.99557/68.34319. Took 0.34 sec\n",
      "Epoch 3, Loss(train/val) 68.45663/67.75892. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 67.96147/67.14523. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 67.38268/66.50267. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 66.87342/65.84318. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 66.42059/65.16228. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 65.79242/64.56031. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 65.12779/64.00222. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 64.62688/63.43750. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 64.21199/62.87858. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 63.54282/62.33681. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 63.24444/61.83719. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 62.92990/61.36959. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 62.64116/60.93248. Took 0.35 sec\n",
      "Epoch 16, Loss(train/val) 62.28210/60.58898. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.20764/60.27509. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 61.86226/59.99156. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 61.78415/59.73137. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 61.53461/59.49553. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.49003/59.28131. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 61.24515/59.05470. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.11957/58.81853. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 61.10278/58.59244. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 60.99905/58.35104. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.76396/58.07747. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 60.64146/57.79091. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.53387/57.54675. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.42246/57.35940. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 60.22595/57.19390. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 60.18857/57.05178. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 60.12504/56.93372. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.01366/56.82078. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.96391/56.71181. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.73670/56.61278. Took 0.34 sec\n",
      "Epoch 36, Loss(train/val) 59.78891/56.52842. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.65969/56.46416. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 59.55515/56.39743. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 59.43637/56.31213. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 59.49407/56.22017. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.24874/56.12977. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 59.26271/56.04588. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.08913/55.95522. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.01877/55.88873. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 59.09507/55.82572. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 59.09524/55.73963. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.80108/55.65529. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.74916/55.59742. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.74663/55.49061. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.75330/55.42067. Took 0.34 sec\n",
      "Epoch 51, Loss(train/val) 58.53915/55.31390. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.52858/55.21675. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.53110/55.15464. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.36356/55.03780. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 58.23637/55.00096. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 58.42764/54.99606. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.15406/54.87934. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 58.08510/54.84116. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 57.91571/54.79991. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 57.93969/54.72255. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 57.83714/54.64050. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 57.84217/54.55511. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 57.82470/54.51748. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 57.67381/54.41118. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.55989/54.35448. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.48791/54.25261. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.46727/54.23204. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.26368/54.08610. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.18390/54.08469. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.17467/53.95649. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.06476/53.93977. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 56.87380/53.83142. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 57.14250/53.85722. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 56.93563/53.71566. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.83525/53.78386. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 56.97616/53.60766. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.84236/53.61002. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 56.67088/53.60646. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 56.68873/53.49342. Took 0.34 sec\n",
      "Epoch 80, Loss(train/val) 56.75318/53.59703. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.64148/53.42266. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.60247/53.57712. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.57421/53.44862. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.49052/53.36379. Took 0.34 sec\n",
      "Epoch 85, Loss(train/val) 56.59356/53.43661. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.48784/53.35495. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.52283/53.33022. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 56.40959/53.35863. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 56.49353/53.25032. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.50564/53.31070. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.41684/53.30817. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 56.45039/53.17825. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.37205/53.26731. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 56.40962/53.20915. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.37035/53.23716. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 56.39298/53.26397. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 56.09480/53.19702. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 56.31403/53.17619. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 56.21993/53.22112. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: -0.0010820172848339962\n",
      "Epoch 0, Loss(train/val) 70.82018/70.05644. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.31974/69.83356. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.83321/69.61429. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.38885/69.38799. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.90962/69.14152. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.38837/68.86614. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.81884/68.54931. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.15728/68.18374. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.50057/67.76879. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 65.76448/67.30754. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.02778/66.80435. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 64.38034/66.27361. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 63.58224/65.72897. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 63.05788/65.20114. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 62.45034/64.69360. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 61.93270/64.20750. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 61.52414/63.77149. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 61.17687/63.42436. Took 0.34 sec\n",
      "Epoch 18, Loss(train/val) 60.79732/63.09552. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 60.48982/62.78545. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 60.24587/62.48380. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 60.03533/62.19875. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 59.83476/61.93056. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 59.64071/61.69444. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 59.43986/61.48760. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 59.26494/61.34208. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 59.22018/61.22475. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 59.08644/61.12176. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 58.87331/61.02787. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 58.84075/60.95189. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 58.86769/60.88194. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 58.82174/60.82256. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 58.62455/60.78008. Took 0.34 sec\n",
      "Epoch 33, Loss(train/val) 58.55916/60.75381. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.61508/60.71388. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 58.44827/60.66911. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 58.43162/60.62914. Took 0.34 sec\n",
      "Epoch 37, Loss(train/val) 58.30117/60.59405. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.26175/60.55529. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.28693/60.53140. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 58.21664/60.51242. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.07701/60.49085. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 58.07365/60.47106. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 58.11194/60.45484. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 58.05448/60.43214. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.96920/60.39630. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 58.04882/60.35495. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 57.99017/60.31150. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 57.84060/60.24937. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.85516/60.19581. Took 0.34 sec\n",
      "Epoch 50, Loss(train/val) 57.68617/60.12414. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 57.53241/60.01898. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 57.51069/59.88093. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 57.26932/59.71561. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 57.19222/59.56425. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 56.87183/59.43086. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 56.74072/59.29351. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 56.74005/59.17772. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 56.49107/59.10194. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 56.48488/59.08984. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 56.43787/59.07181. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 56.31624/58.96152. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 56.30247/58.93304. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 56.14952/58.88620. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 56.13029/58.85545. Took 0.34 sec\n",
      "Epoch 65, Loss(train/val) 56.24903/58.77741. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 56.11820/58.65745. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 55.99820/58.62301. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 55.90347/58.64167. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 55.92430/58.59435. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.01189/58.55346. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 55.93637/58.52802. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 55.72506/58.48753. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 55.68131/58.45747. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 55.69288/58.46810. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 55.86071/58.42319. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 55.62691/58.33946. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 55.77761/58.29218. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 55.67677/58.24520. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 55.64129/58.21204. Took 0.34 sec\n",
      "Epoch 80, Loss(train/val) 55.75991/58.20312. Took 0.34 sec\n",
      "Epoch 81, Loss(train/val) 55.63465/58.20816. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 55.47772/58.23845. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 55.31388/58.18264. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 55.44485/58.13273. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 55.36614/58.08419. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 55.36621/58.08258. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 55.22822/58.05064. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 55.19365/58.03800. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 55.37053/58.01696. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 55.42144/57.98500. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 55.21825/57.91288. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 55.26602/57.93411. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 55.25670/57.91079. Took 0.34 sec\n",
      "Epoch 94, Loss(train/val) 55.20190/57.88378. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.16705/57.82978. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.12473/57.72474. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.03032/57.78095. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.13548/57.70261. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.01797/57.74593. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.045322786711889926\n",
      "Epoch 0, Loss(train/val) 71.61043/70.83064. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 71.42640/70.73386. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.20575/70.64975. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 71.00253/70.57577. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.79903/70.51093. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.63223/70.45251. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.40753/70.39993. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 70.22902/70.35143. Took 0.34 sec\n",
      "Epoch 8, Loss(train/val) 70.03330/70.30742. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.79907/70.26717. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.57453/70.23851. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.34654/70.21826. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 69.05435/70.20316. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.74086/70.19920. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.41979/70.20319. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 68.08824/70.20908. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 67.69050/70.21560. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.28073/70.21604. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.89211/70.20866. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.57437/70.19604. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 66.17697/70.19013. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.73854/70.19373. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.51832/70.18993. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.41211/70.17813. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.16070/70.15462. Took 0.34 sec\n",
      "Epoch 25, Loss(train/val) 65.02925/70.12215. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.81465/70.08372. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 64.77131/70.03215. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.50255/69.97585. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.34111/69.91329. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.20639/69.84997. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 64.02035/69.79204. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.95621/69.71667. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.82588/69.63229. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.78095/69.54417. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.51519/69.46724. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.36143/69.38912. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.30423/69.31891. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.26688/69.24458. Took 0.34 sec\n",
      "Epoch 39, Loss(train/val) 63.09726/69.14708. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.91598/69.04681. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.84886/68.97197. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.59430/68.88020. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.54262/68.77803. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.49198/68.69470. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.33754/68.58091. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.13333/68.48126. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.01804/68.36728. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.76686/68.26736. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.64598/68.18164. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.69195/68.13951. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.51122/68.06190. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.38429/67.95740. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.11851/67.89169. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.09746/67.81281. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.05249/67.72333. Took 0.34 sec\n",
      "Epoch 56, Loss(train/val) 60.78635/67.63847. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.53523/67.53867. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.50951/67.43999. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.41108/67.36559. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.17344/67.29562. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 59.99866/67.18642. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.09181/67.15659. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 59.91263/67.05069. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.80265/66.99297. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 59.62135/66.94126. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.31923/66.94996. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.41965/66.82712. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.25247/66.86899. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.12067/66.91322. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 58.95550/66.74236. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.76126/66.78375. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.85788/66.78731. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.91519/66.71901. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 58.52185/66.60096. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 58.38464/66.63506. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.41035/66.48270. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.34018/66.55018. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.24473/66.32065. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.15471/66.38727. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.02890/66.31219. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.03281/66.22340. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.84600/66.12794. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.78364/66.05634. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.64210/65.95672. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.77167/65.90760. Took 0.34 sec\n",
      "Epoch 86, Loss(train/val) 57.50763/65.87585. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.52193/65.85852. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 57.54540/65.77927. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 57.49958/65.73337. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 57.28912/65.64017. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 57.41102/65.60111. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.40777/65.48405. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.24456/65.42549. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.15462/65.34548. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.08746/65.28821. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.01193/65.23592. Took 0.34 sec\n",
      "Epoch 97, Loss(train/val) 56.94773/65.19475. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.04453/65.12360. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.01643/65.13808. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.07273929674533079\n",
      "Epoch 0, Loss(train/val) 70.10819/70.03416. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.62617/69.88414. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.15559/69.71041. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 68.65048/69.50758. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.08163/69.24831. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 67.39930/68.92204. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 66.70850/68.51562. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 65.90243/67.99050. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 65.01675/67.33527. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 64.02377/66.54936. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 63.04186/65.67228. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 62.11126/64.75266. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 61.34274/63.84803. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 60.50495/62.98298. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 59.80402/62.18145. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 59.40669/61.46227. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 58.62871/60.81454. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 58.32334/60.24837. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 57.82600/59.75331. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 57.56386/59.36249. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 57.33788/59.04539. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 57.22707/58.81384. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 56.92011/58.66240. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 56.94930/58.49173. Took 0.34 sec\n",
      "Epoch 24, Loss(train/val) 56.73655/58.24926. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 56.54573/58.05020. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 56.36974/57.90725. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 56.33807/57.78378. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 56.09713/57.76302. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 56.14538/57.70033. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 56.00391/57.64528. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 55.89114/57.56114. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 55.87752/57.49975. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 55.82707/57.49089. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 55.82554/57.47275. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 55.82513/57.43115. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 55.52402/57.40337. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 55.55562/57.38742. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 55.61366/57.37412. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 55.53686/57.36827. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 55.53938/57.32763. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 55.50938/57.32516. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 55.46808/57.37590. Took 0.34 sec\n",
      "Epoch 43, Loss(train/val) 55.33744/57.41367. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 55.39398/57.32224. Took 0.34 sec\n",
      "Epoch 45, Loss(train/val) 55.28250/57.34383. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 55.45511/57.33160. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 55.14889/57.30579. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 55.18615/57.34511. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 55.30399/57.19151. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 55.11862/57.28133. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 55.08282/57.30418. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 54.99085/57.19732. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 55.21922/57.21798. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 55.10263/57.15314. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 55.08310/57.13751. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 55.03225/57.14576. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 55.01816/57.14785. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 54.96382/57.06993. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 55.03035/57.08455. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 54.95550/56.95150. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 54.85380/57.02375. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 54.86555/56.81019. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 54.84262/56.92648. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 54.91530/56.89614. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 54.85180/56.83230. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 54.80246/56.86066. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 54.63333/56.78964. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 54.69922/56.74102. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 54.69636/56.75155. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 54.62629/56.62658. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 54.66990/56.75397. Took 0.34 sec\n",
      "Epoch 72, Loss(train/val) 54.76438/56.68016. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 54.63597/56.62395. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 54.54863/56.54587. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 54.87007/56.35992. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 54.66634/56.57513. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 54.72738/56.58249. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 54.53490/56.37241. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 54.56094/56.46653. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 54.25316/56.48684. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 54.59824/56.49749. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 54.40443/56.28912. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 54.59606/56.28333. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 54.40112/56.07405. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 54.48891/55.90930. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 54.30792/55.92253. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 54.34739/55.80827. Took 0.34 sec\n",
      "Epoch 88, Loss(train/val) 54.42956/55.89664. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 54.39207/55.82859. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 54.23998/55.67981. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 54.21470/55.68715. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 54.54190/55.65593. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 54.24855/55.58828. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 54.04407/55.58675. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 54.43321/55.61481. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 54.27697/55.43784. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 54.33312/55.58267. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 54.15638/55.51695. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 54.11767/55.63331. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.07052955496249108\n",
      "Epoch 0, Loss(train/val) 70.27695/70.28194. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.07473/70.16765. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.84652/70.04380. Took 0.34 sec\n",
      "Epoch 3, Loss(train/val) 69.63571/69.91037. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.36778/69.76243. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.11690/69.60744. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.86746/69.44093. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.62991/69.26817. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.44291/69.09615. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.16989/68.92269. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.88384/68.75282. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.71823/68.58835. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.45951/68.42500. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.29669/68.26893. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.06461/68.10999. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.87813/67.95290. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.76356/67.81037. Took 0.34 sec\n",
      "Epoch 17, Loss(train/val) 66.55587/67.65578. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.38089/67.49744. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.25114/67.33339. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 66.01460/67.16998. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.87788/67.00568. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.73092/66.83755. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.55173/66.69032. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.36891/66.55370. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 65.11468/66.42699. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 65.04987/66.32072. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 64.82481/66.21326. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.68929/66.11533. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.49756/66.02379. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.41123/65.95314. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 64.36962/65.88025. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.10420/65.81844. Took 0.34 sec\n",
      "Epoch 33, Loss(train/val) 63.96622/65.78556. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.05062/65.79010. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.82011/65.78197. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.70911/65.80315. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.57046/65.80811. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 63.48086/65.84145. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.39160/65.85598. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.34821/65.88635. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.37211/65.90308. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.11406/65.91888. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 63.12557/65.94183. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 63.12456/65.95297. Took 0.34 sec\n",
      "Epoch 45, Loss(train/val) 62.93352/66.06213. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.89791/66.06445. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.81309/66.04974. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.90040/66.17615. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.78697/66.29848. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.70608/66.25861. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.56485/66.32378. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.62605/66.37875. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.43886/66.32505. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 62.42839/66.45811. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 62.39395/66.45570. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 62.28680/66.56586. Took 0.34 sec\n",
      "Epoch 57, Loss(train/val) 62.03728/66.56311. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 62.05467/66.51505. Took 0.35 sec\n",
      "Epoch 59, Loss(train/val) 61.92369/66.62010. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.03951/66.64297. Took 0.34 sec\n",
      "Epoch 61, Loss(train/val) 61.82967/66.72235. Took 0.34 sec\n",
      "Epoch 62, Loss(train/val) 61.74324/66.82179. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.77432/66.71332. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.68556/66.88441. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 61.55689/66.75623. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.51586/66.98325. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.43508/67.00127. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 61.26634/67.04533. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 61.21938/66.98997. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.07276/67.24220. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 61.07554/67.05385. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.93445/67.19301. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.67679/67.46078. Took 0.34 sec\n",
      "Epoch 74, Loss(train/val) 60.62917/67.26653. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.59417/67.26721. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.49736/67.51031. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.23549/67.26602. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.99826/67.32549. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.94247/67.37122. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.65238/67.17722. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.53902/67.34592. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.32339/66.83305. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.28527/67.20344. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.17794/66.88704. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.07132/67.01493. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.02965/66.90019. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.82789/66.95575. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.82335/66.86478. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.64836/66.93616. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.55107/66.90557. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.59275/66.95484. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.58511/66.87502. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 58.48148/66.98598. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 58.35774/66.82206. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.43559/66.92516. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.22080/66.95856. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.18927/66.94666. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 58.12932/66.86899. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 58.01524/66.92454. Took 0.33 sec\n",
      "ACC: 0.4375, MCC: -0.12115833547198933\n",
      "Epoch 0, Loss(train/val) 69.95024/69.99527. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 69.76106/69.83640. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 69.62057/69.66428. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.42273/69.48867. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.34220/69.31049. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.14280/69.12881. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.94590/68.92870. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.80960/68.71621. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.57903/68.49771. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.29045/68.24879. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.07485/67.98127. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.69691/67.69514. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.64112/67.39512. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.29006/67.06677. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.90443/66.71593. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.61720/66.34814. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.32997/65.98341. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.92578/65.66562. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.52636/65.38628. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.37059/65.14763. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.09210/64.92726. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.88813/64.72807. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.62617/64.57716. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.60445/64.44700. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 64.45323/64.34342. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.14685/64.28104. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.09749/64.25156. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.05167/64.11951. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.90727/64.03915. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.87935/63.95139. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.56826/63.86050. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.52910/63.85715. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.48160/63.80101. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.32482/63.88676. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.31165/63.86639. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.18076/63.75315. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.28220/63.78389. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.88153/63.71234. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.12273/63.60088. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.80209/63.61540. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.88620/63.46968. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.66203/63.44948. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.51057/63.46426. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.49671/63.21087. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.48920/63.29163. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.35671/63.17481. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.27988/63.11097. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.16989/63.11789. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.13833/62.84702. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.93029/62.92379. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.25326/62.79276. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.68493/62.74410. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.76536/62.71068. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.86531/62.71235. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.66002/62.57960. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.59212/62.54999. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.67772/62.66264. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.38613/62.48949. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.45228/62.32751. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.36961/62.38541. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.35526/62.41028. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.23224/62.48889. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.10765/62.06557. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.23824/62.26364. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.11964/62.35889. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.93913/62.16623. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.98100/62.07355. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.91966/62.02840. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.61360/62.01985. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.81952/62.01812. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.66992/61.55286. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.45250/61.97365. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.36485/61.57515. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.32369/61.32995. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.26419/61.76323. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.22022/61.67376. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.12449/61.30213. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.12714/61.11566. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.04104/61.97964. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.87665/61.65633. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.67330/61.55080. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.73990/61.36652. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.67129/61.62746. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.52103/61.76532. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.40988/61.22870. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.69760/61.50349. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.43156/61.94987. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.29298/61.68266. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.25216/61.19237. Took 0.34 sec\n",
      "Epoch 89, Loss(train/val) 59.38452/61.14341. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 59.38824/61.59293. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.04530/61.38751. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.07135/61.20818. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.12291/61.61231. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.85919/61.35650. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.01233/61.27243. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.92000/61.40625. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.67146/61.25605. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.59115/61.05714. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.58522/60.89638. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.07495746605704415\n",
      "Epoch 0, Loss(train/val) 71.03226/71.05516. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.79802/70.83326. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.56623/70.60616. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.30534/70.37161. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.05233/70.12226. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.80902/69.85275. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.49485/69.57038. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.19691/69.27116. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.92264/68.95293. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.57622/68.62168. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.30764/68.27729. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.11005/67.92978. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.83246/67.58124. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.66407/67.23792. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.38992/66.89877. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.15088/66.56693. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.87381/66.23749. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.80518/65.92133. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.59291/65.61605. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.30295/65.30891. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.26539/65.01587. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.98936/64.72744. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.73619/64.44394. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.67724/64.16289. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.42634/63.88443. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 65.32035/63.62022. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.08182/63.37031. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.08808/63.14056. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.88382/62.92732. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.76832/62.73067. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.61883/62.55061. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 64.51427/62.37240. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.30968/62.20057. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.15927/62.03363. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 64.04415/61.86689. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.97149/61.70436. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.79149/61.53576. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.55929/61.35038. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.23859/61.13611. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.07711/60.89353. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.74387/60.63831. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.54255/60.40963. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.14759/60.23977. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.16868/60.12647. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.98827/60.04675. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.97098/59.98326. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.57847/59.92421. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.54323/59.86509. Took 0.34 sec\n",
      "Epoch 48, Loss(train/val) 61.52738/59.80849. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.52778/59.75146. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.43723/59.69279. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.23606/59.62595. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.22616/59.55897. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.07011/59.48940. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.08245/59.41761. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.87583/59.34415. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.81228/59.27057. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.85536/59.19872. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.61201/59.12885. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.60638/59.06556. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.49847/59.00522. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.49553/58.95051. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.27733/58.91048. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.34753/58.87731. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.25096/58.83990. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.29302/58.80171. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.13965/58.78411. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.12336/58.76890. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 60.10075/58.75522. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.96970/58.75088. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.81671/58.73095. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.02791/58.71182. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.90757/58.69774. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.89828/58.69440. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.80109/58.67731. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 59.78162/58.67112. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.77907/58.66820. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.66415/58.66861. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.63547/58.66446. Took 0.34 sec\n",
      "Epoch 79, Loss(train/val) 59.73971/58.65977. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.54394/58.65245. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 59.49801/58.64682. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.57544/58.65195. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.45815/58.64645. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.48873/58.62369. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.53185/58.61530. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.40689/58.61898. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.36893/58.60830. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.49503/58.58038. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.35547/58.56817. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.34890/58.54641. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.22177/58.54009. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 59.19983/58.52280. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 58.99384/58.50393. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.18139/58.47859. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.06998/58.45766. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.24310/58.45086. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.13618/58.45280. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.09692/58.43824. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.07260/58.46069. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.10977208603939476\n",
      "Epoch 0, Loss(train/val) 70.96388/71.81221. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.69374/71.57744. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.41989/71.36047. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.19700/71.14886. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.95917/70.94408. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.65989/70.74278. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.41702/70.53630. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.14647/70.32114. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.85016/70.09348. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.52324/69.85042. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.14442/69.58611. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 67.79793/69.29591. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.44175/68.96627. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.92698/68.57562. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.36792/68.10899. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.82453/67.56449. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.14248/66.92797. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.54656/66.24813. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.94290/65.55439. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.32980/64.86307. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.76170/64.16730. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.36461/63.51197. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.88750/62.95175. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.25605/62.46696. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.06111/62.14029. Took 0.34 sec\n",
      "Epoch 25, Loss(train/val) 60.85479/61.88417. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 60.69757/61.66769. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.56998/61.46790. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.39934/61.28426. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.37820/61.11704. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.03754/60.96384. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.88811/60.84717. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.99437/60.74241. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.73859/60.60751. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.66965/60.49366. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.61658/60.39455. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.59747/60.28425. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.53840/60.16402. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.66446/60.05317. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.30982/59.95624. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.22423/59.87777. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.30766/59.80464. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.19507/59.74039. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.32517/59.68920. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.19757/59.61607. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.90781/59.57197. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.86962/59.52133. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 58.90952/59.44766. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.97020/59.37362. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.86622/59.28643. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.81449/59.22208. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.69955/59.16861. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.66810/59.08074. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.61000/58.98502. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.62871/58.92359. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 58.59703/58.84423. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.41769/58.78377. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.46204/58.69933. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 58.34558/58.60063. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.34245/58.54677. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.15865/58.44653. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.32146/58.35892. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.09735/58.36641. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.16005/58.30701. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.17953/58.26163. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.16901/58.20819. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.04145/58.12356. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.83883/58.07946. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 57.93573/58.09113. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.07790/57.98920. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.79857/57.93369. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.80457/57.92709. Took 0.34 sec\n",
      "Epoch 72, Loss(train/val) 57.84348/57.87258. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.81083/57.82229. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.73947/57.79374. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.74765/57.78358. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 57.63037/57.76921. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.31267/57.69781. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.65500/57.63902. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.42431/57.59983. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.44604/57.67733. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.48246/57.58147. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 57.39663/57.58856. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.32620/57.56913. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.36435/57.51523. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.32079/57.44626. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.14530/57.43108. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.18076/57.52544. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 57.15380/57.44985. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.19702/57.47622. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.11740/57.42159. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.14738/57.39362. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.17622/57.32707. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.05962/57.44925. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.97984/57.48217. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.21308/57.47586. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.03625/57.44522. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.94656/57.49888. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.90530/57.44170. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.85883/57.40981. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.07622548215427608\n",
      "Epoch 0, Loss(train/val) 71.08042/70.92975. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.93664/70.82970. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.76855/70.73477. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.58094/70.63878. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.49630/70.54054. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.34050/70.43703. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.17043/70.32506. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 70.03091/70.20539. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.90178/70.07268. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.68479/69.92487. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.54129/69.76333. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.39338/69.58281. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.16738/69.38193. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.92593/69.16016. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.67387/68.90047. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.38085/68.59961. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.09256/68.26457. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.62809/67.88332. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.36204/67.46198. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.01139/67.02227. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.59331/66.59765. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 66.26295/66.21650. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 66.03455/65.91567. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.79634/65.63031. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.46258/65.35381. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 65.37909/65.06149. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.03861/64.76176. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.03216/64.46075. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.86986/64.16706. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.59101/63.90450. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.48430/63.68748. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.56919/63.50134. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.30925/63.31499. Took 0.34 sec\n",
      "Epoch 33, Loss(train/val) 64.16389/63.17845. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.26378/63.09105. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.16837/63.01308. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.99393/62.99768. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.82639/62.98575. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.83740/63.00860. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.84797/63.05159. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.72814/63.15913. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.55432/63.21316. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.50000/63.25954. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.45741/63.30259. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.58850/63.29557. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.48103/63.32994. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.41259/63.37375. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 63.39213/63.35950. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.18214/63.35634. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.23296/63.35494. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.20938/63.34171. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 63.05225/63.32693. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.05903/63.29298. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.91887/63.24699. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 62.90132/63.21220. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.79163/63.17216. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.80702/63.10408. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 62.82946/63.05492. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 62.72963/62.99330. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.61414/62.92899. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.63518/62.91702. Took 0.34 sec\n",
      "Epoch 61, Loss(train/val) 62.34778/62.90516. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.35999/62.81406. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.29424/62.69155. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.08165/62.62407. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.87884/62.62397. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.85962/62.45221. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.72275/62.55556. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 61.68466/62.31016. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 61.67190/62.10844. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.60148/62.02995. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 61.33601/62.11771. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.49145/62.01193. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.31048/61.50324. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.26676/62.00267. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 61.22702/61.22889. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.88911/61.92330. Took 0.34 sec\n",
      "Epoch 77, Loss(train/val) 61.10587/61.05407. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.83476/62.07732. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.13709/61.93438. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.70151/62.01637. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.79963/60.95438. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 60.62546/61.40820. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 60.65706/60.89154. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.42888/61.14017. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.31479/61.08886. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.28121/61.45811. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.47282/61.21764. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 60.17827/60.89513. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.31202/61.19811. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.96027/60.35358. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.05661/60.34717. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.94763/60.51100. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 60.04987/60.28831. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.86757/60.61499. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.72842/60.45667. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.61918/60.07467. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.06131/60.05113. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.72063/60.55815. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.73295/60.24592. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.05790766725522051\n",
      "Epoch 0, Loss(train/val) 69.75162/69.77967. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.54115/69.70526. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.41560/69.62704. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.25094/69.54906. Took 0.34 sec\n",
      "Epoch 4, Loss(train/val) 69.15247/69.46650. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.92862/69.37260. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.77551/69.26530. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.53982/69.15040. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.37445/69.03136. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.16060/68.90942. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.83826/68.78696. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.62625/68.66086. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.30525/68.52775. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.02530/68.38471. Took 0.34 sec\n",
      "Epoch 14, Loss(train/val) 66.63944/68.22079. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.41766/68.04248. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.16595/67.84745. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.61340/67.64179. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.38857/67.42856. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.00915/67.23216. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.71287/67.07127. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.47463/66.93395. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.23327/66.81275. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.98590/66.70313. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.92101/66.61124. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.68381/66.51140. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.39947/66.42883. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.25332/66.36314. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.13060/66.29152. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.84747/66.23767. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.62227/66.18866. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.51831/66.14111. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.43290/66.11501. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.31303/66.07713. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.08762/66.03630. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.08461/65.99279. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.74153/65.94572. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.77990/65.90451. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.70539/65.87400. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 61.59594/65.82735. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.42898/65.78410. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.44094/65.82269. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 61.19594/65.83704. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.11428/65.77841. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.09540/65.81978. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.07310/65.83434. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.84890/65.80910. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.75310/65.82181. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.63303/65.80280. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 60.62756/65.74556. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 60.63937/65.82092. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.64317/65.75694. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.75467/65.77749. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.52128/65.92344. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 60.40040/65.86897. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.44520/65.87520. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.29968/65.94318. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.28217/65.84177. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.18410/65.88583. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.10800/65.90753. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.15841/65.91156. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.22273/65.84920. Took 0.34 sec\n",
      "Epoch 62, Loss(train/val) 59.97084/65.93874. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.16262/65.92049. Took 0.34 sec\n",
      "Epoch 64, Loss(train/val) 59.89995/65.94386. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.90160/66.04342. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.86969/65.81551. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.94787/66.07798. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.81004/65.98286. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.79464/66.05431. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.69909/65.88522. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.69300/66.17274. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.60148/65.86216. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.57478/66.19063. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.64623/65.93221. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.55456/66.15747. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 59.45898/65.95699. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.28030/66.22577. Took 0.34 sec\n",
      "Epoch 78, Loss(train/val) 59.57844/65.96630. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.37933/66.12415. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.26449/66.03593. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.28359/66.02824. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.31112/66.05179. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.27763/66.07084. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.27072/66.01204. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.06543/66.13531. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.97632/66.00967. Took 0.34 sec\n",
      "Epoch 87, Loss(train/val) 59.07400/66.08398. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.94726/66.02331. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.97765/66.05402. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.86041/66.08221. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.07366/65.95141. Took 0.34 sec\n",
      "Epoch 92, Loss(train/val) 58.93666/65.98432. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.73000/65.93452. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.87184/66.01873. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.63433/65.91840. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.81745/65.94581. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.62710/66.07904. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.65474/65.88949. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.73491/66.03063. Took 0.32 sec\n",
      "ACC: 0.40625, MCC: -0.1807753815155468\n",
      "Epoch 0, Loss(train/val) 70.87787/69.63380. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.41407/69.13676. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.99538/68.63167. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.53297/68.12714. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 69.02118/67.63367. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 68.51606/67.15546. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.00525/66.69182. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.47626/66.24725. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 66.93743/65.81226. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.44119/65.39093. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.95896/64.97369. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.45602/64.56520. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.01105/64.16014. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 64.49351/63.75447. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.11888/63.34618. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.62203/62.93887. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 63.29856/62.53678. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.86657/62.14433. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.51534/61.76207. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.18979/61.39689. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 61.79085/61.05699. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 61.38692/60.73824. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 60.93258/60.45595. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 60.66130/60.17776. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.40291/59.90635. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 59.93394/59.64862. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 59.72803/59.43114. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 59.35080/59.25520. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 59.24599/59.10622. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.09427/58.96545. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 58.89702/58.83209. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 58.62126/58.70508. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 58.43583/58.58218. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 58.38746/58.46386. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.10444/58.34461. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 57.99656/58.23246. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 57.86423/58.12228. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 57.71581/58.01796. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 57.86035/57.91724. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 57.63870/57.81553. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 57.35951/57.72385. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 57.57002/57.64280. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 57.28713/57.56158. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 57.38589/57.48354. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 57.38087/57.40953. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.09013/57.34514. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 57.16281/57.27660. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 57.01595/57.20395. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 56.96592/57.13131. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 57.03534/57.05603. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 56.78000/56.98846. Took 0.34 sec\n",
      "Epoch 51, Loss(train/val) 56.66854/56.92938. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 56.77068/56.87118. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 56.78826/56.80600. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 56.74330/56.75157. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 56.62670/56.69084. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 56.45904/56.62849. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 56.37311/56.56990. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 56.50806/56.50557. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 56.56616/56.43695. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 56.35161/56.36629. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 56.40854/56.29727. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 56.20993/56.21172. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 56.13474/56.12783. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.43419/56.06398. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.32725/56.00665. Took 0.35 sec\n",
      "Epoch 66, Loss(train/val) 56.20929/55.94600. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 55.97007/55.92821. Took 0.34 sec\n",
      "Epoch 68, Loss(train/val) 55.96061/55.84423. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 55.80973/55.79031. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 55.87084/55.71929. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 55.99018/55.62036. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 55.81085/55.55916. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 55.73798/55.42296. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 55.75949/55.29361. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 55.67742/55.13609. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 55.62293/55.08016. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 55.65000/54.88842. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 55.51152/54.85615. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 55.49996/54.72915. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 55.64420/54.66999. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 55.39069/54.57512. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 55.32899/54.56028. Took 0.34 sec\n",
      "Epoch 83, Loss(train/val) 55.23649/54.51468. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 55.15274/54.52723. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.26284/54.52139. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 55.24590/54.42284. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 55.08130/54.44164. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 55.14787/54.34665. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.10180/54.50400. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.09958/54.38420. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.18515/54.39303. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 54.92537/54.27409. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 54.90991/54.39534. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 54.79427/54.27120. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 54.80184/54.25047. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 54.82602/54.17348. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 54.78331/54.20097. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 54.93246/54.11837. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 54.84532/54.10951. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: -0.11008838664532174\n",
      "Epoch 0, Loss(train/val) 70.32018/71.00503. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.11822/70.78004. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.85883/70.54417. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.65803/70.28549. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.45930/70.00375. Took 0.42 sec\n",
      "Epoch 5, Loss(train/val) 69.14682/69.68816. Took 0.42 sec\n",
      "Epoch 6, Loss(train/val) 68.88551/69.33125. Took 0.42 sec\n",
      "Epoch 7, Loss(train/val) 68.59677/68.91548. Took 0.42 sec\n",
      "Epoch 8, Loss(train/val) 68.24401/68.41835. Took 0.42 sec\n",
      "Epoch 9, Loss(train/val) 67.95898/67.85152. Took 0.42 sec\n",
      "Epoch 10, Loss(train/val) 67.61910/67.21714. Took 0.43 sec\n",
      "Epoch 11, Loss(train/val) 67.18995/66.51392. Took 0.43 sec\n",
      "Epoch 12, Loss(train/val) 66.90214/65.79017. Took 0.42 sec\n",
      "Epoch 13, Loss(train/val) 66.43072/65.08500. Took 0.43 sec\n",
      "Epoch 14, Loss(train/val) 66.11458/64.43237. Took 0.43 sec\n",
      "Epoch 15, Loss(train/val) 65.74942/63.82390. Took 0.42 sec\n",
      "Epoch 16, Loss(train/val) 65.39269/63.23981. Took 0.38 sec\n",
      "Epoch 17, Loss(train/val) 65.06281/62.67698. Took 0.37 sec\n",
      "Epoch 18, Loss(train/val) 64.68722/62.11314. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.35193/61.56310. Took 0.35 sec\n",
      "Epoch 20, Loss(train/val) 64.01611/60.99776. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.69059/60.43001. Took 0.35 sec\n",
      "Epoch 22, Loss(train/val) 63.31927/59.92871. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.01032/59.53004. Took 0.34 sec\n",
      "Epoch 24, Loss(train/val) 62.67612/59.21277. Took 0.34 sec\n",
      "Epoch 25, Loss(train/val) 62.47315/58.95869. Took 0.34 sec\n",
      "Epoch 26, Loss(train/val) 62.12243/58.72071. Took 0.34 sec\n",
      "Epoch 27, Loss(train/val) 61.99101/58.50088. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.76410/58.28593. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.69902/58.06886. Took 0.34 sec\n",
      "Epoch 30, Loss(train/val) 61.67689/57.85996. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 61.54889/57.65904. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.40736/57.48489. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.23441/57.30495. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.25908/57.11414. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.95545/56.93858. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.93836/56.79963. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.86255/56.72780. Took 0.35 sec\n",
      "Epoch 38, Loss(train/val) 60.83471/56.69336. Took 0.42 sec\n",
      "Epoch 39, Loss(train/val) 60.72030/56.65114. Took 0.43 sec\n",
      "Epoch 40, Loss(train/val) 60.57558/56.59063. Took 0.43 sec\n",
      "Epoch 41, Loss(train/val) 60.51397/56.56506. Took 0.42 sec\n",
      "Epoch 42, Loss(train/val) 60.59419/56.52453. Took 0.44 sec\n",
      "Epoch 43, Loss(train/val) 60.53557/56.52464. Took 0.42 sec\n",
      "Epoch 44, Loss(train/val) 60.26748/56.51003. Took 0.43 sec\n",
      "Epoch 45, Loss(train/val) 60.32657/56.49436. Took 0.43 sec\n",
      "Epoch 46, Loss(train/val) 60.13998/56.47301. Took 0.42 sec\n",
      "Epoch 47, Loss(train/val) 60.13356/56.43243. Took 0.42 sec\n",
      "Epoch 48, Loss(train/val) 60.00793/56.41515. Took 0.42 sec\n",
      "Epoch 49, Loss(train/val) 59.97573/56.35548. Took 0.42 sec\n",
      "Epoch 50, Loss(train/val) 59.89217/56.32096. Took 0.41 sec\n",
      "Epoch 51, Loss(train/val) 60.02491/56.32931. Took 0.42 sec\n",
      "Epoch 52, Loss(train/val) 59.61908/56.34303. Took 0.42 sec\n",
      "Epoch 53, Loss(train/val) 59.65471/56.31089. Took 0.43 sec\n",
      "Epoch 54, Loss(train/val) 59.68262/56.26804. Took 0.41 sec\n",
      "Epoch 55, Loss(train/val) 59.64488/56.22301. Took 0.42 sec\n",
      "Epoch 56, Loss(train/val) 59.37877/56.18418. Took 0.42 sec\n",
      "Epoch 57, Loss(train/val) 59.55031/56.19379. Took 0.42 sec\n",
      "Epoch 58, Loss(train/val) 59.41101/56.16615. Took 0.42 sec\n",
      "Epoch 59, Loss(train/val) 59.27577/56.13418. Took 0.44 sec\n",
      "Epoch 60, Loss(train/val) 59.19818/56.11377. Took 0.42 sec\n",
      "Epoch 61, Loss(train/val) 59.32171/56.09647. Took 0.43 sec\n",
      "Epoch 62, Loss(train/val) 59.32377/56.02285. Took 0.42 sec\n",
      "Epoch 63, Loss(train/val) 59.30235/55.96114. Took 0.42 sec\n",
      "Epoch 64, Loss(train/val) 59.20257/55.93111. Took 0.41 sec\n",
      "Epoch 65, Loss(train/val) 59.13388/55.89007. Took 0.40 sec\n",
      "Epoch 66, Loss(train/val) 59.08344/55.86287. Took 0.39 sec\n",
      "Epoch 67, Loss(train/val) 59.22084/55.85490. Took 0.39 sec\n",
      "Epoch 68, Loss(train/val) 58.83696/55.77759. Took 0.37 sec\n",
      "Epoch 69, Loss(train/val) 59.07943/55.77628. Took 0.39 sec\n",
      "Epoch 70, Loss(train/val) 58.95010/55.75856. Took 0.40 sec\n",
      "Epoch 71, Loss(train/val) 58.91404/55.75225. Took 0.37 sec\n",
      "Epoch 72, Loss(train/val) 58.88690/55.71721. Took 0.36 sec\n",
      "Epoch 73, Loss(train/val) 58.78291/55.66993. Took 0.36 sec\n",
      "Epoch 74, Loss(train/val) 58.69540/55.62276. Took 0.35 sec\n",
      "Epoch 75, Loss(train/val) 58.83367/55.58049. Took 0.34 sec\n",
      "Epoch 76, Loss(train/val) 58.65586/55.56887. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 58.71208/55.59293. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.43952/55.56508. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.51673/55.59843. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.49305/55.51202. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.33684/55.47547. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.40959/55.43842. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.51824/55.44154. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.46002/55.40982. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.33502/55.41969. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.35391/55.38034. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.37854/55.37202. Took 0.34 sec\n",
      "Epoch 88, Loss(train/val) 58.19957/55.37024. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.23853/55.33620. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.08754/55.32681. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.12897/55.33332. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.02613/55.28983. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.00438/55.26963. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.13957/55.26414. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.06897/55.22463. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.07928/55.30157. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.92217/55.21294. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.97521/55.26483. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 58.15322/55.22173. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.15863531325832828\n",
      "Epoch 0, Loss(train/val) 70.46769/70.48035. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.31967/70.31866. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.16546/70.15166. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.01396/69.98553. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.86379/69.81192. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.75859/69.64577. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.59159/69.48639. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.39836/69.33167. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.24995/69.17698. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.08684/69.00469. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.88326/68.82932. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.61033/68.63454. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 68.37335/68.42767. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.09348/68.20599. Took 0.34 sec\n",
      "Epoch 14, Loss(train/val) 67.84974/67.97852. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.52651/67.72382. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 67.12640/67.44904. Took 0.34 sec\n",
      "Epoch 17, Loss(train/val) 66.63198/67.16225. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.24416/66.87785. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.89855/66.59712. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.45196/66.42230. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.09970/66.27991. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.85280/66.14700. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.73708/66.02718. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 64.74263/65.92184. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.44893/65.82737. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.39953/65.75025. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.15397/65.70242. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.10932/65.68092. Took 0.34 sec\n",
      "Epoch 29, Loss(train/val) 64.10371/65.67679. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.12838/65.68176. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.87126/65.70126. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.80735/65.72868. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.77873/65.76042. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.70317/65.80099. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.66647/65.83307. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.52253/65.85348. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.61337/65.86334. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.58829/65.84576. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.33018/65.83729. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.42799/65.82778. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.28855/65.82486. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.28124/65.82016. Took 0.34 sec\n",
      "Epoch 43, Loss(train/val) 63.26852/65.80968. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.24170/65.80555. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 63.25505/65.80526. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 63.12167/65.79816. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 63.06296/65.77813. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.99113/65.78934. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.91489/65.81284. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 63.05332/65.82959. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.92229/65.81073. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.81202/65.81174. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.81309/65.82986. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.84046/65.85355. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 62.76418/65.87431. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.78751/65.89333. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.71268/65.89663. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 62.67481/65.88111. Took 0.34 sec\n",
      "Epoch 59, Loss(train/val) 62.56547/65.86536. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.62138/65.85236. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.39093/65.86209. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 62.52902/65.85152. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.32894/65.83131. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.14693/65.78322. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 62.04526/65.73389. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 62.17862/65.72782. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.14772/65.73664. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 62.09881/65.71124. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.02024/65.68887. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.91414/65.66061. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 61.80681/65.65774. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.85281/65.63972. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 61.61049/65.54045. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.63252/65.57015. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 61.59216/65.53780. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 61.40375/65.48276. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 61.20013/65.51769. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 61.42830/65.51416. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 61.16532/65.63291. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 61.03613/65.40442. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.05572/65.51420. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.85106/65.52453. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.87148/65.45137. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.88911/65.55747. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.58860/65.45740. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 60.56114/65.52209. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.69720/65.59840. Took 0.34 sec\n",
      "Epoch 88, Loss(train/val) 60.53036/65.48035. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 60.42178/65.45735. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.47593/65.42382. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.27432/65.50777. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 60.38254/65.41845. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 60.27830/65.49371. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.14841/65.39425. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.01876/65.46857. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.20437/65.36317. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.03173/65.32406. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 59.86142/65.30923. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.73728/65.27440. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.0518191557963571\n",
      "Epoch 0, Loss(train/val) 70.85442/69.92578. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.74375/69.78770. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.54769/69.67166. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.38122/69.56319. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.21339/69.44963. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.07449/69.33243. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.86182/69.20045. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.66087/69.05437. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.46912/68.88480. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.22541/68.70452. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.93759/68.50906. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.69376/68.31687. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.43305/68.13776. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.13224/67.97601. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.92012/67.83890. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 67.67773/67.72084. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 67.41129/67.61753. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.13844/67.52493. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.89283/67.44159. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.66868/67.36155. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 66.35356/67.29004. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.16072/67.23064. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.96065/67.17797. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.69583/67.13039. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.51005/67.09732. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 65.26085/67.07193. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.08564/67.05134. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 64.92786/67.03802. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.71045/67.03300. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.47667/67.03447. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.26698/67.04588. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 64.00943/67.06334. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.76768/67.06348. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 63.63924/67.04263. Took 0.34 sec\n",
      "Epoch 34, Loss(train/val) 63.27853/67.02262. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.23457/67.00623. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.08202/67.00027. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.81513/67.01022. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.82327/66.98711. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.64178/66.94775. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.55520/66.91304. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.22892/66.82607. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.12411/66.75047. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.07677/66.66318. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.81308/66.53939. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.78866/66.42249. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.78143/66.33044. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.47731/66.24088. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.46449/66.15645. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.28606/66.09009. Took 0.34 sec\n",
      "Epoch 50, Loss(train/val) 61.29621/66.03930. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.18609/66.03519. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.11929/65.94254. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.01189/65.93751. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.89385/65.95750. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.71414/65.95155. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.67829/65.86878. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.61130/65.83797. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.44778/65.85616. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.39556/65.80769. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.18490/65.73592. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.14611/65.79019. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.14531/65.71636. Took 0.34 sec\n",
      "Epoch 63, Loss(train/val) 60.02687/65.65173. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.93429/65.61811. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.93652/65.57854. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.83584/65.66367. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.67949/65.49496. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.59269/65.65237. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.68719/65.53534. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.51151/65.48778. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.46049/65.50223. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.24267/65.45592. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.25496/65.47040. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.27887/65.46970. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.14806/65.30949. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 59.21127/65.42017. Took 0.34 sec\n",
      "Epoch 77, Loss(train/val) 58.96654/65.40039. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.01954/65.31510. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.04462/65.25195. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.76558/65.29185. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.86990/65.34211. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.96505/65.27216. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.89873/65.17519. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.69647/65.23392. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.63970/65.18034. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.62476/65.24627. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.53249/65.03667. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.47686/65.23667. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.48627/65.15517. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.56318/65.11933. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.48704/65.09155. Took 0.34 sec\n",
      "Epoch 92, Loss(train/val) 58.51290/65.07095. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 58.30098/65.04681. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.24901/64.99669. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.23356/65.07429. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 58.18510/65.05354. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.14111/65.09806. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.07250/64.96153. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 58.03834/65.00159. Took 0.32 sec\n",
      "ACC: 0.421875, MCC: -0.25894970905466325\n",
      "Epoch 0, Loss(train/val) 70.68157/72.31409. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.48503/72.23142. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.26877/72.15319. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.06170/72.08064. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.82097/72.01437. Took 0.34 sec\n",
      "Epoch 5, Loss(train/val) 69.60104/71.94901. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.33428/71.88206. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.07788/71.81145. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.82438/71.73373. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.44162/71.64615. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.06257/71.53797. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.61876/71.38964. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.18522/71.19675. Took 0.34 sec\n",
      "Epoch 13, Loss(train/val) 66.79255/70.94826. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.31727/70.63769. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.02838/70.27716. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.50605/69.86037. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.09822/69.39623. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.74514/68.90521. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.43900/68.40391. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.13590/67.92382. Took 0.34 sec\n",
      "Epoch 21, Loss(train/val) 63.81154/67.45452. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.47297/66.95750. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.27721/66.46201. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.01306/65.97446. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.73041/65.49272. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.42103/65.00090. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.31539/64.52966. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.93222/64.07713. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.72873/63.66338. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.63342/63.29853. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.36764/62.97097. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.24432/62.66365. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.13362/62.39841. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.87944/62.16076. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.82109/61.94871. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 60.67166/61.76279. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.46119/61.62201. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.34558/61.50109. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.30768/61.42734. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.11684/61.36629. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.03875/61.31956. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.82919/61.34631. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.92501/61.40805. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.70353/61.44373. Took 0.34 sec\n",
      "Epoch 45, Loss(train/val) 59.61732/61.41192. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.31884/61.31669. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.24570/61.37752. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.19350/61.52723. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.11333/61.40270. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.91324/61.42509. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.00386/61.48155. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 58.88505/61.50476. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 58.91601/61.39226. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.66559/61.44353. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.45849/61.61891. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.64237/61.53758. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.65709/61.39452. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.42097/61.50785. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.49460/61.59371. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.42307/61.26926. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.36486/61.28688. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.27299/61.42072. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.38383/61.25949. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 58.22119/61.19228. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.29134/61.33867. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.04369/61.39457. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.00886/61.30353. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.00188/61.36057. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.05596/61.31657. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.96289/61.29433. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.87951/61.39042. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.84755/61.43371. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.71511/61.23793. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.71531/61.18645. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.80045/61.40958. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.71031/61.27433. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.72245/61.26112. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 57.43385/61.30072. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.56959/61.33355. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.45657/61.25824. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 57.39280/61.31750. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.37772/61.33371. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.31432/61.18667. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.37042/61.30214. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.19749/61.30897. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.15378/61.27641. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.19205/61.39230. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.07222/61.24612. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.15430/61.31182. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 57.06734/61.28276. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.20040/61.13357. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.00520/61.08707. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.91164/61.11452. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.96233/60.98847. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.86387/61.07887. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.86192/61.06320. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.84404/61.06150. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 56.74517/61.03070. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.53444/61.14421. Took 0.34 sec\n",
      "ACC: 0.515625, MCC: 0.03734655007457467\n",
      "Epoch 0, Loss(train/val) 71.71106/71.07240. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.48949/70.87268. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.28415/70.66934. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 71.14526/70.46999. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.92262/70.26514. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.79840/70.05138. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.57645/69.83347. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.35944/69.60688. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.16427/69.36012. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.99321/69.10748. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 69.72564/68.84760. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 69.51448/68.57915. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.25816/68.30125. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.98208/68.02122. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.73607/67.73301. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.42396/67.44077. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.13295/67.13027. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.00683/66.83281. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.69249/66.54810. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.47460/66.25658. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 67.08559/65.95839. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.76417/65.65016. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.66774/65.35616. Took 0.34 sec\n",
      "Epoch 23, Loss(train/val) 66.38702/65.03964. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 66.19791/64.72627. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 65.82625/64.40704. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.67864/64.10506. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 65.24056/63.78544. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.01987/63.46160. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.85143/63.16224. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.58390/62.87337. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.39011/62.61349. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.19354/62.41671. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.97788/62.21559. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.86497/62.03811. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.78428/61.86656. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.60201/61.73746. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.62785/61.62072. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.52246/61.53666. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.51144/61.42821. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.44385/61.30302. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.45126/61.19141. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.31836/61.11271. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 63.32116/61.07592. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.26086/61.03762. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.26287/60.97260. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.13175/60.85678. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.90750/60.77022. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.23465/60.69388. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 63.08866/60.65768. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.04694/60.62514. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.95016/60.58768. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.91314/60.55800. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.87393/60.53308. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.80373/60.52010. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.78247/60.46478. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.79680/60.44608. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.71345/60.41570. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.70991/60.37640. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 62.54522/60.39627. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.78984/60.39192. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 62.55067/60.37339. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 62.70653/60.38476. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.66099/60.39371. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.56539/60.38694. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.50020/60.39944. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.56960/60.38999. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.47802/60.36449. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.50251/60.37424. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.44589/60.35922. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.23676/60.34282. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.28788/60.35701. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 62.27552/60.35524. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.36238/60.35023. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.18808/60.35607. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.21957/60.36723. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.34794/60.36358. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.18563/60.36829. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.19298/60.38225. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.20631/60.37918. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.05230/60.37067. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.17883/60.38543. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 62.01856/60.38642. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 62.05191/60.39565. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.92550/60.39626. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 62.08605/60.40899. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.08549/60.40857. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.92949/60.41265. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.78222/60.42469. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 61.93845/60.42267. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.85556/60.43010. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.80821/60.44020. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.61892/60.45006. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.90596/60.46121. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 61.70058/60.46756. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.78391/60.47406. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 61.65839/60.48083. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.61892/60.49011. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.63827/60.49282. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.72265/60.50604. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: 0.029863035542303663\n",
      "Epoch 0, Loss(train/val) 70.95364/70.62352. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.61656/70.29392. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.32370/69.99280. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.08499/69.70846. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.80767/69.42336. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.45501/69.14953. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.20662/68.87678. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.88513/68.59298. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.58309/68.29321. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.27986/67.97460. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.94144/67.63544. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.56737/67.27139. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.22987/66.86893. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 66.65392/66.41544. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.23916/65.92559. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.66648/65.40952. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.03221/64.87966. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.61975/64.38681. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.96473/63.93409. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.50782/63.52063. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.10477/63.14378. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.60008/62.78238. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 62.26358/62.45264. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.88930/62.10193. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.61958/61.73587. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.45671/61.35317. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.07553/61.01326. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.89623/60.70681. Took 0.34 sec\n",
      "Epoch 28, Loss(train/val) 60.71655/60.44834. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 60.52027/60.24407. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.46598/60.06901. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.30928/59.90241. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.02783/59.74810. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.14491/59.59829. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.98783/59.46164. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.80166/59.34919. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.61313/59.25471. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.55894/59.16629. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.47673/59.10691. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.21297/59.05083. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.29416/58.99458. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.10693/58.88713. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.85044/58.86627. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.93407/58.79377. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 58.83094/58.76509. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.72147/58.77626. Took 0.34 sec\n",
      "Epoch 46, Loss(train/val) 58.44008/58.70672. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.40281/58.72609. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.26864/58.70637. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.30990/59.07872. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.19380/58.69770. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.87617/59.10352. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.14535/58.64539. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.87855/59.41064. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.92352/59.03983. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 57.72201/59.24305. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.68726/59.06339. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.34823/59.36995. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.56918/60.26957. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 57.31694/59.08732. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.38180/58.56496. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.48560/58.43309. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.23696/61.03871. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.26869/60.02933. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.29837/58.34828. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.04895/58.22122. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.07222/59.95335. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.00014/59.60067. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.18149/57.90760. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.04822/60.80227. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.04255/58.34770. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.96874/57.87337. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.03908/60.58913. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.75661/58.20309. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.99972/58.05947. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.80741/58.44496. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.76517/58.74319. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.72870/58.33049. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.68324/58.11795. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.47498/58.57920. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.54071/58.82259. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.57232/58.72224. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.62570/58.78310. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.39067/57.99073. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.36695/58.04067. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.40337/59.43694. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.49242/59.93249. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.44899/58.64128. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.31404/57.72159. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 56.17627/58.17018. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.11055/58.37130. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.99408/58.47547. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.23744/58.70121. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.33486/60.50370. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.15788/59.18033. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.12133/58.05456. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.04670/57.58498. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.02280/58.58033. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.98756/59.87541. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.90839/59.02662. Took 0.32 sec\n",
      "ACC: 0.5, MCC: -0.049969626464415974\n",
      "Epoch 0, Loss(train/val) 71.92818/72.11198. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 71.69081/71.95277. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.42846/71.80469. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 71.20869/71.67344. Took 0.34 sec\n",
      "Epoch 4, Loss(train/val) 70.99892/71.54929. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.81148/71.42690. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.55022/71.30687. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.38425/71.17275. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.13729/71.02731. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.89859/70.88507. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.67357/70.74519. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.48782/70.61106. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.25862/70.48267. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.03326/70.36273. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.80864/70.24950. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.72990/70.15289. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 68.39063/70.06421. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 68.23237/69.98815. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.19669/69.92307. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.95405/69.85800. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.79720/69.79049. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.61171/69.72282. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.39132/69.65184. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.34040/69.57582. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 67.04334/69.48647. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 66.89558/69.38724. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 66.75720/69.28116. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.53757/69.17616. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.22536/69.09946. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.17741/69.00966. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.00421/68.90919. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.71083/68.79608. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.59958/68.68343. Took 0.34 sec\n",
      "Epoch 33, Loss(train/val) 65.45540/68.55977. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.44346/68.45401. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 65.19393/68.34094. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 64.90838/68.21315. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 64.99470/68.07832. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.74703/67.93272. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.47988/67.77216. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.36629/67.60174. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.34053/67.41294. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.15743/67.24686. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.89914/67.11951. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.72957/67.03809. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.60795/66.95349. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 63.48763/66.87975. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.36661/66.81145. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.29218/66.74935. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.17392/66.67239. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.16975/66.58235. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.01842/66.45394. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.81575/66.34197. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.85898/66.20572. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.62214/66.07253. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.60363/65.93756. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 62.41221/65.79702. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.30207/65.62964. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.18453/65.42450. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 62.19121/65.20171. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 61.99209/64.99893. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.80754/64.77673. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 61.63711/64.53820. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.58867/64.37292. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.43653/64.25949. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 61.42282/64.13534. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.34344/64.01590. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.10031/63.92347. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.15177/63.84647. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.13143/63.79227. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 60.94039/63.76751. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.88875/63.65897. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.86376/63.47142. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.71228/63.40007. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.91940/63.28485. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.69670/63.16585. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.55675/63.02896. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 60.61865/62.93049. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.47923/62.94054. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.42288/62.93430. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 60.42058/62.92257. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.32851/62.98683. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 60.38984/62.92764. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.55529/62.86836. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.29023/62.86287. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.39122/62.75447. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.20122/62.77729. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.19961/62.73714. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 60.21003/62.73880. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.12118/62.60225. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.15077/62.54356. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.09851/62.46114. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.97203/62.39760. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.85810/62.29145. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.06568/62.36777. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.03161/62.27591. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.77259/62.19923. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.81795/62.14834. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.74137/62.11124. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.80579/62.16433. Took 0.31 sec\n",
      "ACC: 0.453125, MCC: -0.19601950239758556\n",
      "Epoch 0, Loss(train/val) 71.05642/71.78551. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.73956/71.36327. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.41970/70.92751. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.06948/70.46465. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.67021/69.95197. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.29762/69.42209. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.93385/68.88238. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.55913/68.35022. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.16521/67.83960. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.71186/67.36139. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.26785/66.92637. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.97487/66.53788. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.68090/66.18559. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.30390/65.85889. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.04814/65.55166. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 65.76917/65.24706. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 65.42604/64.95226. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.13306/64.66824. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.85356/64.40089. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.55156/64.15176. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 64.31535/63.91549. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.19173/63.68213. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.88906/63.46573. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.64008/63.25996. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.50058/63.04906. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.45056/62.84904. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.14511/62.65413. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.10693/62.45987. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.90263/62.25478. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.58246/62.03316. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.72195/61.83389. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.71733/61.65499. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.43300/61.49221. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.26310/61.36323. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.12989/61.24120. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.18046/61.13801. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.11168/61.05452. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.06538/60.97935. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.01996/60.88745. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.83002/60.80302. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.75478/60.72957. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.74774/60.66094. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 61.66956/60.59809. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.61879/60.53995. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.58084/60.48299. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.60012/60.44374. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.40015/60.39075. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.54314/60.27827. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.33617/60.17619. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.29013/60.09614. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.15480/60.01356. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.21819/59.94542. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.01806/59.84228. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.99021/59.74580. Took 0.34 sec\n",
      "Epoch 54, Loss(train/val) 60.91848/59.61671. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.83500/59.60936. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.00274/59.46867. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.83342/59.44123. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.59375/59.31179. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.58696/59.29846. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.87928/59.23288. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 60.45967/59.15083. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.46242/59.11564. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.40397/58.99340. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.37915/59.00439. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.16027/58.87286. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.39433/58.76802. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.09434/58.69606. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.06866/58.61894. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.01868/58.86202. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.01340/58.61365. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.00340/58.56290. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.93098/58.38770. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.84054/58.34963. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.72781/58.47487. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.86974/58.36841. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.62249/58.28616. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.66198/58.26506. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.52068/58.59151. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.65215/58.25775. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.48298/58.07486. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.29441/58.47225. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.36896/58.53910. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.12033/58.03883. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.25325/58.02020. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.13205/58.51811. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.28663/58.01303. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.00276/57.87128. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.89977/58.19172. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.94131/58.09883. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.91880/58.19880. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.91321/58.05197. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 58.83721/57.59667. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.85825/57.99153. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.76745/58.39684. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.83425/57.88912. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 58.50282/57.55651. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.50317/57.50111. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 58.37604/57.89601. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 58.36659/58.10280. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.07570682517832987\n",
      "Epoch 0, Loss(train/val) 70.71072/71.12750. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.62963/71.05893. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.43347/70.98795. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.30829/70.90801. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.16017/70.82123. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.01506/70.71359. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.88060/70.59216. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.62654/70.44575. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.41499/70.26426. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.14991/70.05157. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.87655/69.80230. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.53703/69.52397. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.24306/69.21564. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.94896/68.88374. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.59991/68.53325. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.32205/68.17590. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.95305/67.82272. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.64965/67.48438. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.33393/67.17786. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.15381/66.91399. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.94474/66.68534. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.54968/66.47818. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.31414/66.29209. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.17673/66.12896. Took 0.34 sec\n",
      "Epoch 24, Loss(train/val) 64.98391/65.97707. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.73719/65.83470. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.68014/65.70551. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 64.59046/65.58834. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.47569/65.48296. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.21222/65.37356. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.18910/65.26844. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.12161/65.16929. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.06096/65.06372. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 63.70860/64.96730. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.88053/64.86659. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.74128/64.75822. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.52743/64.65051. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.39319/64.56088. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.27341/64.46391. Took 0.34 sec\n",
      "Epoch 39, Loss(train/val) 63.22952/64.37347. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.15721/64.30060. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.96408/64.22408. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.02682/64.18154. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.84277/64.10382. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.79804/64.05243. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.72247/64.00781. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.58566/63.94355. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.44114/63.88846. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.40958/63.83877. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.16896/63.77769. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.24116/63.76970. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.24096/63.68753. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.31639/63.67162. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.24414/63.61797. Took 0.34 sec\n",
      "Epoch 54, Loss(train/val) 62.00066/63.60299. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.01421/63.54685. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.90080/63.53370. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.93428/63.46425. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.85271/63.43398. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.72583/63.41029. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.89739/63.37422. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.74193/63.34583. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 61.81031/63.29433. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.60538/63.28688. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.53493/63.23838. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.54170/63.19268. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.62329/63.16559. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.45570/63.14263. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 61.30819/63.11859. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 61.36792/63.10186. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.23262/63.07665. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.28181/63.05816. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.16424/63.04395. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.23519/63.00142. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.10401/62.98968. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 61.21847/62.97217. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.22500/62.95042. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.15074/62.92714. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 61.07199/62.91760. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 61.17420/62.89183. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.88728/62.87319. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.04913/62.86137. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 61.03884/62.83126. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 60.85672/62.81358. Took 0.34 sec\n",
      "Epoch 84, Loss(train/val) 60.90958/62.79855. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 60.85083/62.78251. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.81688/62.76927. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 60.63286/62.76243. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.78407/62.74052. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.73039/62.74833. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.78364/62.71691. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.53147/62.70058. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.60744/62.68963. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.76658/62.69133. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.58116/62.67260. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.64479/62.67509. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.63314/62.66454. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 60.79466/62.67046. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 60.48784/62.65757. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 60.52434/62.64760. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.1619047619047619\n",
      "Epoch 0, Loss(train/val) 69.55833/68.73534. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.13266/68.24373. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 68.69215/67.72250. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 68.23486/67.14162. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 67.68743/66.47905. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 67.05350/65.70471. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 66.37449/64.78311. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 65.40202/63.65698. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 64.54580/62.32322. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 63.29958/60.80171. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 62.16158/59.21166. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 61.04054/57.81971. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 59.99522/56.81060. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 59.17330/56.13813. Took 0.34 sec\n",
      "Epoch 14, Loss(train/val) 58.61231/55.70216. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 58.10582/55.41724. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 57.74512/55.23685. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 57.30385/55.08993. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 57.09493/54.97065. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 56.87282/54.86812. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 56.83866/54.78443. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 56.56608/54.69984. Took 0.34 sec\n",
      "Epoch 22, Loss(train/val) 56.61261/54.62142. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 56.48852/54.55324. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 56.38343/54.48715. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 56.18719/54.42104. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 56.06717/54.35416. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 56.04606/54.29132. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 56.01283/54.23011. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 55.85860/54.17423. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 55.91815/54.11983. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 55.88545/54.07066. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 55.83274/54.02066. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 55.52579/53.96779. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 55.77027/53.91507. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 55.57385/53.86586. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 55.54285/53.81457. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 55.50934/53.75700. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 55.56404/53.69682. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 55.49898/53.62678. Took 0.34 sec\n",
      "Epoch 40, Loss(train/val) 55.35020/53.56290. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 55.21408/53.48928. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 55.23406/53.39598. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 55.06682/53.28970. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 54.96359/53.19499. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 55.09453/53.12992. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 54.95292/53.07979. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 54.75994/53.01291. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 54.79032/52.91947. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 54.61307/52.90527. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 54.60634/52.94328. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 54.32451/52.89341. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 54.36364/52.89272. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 54.14250/52.81413. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 54.08220/52.82219. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 54.16702/52.80112. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 54.10081/52.77601. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 53.93026/52.79357. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 53.89563/52.72188. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 53.84008/52.74377. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 53.78603/52.72314. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 53.85813/52.66447. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 53.65082/52.64407. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 53.65058/52.68235. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 53.94673/52.65281. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 53.82239/52.61890. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 53.66377/52.65468. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 53.64982/52.59354. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 53.60376/52.57380. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 53.54753/52.48806. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 53.54290/52.49055. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 53.51892/52.48471. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 53.21157/52.49648. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 53.43962/52.44888. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 53.36257/52.38391. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 53.31682/52.41823. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 53.23214/52.32626. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 53.38269/52.32725. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 53.23931/52.33755. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 53.16182/52.28467. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 53.34024/52.28670. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 53.39538/52.27933. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 53.29619/52.24517. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 53.22006/52.17837. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 53.07458/52.23244. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 53.06232/52.19668. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 53.12717/52.15046. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 53.01842/52.11545. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 53.12263/52.05956. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 53.02959/52.14459. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 53.12846/52.01736. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 53.09622/52.16313. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 52.97789/51.96752. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 53.12360/52.10875. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 53.01777/51.99379. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 53.13244/51.99869. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 52.75117/51.94491. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 52.97901/51.95741. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 53.02503/51.90016. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 52.88156/51.97937. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.2886855012525504\n",
      "Epoch 0, Loss(train/val) 70.70952/69.98102. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.23094/69.42918. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.71304/68.85083. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.21402/68.26594. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.72761/67.70013. Took 0.34 sec\n",
      "Epoch 5, Loss(train/val) 68.29691/67.17226. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.85821/66.67859. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.41712/66.22066. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.08821/65.79711. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.86097/65.38985. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.46384/65.00078. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.23711/64.62827. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 65.91414/64.26140. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.60538/63.88666. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.31607/63.50305. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.00678/63.11439. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.73934/62.69429. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.38130/62.24287. Took 0.34 sec\n",
      "Epoch 18, Loss(train/val) 63.98465/61.77053. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 63.61542/61.26015. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.17899/60.73131. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.77189/60.24530. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.23848/59.80779. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.78867/59.42096. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.40357/59.06931. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 60.96800/58.79114. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.58835/58.51617. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.33921/58.21517. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 59.97551/57.96633. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.74875/57.75082. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.56975/57.55846. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.27745/57.36492. Took 0.34 sec\n",
      "Epoch 32, Loss(train/val) 59.16382/57.14750. Took 0.34 sec\n",
      "Epoch 33, Loss(train/val) 59.04825/56.98904. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 58.96579/56.75472. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 58.81172/56.59813. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 58.73245/56.44685. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.46796/56.37855. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 58.47774/56.21095. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 58.28737/56.06144. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.22855/55.93255. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.15195/55.86584. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.11321/55.76788. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 57.97045/55.66878. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 57.84143/55.55252. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.97372/55.42511. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 57.75379/55.34376. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.60364/55.24430. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 57.55441/55.16714. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 57.55314/55.08780. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.51602/54.98763. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.40973/54.91299. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.29991/54.82682. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.24223/54.76301. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 57.14462/54.74723. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.28668/54.65998. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 57.29224/54.64150. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 57.01985/54.59478. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.12532/54.53896. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 56.84340/54.50069. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 56.97951/54.48040. Took 0.34 sec\n",
      "Epoch 61, Loss(train/val) 56.95403/54.46119. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 56.82439/54.47263. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 56.85860/54.43181. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.65548/54.42426. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 56.75064/54.41050. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 56.76802/54.39875. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 56.67735/54.40477. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 56.52364/54.39181. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 56.37814/54.40047. Took 0.34 sec\n",
      "Epoch 70, Loss(train/val) 56.54321/54.36446. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.37795/54.36389. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.29864/54.30637. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 56.41857/54.26770. Took 0.34 sec\n",
      "Epoch 74, Loss(train/val) 56.30357/54.24619. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.23117/54.23878. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.05010/54.24516. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.08204/54.27783. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.04301/54.21706. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 56.05663/54.17565. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.17858/54.16080. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.10464/54.10867. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 55.91724/54.05756. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 55.90038/54.11573. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 55.79841/54.09536. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 55.77325/54.05611. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 55.69948/54.02745. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 55.77932/54.05919. Took 0.34 sec\n",
      "Epoch 88, Loss(train/val) 55.79571/54.05663. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.80205/54.03835. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 55.66825/54.05963. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.64213/54.07308. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 55.55333/53.97884. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.71285/53.79731. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.73823/53.84306. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.41690/53.89344. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.46606/53.90997. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.33820/53.86833. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.31212/53.85918. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.45643/53.82172. Took 0.32 sec\n",
      "ACC: 0.59375, MCC: 0.16323411311709218\n",
      "Epoch 0, Loss(train/val) 70.58506/70.61633. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.35900/70.44727. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.14199/70.27175. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.93039/70.08781. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.69658/69.89420. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.42927/69.69417. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.11991/69.48287. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.78921/69.25256. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.42003/68.98268. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.14493/68.67037. Took 0.34 sec\n",
      "Epoch 10, Loss(train/val) 67.65773/68.30101. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.20026/67.87463. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.81056/67.37634. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.08306/66.82157. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.46036/66.30646. Took 0.34 sec\n",
      "Epoch 15, Loss(train/val) 65.14692/65.95196. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.73879/65.75695. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.31054/65.62186. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.21477/65.52372. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.89341/65.43510. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.66177/65.36694. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.66836/65.31712. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.56945/65.27881. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.52373/65.23866. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.19535/65.20223. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.25515/65.17817. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.23613/65.14707. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.11973/65.11710. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.06884/65.06283. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.88273/65.02351. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.95422/64.98988. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.69194/64.97046. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.87437/64.95719. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.71328/64.94931. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.64927/64.96980. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.44640/64.99427. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.54783/65.01528. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.37788/65.03783. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.17983/65.06036. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.39576/65.08163. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.15548/65.10056. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.20592/65.12240. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.07072/65.12886. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.01040/65.14034. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.06228/65.16211. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.91554/65.17410. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.88517/65.18449. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.78186/65.18779. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.00310/65.18493. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.96941/65.18865. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.81759/65.19753. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.68193/65.20905. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.61057/65.22516. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.68283/65.23527. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.62742/65.23475. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.71963/65.23128. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.51858/65.23291. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.52086/65.23610. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.35010/65.24132. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.52192/65.24867. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.43315/65.25359. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.31838/65.26157. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.36394/65.25980. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.21428/65.25420. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.19701/65.26847. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.33369/65.26753. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.19042/65.26773. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.21341/65.26312. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 61.27862/65.24722. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.12941/65.24496. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.17383/65.25816. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.29660/65.24186. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.00437/65.22182. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.92456/65.21278. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.93166/65.18202. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.00618/65.16017. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.95714/65.16470. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 61.01268/65.15340. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.13107/65.14025. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.96257/65.13120. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.87002/65.13204. Took 0.34 sec\n",
      "Epoch 81, Loss(train/val) 60.76633/65.11892. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.85258/65.10450. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.79554/65.08901. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 61.06161/65.06968. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.91640/65.07298. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.95233/65.06628. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.82826/65.01941. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.96001/65.01913. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.50002/65.04565. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.60734/65.00364. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.65788/64.96183. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.56408/64.93324. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.59463/64.94785. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.76009/64.95284. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 60.38256/64.94534. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.58676/64.97578. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.53565/64.92532. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.55117/64.90276. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.43464/64.88894. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: -0.004232389556904849\n",
      "Epoch 0, Loss(train/val) 70.08153/71.57458. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.96753/71.55933. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.82289/71.54721. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.70566/71.53880. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.55874/71.53868. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.40978/71.54201. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.28017/71.55083. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.07896/71.56595. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.90829/71.58710. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.67556/71.60773. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.54535/71.61925. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.28727/71.62289. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.10110/71.61501. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.78698/71.60091. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.60577/71.57722. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.39146/71.53561. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 67.18401/71.48401. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.97799/71.42451. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.63238/71.35645. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.47870/71.27881. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 66.26199/71.18304. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 66.05563/71.05785. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.80438/70.90927. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.74502/70.74040. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.50243/70.55684. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.33117/70.35798. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.04833/70.14883. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.88530/69.92208. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.61737/69.70112. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.50738/69.47640. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.24412/69.26610. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.30258/69.07915. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 64.10127/68.89296. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.94092/68.72125. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.87829/68.56536. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.64318/68.42410. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.66246/68.29989. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.41854/68.19930. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 63.45036/68.07431. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 63.32571/67.96330. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.24467/67.86575. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.09862/67.75204. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.99645/67.63992. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.80301/67.51765. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.95332/67.38947. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.83201/67.27542. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.70109/67.17465. Took 0.34 sec\n",
      "Epoch 47, Loss(train/val) 62.59278/67.08392. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.60053/66.98224. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 62.35391/66.87247. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.32686/66.78149. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.15140/66.68480. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.25725/66.59038. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.13011/66.49478. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.13481/66.41354. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.93641/66.34471. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.96223/66.27812. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.95908/66.22004. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.91322/66.18601. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.71128/66.14009. Took 0.34 sec\n",
      "Epoch 60, Loss(train/val) 61.65196/66.09588. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.60631/66.07583. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.54492/66.04223. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.41809/66.04150. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.50055/66.02534. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 61.33243/65.94469. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.31939/65.93463. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.14524/65.89461. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 61.10364/65.88223. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.90440/65.84936. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.87383/65.86826. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 61.02709/65.81424. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.97220/65.77624. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.92731/65.77532. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.75119/65.77062. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.79907/65.73222. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.74115/65.68359. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.56851/65.72005. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.49625/65.66355. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.46650/65.61562. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.42366/65.53854. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.47943/65.49371. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 60.34048/65.40293. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.23637/65.37620. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.11237/65.30616. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 60.20719/65.29707. Took 0.34 sec\n",
      "Epoch 86, Loss(train/val) 60.08077/65.24001. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.11687/65.17212. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 59.95093/65.12112. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 60.04787/65.01858. Took 0.34 sec\n",
      "Epoch 90, Loss(train/val) 59.77557/64.93346. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.97278/64.84895. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.78072/64.83063. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.73333/64.85901. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.68604/64.78663. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.64941/64.77753. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.64731/64.68024. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.68130/64.69446. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 59.55141/64.65841. Took 0.34 sec\n",
      "Epoch 99, Loss(train/val) 59.62720/64.64270. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.056730862893117545\n",
      "Epoch 0, Loss(train/val) 70.17867/70.88367. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.86233/70.89759. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.57964/70.90768. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.31116/70.90797. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.07527/70.90075. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.74763/70.88491. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.48076/70.86079. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.13113/70.83160. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.90611/70.79622. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.57836/70.75044. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.29133/70.69531. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.97683/70.63049. Took 0.34 sec\n",
      "Epoch 12, Loss(train/val) 66.63659/70.55968. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.38739/70.48363. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.14259/70.40420. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.77668/70.31865. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.48327/70.22305. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.32692/70.12961. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.06255/70.02859. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.82947/69.91754. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 64.60339/69.80141. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.35522/69.67075. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.22320/69.53522. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.04673/69.38972. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.90932/69.22178. Took 0.34 sec\n",
      "Epoch 25, Loss(train/val) 63.80457/69.05190. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.49784/68.89024. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.43010/68.76559. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.14067/68.65403. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 63.28123/68.56588. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 63.20888/68.48826. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.91772/68.41427. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.81311/68.35195. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.75671/68.30617. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.70837/68.26174. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.66048/68.23647. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.58127/68.21907. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.43525/68.19984. Took 0.34 sec\n",
      "Epoch 38, Loss(train/val) 62.58436/68.18279. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.56882/68.17546. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.46556/68.15640. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.52054/68.15633. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.40160/68.14857. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.34850/68.14307. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.23851/68.14324. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.31882/68.15823. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.21648/68.19540. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.18514/68.23705. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 62.22693/68.27061. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 62.21991/68.28520. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.98719/68.30101. Took 0.34 sec\n",
      "Epoch 51, Loss(train/val) 62.02905/68.31527. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.03573/68.38871. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.99547/68.42054. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.93829/68.43897. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.76763/68.46180. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.73146/68.46324. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.74294/68.45773. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.63287/68.45473. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.64166/68.43322. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.46967/68.46713. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.63274/68.44265. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 61.50507/68.40327. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.70524/68.35558. Took 0.34 sec\n",
      "Epoch 64, Loss(train/val) 61.38189/68.37848. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 61.44109/68.36521. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.30120/68.32426. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.23599/68.24568. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 61.21312/68.14453. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.04890/68.10270. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.03310/67.96840. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.70568/67.90533. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.77308/67.85992. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.77671/67.74904. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.49295/67.59100. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.29658/67.47424. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.18912/67.41369. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.24797/67.18244. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.97844/66.99421. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.76462/66.80934. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.66777/66.67691. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 59.55328/66.56403. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.43716/66.50771. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.33574/66.19575. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.21900/66.17908. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.15710/65.78941. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.96068/65.89754. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.96803/65.70235. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.65956/65.58259. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.74955/65.36266. Took 0.34 sec\n",
      "Epoch 90, Loss(train/val) 58.66319/65.29446. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.41782/65.19476. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.47048/65.23195. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 58.43052/65.08310. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.33117/64.96530. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.05069/64.90952. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.18470/64.81843. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.86839/64.60838. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.00036/64.81239. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.90985/64.60571. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.08006407690254357\n",
      "Epoch 0, Loss(train/val) 70.36642/69.57286. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.13923/69.32526. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.97104/69.07838. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.71904/68.82223. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.61826/68.56458. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.42636/68.29768. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.13554/68.01108. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.86652/67.70898. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.61640/67.40479. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.36987/67.09070. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.10233/66.76242. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.86682/66.42373. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.61975/66.06406. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 67.38319/65.69178. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 67.09591/65.30161. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.95114/64.93414. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.69419/64.55936. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.51836/64.17950. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.35704/63.81517. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.04007/63.45138. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.99672/63.09422. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.68579/62.76251. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.73043/62.47815. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.41603/62.18640. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.26256/61.88163. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.22601/61.56083. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.93673/61.23355. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.79080/60.89773. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.66677/60.53641. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.47895/60.13387. Took 0.34 sec\n",
      "Epoch 30, Loss(train/val) 64.20566/59.71292. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 64.05928/59.28545. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.96529/58.84731. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 63.81680/58.44338. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.66940/58.07681. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 63.49366/57.73218. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.38013/57.43619. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.27943/57.15464. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.13197/56.91545. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.10742/56.71814. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.85916/56.58574. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.84426/56.46332. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.90461/56.35317. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.68874/56.25304. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.65143/56.16776. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.72971/56.10660. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.49314/56.03678. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.46674/55.96992. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 62.46003/55.90817. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.37623/55.84982. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.17836/55.79071. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.31874/55.74549. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.18644/55.70243. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.18238/55.65391. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.17851/55.59586. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 62.12665/55.54380. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.05232/55.49887. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.98149/55.45074. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.88643/55.39811. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.92700/55.30853. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.86921/55.22145. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.77389/55.09782. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.59728/55.01374. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.59752/54.98484. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.37530/54.92098. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.55387/54.83434. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 61.51766/54.78109. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.42597/54.75219. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.19781/54.66553. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.36131/54.64871. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.32599/54.61411. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 61.13462/54.60315. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.00073/54.56433. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.10907/54.56005. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.05131/54.52452. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 60.90934/54.52493. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 60.88457/54.48753. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.89886/54.49358. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 60.70665/54.45888. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.80973/54.45046. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 60.66343/54.43706. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.54394/54.45142. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.64888/54.43320. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.53955/54.43858. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.54724/54.45054. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.41305/54.57224. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.38626/54.50439. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.35593/54.41856. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.27198/54.57162. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.15073/54.52242. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.19789/54.49082. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.10291/54.49711. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.07811/54.46910. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.97502/54.54430. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.14189/54.53204. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.09189/54.47948. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.89918/54.53765. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.91283/54.44199. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.93044/54.56366. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.80917/54.48745. Took 0.32 sec\n",
      "ACC: 0.40625, MCC: -0.17189402517942118\n",
      "Epoch 0, Loss(train/val) 70.57087/69.89849. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.30446/69.74841. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 69.95896/69.59492. Took 0.34 sec\n",
      "Epoch 3, Loss(train/val) 69.66688/69.42920. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 69.29121/69.23712. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.94838/68.99977. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.52407/68.70279. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.04004/68.36195. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.49342/67.99461. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.93169/67.58480. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.31197/67.13521. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.68664/66.66386. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 65.03134/66.22117. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 64.60001/65.85750. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.05555/65.53470. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.71715/65.26035. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.59483/65.02010. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.19777/64.79671. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.04483/64.59460. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.83630/64.41074. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 62.58003/64.23627. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.43118/64.07305. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.32164/63.92302. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.27116/63.78860. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.09760/63.66977. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.06101/63.55981. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.05376/63.46724. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.87407/63.39530. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 61.62805/63.32560. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.74180/63.26175. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.44112/63.20720. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.59870/63.15766. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.51211/63.11065. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.36099/63.06907. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 61.35317/63.03456. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.24862/63.00271. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.14480/62.97638. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 61.29826/62.95099. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.19213/62.93276. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.15579/62.92067. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 61.16664/62.91267. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.91443/62.90966. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 61.03675/62.89818. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.93497/62.90297. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.91307/62.90209. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.87467/62.91039. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.76120/62.91295. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.98765/62.91160. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.67855/62.91695. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.85415/62.91404. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 60.81342/62.91608. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.63479/62.92487. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.73321/62.93414. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.66465/62.94003. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.67956/62.95180. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 60.47211/62.96825. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.37663/62.98141. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.53771/62.98896. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.35115/62.98637. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.43540/62.98872. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.49815/62.98681. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.21757/62.97262. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.30853/62.96653. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.31682/62.96352. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.43451/62.96658. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 60.16744/62.96429. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 60.12771/62.95120. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.20478/62.96132. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.15989/62.97105. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 60.16660/62.96332. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.04773/62.95147. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.96524/62.93880. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.13925/62.92254. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.16904/62.92730. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.05971/62.94625. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 60.07305/62.95251. Took 0.34 sec\n",
      "Epoch 76, Loss(train/val) 59.84161/62.93451. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 59.81375/62.93506. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.87861/62.93647. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.76718/62.93686. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.80673/62.95391. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.70558/62.96086. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.69656/62.96051. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.79342/62.94616. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.52965/62.94613. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.60683/62.93826. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.52182/62.93827. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.51179/62.93371. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.70208/62.91100. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.55074/62.86734. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 59.51567/62.88609. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.59578/62.84319. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.48919/62.82444. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.24838/62.84188. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.31786/62.85299. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.21439/62.82870. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.34629/62.78350. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.16451/62.78992. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.23692/62.74524. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.17297/62.73938. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.09607689228305229\n",
      "Epoch 0, Loss(train/val) 70.37374/71.14368. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.22539/71.07699. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.13343/71.01446. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.02826/70.95851. Took 0.34 sec\n",
      "Epoch 4, Loss(train/val) 69.95050/70.91501. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.82298/70.87551. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.75035/70.83617. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.66899/70.80145. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.53536/70.77276. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.42581/70.75038. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.36000/70.73539. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.23082/70.72189. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 69.12874/70.71301. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.00044/70.70366. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.91305/70.68649. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.70996/70.67927. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 68.59821/70.66446. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 68.48702/70.63945. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.31799/70.60624. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.18512/70.56515. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 68.07387/70.53072. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.83459/70.48700. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.73360/70.44830. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.61401/70.40610. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 67.41257/70.37003. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 67.19193/70.34912. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 67.09918/70.32650. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.88638/70.26402. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 66.60594/70.18016. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 66.47177/70.14342. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.29261/70.06618. Took 0.34 sec\n",
      "Epoch 31, Loss(train/val) 66.13686/70.00471. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.87599/69.97745. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.77347/69.95576. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.59039/69.98665. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.41212/70.03007. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.40529/70.03935. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.12135/70.15770. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 65.19962/70.08679. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.85775/70.28557. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.80022/70.08132. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 64.65733/70.41566. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.68440/70.24471. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.47178/70.36485. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.29829/70.24351. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 64.38885/70.46030. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.24922/70.33453. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 64.32119/70.52151. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.26738/70.40419. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.01790/70.48739. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 63.90844/70.69713. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.96162/70.44508. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.78918/70.74715. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 63.76293/70.83268. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.70359/70.48539. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 63.71185/71.00743. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 63.69859/70.68205. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 63.51037/71.27179. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 63.49151/71.04273. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.46644/71.21877. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.40449/70.93430. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 63.31505/71.41648. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 63.18781/71.50820. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.20706/71.46046. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 63.08877/71.46732. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 63.08229/71.52641. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 63.08341/71.35702. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.81769/71.62211. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 62.77866/71.61496. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.70205/71.46105. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 62.75160/71.46354. Took 0.34 sec\n",
      "Epoch 71, Loss(train/val) 62.72811/71.68129. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.54072/71.50996. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.54122/71.66183. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.47815/71.68875. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.57689/71.71368. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 62.40909/71.72063. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 62.30428/71.83807. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.38833/71.66384. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.23045/71.67229. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 62.11465/71.60415. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 61.98561/71.84695. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 62.04161/71.49832. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 61.97641/71.64915. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.99127/71.53043. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.92075/71.66797. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.99203/71.47634. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.95226/71.43051. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.77922/71.63811. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 61.79398/71.45824. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 61.69620/71.94933. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.68022/71.58766. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.44267/71.54362. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 61.59531/71.65931. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 61.63198/71.79277. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.38752/71.37376. Took 0.34 sec\n",
      "Epoch 96, Loss(train/val) 61.31518/71.82762. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.35146/71.36319. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.18430/71.50651. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.20222/71.71790. Took 0.31 sec\n",
      "ACC: 0.46875, MCC: 0.06497057526101395\n",
      "Epoch 0, Loss(train/val) 70.68640/69.65005. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.51387/69.50391. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.33889/69.37302. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.16955/69.23885. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.06343/69.10406. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.88304/68.97046. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.71895/68.82780. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.61011/68.67184. Took 0.34 sec\n",
      "Epoch 8, Loss(train/val) 69.44648/68.50383. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.23327/68.31750. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.03080/68.11486. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.90071/67.89460. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 68.67551/67.64777. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.56065/67.37862. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.32120/67.09144. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 68.15463/66.79023. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 67.95897/66.46804. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.70966/66.13422. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 67.55118/65.80206. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.31909/65.49178. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 67.17475/65.21301. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 66.90765/64.96466. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 66.75008/64.73409. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.54287/64.54814. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.39794/64.37524. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.39175/64.22523. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 66.04894/64.08524. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.92615/63.95385. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.89950/63.83347. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.58903/63.71801. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.50293/63.61904. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.33718/63.54046. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 65.23590/63.46788. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.16315/63.38456. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 64.99924/63.32300. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.85932/63.24057. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.89685/63.17500. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.64667/63.10353. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.79293/63.05257. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.54327/62.97991. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.55390/62.94572. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.48848/62.88768. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.23373/62.82886. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.27111/62.76238. Took 0.34 sec\n",
      "Epoch 44, Loss(train/val) 64.11872/62.71054. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 63.98950/62.66706. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 63.88970/62.62305. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 63.93059/62.58797. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 63.86288/62.56675. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 63.70599/62.52275. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.75223/62.50261. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.63105/62.48553. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.65238/62.48428. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.58576/62.48166. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.46017/62.45383. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.23600/62.43236. Took 0.34 sec\n",
      "Epoch 56, Loss(train/val) 63.38017/62.40483. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.20674/62.37329. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.28039/62.34766. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.15260/62.33328. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 63.06598/62.28849. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 63.22981/62.26831. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.08460/62.26004. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 62.96310/62.22218. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.00495/62.20336. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.01567/62.18906. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.90766/62.15232. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 63.03724/62.13244. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 62.89224/62.08352. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.85551/62.02438. Took 0.34 sec\n",
      "Epoch 70, Loss(train/val) 62.66190/62.00429. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.54674/61.96832. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.66306/61.92421. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 62.57493/61.88699. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 63.09576/61.90063. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.83851/61.78855. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.49309/61.73220. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.36480/61.68358. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 62.50007/61.58631. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.66918/61.57981. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.52937/61.50386. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 62.55417/61.45686. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 62.37110/61.40092. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 62.18817/61.37943. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.04301/61.31081. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 62.18971/61.29949. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.22908/61.24219. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 62.31346/61.28116. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 62.09338/61.17846. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 62.26589/61.21174. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 62.20898/61.16860. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 61.89253/61.06618. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.87805/60.98940. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.72011/61.04319. Took 0.34 sec\n",
      "Epoch 94, Loss(train/val) 61.75460/61.01725. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.75902/61.00377. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.53173/60.97742. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 62.12059/61.06376. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.81812/60.92286. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.75451/61.02471. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.09288407280256479\n",
      "Epoch 0, Loss(train/val) 70.10283/70.40116. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 69.89375/70.23396. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.67675/70.06205. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.51135/69.88264. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.26376/69.69233. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.03280/69.49101. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.78643/69.27867. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.52979/69.06480. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.28822/68.83649. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.05730/68.58897. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.77176/68.32494. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.54480/68.03104. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.26120/67.70602. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.03747/67.34671. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 66.62387/66.94753. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 66.38174/66.51891. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.98545/66.05328. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.68094/65.53887. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.45398/65.01550. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 65.00480/64.49951. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 64.71214/64.02753. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 64.26616/63.61181. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.08562/63.22280. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.73447/62.87496. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.53413/62.58689. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.42521/62.33311. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.02662/62.07500. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.84202/61.82875. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 62.85905/61.67464. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.55075/61.46694. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.40409/61.30246. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.28467/61.18683. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.32797/61.05819. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.22610/60.92123. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.04962/60.82010. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.88807/60.73188. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.93565/60.60187. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.91712/60.50896. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.67415/60.44289. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.68672/60.32709. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.79787/60.32583. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.53276/60.21678. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.56821/60.20142. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 61.42662/60.06015. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.29055/60.07829. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.35628/59.93520. Took 0.34 sec\n",
      "Epoch 46, Loss(train/val) 61.20564/59.97004. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.23481/59.82185. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.13694/59.85399. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.09585/59.70935. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.07329/59.70861. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.91726/59.59607. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.92632/59.59145. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.84347/59.50222. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.76819/59.43813. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.64400/59.37331. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.75841/59.31836. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.73838/59.26674. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.81422/59.22038. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 60.48948/59.15247. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.69256/59.11812. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.47342/59.06226. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.43637/59.02959. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.37713/58.97496. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.23174/58.93266. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.53114/58.89043. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.35032/58.85806. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.30773/58.80597. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.22885/58.77601. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.98931/58.77790. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.90658/58.73554. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.97621/58.67852. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.93135/58.65700. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.04666/58.66190. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 59.95305/58.63063. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.97374/58.57700. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.97411/58.56256. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.97405/58.54360. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.75598/58.52255. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.76019/58.53923. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 59.68051/58.53512. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.82830/58.46137. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.76005/58.46642. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.66722/58.49096. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.50246/58.37906. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.53589/58.36395. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.41996/58.37084. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.37958/58.35357. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.28668/58.36060. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 59.58674/58.38335. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.35016/58.26311. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.42561/58.26567. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.27492/58.23855. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.28489/58.22062. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.43043/58.15664. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.10795/58.17361. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.30561/58.11888. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.19049/58.07699. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.97816/58.05215. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.18702/58.02013. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: 0.018490006540840973\n",
      "Epoch 0, Loss(train/val) 70.37627/70.94116. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.95982/70.50350. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.63213/70.06532. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.21801/69.61032. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.81971/69.14519. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.44347/68.67101. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.04273/68.18532. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.62820/67.68130. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.24890/67.15713. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.75918/66.61983. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.42738/66.07388. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 65.94236/65.51400. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.52663/64.95443. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.05486/64.38925. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.70091/63.80532. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.16276/63.19928. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.88524/62.57282. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.29761/61.91625. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 62.90170/61.22669. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.39682/60.52144. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.03764/59.83636. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.53321/59.19418. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 61.23750/58.61924. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 60.90177/58.11533. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.61193/57.66857. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 60.09691/57.29788. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.00136/56.99197. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 59.75583/56.72330. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 59.70699/56.48022. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.34727/56.26040. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.36817/56.06873. Took 0.36 sec\n",
      "Epoch 31, Loss(train/val) 59.17158/55.96174. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.06333/55.88825. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.00683/55.80061. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.88196/55.71885. Took 0.34 sec\n",
      "Epoch 35, Loss(train/val) 58.83891/55.63736. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.73295/55.55745. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 58.63376/55.48787. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 58.44774/55.41233. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.75234/55.33711. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.59104/55.26150. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.47228/55.19368. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.47286/55.10860. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.26390/55.02805. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.33645/54.97564. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.17270/54.92782. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 58.15171/54.88585. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.20997/54.85038. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.24074/54.82078. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.08680/54.79311. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.09401/54.76744. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.94183/54.74971. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.88371/54.73698. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.89774/54.72028. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.05140/54.70357. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.94566/54.68694. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.76011/54.67107. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 57.83989/54.65595. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.97091/54.65427. Took 0.34 sec\n",
      "Epoch 59, Loss(train/val) 57.86157/54.64347. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.87138/54.64269. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.64064/54.63800. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.72068/54.63366. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 57.91929/54.63212. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.54923/54.63144. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.65314/54.62447. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.61533/54.62432. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 57.48194/54.62014. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.68984/54.60841. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.62635/54.59354. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 57.61359/54.57155. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.67790/54.57138. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.45878/54.57976. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.53484/54.56725. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.40706/54.55519. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.59307/54.54077. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.44893/54.53291. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.57049/54.52525. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 57.40077/54.50953. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.29960/54.48528. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 57.21861/54.46321. Took 0.34 sec\n",
      "Epoch 81, Loss(train/val) 57.31286/54.45277. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 57.45041/54.43915. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 57.33781/54.42379. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.34134/54.40472. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.29848/54.38826. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 57.23866/54.37000. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 57.39817/54.35023. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 57.31271/54.33083. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.24508/54.32402. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.42641/54.29673. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.32047/54.28567. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.24862/54.26225. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.25630/54.24607. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.18114/54.20029. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 57.23145/54.18100. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.12506/54.14695. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.04889/54.13807. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.95845/54.14965. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.17670/54.13941. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: -0.047619047619047616\n",
      "Epoch 0, Loss(train/val) 70.54056/71.36315. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.34251/71.20578. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.17044/71.04110. Took 0.34 sec\n",
      "Epoch 3, Loss(train/val) 69.97422/70.86962. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.75077/70.68681. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.56893/70.49213. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.35301/70.28505. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.13687/70.06217. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.87197/69.81429. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.67863/69.54166. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.42375/69.24904. Took 0.34 sec\n",
      "Epoch 11, Loss(train/val) 68.14208/68.92720. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.85944/68.58418. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.56738/68.22364. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.16628/67.84560. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 66.77639/67.46766. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.42449/67.12118. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.07314/66.81755. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.64668/66.55039. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.30944/66.32567. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.04181/66.13911. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 64.71152/65.97279. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.37175/65.82579. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.36883/65.69216. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.11293/65.58383. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.86696/65.48996. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.63906/65.41291. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.55422/65.34872. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.38837/65.28121. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.29595/65.22457. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 63.06374/65.16081. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.10016/65.08775. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.97150/65.01640. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.76803/64.97334. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.80892/64.94208. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.67848/64.87947. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.42815/64.83024. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 62.49003/64.77116. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.39411/64.70899. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.23807/64.64089. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.15711/64.58103. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.00489/64.49634. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.99758/64.44172. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.93853/64.36585. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.82823/64.29951. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.61853/64.20522. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 61.64019/64.13183. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.48188/64.10046. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.29987/64.02151. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.35714/63.89853. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.27475/63.77385. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.08590/63.70227. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.13181/63.62447. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.04262/63.60011. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.01503/63.56882. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.88776/63.47582. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.83303/63.46289. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.62465/63.32449. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 60.68833/63.25019. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.71643/63.18201. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.66624/63.13200. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.46621/63.17270. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.35768/63.13460. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.41879/63.08189. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.28095/63.05283. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.13721/62.98340. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.06466/62.89809. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.04741/62.82291. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.08536/62.85582. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 59.87650/62.79183. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.98870/62.81666. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.92148/62.78960. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.64698/62.78126. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.70386/62.77982. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 59.73853/62.72739. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.68351/62.69664. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.67990/62.69292. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.40127/62.62061. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.34724/62.56376. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.43550/62.61644. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.26836/62.56478. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.37332/62.58920. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.40305/62.59781. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.25579/62.55726. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.06404/62.54940. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 59.11590/62.58417. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.01822/62.55791. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.09936/62.59841. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.95732/62.57036. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 59.12110/62.63699. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.90563/62.53472. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.95402/62.61099. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.99162/62.60515. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.84501/62.56774. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.82466/62.65673. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.68296/62.68074. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.76778/62.61382. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.62131/62.73071. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.58020/62.70716. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.61638/62.66639. Took 0.33 sec\n",
      "ACC: 0.390625, MCC: -0.21202254684706773\n",
      "Epoch 0, Loss(train/val) 69.74261/70.02399. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.47593/69.96188. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.22703/69.88865. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 68.94736/69.80492. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.66953/69.70656. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.37089/69.59430. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.05511/69.46773. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.70710/69.32827. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.37621/69.18121. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.99452/69.03894. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.56885/68.88490. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.12244/68.72987. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.83929/68.58435. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.40571/68.44111. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.16158/68.29900. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.75337/68.17189. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.49282/68.05498. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.18249/67.95134. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.83199/67.85775. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.58973/67.77121. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.34288/67.70685. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.22126/67.64337. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.04897/67.57558. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 62.74722/67.49956. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.65555/67.40578. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.42109/67.31322. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.40516/67.21663. Took 0.34 sec\n",
      "Epoch 27, Loss(train/val) 62.25772/67.12101. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.92767/67.02747. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.94562/66.94476. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.02929/66.89458. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.77912/66.83434. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.78342/66.79003. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.56165/66.74986. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.53100/66.70327. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.50359/66.66666. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.50911/66.64003. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 61.42705/66.63065. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 61.25023/66.63087. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 61.23994/66.62416. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 61.07261/66.63189. Took 0.34 sec\n",
      "Epoch 41, Loss(train/val) 61.11173/66.63356. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.12072/66.63912. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.06997/66.64292. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.06356/66.64378. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.03563/66.65857. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.78051/66.66244. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.05434/66.67737. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.97707/66.68892. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.71201/66.67961. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.65752/66.67816. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.85129/66.66669. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.74427/66.66597. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.61952/66.67265. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.49081/66.66201. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.56816/66.65395. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.45609/66.64954. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.50373/66.63992. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.50560/66.63480. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.34878/66.62585. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.40366/66.62847. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.22796/66.63522. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.32860/66.64069. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.22695/66.64635. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.14964/66.64602. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.09627/66.64052. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.08684/66.65340. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.03121/66.68394. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.92843/66.70205. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 59.94688/66.69926. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.00199/66.72079. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.79278/66.74657. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.88998/66.76742. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.86942/66.77649. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.80865/66.78229. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.56634/66.79833. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.76971/66.81965. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.66278/66.83517. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.66300/66.84932. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.45915/66.85666. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.52461/66.85441. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.40467/66.82877. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.58808/66.84074. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.52510/66.76798. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.24649/66.79480. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.34155/66.76280. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.24920/66.77354. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.18906/66.76619. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.19209/66.74905. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.16795/66.76587. Took 0.34 sec\n",
      "Epoch 90, Loss(train/val) 59.13233/66.69330. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.07811/66.72098. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.05889/66.62626. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.82751/66.68541. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.86884/66.64093. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.82244/66.67680. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.91517/66.64439. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.74201/66.72845. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.67507/66.63348. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.59600/66.63898. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.03779786830012622\n",
      "Epoch 0, Loss(train/val) 70.57267/69.56757. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.34305/69.50858. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.10167/69.44353. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.85441/69.37122. Took 0.34 sec\n",
      "Epoch 4, Loss(train/val) 69.68947/69.29418. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.41363/69.21272. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.21151/69.12997. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.97020/69.04669. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.69685/68.96319. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.48711/68.88210. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.28314/68.80897. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.11355/68.73892. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.84651/68.67218. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.56269/68.60874. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.49979/68.54658. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.24093/68.48856. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.94712/68.43381. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.79426/68.37993. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.71111/68.33022. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.49126/68.28321. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 66.26884/68.23801. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.12664/68.19470. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.90358/68.15364. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.85803/68.11691. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.64128/68.08289. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 65.43316/68.05400. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.31661/68.02531. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.16516/67.99706. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.05920/67.97273. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.86887/67.95490. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.69314/67.94480. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.48680/67.93558. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.38337/67.92553. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.29125/67.91651. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.15379/67.90845. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.90524/67.90508. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.91299/67.89986. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.74103/67.89315. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 63.58560/67.88292. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.46393/67.87184. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.25687/67.86414. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.22543/67.85390. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.08872/67.84980. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.01994/67.84301. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.90189/67.83132. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.74638/67.82051. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.54021/67.80768. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.56163/67.80721. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.52518/67.79245. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.15660/67.78165. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.05990/67.77397. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.72750/67.75723. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.67735/67.72826. Took 0.35 sec\n",
      "Epoch 53, Loss(train/val) 61.60575/67.68884. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.46394/67.65603. Took 0.34 sec\n",
      "Epoch 55, Loss(train/val) 61.37851/67.61230. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.16812/67.55962. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.09866/67.51672. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.05711/67.46246. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.85370/67.41537. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.75141/67.36044. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.66182/67.30034. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.73055/67.24332. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.54523/67.18880. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.34823/67.12792. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.30801/67.09116. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.08660/67.02386. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.17074/66.97260. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.96021/66.90536. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.08602/66.83379. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.86721/66.77452. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.78457/66.72696. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.88877/66.64939. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.79950/66.58805. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.73974/66.53963. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.61768/66.44896. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.56707/66.37592. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.43651/66.32730. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.36130/66.26854. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.24433/66.18681. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.34313/66.11044. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 59.31946/66.04477. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.28625/66.01208. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.09577/65.94177. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.07341/65.87612. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.87803/65.81510. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.90914/65.76993. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.89554/65.72477. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.55719/65.67254. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.58217/65.65855. Took 0.34 sec\n",
      "Epoch 90, Loss(train/val) 58.58649/65.60603. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.53281/65.56487. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.63718/65.53085. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 58.35610/65.53157. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.54770/65.53860. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.42910/65.52864. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 58.21569/65.49924. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.22592/65.49680. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 58.15203/65.46947. Took 0.34 sec\n",
      "Epoch 99, Loss(train/val) 58.05400/65.44247. Took 0.35 sec\n",
      "ACC: 0.578125, MCC: 0.14859644825447751\n",
      "Epoch 0, Loss(train/val) 70.30812/70.21404. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.15489/70.11880. Took 0.34 sec\n",
      "Epoch 2, Loss(train/val) 69.90935/70.02090. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.79323/69.91761. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.59739/69.80542. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.41798/69.68444. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.23931/69.54988. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.06329/69.39028. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.79847/69.21392. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.55533/69.02989. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.26499/68.83026. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.02059/68.63492. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.84348/68.43993. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.56535/68.25199. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.28621/68.06716. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.11081/67.88896. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.81975/67.71668. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.60084/67.53783. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.41261/67.35406. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.23743/67.17219. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.96752/66.99387. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.79891/66.81483. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.63332/66.63185. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.42674/66.45684. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.40092/66.29679. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 65.23452/66.14245. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.32365/65.99365. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.18248/65.84682. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.02233/65.70116. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.88199/65.57438. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.78827/65.44675. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.82367/65.31696. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 64.59376/65.19877. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 64.45500/65.09361. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.51410/65.00314. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 64.27485/64.92632. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.53726/64.85104. Took 0.34 sec\n",
      "Epoch 37, Loss(train/val) 64.29638/64.80869. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 64.19978/64.77578. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.07851/64.72154. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 64.06858/64.66212. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 64.24873/64.54504. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.84093/64.48894. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 63.88341/64.45663. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.88436/64.40853. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.84251/64.33443. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.63531/64.27181. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.80398/64.18458. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 63.65796/64.09292. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.60098/64.06694. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.39840/63.95042. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 63.51459/63.87231. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 63.41320/63.78825. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.24487/63.68997. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.42365/63.62834. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 63.17517/63.58794. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.03291/63.54284. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 63.25809/63.45654. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.02481/63.38661. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.02490/63.28952. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 63.00471/63.24994. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.96843/63.17194. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 62.77692/63.07584. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 62.73704/63.01161. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 62.69239/62.93431. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.48268/62.82569. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.59151/62.77637. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.45166/62.74098. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.30946/62.67575. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 62.33616/62.52162. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.27075/62.51696. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 62.09141/62.50420. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.16237/62.24807. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 62.08921/62.21562. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.85479/62.34455. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.79868/62.10633. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.97046/62.34171. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 61.73788/62.27358. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 61.57247/62.31335. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.65802/62.32141. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 61.48881/62.32880. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.51082/62.67125. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 61.36250/62.47520. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.49386/62.52209. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 61.48300/62.44312. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.37887/62.56807. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.34339/62.53501. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.17580/62.38209. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 61.32480/62.15407. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.11441/62.46686. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.04753/62.54588. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.14767/62.45162. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.93421/62.25325. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.92750/62.28349. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.86795/62.26556. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 60.94784/62.34511. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.82927/62.04887. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.88355/61.94177. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.88086/61.94357. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.79377/61.96374. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.11065666703449763\n",
      "Epoch 0, Loss(train/val) 70.56736/70.91721. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.39494/70.80502. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.18603/70.68833. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.99045/70.56116. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.76860/70.40921. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.53887/70.23858. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.26401/70.03992. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.97571/69.80827. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.70392/69.54405. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.38347/69.23543. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.04674/68.87510. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.66073/68.44788. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.21752/67.93502. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.78953/67.32834. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.28167/66.60810. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.81111/65.77966. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.15033/64.87865. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.57746/64.03995. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.99426/63.36736. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.56696/62.86353. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.19754/62.47093. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.94982/62.16325. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.69368/61.91920. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.50604/61.73470. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.36565/61.57936. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.34221/61.44553. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.17315/61.32626. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.04581/61.20892. Took 0.34 sec\n",
      "Epoch 28, Loss(train/val) 61.97765/61.13470. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.83428/61.07930. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.70669/61.00103. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 61.62244/60.91022. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.64522/60.82034. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.44578/60.71509. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.48125/60.63591. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.32369/60.57420. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.39036/60.50763. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 61.26408/60.39416. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.01878/60.27445. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.90113/60.15582. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.99841/60.04687. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.82279/60.02775. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.77684/59.90859. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.67005/59.76620. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 60.51957/59.63588. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.45330/59.53375. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.44719/59.46162. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.37477/59.35532. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.16008/59.24657. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.15200/59.17844. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 60.11753/59.11927. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.03581/59.03675. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.91759/58.97541. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.90190/58.91181. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.85810/58.84383. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.73812/58.84451. Took 0.34 sec\n",
      "Epoch 56, Loss(train/val) 59.59518/58.83039. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.45809/58.78241. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.41480/58.70772. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.37936/58.63544. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.49111/58.58398. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 59.29831/58.52705. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.20892/58.49050. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.17564/58.41861. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.00344/58.37534. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.96504/58.35482. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 58.93021/58.30105. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.00245/58.22303. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 58.75692/58.17677. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.78477/58.12946. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 58.71936/58.09126. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.54673/57.99854. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.50187/57.91830. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.50517/57.84594. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.50615/57.79519. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.42637/57.72491. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.35163/57.61909. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.35135/57.56503. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.13362/57.48164. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.12563/57.40654. Took 0.34 sec\n",
      "Epoch 80, Loss(train/val) 58.18204/57.34479. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.14382/57.29460. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.01350/57.24350. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 57.87787/57.21817. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.77455/57.16059. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.80151/57.11692. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.66545/57.08215. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.67890/56.98984. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 57.67279/56.82304. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.55211/56.77615. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 57.37822/56.81719. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 57.44560/56.79025. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.37233/56.77035. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.23567/56.70514. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.20477/56.65659. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 57.13795/56.60738. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.12368/56.52373. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.99315/56.50560. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.04962/56.44975. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 56.84486/56.33687. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.19210545285208808\n",
      "Epoch 0, Loss(train/val) 69.44045/70.31322. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.10723/70.10561. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 68.79989/69.87388. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 68.51466/69.59640. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.09709/69.26423. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 67.64281/68.87038. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.17827/68.42706. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 66.63135/67.95445. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 66.12589/67.45459. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 65.61255/67.02254. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.16424/66.71049. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 64.76256/66.44352. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 64.31027/66.18610. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 63.91845/65.93262. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 63.37956/65.68913. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.20719/65.45856. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.01700/65.23069. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 62.77035/65.02805. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.54878/64.84939. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.45658/64.69769. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.24560/64.59204. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.98621/64.50786. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.94876/64.43884. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.88898/64.37798. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.68570/64.35802. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.56125/64.30322. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.48897/64.27597. Took 0.34 sec\n",
      "Epoch 27, Loss(train/val) 61.33104/64.21942. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.33556/64.19881. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.27457/64.15652. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.13523/64.16351. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 60.72676/64.10847. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 60.75016/64.09289. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.82527/64.01927. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.66306/64.00042. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.57059/63.94683. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.48620/63.91455. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.25143/63.87367. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.27446/63.81852. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.35730/63.75824. Took 0.34 sec\n",
      "Epoch 40, Loss(train/val) 60.17639/63.71473. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 60.12482/63.64780. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.11745/63.60490. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.98245/63.55741. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.99686/63.48421. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.01752/63.43606. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 59.89950/63.38328. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.86490/63.30083. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.74306/63.26163. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.68688/63.28374. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.61861/63.21527. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.57961/63.25013. Took 0.34 sec\n",
      "Epoch 52, Loss(train/val) 59.48443/63.14273. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.40128/63.18577. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 59.45930/63.00255. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.38603/63.17063. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.50058/63.05523. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.28758/63.12807. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.18666/63.07306. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.17178/63.00670. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.36812/62.84794. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.99577/62.88471. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.99305/62.86416. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.00706/62.82505. Took 0.34 sec\n",
      "Epoch 64, Loss(train/val) 58.87259/62.73829. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.85279/62.78360. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.96257/62.66917. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.98265/62.64887. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 58.59982/63.13284. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.00888/62.66879. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 58.75579/62.60512. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.64869/63.06340. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.72586/62.49691. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.82625/62.45582. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.50292/63.18046. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 58.84713/62.66924. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 58.44080/62.63129. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.48878/62.49414. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.35870/62.19132. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.22307/62.54492. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.36800/62.97914. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.32397/62.00339. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.00853/62.66011. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.04416/62.99575. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.08285/61.87409. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.94031/62.41702. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.94508/62.59001. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.69342/61.93490. Took 0.34 sec\n",
      "Epoch 88, Loss(train/val) 57.62125/62.94881. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 57.84494/61.76492. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 57.59048/61.98404. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.37961/61.93304. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.45616/62.22579. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.67564/62.18753. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.47388/61.44234. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.25139/61.80747. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.23548/61.66959. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 56.86735/61.65765. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.15053/61.62745. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.98652/61.55475. Took 0.32 sec\n",
      "ACC: 0.359375, MCC: -0.0029434052379223195\n",
      "Epoch 0, Loss(train/val) 70.03593/69.67529. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.87345/69.57219. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.80813/69.46580. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.66094/69.35561. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.51019/69.24435. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.38776/69.12759. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.19350/68.99687. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.02709/68.85704. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.82909/68.69688. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.54489/68.51037. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.33243/68.30384. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.05028/68.08038. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.90788/67.86835. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.60527/67.66438. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.41095/67.46542. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.18703/67.26598. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.91180/67.07134. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.77286/66.88444. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.61758/66.69763. Took 0.34 sec\n",
      "Epoch 19, Loss(train/val) 66.35795/66.51678. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.12034/66.35069. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.09404/66.17769. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.79253/66.01875. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.73422/65.86369. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.54473/65.72189. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 65.38066/65.58592. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 65.20912/65.43697. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 65.04496/65.29465. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.02911/65.15308. Took 0.34 sec\n",
      "Epoch 29, Loss(train/val) 64.70444/65.04898. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.69470/64.93556. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 64.59222/64.78599. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.61524/64.62206. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 64.23401/64.49693. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.18116/64.42219. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 64.08796/64.33117. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.92902/64.24847. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.83783/64.14133. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.80235/63.99458. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 63.57445/63.85602. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 63.68019/63.72352. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.36484/63.63887. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.46702/63.57590. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.15981/63.43245. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.24185/63.35706. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.05388/63.24197. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 63.08291/63.19677. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.81099/63.02970. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.84506/62.98863. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 62.81599/62.88279. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.55402/62.78394. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.50025/62.65338. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.43053/62.62128. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.34361/62.49438. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.10108/62.37330. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.94936/62.20763. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.89566/62.21245. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.68153/62.04539. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.68298/62.21790. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.59941/62.19369. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.35530/62.98444. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.31646/62.08483. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.22941/61.88602. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.00997/62.53360. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.83888/62.10042. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.65997/61.82389. Took 0.34 sec\n",
      "Epoch 66, Loss(train/val) 60.75637/62.12547. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.60007/61.23852. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.45658/61.58669. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.25517/61.64287. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.08912/61.48513. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.89269/61.22264. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.04863/60.55596. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.60354/60.30806. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.39110/60.37722. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.59444/60.40820. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.58807/62.37585. Took 0.34 sec\n",
      "Epoch 77, Loss(train/val) 59.41175/60.41220. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.27463/59.28477. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.14041/59.49596. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.21098/59.82620. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 59.20315/61.82592. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.85145/61.20985. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.68789/60.22251. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.78570/59.96800. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.55739/58.82886. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.17420/59.26906. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.39969/58.81519. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.62119/61.94588. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.39823/60.78267. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.32426/60.81743. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.17291/59.80846. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.03936/58.70203. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.98705/59.56336. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.02927/60.30633. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.71052/61.37655. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.86644/59.55133. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.42777/60.47306. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.69205/58.30024. Took 0.34 sec\n",
      "Epoch 99, Loss(train/val) 57.76859/60.69609. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.2188190425877391\n",
      "Epoch 0, Loss(train/val) 72.03157/72.42703. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.80097/72.16141. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.61419/71.90488. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 71.42191/71.64288. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 71.24773/71.37035. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 71.04466/71.08433. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 70.82380/70.76455. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.58173/70.41669. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 70.29216/70.02493. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.98153/69.59418. Took 0.34 sec\n",
      "Epoch 10, Loss(train/val) 69.65397/69.15105. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.35817/68.71080. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.05865/68.28435. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.85693/67.89117. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.44450/67.50597. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 68.14008/67.12500. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 67.82050/66.75551. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.60197/66.39941. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 67.39907/66.02968. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 67.03798/65.60060. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 66.71431/65.12086. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 66.30273/64.63431. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 66.05006/64.14824. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.64613/63.67757. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.48241/63.27848. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.13494/62.91833. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.86121/62.57208. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.54124/62.23845. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.28480/61.93771. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 63.99081/61.64067. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 63.82870/61.34905. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.49584/61.04393. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.14942/60.71655. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.93778/60.37964. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.77818/60.03606. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.58014/59.69189. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.50012/59.34396. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.18303/59.01665. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.21167/58.69558. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 61.87738/58.37093. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 61.80055/58.02523. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.67685/57.67802. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 61.54891/57.37905. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.30023/57.13046. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.34708/56.96312. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.11292/56.84435. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.19719/56.78895. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.01535/56.77905. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.92696/56.76714. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.76124/56.69234. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.76074/56.60804. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.48444/56.63802. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.52872/56.74699. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.57629/56.70809. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.49728/56.84782. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.34563/56.89827. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.29495/56.92886. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.15190/57.12712. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.16320/57.10993. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.15322/57.19441. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.13288/57.33472. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.07739/57.39202. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.82172/57.42661. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 59.92765/57.55331. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.04659/57.69278. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.87906/57.59488. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.88260/57.72754. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.83036/57.78158. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.85751/57.75829. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.69870/57.79580. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.73309/57.89484. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.57183/57.89113. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.61207/57.77658. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.48746/57.81693. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.45967/57.80585. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.34669/57.82998. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 59.28114/57.80114. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.29229/57.70138. Took 0.34 sec\n",
      "Epoch 78, Loss(train/val) 59.18643/57.68547. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.20894/57.51947. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.02570/57.75674. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.07346/57.56083. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.16694/57.64243. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.95171/57.71581. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.99813/57.71732. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.93011/57.85786. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.81096/57.92220. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.86203/57.97044. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.62750/58.14136. Took 0.34 sec\n",
      "Epoch 89, Loss(train/val) 58.67883/58.15023. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.58206/58.28748. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.45039/58.15872. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.41164/58.48198. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 58.64086/58.52057. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.43645/58.52725. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.33074/58.55883. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 58.38269/58.75903. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.31035/58.57135. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.03140/58.78296. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.03811/58.87037. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.03419927840283847\n",
      "Epoch 0, Loss(train/val) 71.01722/69.75316. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.87518/69.64797. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.63400/69.53926. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.52551/69.42390. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.34495/69.30177. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.18377/69.17438. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.96714/69.03362. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.79627/68.87740. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.53904/68.71448. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.32224/68.53610. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.17829/68.34647. Took 0.34 sec\n",
      "Epoch 11, Loss(train/val) 68.93926/68.15271. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.67654/67.94909. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.42108/67.72279. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.19501/67.47075. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.82522/67.18767. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 67.53440/66.87562. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.17942/66.53811. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.75302/66.16626. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.44560/65.78953. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 66.09741/65.41846. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.83272/65.07210. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.47839/64.74887. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.19631/64.46738. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 64.93932/64.21154. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.67372/64.00861. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.48331/63.87604. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.19757/63.78091. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.93504/63.69573. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 63.72969/63.63783. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 63.74783/63.60139. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.28743/63.56938. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.26944/63.54446. Took 0.34 sec\n",
      "Epoch 33, Loss(train/val) 63.26441/63.52309. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.07454/63.50873. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.00393/63.51031. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.70149/63.51535. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.53317/63.52429. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.49668/63.49670. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.40302/63.47745. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.19512/63.47132. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.28345/63.49324. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.27250/63.50384. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.88667/63.46886. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.10932/63.42216. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.98532/63.40739. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.84092/63.38224. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.62876/63.35094. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.58844/63.34745. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.31739/63.33313. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.19644/63.32320. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.96361/63.30818. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.97967/63.25662. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.11423/63.22620. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 60.94353/63.21074. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.90929/63.17875. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.02383/63.14729. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.97302/63.12638. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.76801/63.09647. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.88113/63.09462. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.50560/63.02778. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.66941/63.02166. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.40267/62.97547. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.36390/62.94500. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.35420/62.94680. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.40522/62.91231. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.32310/62.86220. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.28172/62.87014. Took 0.34 sec\n",
      "Epoch 68, Loss(train/val) 60.09470/62.84647. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.06771/62.85604. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.98453/62.73265. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.09960/62.90688. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.05535/62.70667. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.97091/62.84226. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.78766/62.66008. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.06470/62.79806. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 59.87458/62.64065. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.78446/62.80341. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.72665/62.60485. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.93854/62.84970. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.64116/62.65447. Took 0.34 sec\n",
      "Epoch 81, Loss(train/val) 59.76858/62.76712. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.55282/62.62376. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.68476/62.78736. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.59610/62.51545. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.48544/62.77456. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.48833/62.46343. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.67713/62.82239. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 59.34788/62.45250. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.46979/62.76657. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 59.39700/62.38311. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.75635/62.82837. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.40168/62.45083. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 59.30834/62.70448. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.36558/62.40918. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.43322/62.70557. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.10057/62.33435. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 59.28524/62.63151. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 59.05999/62.38810. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.22619/62.59845. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.13471563869719666\n",
      "Epoch 0, Loss(train/val) 69.50999/68.48968. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.26198/68.12497. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.00413/67.71816. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 68.79895/67.25530. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.34783/66.72115. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.00748/66.09429. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.54217/65.38758. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 66.94247/64.58942. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.26109/63.70388. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 65.63608/62.75330. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 65.01336/61.83169. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 64.51752/61.01627. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 64.12918/60.35285. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 63.76643/59.86245. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 63.59977/59.45932. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 63.21854/59.11858. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.20865/58.83403. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 62.88079/58.56837. Took 0.34 sec\n",
      "Epoch 18, Loss(train/val) 62.74540/58.31846. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.60921/58.07647. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.46190/57.82775. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 62.33404/57.62341. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 62.18619/57.47923. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 62.13524/57.32016. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 61.90771/57.17295. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 61.76720/57.03596. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 61.87879/56.90942. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 61.70300/56.81132. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.67065/56.71137. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.45482/56.58025. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 61.27122/56.46312. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 61.15927/56.36528. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.05770/56.26165. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.17641/56.16819. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.04086/56.05112. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.99359/55.93359. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 60.80664/55.81785. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.90366/55.71748. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.70271/55.62276. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.53244/55.52486. Took 0.34 sec\n",
      "Epoch 40, Loss(train/val) 60.50994/55.45029. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.35775/55.38031. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.19492/55.31087. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.16182/55.25439. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.06847/55.17704. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.09698/55.11784. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.01776/55.06160. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 59.88728/54.99918. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.79782/54.91108. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 59.67094/54.84003. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.61843/54.78580. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.50738/54.71641. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.44497/54.68342. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.37678/54.61275. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.15674/54.55082. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 59.09377/54.49122. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.20166/54.45611. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.13675/54.35613. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.10583/54.31894. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.86938/54.22536. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 58.92638/54.22165. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.85400/54.13175. Took 0.34 sec\n",
      "Epoch 62, Loss(train/val) 58.72844/54.09688. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.71431/54.01278. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 58.57902/53.95476. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.66169/53.94888. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.53559/53.89791. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.54389/53.77873. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.30145/53.82547. Took 0.34 sec\n",
      "Epoch 69, Loss(train/val) 58.24893/53.74933. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 58.26275/53.79538. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.06190/53.73336. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.18945/53.70096. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.01979/53.71146. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 58.14833/53.63020. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 58.05076/53.60389. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.81479/53.57319. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 57.84221/53.62239. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.80809/53.60590. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 57.86874/53.54066. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.77168/53.58191. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 57.57444/53.52135. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 57.54753/53.57535. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 57.63728/53.61105. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.53962/53.47456. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.46986/53.64772. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.37942/53.61705. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.18937/53.64162. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.18356/53.63943. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.00498/53.67335. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.13830/53.58964. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.14131/53.55937. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.12544/53.69656. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.01120/53.51554. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 56.92534/53.64861. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.85149/53.62638. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 56.81125/53.80446. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.68521/54.17750. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.62865/53.97967. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.81379/53.81929. Took 0.32 sec\n",
      "ACC: 0.59375, MCC: 0.16323411311709218\n",
      "Epoch 0, Loss(train/val) 70.26348/70.14396. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.95927/70.00328. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.60261/69.83450. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.25989/69.63334. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.81129/69.38689. Took 0.34 sec\n",
      "Epoch 5, Loss(train/val) 68.38136/69.08849. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.84740/68.72276. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.26404/68.28693. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.58941/67.79665. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 65.84212/67.28260. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 65.09613/66.76695. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 64.18576/66.29219. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 63.35842/65.86425. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 62.59788/65.46033. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 61.93677/65.02770. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 61.15553/64.54156. Took 0.34 sec\n",
      "Epoch 16, Loss(train/val) 60.51967/64.09293. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 59.88253/63.65857. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 59.11331/63.24931. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 58.67734/62.95577. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 58.20963/62.76558. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 58.19335/62.63232. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 58.00918/62.52877. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 57.70180/62.45306. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 57.69833/62.39750. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 57.64516/62.34853. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 57.48617/62.30243. Took 0.34 sec\n",
      "Epoch 27, Loss(train/val) 57.55455/62.26379. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 57.43950/62.22884. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 57.36853/62.19447. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 57.30684/62.16434. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 57.15154/62.13291. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 57.20647/62.10317. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 57.21101/62.07377. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 57.02723/62.05157. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 57.11534/62.03183. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 56.89858/62.01035. Took 0.34 sec\n",
      "Epoch 37, Loss(train/val) 57.08245/61.99427. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 57.00931/61.97419. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 56.91832/61.95316. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 57.04205/61.93327. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 57.04177/61.91680. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 56.72390/61.89574. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 56.78636/61.87947. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 56.73837/61.86159. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 56.86322/61.84279. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 57.03471/61.82525. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 56.80334/61.80767. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 56.71322/61.79174. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 56.57794/61.77642. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 56.82227/61.76504. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 56.83733/61.75858. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 56.78248/61.74853. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 56.82799/61.74170. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 56.65896/61.73684. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 56.84573/61.73088. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 56.61808/61.71848. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 56.65379/61.71310. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 56.67671/61.69805. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 56.56750/61.67805. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 56.59020/61.65726. Took 0.34 sec\n",
      "Epoch 61, Loss(train/val) 56.65242/61.63995. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 56.54528/61.63144. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 56.53865/61.61555. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.66264/61.60341. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 56.56751/61.59594. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 56.62013/61.57986. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 56.70049/61.55219. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 56.45964/61.51561. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 56.45886/61.49995. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 56.44303/61.47050. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.46743/61.46156. Took 0.34 sec\n",
      "Epoch 72, Loss(train/val) 56.28738/61.43225. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 56.31359/61.41757. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 56.34896/61.41114. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.25964/61.38680. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 56.40701/61.34177. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.27486/61.27102. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 56.25481/61.17357. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 56.28686/61.14097. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 56.19319/61.04649. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.28977/60.96188. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.26317/60.90201. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.17419/60.79312. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.06422/60.73177. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 55.99625/60.59452. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 55.93563/60.49904. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.14312/60.43418. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.87872/60.40811. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.72957/60.33842. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 55.92060/60.25323. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 55.83226/60.17046. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 56.01194/60.14810. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 55.78318/60.09252. Took 0.34 sec\n",
      "Epoch 94, Loss(train/val) 55.74122/60.00819. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.74120/59.93128. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.54193/59.87566. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.67039/59.82837. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.51349/59.76635. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.72127/59.71357. Took 0.33 sec\n",
      "ACC: 0.4375, MCC: -0.1315903389919538\n",
      "Epoch 0, Loss(train/val) 69.76733/70.21696. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.52920/70.09511. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.37822/69.95967. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.14077/69.80656. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.94162/69.62984. Took 0.34 sec\n",
      "Epoch 5, Loss(train/val) 68.69256/69.41451. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.34715/69.16012. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.98273/68.84072. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.58364/68.43024. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.18210/67.92834. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.55558/67.32057. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.02631/66.67907. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 65.50403/66.10669. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.09643/65.74019. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 64.83915/65.48556. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.55387/65.32204. Took 0.34 sec\n",
      "Epoch 16, Loss(train/val) 64.41565/65.22971. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.02018/65.15695. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 63.94265/65.12177. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.83037/65.11289. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.50321/65.12912. Took 0.34 sec\n",
      "Epoch 21, Loss(train/val) 63.40672/65.17467. Took 0.34 sec\n",
      "Epoch 22, Loss(train/val) 63.22781/65.23923. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.14626/65.30771. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.99630/65.36759. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.80441/65.39278. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.65612/65.41785. Took 0.34 sec\n",
      "Epoch 27, Loss(train/val) 62.45264/65.44482. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.26439/65.47694. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.08551/65.49316. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.06537/65.51955. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 61.75822/65.53982. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.78902/65.58488. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.63732/65.64912. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.50900/65.71940. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 61.46698/65.78882. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.38985/65.83710. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 61.11114/65.89170. Took 0.34 sec\n",
      "Epoch 38, Loss(train/val) 61.20536/65.96847. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.99235/66.04491. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.03210/66.11735. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 60.84050/66.19288. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.64454/66.25033. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.68469/66.31053. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 60.60554/66.34806. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.51299/66.39490. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.36122/66.44761. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.17663/66.45649. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.27064/66.49383. Took 0.34 sec\n",
      "Epoch 49, Loss(train/val) 60.27576/66.50200. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 60.18261/66.53226. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.04939/66.57331. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.93174/66.56384. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.81054/66.58872. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.99587/66.61132. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 59.73823/66.60625. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.70991/66.62072. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.85281/66.63345. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.63331/66.63458. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 59.53557/66.64760. Took 0.34 sec\n",
      "Epoch 60, Loss(train/val) 59.59027/66.63921. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 59.46709/66.65337. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 59.50774/66.65550. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 59.40479/66.65800. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.35631/66.65166. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 59.28123/66.66867. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.33517/66.68198. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.22183/66.63225. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.16968/66.64999. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 59.07090/66.66339. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.07115/66.63911. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.92558/66.62569. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.92532/66.62215. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.98614/66.60339. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 58.77367/66.57898. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 58.86698/66.57870. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.66044/66.55170. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.67335/66.59744. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.71640/66.50307. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.67887/66.58281. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.90396/66.49583. Took 0.34 sec\n",
      "Epoch 81, Loss(train/val) 58.42907/66.58289. Took 0.34 sec\n",
      "Epoch 82, Loss(train/val) 58.73357/66.50463. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.37987/66.55800. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.45551/66.48239. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.36822/66.54125. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.42253/66.49184. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.27524/66.53459. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.41627/66.48264. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.13022/66.53165. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.30699/66.49561. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.19356/66.50220. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.06220/66.50780. Took 0.34 sec\n",
      "Epoch 93, Loss(train/val) 58.08981/66.47826. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.13055/66.45973. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.15782/66.39893. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.84347/66.34815. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.66433/66.24303. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.44335/66.13898. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.29843/66.00623. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.2104651171461688\n",
      "Epoch 0, Loss(train/val) 69.74095/70.32172. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.47386/70.23029. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.27719/70.13538. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 68.94101/70.03914. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.60861/69.94112. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.37187/69.83410. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.01681/69.71927. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.67169/69.59187. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.17136/69.45062. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.85275/69.29645. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.51723/69.13126. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.24671/68.96687. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 65.83618/68.80797. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.58549/68.65856. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.19476/68.51447. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.86578/68.37142. Took 0.34 sec\n",
      "Epoch 16, Loss(train/val) 64.65541/68.22099. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.30509/68.07025. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.85219/67.91534. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.72089/67.76827. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.48350/67.63132. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.14629/67.51749. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.69567/67.43874. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.64281/67.36986. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.44830/67.28425. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.13576/67.16690. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.00578/67.02047. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 61.60543/66.88286. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.76043/66.75665. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.25088/66.65836. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 61.41007/66.60656. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.24920/66.58196. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.11195/66.57747. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.03221/66.58070. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.05262/66.56909. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.86469/66.54177. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.00658/66.52038. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.96105/66.50397. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.81471/66.48895. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.68096/66.48551. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.74487/66.46739. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.64384/66.46013. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.54340/66.40603. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.56000/66.41387. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 60.40195/66.40341. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.42819/66.37883. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.59563/66.33334. Took 0.34 sec\n",
      "Epoch 47, Loss(train/val) 60.31986/66.27277. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.56130/66.20927. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.33505/66.18291. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.48694/66.14709. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.40384/66.09245. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.18991/66.11224. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.10600/66.15993. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.07641/66.13396. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.19321/66.15676. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.05698/66.14846. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.12695/66.18843. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.23857/66.27216. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.14476/66.27130. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.92653/66.28279. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.04477/66.22660. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.78123/66.24072. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.80289/66.27415. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.05903/66.28429. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.86018/66.27927. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.69641/66.31930. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.87393/66.33628. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.72740/66.35349. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 59.88594/66.36304. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.72216/66.37857. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.64663/66.39771. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.73224/66.37490. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.66509/66.33681. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.63764/66.33054. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.70773/66.32666. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.54053/66.30495. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.54514/66.34311. Took 0.34 sec\n",
      "Epoch 78, Loss(train/val) 59.46063/66.37564. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.57835/66.34285. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.37647/66.33884. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.34069/66.34096. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.50764/66.34411. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.27489/66.37411. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.24995/66.37850. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.56031/66.30782. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.16858/66.35597. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.29002/66.39567. Took 0.34 sec\n",
      "Epoch 88, Loss(train/val) 59.44291/66.44286. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.25443/66.43021. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.28903/66.37651. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.25522/66.30084. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.24026/66.36127. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 59.35430/66.34474. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.21493/66.38384. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.31180/66.32307. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.06438/66.31272. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.94614/66.32051. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 58.94490/66.33369. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.02956/66.32553. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: 0.035182987609823045\n",
      "Epoch 0, Loss(train/val) 70.37417/70.68500. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.93610/70.06897. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.44405/69.42285. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 68.92825/68.72258. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.43575/67.94593. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 67.88176/67.08601. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.20714/66.12852. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 66.48947/65.11383. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 65.78637/64.08198. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 65.03628/63.10307. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 64.40517/62.22292. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 63.63926/61.39961. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 62.97845/60.61883. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 62.33778/59.87565. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 61.69574/59.15999. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 61.04332/58.61121. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 60.41181/58.10788. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 59.71719/57.64173. Took 0.34 sec\n",
      "Epoch 18, Loss(train/val) 59.17812/57.20229. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 58.64799/56.74947. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 58.20044/56.30745. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 57.90541/55.90540. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 57.60809/55.55289. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 57.44379/55.25340. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 57.20501/54.99800. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 56.80508/54.78455. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 56.86896/54.61088. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 56.51401/54.47296. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 56.31222/54.35011. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 56.45558/54.26009. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 56.11250/54.16317. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 56.03028/54.06880. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 56.00297/53.99873. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 55.99544/53.96717. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 55.82653/53.88308. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 55.76551/53.75440. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 55.62837/53.72374. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 55.54370/53.59139. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 55.31557/53.52925. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 55.53880/53.46496. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 55.32559/53.34536. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 55.20177/53.32063. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 54.97464/53.23516. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 55.01557/53.17678. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 55.03590/53.13061. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 54.86355/53.07203. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 54.78399/53.05716. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 54.73358/52.83069. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 54.89909/52.71785. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 54.57395/52.86624. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 54.59450/52.43346. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 54.35317/52.44982. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 54.40027/52.52341. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 54.33401/52.40924. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 54.26291/52.41473. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 54.21876/52.34798. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 54.07230/52.26526. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 53.98101/52.38258. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 53.96398/52.22487. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 53.94649/52.14144. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 53.97492/52.28875. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 53.64796/52.33528. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 53.62851/52.11154. Took 0.34 sec\n",
      "Epoch 63, Loss(train/val) 53.59723/52.15843. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 53.69895/52.41686. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 53.66484/52.26505. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 53.44305/52.10134. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 53.54849/52.11818. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 53.51238/52.24760. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 53.43959/52.15908. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 53.48593/52.13342. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 53.43579/52.06109. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 53.29643/52.35810. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 53.34754/52.33313. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 53.24597/52.21790. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 53.33366/52.19348. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 53.28373/52.22167. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 53.17425/52.07139. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 53.14225/52.21215. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 53.21806/52.50338. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 53.21691/52.19364. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 53.08079/52.22790. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 52.96852/52.44781. Took 0.34 sec\n",
      "Epoch 83, Loss(train/val) 52.89084/51.87083. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 52.92264/52.11341. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 52.92783/52.19194. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 53.01798/52.14315. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 52.92824/52.14931. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 52.82140/52.08614. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 52.94410/52.30920. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 52.84981/51.80957. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 52.83525/51.98526. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 52.82559/52.37326. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 52.94507/52.00657. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 52.81846/52.04495. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 52.79646/52.05397. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 52.64936/51.93584. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 52.84504/52.09204. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 52.57497/51.98785. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 52.68779/51.81488. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.11968263863870991\n",
      "Epoch 0, Loss(train/val) 70.96286/69.74968. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.78626/69.65575. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.63444/69.56925. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.44785/69.47932. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.27382/69.38313. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.07780/69.27760. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.84200/69.16453. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.64503/69.04035. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.40355/68.91015. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.25050/68.77283. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.98448/68.62720. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.72821/68.47764. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.56859/68.32758. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.31740/68.17863. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 68.08870/68.03331. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 67.88685/67.88704. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 67.68914/67.74571. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.51378/67.60001. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.34623/67.46380. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.15161/67.32926. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.02382/67.19028. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.82241/67.05557. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.62737/66.91933. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.49933/66.78780. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.22506/66.65598. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.03964/66.52466. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.91412/66.39427. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 65.70011/66.26363. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.57932/66.13835. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.38722/66.02137. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.26899/65.90853. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.11740/65.80260. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.96110/65.70847. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.82267/65.60830. Took 0.34 sec\n",
      "Epoch 34, Loss(train/val) 64.67393/65.51499. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.62064/65.43177. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.40291/65.34600. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.29995/65.25376. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.11095/65.16010. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.02654/65.08298. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.05643/65.00477. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.03926/64.92343. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.90586/64.85905. Took 0.34 sec\n",
      "Epoch 43, Loss(train/val) 63.70665/64.78333. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.69828/64.68142. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 63.64021/64.61816. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.49507/64.56522. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.58053/64.47802. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.42473/64.44261. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.20097/64.39914. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.15944/64.32285. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.07266/64.26601. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.02884/64.19835. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.76199/64.19430. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.89036/64.16823. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.88067/64.14600. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 62.71078/64.14079. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.55799/64.11209. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.56729/64.03199. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.39344/64.11529. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 62.60655/63.99448. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.30434/64.10724. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 62.33212/63.95965. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.06212/64.08253. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.26313/63.83297. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.15445/64.05294. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.05004/63.86899. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 61.94860/63.98738. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 61.91489/63.85451. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.82532/63.94080. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.88930/63.80273. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.81098/63.89724. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.74722/63.68887. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.56963/63.90609. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.69958/63.65312. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 61.46202/63.86121. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.55581/63.72411. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.38608/63.77953. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.29184/63.70717. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 61.22431/63.73375. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.27532/63.65036. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 61.20495/63.75498. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.24446/63.57139. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.02983/63.75200. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.14336/63.57931. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.92969/63.73065. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.11383/63.59985. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.87172/63.60088. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.88569/63.47367. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 60.78331/63.53700. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.86263/63.45271. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.65248/63.53623. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.62002/63.44424. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.69562/63.62103. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 60.63608/63.26936. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 60.51764/63.67376. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 60.45984/63.21843. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.50169/63.65944. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.30725/63.25569. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.08310/63.63057. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.06362847629757777\n",
      "Epoch 0, Loss(train/val) 71.14885/69.59206. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.95462/69.49790. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.76126/69.40613. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.54598/69.31514. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.34081/69.22154. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.13924/69.12544. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.94822/69.02856. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.73849/68.93488. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.53974/68.84603. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.35452/68.74851. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.15733/68.65453. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.85921/68.55864. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.63521/68.46442. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.39798/68.36797. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.13893/68.27023. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 67.74789/68.16565. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.48975/68.05444. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.06433/67.93762. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 66.71066/67.80689. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.29464/67.67047. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 65.74632/67.52550. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.29471/67.37923. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.82249/67.24991. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.20253/67.14589. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.73358/67.03262. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.15481/66.89815. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.89243/66.77281. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.29052/66.60134. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.00896/66.48294. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.75421/66.37328. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.40607/66.29503. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.25350/66.23110. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.98098/66.17337. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.73693/66.11715. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.67651/66.04635. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.67740/65.96384. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.46853/65.87510. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.25091/65.79269. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.15201/65.71268. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.29456/65.61143. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.17069/65.52141. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.95019/65.40273. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.91217/65.27061. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.77691/65.21590. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.88367/65.14550. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.68575/65.06588. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.80566/65.00593. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 59.53556/64.95949. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.39711/64.87710. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.38451/64.81052. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.40988/64.75221. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.45745/64.73747. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.22869/64.72689. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.09351/64.68208. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.17187/64.62103. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 59.11331/64.62367. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.98426/64.52425. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.05472/64.49582. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.13066/64.40407. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.89473/64.38848. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.00414/64.32156. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.81191/64.21346. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.69388/64.21820. Took 0.34 sec\n",
      "Epoch 63, Loss(train/val) 58.65335/64.12380. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.43406/64.15740. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 58.42755/64.06697. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.61167/64.14893. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.55709/64.09169. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.42455/64.04662. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.31424/64.02635. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.27595/64.09169. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.27442/64.05688. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.10464/64.01296. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.29825/64.04559. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.24765/63.95065. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.09936/63.97527. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.96760/63.95423. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.08792/63.94044. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.15571/63.92286. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.80186/63.94426. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.01440/63.89574. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.92847/63.90795. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 57.76460/63.83958. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.75464/63.83922. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.88207/63.77008. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.67163/63.73260. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.59974/63.79603. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.56178/63.60533. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.66350/63.70458. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.57810/63.60501. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.34668/63.57555. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 57.32260/63.48419. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 57.23698/63.55189. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.11229/63.45449. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.31121/63.40557. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.04528/63.38594. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.23313/63.42544. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.06159/63.19117. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.13339/63.49104. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 56.90779/63.24570. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: 0.05004910343073324\n",
      "Epoch 0, Loss(train/val) 70.53889/71.05003. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.34225/70.90965. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.15462/70.76582. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.97486/70.61818. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.77914/70.46426. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.58243/70.29956. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.34681/70.12457. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.06569/69.93672. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.84036/69.73647. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.50077/69.52178. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.14916/69.29184. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.76705/69.05003. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.36021/68.78233. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.94828/68.48926. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.40163/68.16032. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.01610/67.78526. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.45332/67.35081. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.02255/66.83535. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.58617/66.26382. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.11149/65.64462. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.76017/65.05120. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.39490/64.54834. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.13249/64.14049. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.96119/63.82724. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.84659/63.58232. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 62.71284/63.37309. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 62.52960/63.17125. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.46183/62.98403. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 62.38669/62.80889. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.28091/62.66157. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.13602/62.53352. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.04946/62.40902. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.96135/62.30091. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 61.87302/62.19566. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.91299/62.10507. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 61.85148/62.01879. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.76307/61.94263. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.76028/61.86346. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.66356/61.79059. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.54118/61.72202. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.34371/61.66662. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.52050/61.61030. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.40628/61.56090. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.36152/61.52151. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.24014/61.47646. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.07103/61.42404. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.03385/61.38029. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.20713/61.33355. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.90474/61.27078. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.99069/61.21719. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.02709/61.17791. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.89530/61.12757. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.87802/61.08157. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.78060/61.01815. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.74473/60.98123. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.73368/60.93594. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.72353/60.90076. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.53913/60.86042. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.43974/60.82700. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.41220/60.79536. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.36690/60.78213. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.22813/60.74981. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.17509/60.73187. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.14365/60.71086. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.13533/60.68690. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 59.86914/60.66771. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.97861/60.63101. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.02199/60.62518. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.90024/60.62200. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.77926/60.61382. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.84429/60.61747. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.69217/60.59628. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.56744/60.60869. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.45779/60.56752. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.54266/60.52122. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.54534/60.48497. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.34647/60.41540. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.35879/60.37817. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.25099/60.35989. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.18780/60.32925. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.03318/60.27892. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.25847/60.28664. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.90580/60.23120. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.01792/60.18873. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.91839/60.13455. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.78292/60.08312. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.75568/60.06768. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.52179/60.04559. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.49894/59.96738. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 58.60912/60.00750. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.46989/59.82679. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 58.40847/59.91591. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.22441/59.91565. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.29451/59.78193. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.07652/59.83653. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.08555/59.70411. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.71801/59.80330. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.72637/59.80983. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.90422/59.74862. Took 0.34 sec\n",
      "Epoch 99, Loss(train/val) 57.81332/59.52166. Took 0.31 sec\n",
      "ACC: 0.46875, MCC: -0.17407765595569785\n",
      "Epoch 0, Loss(train/val) 71.55587/70.47993. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.40033/70.41444. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.19349/70.34671. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.99361/70.27128. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.85786/70.19227. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.66490/70.10276. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.49860/70.00121. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 70.32066/69.88765. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.12655/69.76069. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.88533/69.61792. Took 0.34 sec\n",
      "Epoch 10, Loss(train/val) 69.63999/69.46789. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.36174/69.31044. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.14779/69.14689. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.82792/68.99730. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.52625/68.86590. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.23402/68.74512. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.02542/68.64461. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.72270/68.55266. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.40327/68.44981. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 67.09388/68.34307. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 66.79814/68.23072. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.43788/68.11481. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.10328/67.98595. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.80164/67.84846. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.39110/67.69793. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.05911/67.57825. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.69085/67.46465. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.46364/67.35529. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.09575/67.27746. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.82995/67.22498. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.58553/67.17743. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.57077/67.10482. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.30364/67.00857. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.11155/66.91428. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.87969/66.81046. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.69400/66.68820. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.53714/66.53362. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.36931/66.41594. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.19151/66.30091. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.26353/66.16219. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.09512/66.00359. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.89195/65.88476. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.03142/65.77411. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.73463/65.70018. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.58170/65.59936. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.50471/65.44465. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.34527/65.28328. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.32625/65.22696. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.17463/65.10800. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.25296/64.97535. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.18906/64.90476. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.15934/64.84934. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.97660/64.75734. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.67390/64.67913. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 60.74285/64.64777. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.68911/64.55347. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.72484/64.43542. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.56281/64.38262. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.64379/64.32623. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.49809/64.19262. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.29488/64.04333. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.30487/64.09632. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.18521/64.03281. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.01392/63.85267. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.31014/63.75383. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.14750/63.67369. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 60.16905/63.73873. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.09359/63.61450. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.03834/63.58884. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.96992/63.45210. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.72995/63.47124. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.92472/63.42548. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.70283/63.51155. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.80024/63.36411. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.78005/63.30400. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.68622/63.28032. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.74037/63.31234. Took 0.34 sec\n",
      "Epoch 77, Loss(train/val) 59.64135/63.28355. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.44684/63.23344. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.55555/63.21661. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.37842/63.27976. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.54646/63.11353. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.49069/63.24891. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.18453/63.27207. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.28527/63.19679. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.19878/63.04768. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.32152/63.34077. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.01868/63.33793. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 59.12003/63.24214. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.14641/63.11196. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.16908/63.33400. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.18002/63.25701. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.90180/63.18276. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.95862/63.29635. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.80315/63.15857. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.91645/63.12221. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 58.98437/63.18593. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.86809/63.19687. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 58.84661/63.13252. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.81885/63.16489. Took 0.32 sec\n",
      "ACC: 0.609375, MCC: 0.21796176586341726\n",
      "Epoch 0, Loss(train/val) 70.44674/70.02827. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.31281/69.90591. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.19291/69.78308. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.01026/69.66141. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.85488/69.53616. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.72744/69.40390. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.56357/69.26833. Took 0.34 sec\n",
      "Epoch 7, Loss(train/val) 69.42681/69.13354. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.22765/68.98748. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.12988/68.84158. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.86252/68.69407. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.73126/68.54683. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.56253/68.39517. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.39292/68.24937. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.09428/68.10204. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.02043/67.95487. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.78343/67.81004. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.56027/67.66998. Took 0.34 sec\n",
      "Epoch 18, Loss(train/val) 67.29245/67.53138. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.11889/67.41286. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.82986/67.30603. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.63392/67.21490. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.36547/67.15211. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 66.04496/67.11459. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.80208/67.08425. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.59909/67.07212. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.39145/67.13467. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.08177/67.15910. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.87296/67.16272. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.81042/67.16627. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.55185/67.15507. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.40527/67.14780. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.20356/67.13586. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 64.22994/67.11565. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.98416/67.12526. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.87345/67.13355. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.63990/67.14148. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.79155/67.14756. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.65050/67.13052. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 63.59753/67.10788. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.45324/67.10871. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.43439/67.10588. Took 0.34 sec\n",
      "Epoch 42, Loss(train/val) 63.53903/67.07732. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 63.42050/67.04140. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 63.32742/67.03744. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 63.24986/67.02792. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.34793/67.02589. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 63.09733/66.98940. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 63.15138/66.99186. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 63.14129/66.95413. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.99983/66.91035. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 63.06403/66.89062. Took 0.34 sec\n",
      "Epoch 52, Loss(train/val) 63.01545/66.84111. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.06201/66.80434. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.10826/66.78312. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 63.05469/66.74503. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 62.92269/66.71288. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.83483/66.68931. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 62.78980/66.64178. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.73635/66.61379. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 62.87280/66.55440. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.71493/66.52856. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 62.78376/66.48458. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 62.80918/66.45656. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.65673/66.38702. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.51136/66.40213. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 62.57678/66.65347. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.37852/66.71690. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.57845/66.53519. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 62.45553/66.64757. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.29091/66.58852. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 62.26675/66.62146. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 62.45961/66.49862. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 62.37496/66.44489. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.17197/66.45606. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.13905/66.41785. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.34977/66.26905. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 62.10584/66.25974. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.18991/66.36200. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.23255/66.21954. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.04362/66.33840. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 62.07504/66.24821. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.98076/66.37135. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 61.87987/66.15940. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 61.94910/66.13568. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.98781/66.17734. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 61.80991/66.13709. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 61.74214/66.11687. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.99131/66.15688. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.75928/66.06297. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.78353/66.06948. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 61.70627/66.11388. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 61.58497/66.03933. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.71453/66.05804. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 61.51439/65.90382. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 61.62329/66.20732. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 61.61877/65.66748. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 61.56239/66.15147. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 61.52339/65.69403. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.50952/66.19492. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.08006407690254357\n",
      "Epoch 0, Loss(train/val) 70.40419/70.97867. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.11069/70.68758. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.90194/70.39116. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.69421/70.08224. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.44341/69.76323. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.23455/69.42546. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.91698/69.07364. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.71758/68.70513. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.49822/68.31556. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.13423/67.90013. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.83170/67.44646. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.41453/66.94152. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.06804/66.39546. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.71991/65.83911. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.28689/65.35310. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.00914/64.97121. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.68339/64.62437. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.33206/64.31281. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.12656/64.03155. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.83988/63.76723. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.62755/63.50698. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.45750/63.26466. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.27397/63.04316. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.11451/62.83347. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.01472/62.63425. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.83015/62.44489. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.73069/62.26715. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.58127/62.10275. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.67325/61.95511. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.47120/61.81658. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.16243/61.68379. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.19596/61.55483. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.07285/61.42955. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.97311/61.32152. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.90538/61.18724. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.85599/61.09121. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.78069/60.95595. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.56197/60.83508. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.44891/60.74984. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.53894/60.62810. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.41659/60.51369. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.54849/60.41022. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.58136/60.34563. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.49533/60.15782. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.15492/60.13223. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 62.29906/59.97773. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 62.06334/59.98075. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.92479/59.73102. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 62.10011/59.79577. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.03629/59.65571. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.91087/59.68066. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.82786/59.47153. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.94838/59.56955. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.77258/59.35097. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.67898/59.37623. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.77105/59.37457. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.55218/59.29079. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.70364/59.26688. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.44336/59.12947. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.56712/59.13266. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.40935/58.92303. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.55927/58.92486. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.46621/58.78120. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.23142/58.87365. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.42845/58.67665. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 61.29476/58.68774. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.29273/58.67262. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.27324/58.58326. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.28052/58.57537. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 61.13476/58.46493. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.94223/58.44604. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.97598/58.50850. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.90698/58.38180. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.75660/58.37364. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.90385/58.24123. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.92018/58.27016. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.73226/58.20229. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.76975/58.14715. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.74795/58.17136. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.59614/58.14307. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.73576/58.10689. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.61189/58.10894. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.52268/58.03910. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 60.61883/58.07732. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.58340/58.00857. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.67790/58.01126. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.35706/58.02357. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 60.44309/57.96939. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.44205/57.94518. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.22888/57.94943. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.22417/57.92554. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.41565/57.90104. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.30790/57.86194. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 60.28948/57.91800. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.10634/57.88604. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.20278/57.80875. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.05513/57.84026. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.06070/57.88039. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.95529/57.92560. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.83523/57.78294. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.046373889576016826\n",
      "Epoch 0, Loss(train/val) 71.61759/70.97041. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.40294/70.61082. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.22349/70.26340. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 71.02663/69.95065. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.86155/69.67166. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.69788/69.42258. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 70.53996/69.20018. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.38836/68.99986. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 70.24656/68.81676. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 70.11918/68.64523. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 70.01741/68.47920. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.87600/68.31640. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.76278/68.15498. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.59585/67.99177. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 69.45982/67.82147. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.34794/67.64906. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 69.23561/67.47853. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 69.06792/67.30228. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 68.89166/67.12920. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.69326/66.96084. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 68.46152/66.79076. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 68.36691/66.62212. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 68.13539/66.45814. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.79785/66.29431. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 67.55855/66.12080. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 67.34411/65.94754. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 67.05826/65.77156. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 66.86293/65.58652. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 66.54040/65.39467. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 66.21355/65.19713. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.88592/64.98963. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.64483/64.79578. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.27790/64.64019. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.88011/64.51204. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.56421/64.39015. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.28069/64.26598. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 63.94971/64.13268. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.59606/64.01477. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.46151/63.91657. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.22768/63.80698. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.01357/63.70087. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.58719/63.58115. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.67483/63.46122. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.32265/63.34541. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.23446/63.24059. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.12068/63.14332. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.96493/63.04077. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.69876/62.93333. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.67877/62.81676. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.59111/62.68615. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.31522/62.54667. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.08268/62.43111. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.83391/62.38453. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.83608/62.33211. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 60.64538/62.28394. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.31824/62.25029. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.42177/62.25010. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.15252/62.22909. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.92333/62.21456. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.87610/62.21986. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.90095/62.16795. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.83337/62.08824. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.58698/62.04187. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.47806/61.94713. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 59.30210/61.87744. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.38439/61.74900. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.12845/61.62863. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.13554/61.54527. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 58.84690/61.47976. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.69572/61.40865. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.78749/61.34398. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.56482/61.29514. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.47731/61.31272. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.38522/61.26024. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.42653/61.19817. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 58.37630/61.18342. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.32749/61.13894. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 58.11473/61.07747. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.23257/61.09901. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.10802/61.06706. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.15494/61.07404. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.18554/61.00040. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.76934/60.98716. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.05256/61.00350. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.82942/60.94050. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.81121/60.96627. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 57.71067/60.91165. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.72553/60.91095. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 57.61954/60.88070. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 57.41545/60.87607. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 57.38551/60.85757. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.41528/60.85853. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.50063/60.81109. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.46346/60.81078. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.38104/60.84366. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 57.33508/60.79882. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.29322/60.75768. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.29271/60.72355. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.01834/60.73286. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.08521/60.72902. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.02421797398482414\n",
      "Epoch 0, Loss(train/val) 71.12313/70.62668. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.05165/70.53342. Took 0.34 sec\n",
      "Epoch 2, Loss(train/val) 70.96641/70.43966. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.85237/70.33911. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.78010/70.24260. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.68626/70.15438. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 70.60462/70.05750. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.56383/69.95534. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 70.41203/69.84582. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 70.32601/69.72572. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 70.16193/69.59769. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 70.06866/69.45871. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 69.96907/69.31220. Took 0.34 sec\n",
      "Epoch 13, Loss(train/val) 69.79952/69.14833. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 69.61918/68.95181. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 69.48583/68.72449. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 69.27934/68.45928. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 69.05595/68.12549. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.79893/67.75978. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 68.40302/67.42941. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 68.19365/67.23566. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 68.06402/67.12341. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.81743/67.07389. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 67.54766/67.01943. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 67.50711/66.98441. Took 0.34 sec\n",
      "Epoch 25, Loss(train/val) 67.45760/66.94093. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 67.36942/66.84077. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 67.21130/66.73920. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 67.08818/66.67558. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 67.06813/66.60542. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.93464/66.57885. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 66.75718/66.50928. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 66.80624/66.42556. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 66.66296/66.37764. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 66.57091/66.32454. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 66.53574/66.13645. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 66.36380/66.02567. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 66.27834/65.93818. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 66.22766/65.84753. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 66.19266/65.73592. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 66.06928/65.61272. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 66.12360/65.45515. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 65.82453/65.23888. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 65.77594/65.04876. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 65.73744/65.00764. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 65.64400/64.85040. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 65.52675/64.53097. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 65.50310/64.36597. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 65.18846/64.36739. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 65.12269/64.30257. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 65.10824/64.11920. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 64.83423/63.98920. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 64.86963/64.05125. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 64.79263/63.91425. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 64.63001/63.83131. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 64.47394/63.67057. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 64.44316/63.55163. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 64.24119/63.53728. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 64.32627/63.38155. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 64.08522/63.34222. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 63.93326/63.20482. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 63.85891/63.19273. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 63.79900/63.07582. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.60513/62.96340. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.60589/62.59700. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.64865/62.25532. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 63.38376/62.83398. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 63.28577/62.78518. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 62.94341/62.57871. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.92745/63.27467. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.66774/63.38256. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 62.47549/63.44816. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.11335/63.25765. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.08837/63.12928. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 62.12413/63.58762. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.75119/64.17431. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 62.03717/63.08265. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 61.49357/62.94386. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 61.42683/62.33128. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 61.49025/64.25816. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.44898/64.21462. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.56939/61.81718. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.59675/61.89968. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 62.07187/61.84083. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 61.37213/63.63030. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 61.25060/63.53254. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 61.22721/61.72896. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.52872/62.81141. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.60019/62.24935. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.67640/61.61574. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.38686/62.49162. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.43809/62.66450. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.28530/61.37234. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.19513/61.54528. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.10256/61.61405. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 60.39237/61.50203. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.92295/61.54211. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 59.90313/61.66557. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.74755/61.57928. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.72568/61.39813. Took 0.32 sec\n",
      "ACC: 0.421875, MCC: -0.14379213277409608\n",
      "Epoch 0, Loss(train/val) 69.67011/69.34572. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.49276/69.18894. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.27018/69.02142. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.07395/68.85039. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.84662/68.67696. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.65093/68.49329. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.38270/68.30228. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.10789/68.10844. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.79771/67.90494. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.45202/67.69239. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.01730/67.45761. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.49638/67.19308. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.98327/66.90484. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.32693/66.58792. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.36511/66.26143. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 63.46323/65.97102. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 62.91998/65.75088. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.36763/65.66406. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 62.29075/65.63380. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 61.77569/65.60511. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 61.78250/65.57792. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.68956/65.54170. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.62633/65.51428. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.32898/65.47873. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.39840/65.43420. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 61.37275/65.37720. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 61.23627/65.31371. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 61.08193/65.24284. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.06730/65.18355. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.08906/65.12696. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 61.01736/65.06744. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.81204/64.99929. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.89441/64.93187. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.55864/64.86625. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.67753/64.79266. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.52661/64.70892. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.47159/64.66149. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.40844/64.62369. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.35067/64.53671. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.32502/64.51851. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.24997/64.48989. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.01761/64.45887. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.99124/64.42523. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.88743/64.38020. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.93145/64.36229. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 59.92842/64.33503. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 59.87059/64.29069. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.72005/64.27412. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.80017/64.25521. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.54861/64.24281. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.58142/64.22792. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.53601/64.21690. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.51420/64.18219. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.45446/64.16222. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.35188/64.14371. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.39237/64.09682. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.30009/64.06474. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.24591/64.01131. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.06483/63.96727. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.08417/63.94030. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.05800/63.89021. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 59.07393/63.86670. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.87169/63.81511. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.96735/63.79086. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.79507/63.75121. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.81786/63.71032. Took 0.34 sec\n",
      "Epoch 66, Loss(train/val) 58.81391/63.69001. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.85663/63.60028. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.66903/63.59209. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.68118/63.54693. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.62840/63.51544. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.69109/63.48454. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.58525/63.43263. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.60067/63.36705. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.33267/63.34631. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.36772/63.24895. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.39489/63.24058. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 58.43865/63.15274. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.17577/63.10337. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.27810/63.04554. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.18764/63.02279. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.17462/63.04816. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.01663/62.94003. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.92860/62.88681. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.91414/62.86755. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.82329/62.82230. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.82940/62.77092. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.88527/62.80446. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.76366/62.70152. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.71189/62.81541. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.81284/62.85509. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 57.66107/62.75747. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.66981/62.51637. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.40351/62.38137. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.53400/62.52551. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.58488/62.64565. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.45025/62.50490. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.38726/62.17842. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.30264/62.18432. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.33023/62.24755. Took 0.32 sec\n",
      "ACC: 0.390625, MCC: -0.3164569837245282\n",
      "Epoch 0, Loss(train/val) 70.13177/71.53074. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.95391/71.27493. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.80063/71.01928. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.59279/70.74860. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.33709/70.46185. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.10978/70.16427. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.84514/69.84140. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.55787/69.48418. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.27410/69.08565. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.79115/68.63708. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.34468/68.12244. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.72743/67.52485. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.23589/66.84921. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.67671/66.10113. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.20291/65.29362. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.85605/64.58260. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.44020/64.05097. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.39499/63.70900. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.23343/63.50340. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.10066/63.33924. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.93088/63.20007. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.86267/63.07564. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.91245/62.96490. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.78663/62.86819. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.76889/62.77851. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.60872/62.69309. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.58856/62.61539. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.67583/62.54850. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.44615/62.48278. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.47941/62.42001. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.43275/62.36037. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.41574/62.30474. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.37768/62.25369. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.31732/62.20662. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.40013/62.15879. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.35528/62.11058. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.12352/62.06664. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.16785/62.02487. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.21451/61.98387. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.14042/61.94458. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.18121/61.90630. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.05608/61.86458. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.12194/61.82442. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.17769/61.78427. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.08993/61.74722. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.93069/61.71210. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 63.08187/61.67938. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 63.05924/61.64689. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 62.76848/61.61220. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.99789/61.57855. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.92782/61.54310. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.87520/61.50395. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.94598/61.46489. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.94280/61.41716. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 62.82164/61.36768. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 62.86979/61.30323. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 62.76824/61.27444. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.58249/61.36736. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.60972/61.55322. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.53181/61.37173. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.43390/61.34547. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.45540/61.23944. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 62.27465/61.16220. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 62.20628/61.09438. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.27709/60.99976. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.14435/60.91990. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.11518/60.85496. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.16324/60.83372. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 62.13277/60.77740. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 62.04493/60.75353. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.97875/60.71827. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.79214/60.60895. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.08648/60.59983. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.01609/60.48872. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.83226/60.49634. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.84600/60.42836. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 61.65251/60.42645. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.68307/60.37817. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.60794/60.27048. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.68751/60.36765. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.72020/60.21618. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.66197/60.35583. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 61.58005/60.23604. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 61.68649/60.27045. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.57720/60.27803. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.56818/60.15892. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.61738/60.24315. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 61.46961/60.30581. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.52685/60.30388. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.50273/60.25620. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.42181/60.34615. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.42437/59.79887. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 61.62713/60.28775. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.42732/60.33342. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.26845/60.40238. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.25241/60.26954. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.32039/60.23475. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.19177/60.20807. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 61.28504/60.22029. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.39027/60.17827. Took 0.32 sec\n",
      "ACC: 0.375, MCC: -0.20513587275572404\n",
      "Epoch 0, Loss(train/val) 70.77781/72.36675. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.59316/72.30540. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.40372/72.24376. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.24523/72.18529. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.06498/72.12195. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.89204/72.05523. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.68962/71.98479. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.50363/71.90981. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.31698/71.82732. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.02866/71.73834. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.88198/71.64653. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.59192/71.55550. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 68.40078/71.46550. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.14735/71.37337. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.98758/71.27103. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.83371/71.16582. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.57809/71.05354. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.41778/70.93391. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 67.19395/70.80492. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.97239/70.66653. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.88442/70.52233. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.54066/70.36071. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.23662/70.18839. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.99479/70.00848. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.78476/69.82827. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.44081/69.65903. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.12057/69.48987. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.07607/69.33020. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.81512/69.18238. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.70034/69.05444. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.57701/68.92638. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 64.54355/68.80824. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.38961/68.69028. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.01871/68.56706. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.01571/68.46812. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.90213/68.37270. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.67972/68.29168. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.64655/68.22753. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.63206/68.18024. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.38055/68.12885. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 63.36804/68.07098. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.35970/68.00746. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.29503/67.98585. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 63.10027/67.90317. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.95165/67.88501. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.06572/67.85249. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.97226/67.84412. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.88467/67.79623. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.71649/67.77272. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.76413/67.74590. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.69366/67.69394. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.70282/67.65919. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.52165/67.62289. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.38502/67.56012. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.30632/67.51935. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.37833/67.48695. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.30827/67.44402. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.20725/67.38168. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 62.10975/67.34330. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.09089/67.23551. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.03705/67.18506. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.90373/67.11867. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.79458/67.05257. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.86189/66.98049. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.67144/66.92167. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 61.61614/66.87312. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.57921/66.83278. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 61.55716/66.74517. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.53267/66.54919. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.32414/66.65508. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 61.58944/66.53147. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.40642/66.55649. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.46954/66.47997. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.22290/66.36473. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.29169/66.46861. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.14322/66.28766. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.98659/66.02950. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 61.20375/66.23282. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.20359/66.03044. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.08718/66.20413. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.12312/66.15872. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 61.10017/66.20474. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.11797/65.96922. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.08911/65.96005. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.28284/65.94296. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.06352/65.93108. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.04965/65.73412. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.66808/65.76239. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.88138/65.54760. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.78601/65.97664. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.04795/65.72986. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.89647/65.72270. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.55059/65.72471. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 60.66559/64.95043. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.37918/66.02916. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 60.66125/64.86920. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.36014/65.90646. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.30576/65.24387. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.05236/65.73680. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.30430/65.35420. Took 0.32 sec\n",
      "ACC: 0.65625, MCC: 0.3443866451575199\n",
      "Epoch 0, Loss(train/val) 70.29726/70.93108. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.08036/70.86463. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.83886/70.79926. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.65814/70.72502. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.46500/70.64180. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.24744/70.54173. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.98504/70.42479. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.92358/70.28551. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.65840/70.13950. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.47041/69.96892. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.13999/69.78085. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.90605/69.57788. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.68553/69.36563. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.35784/69.13224. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.07989/68.89753. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.74477/68.66721. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.36566/68.45088. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.07287/68.27187. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 65.79255/68.09464. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.48679/67.96100. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.16361/67.88376. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.05937/67.82765. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.65537/67.80515. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.59262/67.77908. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.26449/67.76405. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.10809/67.73351. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.98725/67.70060. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.87415/67.66025. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.67957/67.61523. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.56176/67.60076. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.41655/67.56359. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.43271/67.57737. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.32758/67.60088. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.18920/67.56408. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.11789/67.57452. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.86780/67.63797. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.89365/67.65726. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.97448/67.65080. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.80651/67.65620. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.76562/67.70209. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.65286/67.75495. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.54842/67.76965. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.61080/67.79430. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.54498/67.84074. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.49820/67.90955. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.38345/67.96162. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.41247/67.96500. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.37988/67.95458. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.17013/67.97103. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 62.26853/68.03146. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.06586/68.05801. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.05463/68.09303. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.90893/68.15458. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.06836/68.21341. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.90577/68.24088. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 61.85047/68.26003. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.82924/68.27703. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.58531/68.31837. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.69951/68.40602. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 61.67360/68.49124. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.61745/68.51181. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 61.49943/68.56231. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.53258/68.62559. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.57990/68.68841. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.37618/68.78416. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.43019/68.85974. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.20818/68.87624. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.23908/68.91026. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 61.22307/68.98302. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.20198/69.00414. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.09668/69.03917. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.10881/69.11074. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.06248/69.13746. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.00057/69.16260. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.02790/69.18356. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.88612/69.21515. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.81243/69.25675. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 60.81571/69.25902. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 60.71249/69.31713. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.78920/69.35368. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.69373/69.37133. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.52867/69.40589. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.49387/69.42702. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 60.39728/69.46358. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.52045/69.55909. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.47079/69.52307. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.40015/69.54896. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.28073/69.52435. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 60.18846/69.53986. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.13273/69.54157. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.07781/69.59975. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.20566/69.54591. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.16868/69.52646. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.09994/69.56082. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.97701/69.64984. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.97020/69.62117. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.96069/69.61980. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.94457/69.48963. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 59.84888/69.56097. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 59.70580/69.52342. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.16274554347394107\n",
      "Epoch 0, Loss(train/val) 70.24865/69.81639. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.89281/69.42358. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.60312/69.03719. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.32936/68.65231. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.02230/68.26584. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.66550/67.86476. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.34233/67.44347. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.00730/67.01311. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.60825/66.56185. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.18812/66.07759. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.83173/65.56599. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.41991/65.03891. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.01356/64.49883. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.73952/63.99936. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.28175/63.53510. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.98883/63.07047. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 64.50349/62.60130. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.23668/62.13978. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.95505/61.69187. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.57084/61.25709. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.21203/60.84771. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.01639/60.48614. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.62239/60.15460. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.49953/59.86072. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.14945/59.63868. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.93474/59.45197. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.78487/59.31256. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.64540/59.20751. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.37495/59.14886. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.37328/59.09538. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.20471/59.03524. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.16842/58.97171. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.93838/58.92835. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.87463/58.89807. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.86534/58.86731. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.69165/58.83644. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.95452/58.81063. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.60357/58.78578. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.69435/58.77536. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.35173/58.76114. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.51150/58.75645. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.40139/58.76375. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.42284/58.77018. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.51802/58.75449. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.21397/58.75306. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.25445/58.77338. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.22737/58.79941. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.11262/58.78281. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.21696/58.81082. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.08353/58.81582. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.01113/58.83323. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.12063/58.86372. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.01657/58.86889. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 59.99997/58.82654. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.83802/58.79945. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.98534/58.78593. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.87502/58.76475. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.79731/58.77451. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.93181/58.78800. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 59.63893/58.78746. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.90300/58.77017. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.79404/58.79496. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.72567/58.82161. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.65089/58.79200. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 59.75388/58.76917. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 59.57043/58.79974. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.56568/58.80096. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.52081/58.77382. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.33478/58.75102. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.51020/58.74808. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.54889/58.74272. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.30357/58.75359. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.44198/58.78566. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.34769/58.81467. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.22854/58.78182. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.33617/58.82745. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.20891/58.85007. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 59.11883/58.80101. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 59.29720/58.75500. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.31308/58.73526. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.16412/58.68208. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.97601/58.69077. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.95027/58.72449. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.03593/58.67841. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.19560/58.62880. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.05271/58.62061. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.90263/58.67057. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.08278/58.61516. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.98037/58.51737. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.09188/58.50780. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.88737/58.49414. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.95278/58.53236. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.78397/58.53672. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.73232/58.47212. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.73551/58.39999. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.88465/58.41049. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.63276/58.42682. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.84487/58.37683. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.60660/58.36125. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.72472/58.31372. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.21039790769253672\n",
      "Epoch 0, Loss(train/val) 70.35652/69.79348. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.10577/69.59742. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.90058/69.38802. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.68960/69.16854. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.46877/68.93051. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.24299/68.67481. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.97432/68.40081. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.73728/68.10556. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.39385/67.78396. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.13198/67.44588. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.83143/67.10461. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.39392/66.75232. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.04600/66.39413. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.70103/66.04754. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.28584/65.72095. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.03202/65.42077. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.67764/65.16029. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.42433/64.93511. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.18933/64.72777. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.96037/64.55960. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.85930/64.42492. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 64.58577/64.31985. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.44284/64.24068. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.36579/64.16588. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 64.13991/64.09692. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 64.03749/64.05017. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.80022/64.00459. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.78676/63.95898. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.47195/63.92088. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.50974/63.90487. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.29781/63.91230. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.18618/63.92599. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.14765/63.93520. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 63.06999/63.90953. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.84610/63.89634. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.55706/63.85301. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.55877/63.82865. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.45251/63.79438. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.38416/63.77789. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.20083/63.78161. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.00869/63.72791. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.07483/63.68700. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.88850/63.71021. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.63838/63.56712. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.56655/63.44728. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.43454/63.37584. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.27024/63.31573. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.25113/63.22152. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.04019/63.14017. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.05680/63.02676. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.98618/62.96592. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.83460/62.93921. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.92464/62.88949. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.89440/62.77098. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.76495/62.75080. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.80798/62.59817. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.56262/62.54855. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.61012/62.63220. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.59718/62.59131. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.48839/62.50318. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.52753/62.44314. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.39258/62.37817. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.40375/62.40594. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.40217/62.40557. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.32188/62.33345. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.25786/62.37051. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.02750/62.31031. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.12369/62.27689. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.12397/62.21667. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.02398/62.11333. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.97074/62.11995. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.97081/62.11681. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.85812/62.02268. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.99282/61.99050. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.86537/61.96658. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.87494/61.94920. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 59.72309/61.94365. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.67195/61.87358. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.65061/61.89501. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.47076/61.81640. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.50003/61.75931. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.43755/61.68193. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.48553/61.50558. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.33009/61.58927. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.08841/61.54671. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.30100/61.43353. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.15666/61.35641. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.94725/61.35694. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.04785/61.18821. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.98123/61.16024. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.90796/61.19241. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.97375/61.12979. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.94332/60.95263. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.59762/60.98763. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.56541/60.93423. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.59689/60.72027. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.58409/60.69916. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.66189/60.76295. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.36618/60.81264. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.34446/60.80105. Took 0.33 sec\n",
      "ACC: 0.4375, MCC: -0.1868706368604627\n",
      "Epoch 0, Loss(train/val) 70.05494/69.78521. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.75581/69.65227. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.45439/69.53561. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.22524/69.44311. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.95567/69.35828. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.75262/69.26530. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.51032/69.16703. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.27966/69.06829. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.07032/68.96706. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.89749/68.84070. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.72524/68.70454. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.54083/68.56540. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.47649/68.41963. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.23336/68.25965. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.19828/68.09265. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.93782/67.91276. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.78335/67.71412. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.54978/67.50701. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.38091/67.28311. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.14169/67.04095. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.04129/66.78584. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.83784/66.50333. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.72207/66.20453. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.56977/65.88553. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.27257/65.54779. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.13830/65.19939. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.90213/64.84191. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 64.67363/64.48661. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.65144/64.14709. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.28589/63.82810. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.20037/63.53607. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.97665/63.29992. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.81183/63.07693. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.65502/62.86915. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.45298/62.66886. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.44503/62.48670. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.28581/62.32209. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.25161/62.16116. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.93319/62.00765. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.91175/61.89604. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.77235/61.79342. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.64700/61.70223. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.62092/61.61263. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.53047/61.52638. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.39870/61.43821. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.35930/61.33363. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.17579/61.22562. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.13665/61.14950. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.08839/61.08252. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.04625/61.00182. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.87903/60.93545. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.83546/60.86764. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.84778/60.79577. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.67204/60.73582. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.57544/60.65257. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.48351/60.57959. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.39357/60.51723. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.35523/60.44131. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.18553/60.37206. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.23742/60.27615. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.01596/60.22101. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.87044/60.15502. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.86331/60.08437. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.83985/60.05804. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.70141/59.95639. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.63028/59.91108. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.52617/59.88563. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.56921/59.78303. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.40172/59.80994. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.31149/59.67929. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.33791/59.64730. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.30015/59.59264. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.05664/59.47242. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.03043/59.51111. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.88655/59.30970. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.89321/59.31986. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.81993/59.19508. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.88386/59.10186. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.73328/59.14254. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.72640/59.09659. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.68742/59.00426. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.55218/59.00809. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.43823/59.00473. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.48250/59.04656. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.25863/59.06600. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.47408/59.08139. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.17590/59.10028. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.11159/59.06629. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.32814/59.28022. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.13604/58.89239. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.14610/58.99386. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.71051/59.08510. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.82647/59.08455. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.64786/58.93452. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.95089/59.18669. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.61005/58.58403. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.08511/59.45758. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 58.84271/58.58464. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.81848/59.23558. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.73361/58.52528. Took 0.33 sec\n",
      "ACC: 0.578125, MCC: 0.08921796698522012\n",
      "Epoch 0, Loss(train/val) 70.99464/69.97289. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.73095/69.86050. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.47493/69.73351. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.26532/69.59231. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.95483/69.44015. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.67015/69.26876. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.34395/69.08424. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.00567/68.88238. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.68645/68.66141. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.22535/68.42073. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.91403/68.15515. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.51683/67.86756. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.17275/67.54945. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.67313/67.20253. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.28383/66.82709. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.83295/66.44472. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.36901/66.04778. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.86630/65.63250. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.46079/65.22604. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.13480/64.82983. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.69197/64.43302. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.28659/64.02357. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.90546/63.62034. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 62.51327/63.22445. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.20899/62.82297. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 61.85986/62.43401. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 61.43446/62.06469. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.06823/61.73587. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.99153/61.47357. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.63266/61.26281. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.57837/61.08212. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 60.27694/60.91055. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.23674/60.77015. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.04871/60.62839. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.89483/60.48216. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.70610/60.31228. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.62653/60.23486. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.45840/60.20483. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.38276/60.20298. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.32592/60.27226. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.24679/60.32415. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.19252/60.30066. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.90626/60.32235. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.91553/60.34194. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.70086/60.41209. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 58.88703/60.46823. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.70212/60.44577. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.66947/60.48685. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 58.40427/60.63643. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.34321/60.61154. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 58.35506/60.75912. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 58.31909/60.76051. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.29139/60.87691. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.22132/60.87753. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.01482/60.95765. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.05671/61.00009. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.93966/60.98512. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.92915/61.05493. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.79863/61.12766. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.98163/61.09004. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.85006/61.02361. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.74597/61.10156. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.52415/61.19909. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.66495/61.06897. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.75684/61.25741. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.67271/61.06499. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.63632/61.17631. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.45083/61.22335. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 57.56304/61.24029. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.37429/61.16683. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.33040/61.28456. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.25186/61.12592. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 57.15144/61.15392. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.16019/61.06487. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.30787/61.14829. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.30314/61.05968. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.09622/61.11823. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.02757/61.01857. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.29622/61.16307. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.06714/60.96058. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.88345/61.06793. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.86525/61.07074. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.06994/61.04875. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 56.99752/60.98334. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.89388/61.02530. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.98662/60.95930. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.82676/61.02440. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.97625/60.81911. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.88457/61.01313. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.78812/61.02108. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 56.65344/60.87020. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.71488/60.91389. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.74374/60.87915. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.76822/60.86858. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 56.61102/60.80081. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.63150/60.74858. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.71616/60.94255. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.51803/60.78174. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.61144/60.78793. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.41095/60.76717. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.13966885537786003\n",
      "Epoch 0, Loss(train/val) 69.80725/70.09318. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.54065/69.90411. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.32789/69.69293. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.01519/69.44819. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.66350/69.15644. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.30912/68.81168. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.99901/68.41869. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.57099/67.97377. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.02846/67.48988. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.71762/66.98531. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.34837/66.47150. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.85073/65.95641. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 65.54370/65.45089. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.03892/64.98351. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.71727/64.55842. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.34116/64.18456. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.07190/63.85940. Took 0.30 sec\n",
      "Epoch 17, Loss(train/val) 63.87286/63.57588. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.56372/63.32980. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.40394/63.11324. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.24569/62.93009. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.06328/62.77769. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.03296/62.64591. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.88763/62.53078. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.75573/62.43077. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.75254/62.35180. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.49955/62.28344. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.31776/62.21709. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.41526/62.15385. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.36874/62.09920. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.14596/62.04134. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.32179/61.98717. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.18109/61.94735. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.13273/61.89167. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.09196/61.81936. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.06856/61.76473. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.06169/61.72416. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.06706/61.70728. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.00953/61.68204. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.81589/61.64516. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.76877/61.60392. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.67675/61.55560. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.92173/61.50369. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.77695/61.46006. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.68359/61.38171. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.74867/61.30535. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.44092/61.26818. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.34859/61.27477. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.46622/61.23820. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.29896/61.27620. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.29680/61.32176. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.38965/61.32293. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.29742/61.33336. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.39114/61.35793. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.27232/61.35753. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.37168/61.37558. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.14698/61.40511. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.27981/61.41204. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 61.07648/61.43120. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.18901/61.44183. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.05646/61.46484. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.18504/61.48387. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.13157/61.49436. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.14355/61.50230. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.05724/61.50608. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.96098/61.51538. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.99674/61.50973. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.97339/61.54186. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.03677/61.51207. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.88265/61.56794. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.86268/61.55289. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.03734/61.59208. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.94209/61.59886. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.96154/61.60541. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.86142/61.64378. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 60.70737/61.60548. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.91899/61.65861. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.65876/61.66173. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 60.69470/61.69304. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.70614/61.67157. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.57252/61.71051. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.55907/61.73934. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.84325/61.75285. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 60.45431/61.78508. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.49644/61.75726. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.62605/61.84504. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.41532/61.84667. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.56873/61.82114. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 60.45366/61.86679. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.42753/61.85986. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.38549/61.92352. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.30991/61.90818. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.34478/61.91970. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.30268/61.91247. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.47611/61.92470. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 60.30198/61.95857. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.27890/61.92834. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 60.32540/61.92141. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 60.32891/61.95154. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 60.08800/61.94244. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.03419927840283847\n",
      "Epoch 0, Loss(train/val) 70.83776/68.57981. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.64222/68.40945. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.51049/68.22984. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.28429/68.04115. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.15786/67.85696. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.94401/67.66521. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.82638/67.45241. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.63418/67.23539. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.47686/67.01781. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.36707/66.79906. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.25366/66.58327. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.05135/66.36399. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.84169/66.12471. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.75720/65.88344. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.57755/65.64300. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 68.37333/65.39970. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.17760/65.15096. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 68.02114/64.90769. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 67.72847/64.66101. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.73162/64.43266. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 67.36923/64.23254. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.27642/64.03694. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 67.17156/63.84787. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 66.86212/63.71549. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.61773/63.59048. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 66.46259/63.50647. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 66.30724/63.46452. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.08311/63.43160. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.93280/63.43341. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.75679/63.41041. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.68618/63.40780. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.53469/63.29645. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.41857/63.31273. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.31653/63.17887. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 65.17174/63.14988. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.06383/63.04679. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.92694/63.05930. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.74100/63.10311. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 64.65448/62.94220. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.61431/62.96022. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.43989/62.96689. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 64.40927/62.99694. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 64.38174/62.95628. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.16508/63.00408. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.09507/62.96264. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.11432/62.94486. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.06655/62.90950. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.89645/62.99759. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.76998/63.04348. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.77545/62.88647. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.62993/62.94053. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.71659/62.95998. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.56887/62.95649. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.57819/62.95866. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.41048/62.90514. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.39776/62.69621. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.28909/62.61137. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.21653/62.72366. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.16550/62.73870. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.22833/62.51197. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.15543/62.60537. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 63.26601/62.56488. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.00757/62.59926. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.08705/62.60567. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.98533/62.52882. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.98459/62.53585. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 63.02324/62.52827. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.80542/62.44921. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 62.72970/62.50345. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.96533/62.39609. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.91021/62.36831. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.75134/62.36119. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.62520/62.35195. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.58236/62.21777. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.57829/62.15195. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 62.72013/61.95946. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.67124/61.95985. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.71336/61.88078. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.61034/61.73392. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.49023/61.66001. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.50316/61.72128. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.35659/61.61667. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 62.47351/61.36867. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 62.36767/61.13859. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.43598/61.07984. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 62.34667/60.94073. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.37048/61.08553. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 62.32828/61.03568. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 62.31556/60.98072. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 62.40616/60.69585. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 62.27885/60.62289. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 62.16424/60.46471. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 62.25604/60.39513. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 62.04265/60.39827. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.95965/60.43380. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 62.10251/60.40822. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.88741/60.43611. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 62.13901/60.45591. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.97759/60.35849. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 62.09357/60.32364. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.03546361409014303\n",
      "Epoch 0, Loss(train/val) 69.80293/70.47769. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.54135/70.25322. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.30992/70.03387. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.02762/69.80459. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.70120/69.54798. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.32836/69.27026. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.03681/68.96643. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.51541/68.62355. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.00270/68.22535. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.41928/67.76313. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.92421/67.23325. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.27482/66.63211. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 64.64377/65.95511. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 64.02982/65.19057. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 63.22300/64.35693. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 62.63248/63.54514. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 61.99664/62.81496. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 61.40876/62.18286. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 61.06452/61.65170. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 60.65288/61.19612. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 60.10036/60.77327. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 60.06686/60.38224. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 59.61448/60.01670. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 59.44249/59.74594. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 59.27880/59.53802. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 59.00061/59.37297. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 59.01429/59.23841. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 58.68950/59.11140. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 58.74618/58.99876. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 58.72449/58.90065. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 58.65376/58.80835. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 58.63509/58.71812. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 58.51620/58.63187. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 58.35535/58.54831. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.40661/58.47017. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 58.18810/58.39827. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.12602/58.32945. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.23141/58.26611. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 57.96737/58.20250. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 57.86830/58.14543. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 57.94996/58.09296. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 57.81526/58.03901. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 57.79332/57.98638. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 57.80681/57.94414. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 57.75104/57.90113. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 57.64232/57.85114. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 57.63131/57.81586. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.47248/57.77306. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.61469/57.73595. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.47534/57.71040. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.44661/57.67889. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.28508/57.66286. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.23159/57.62229. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.13988/57.60072. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 56.96163/57.55203. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.22257/57.52335. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.04417/57.48067. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.07551/57.46018. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 56.95056/57.40497. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 56.91300/57.40653. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 56.80881/57.36921. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 56.86668/57.33616. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 56.74901/57.28432. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 56.76819/57.25173. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.64048/57.22549. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 56.52144/57.18043. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 56.50421/57.14656. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 56.51087/57.12568. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 56.56197/57.14038. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 56.51952/57.09078. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 56.35073/57.02697. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 56.31800/57.03250. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 56.29087/57.00574. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.29940/56.96110. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.13127/56.90735. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.21409/56.90251. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 55.90795/56.89495. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 56.13865/56.86001. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 56.08423/56.91285. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.12150/56.83345. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 55.67997/56.81393. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 55.90188/56.80201. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 55.72184/56.78640. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 55.83124/56.78316. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 55.68548/56.73921. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 55.65186/56.71266. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 55.80755/56.73671. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 55.61348/56.74958. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.69437/56.62868. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.61393/56.65195. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.44029/56.66359. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 55.70877/56.66106. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.56298/56.60138. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.48510/56.56930. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.51153/56.65647. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.25579/56.51117. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.30260/56.62443. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.45558/56.47907. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.30291/56.51009. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.36547/56.45504. Took 0.32 sec\n",
      "ACC: 0.5, MCC: -0.10728412736822167\n",
      "Epoch 0, Loss(train/val) 71.13071/70.67030. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.70144/70.14030. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.23232/69.58747. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.86107/69.03895. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.36331/68.53535. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.94527/68.11295. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.52273/67.76333. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.19785/67.45812. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.79259/67.17552. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.37601/66.91050. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.88728/66.63087. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.46477/66.32003. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 65.94379/65.97847. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.26250/65.63763. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.65691/65.33392. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.14348/65.14630. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.67438/65.07618. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.22112/65.04836. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 62.69883/65.03568. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.30813/65.01144. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.01667/64.94771. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.65302/64.83778. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.20332/64.67538. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 60.96382/64.48649. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 60.51528/64.29871. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 60.49385/64.14851. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.23956/64.03353. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.18704/63.93683. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.06304/63.83874. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.99706/63.75678. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.91082/63.68597. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.93352/63.62540. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.89880/63.58236. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 59.72490/63.54638. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.68022/63.51164. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.59965/63.47826. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.52067/63.44854. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.43241/63.41709. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.32085/63.39065. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.37774/63.36548. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.22400/63.31177. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.12486/63.20424. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.18419/63.14888. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.06516/63.09653. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.93904/63.01757. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 59.02187/62.93584. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 58.85749/62.88078. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.78958/62.80320. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 58.59448/62.78201. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.63644/62.69226. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.49624/62.67557. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.36606/62.59249. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 58.60320/62.57206. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 58.22505/62.51993. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.04818/62.53469. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 58.14317/62.45403. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 58.12742/62.45491. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.90488/62.51467. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.90675/62.39801. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.78265/62.56734. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 57.61492/62.37688. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.69908/62.85654. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 57.58961/62.34705. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.58175/62.36554. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 57.35859/62.42497. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.34788/62.28637. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.44698/62.49514. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.32746/62.26322. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 57.37893/62.73678. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.24648/62.25808. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.13917/62.52744. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.09932/62.23415. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 56.84321/62.24472. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.83571/62.18363. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.07343/62.23621. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.98245/62.21656. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 56.71515/62.27095. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.76223/62.20213. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.67484/62.34547. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.58512/62.22785. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 56.73905/62.47459. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.64851/62.12397. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.66259/62.41189. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.63141/62.22057. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.48540/62.46616. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.48433/62.12485. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.52453/62.35756. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.50431/62.21893. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 56.32741/62.37796. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 56.35107/62.23751. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.20462/62.42989. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.13526/62.17501. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.15152/62.43085. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.23038/62.15048. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.11743/62.28712. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.99564/62.14745. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.01115/62.40485. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.04056/62.15712. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.08595/62.55248. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.92223/62.04040. Took 0.33 sec\n",
      "ACC: 0.625, MCC: 0.21821789023599236\n",
      "Epoch 0, Loss(train/val) 70.09502/69.80812. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 69.91319/69.75785. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.83205/69.71209. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.69346/69.67584. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.53514/69.65897. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.37509/69.62935. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.23102/69.59324. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.09606/69.54718. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.90171/69.47605. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.69790/69.38645. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.43686/69.28929. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.25337/69.19442. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.06163/69.10810. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.90483/69.03429. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.70968/68.95776. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.59594/68.87419. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.35130/68.80958. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.27624/68.76554. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.18654/68.71124. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.05306/68.64700. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.00106/68.60724. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.91278/68.56662. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.86936/68.52058. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.76843/68.48518. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.73226/68.45786. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.60489/68.42000. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.37798/68.40408. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.41667/68.35826. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 66.28324/68.26003. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.19402/68.16228. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.10801/68.09807. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 66.01752/68.03500. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.83400/67.92236. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 65.76546/67.76802. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 65.52723/67.52388. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 65.43318/67.29372. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.31286/67.18085. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.17685/67.04531. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 65.13248/66.94668. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.91257/66.86144. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.91504/66.87374. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.67355/66.93677. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.44668/66.93877. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.41389/67.02888. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.37664/67.09879. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.37123/67.10490. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.33727/67.10486. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 64.15910/67.14881. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.05902/67.11690. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.08478/67.14441. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.85402/67.19702. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.83899/67.20731. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.80483/67.21747. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.74600/67.22761. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.63342/67.27779. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.55875/67.28050. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.48615/67.31117. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.40972/67.32806. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.41338/67.38797. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.39966/67.35342. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.21690/67.38458. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 63.28555/67.38484. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.20464/67.38806. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.16495/67.41305. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.23542/67.49750. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.01357/67.49445. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.98123/67.50903. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 63.02246/67.60633. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.87139/67.57584. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.73891/67.63490. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.74280/67.73384. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.80915/67.74500. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.64031/67.75565. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.72422/67.81452. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.51311/67.93669. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.59094/67.91949. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.47030/67.94439. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 62.30967/68.01668. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.47900/68.08118. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.25300/68.12273. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.33341/68.21418. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.21077/68.22400. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 62.31309/68.24564. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 62.10483/68.32990. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.23006/68.27832. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.04847/68.35243. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.04315/68.33045. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.90791/68.39100. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.80601/68.39713. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.89085/68.40891. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.78398/68.45374. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.58687/68.38267. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.52663/68.55183. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 61.66395/68.40691. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.62249/68.61209. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.56255/68.52039. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.40190/68.64477. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.52391/68.61163. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.25362/68.66469. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.35640/68.60090. Took 0.32 sec\n",
      "ACC: 0.390625, MCC: -0.1886680513554908\n",
      "Epoch 0, Loss(train/val) 70.75883/69.66773. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.50850/69.44121. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.23923/69.21938. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.00402/68.99917. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.74835/68.78776. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.61029/68.59332. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.38878/68.41116. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.19864/68.23796. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.04471/68.06898. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.84776/67.89603. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.65053/67.72193. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.53655/67.54864. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.31691/67.37509. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.18251/67.20874. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.01255/67.04445. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.83819/66.87601. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.69000/66.70447. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.43833/66.52744. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.32863/66.34795. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.15918/66.16556. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.03418/65.97158. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.83362/65.77104. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.61589/65.55841. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.44418/65.33883. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.21600/65.11510. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.03768/64.88694. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.90988/64.65901. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.74587/64.44393. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.62013/64.22919. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.46839/64.00819. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 65.11615/63.77604. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.99673/63.52833. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.79809/63.28062. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 64.51787/63.02794. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 64.46290/62.76315. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.18359/62.48552. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.98001/62.18873. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.81473/61.87926. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 63.50933/61.56323. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.33466/61.27714. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 63.15677/60.98759. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.87623/60.74823. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.68627/60.53277. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.57322/60.38340. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 62.51564/60.27843. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 62.32585/60.23161. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.37033/60.17461. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.13658/60.13920. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.13601/60.09721. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.99105/60.06615. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.88792/60.00431. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.61079/59.96169. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 61.67167/59.88226. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 61.71024/59.93484. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.60712/59.81270. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.45100/59.82536. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.36710/59.70361. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.23703/59.73424. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.13347/59.65444. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.05967/59.68135. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.99369/59.57862. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 60.91032/59.67368. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.05982/59.51329. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 60.94108/59.66842. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.92778/59.51293. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.70004/59.63322. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.59220/59.47828. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.63181/59.58712. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.43885/59.41676. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 60.32781/59.50691. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.28578/59.43288. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.26489/59.49541. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.17157/59.47592. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.13081/59.51789. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.21874/59.41888. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.95010/59.51028. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.96331/59.52494. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.85027/59.49557. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 59.89249/59.54799. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.83414/59.54608. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.63666/59.50608. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.75356/59.60162. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.67535/59.61257. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.59997/59.68103. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 59.52158/59.60423. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.45334/59.66927. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.37921/59.74353. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.51634/59.58241. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 59.29698/59.70821. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.32001/59.86750. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.34439/59.54529. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.20344/59.50918. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.32393/59.94993. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.23527/59.78456. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.10047/59.54938. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.11246/59.55344. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.97752/59.79810. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.99775/59.72041. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.95345/59.62448. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.95718/59.60538. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.15244937348544793\n",
      "Epoch 0, Loss(train/val) 70.33347/70.10062. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.06213/69.92080. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.82409/69.73035. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.54551/69.53444. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.26573/69.32775. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.01897/69.10352. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.77300/68.86214. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.47097/68.60465. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.16983/68.33185. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.95354/68.04385. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.63093/67.73939. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.33036/67.41131. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.98493/67.06253. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.75639/66.69907. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.34101/66.31401. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.00373/65.88566. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.57936/65.42819. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.17699/64.91389. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.68469/64.32991. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.12896/63.65386. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.40875/62.89878. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.93511/62.16107. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.40237/61.52176. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.75005/60.98832. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.46899/60.56588. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.05014/60.25906. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.83072/59.99245. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.42729/59.76040. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.26500/59.56138. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.12834/59.38235. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.81467/59.23373. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.56133/59.10332. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.41428/58.97137. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.34544/58.87942. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.15408/58.79648. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.02534/58.69578. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.81854/58.53582. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.79381/58.33279. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 58.54491/58.18122. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.41747/57.97617. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.29783/57.84391. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.14618/57.73018. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 57.89172/57.60643. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 57.96822/57.57241. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 57.87652/57.38591. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.83532/57.25394. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 57.89191/57.17074. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.76532/57.09652. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.65965/56.94695. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.53317/56.90004. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.46764/56.87198. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.30054/56.80128. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 57.43304/56.73381. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.40393/56.71178. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.35910/56.67951. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 57.31995/56.63557. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.23105/56.61024. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.08210/56.58524. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.11504/56.56489. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 56.87825/56.52531. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 56.95333/56.53135. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 56.88080/56.48815. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.06949/56.42131. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 56.91021/56.43398. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.72142/56.39309. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.61647/56.41415. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 56.59149/56.38390. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 56.72394/56.36848. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 56.66625/56.34205. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 56.53158/56.33558. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 56.69468/56.30566. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.75610/56.32527. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.76579/56.31242. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.48212/56.27657. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.40904/56.27092. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.49666/56.23435. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.37534/56.29187. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.32245/56.27023. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.31616/56.23501. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.31353/56.29848. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 56.28564/56.28051. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.30161/56.27671. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.23745/56.28859. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.15983/56.23134. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.25485/56.31886. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.11638/56.23898. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.22073/56.24420. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.02843/56.31904. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.14649/56.27730. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.23355/56.34398. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.94959/56.28388. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.05541/56.30469. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.09834/56.27789. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 55.89207/56.25587. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.97960/56.28559. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.04829/56.32308. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.96100/56.32145. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.91475/56.30126. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.82499/56.30501. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.89110/56.34372. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: -0.07019329771955513\n",
      "Epoch 0, Loss(train/val) 70.50910/71.33463. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.28809/71.19985. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.05992/71.07277. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.86135/70.95062. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.65215/70.82838. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.49603/70.70322. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.31484/70.57645. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.09883/70.45054. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.95121/70.32512. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.77273/70.20329. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.58858/70.08223. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.40862/69.96042. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.15768/69.83918. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.95365/69.72054. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.80266/69.59628. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 67.52329/69.46751. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 67.27172/69.33702. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.06505/69.20615. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.84369/69.06924. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.53610/68.92613. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.38291/68.77749. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.14371/68.62385. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.91976/68.46300. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.80416/68.29501. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.51916/68.12228. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 65.41067/67.93774. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.31163/67.73734. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.03971/67.51678. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.86571/67.26264. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.60343/66.95278. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.38490/66.59999. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 64.19272/66.22182. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.85379/65.83243. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 63.68312/65.39738. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.37948/64.91483. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.08615/64.44210. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.91862/64.01940. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.86819/63.69174. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.76228/63.42543. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.53822/63.17190. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.52591/62.91487. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.40121/62.66872. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.36270/62.44805. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.09587/62.23841. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.84339/62.07355. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.69641/62.00244. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.73752/61.96909. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.51583/61.80857. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.39318/61.57967. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.25410/61.36263. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.09821/61.31709. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.97990/61.20174. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.85911/60.98882. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.80300/60.97930. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.76485/60.75849. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.58942/60.81087. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.59617/60.62554. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.64679/60.45366. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.37360/60.44421. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.60710/60.36259. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.39214/60.36834. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.25263/60.29650. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.13454/60.22046. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.19945/60.14973. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.00910/60.13352. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.98637/60.01696. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.83168/60.13113. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.87906/59.95258. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.94917/60.03061. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.81260/59.84617. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.78650/59.72444. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.62641/59.76625. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.63920/59.70590. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.65240/59.62809. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.66584/59.51685. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.60292/59.51980. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.60774/59.58608. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.53308/59.48080. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.57745/59.50285. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.34947/59.28206. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.49223/59.21983. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 59.42988/59.32454. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.35316/59.46033. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.18130/59.16702. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.21900/59.11109. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.21119/59.13999. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.23540/59.40636. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.01567/58.99213. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.06907/59.24437. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 59.10247/59.17144. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.80478/58.94266. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.07156/58.97345. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.92120/59.10063. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 58.99389/59.08334. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.90919/58.88470. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.99827/58.79133. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.83189/59.03930. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.67476/59.02670. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 58.80945/58.67595. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.81855/58.93594. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.07881104062391008\n",
      "Epoch 0, Loss(train/val) 71.58100/71.66827. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.31078/71.56712. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 71.10327/71.47468. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.94249/71.38581. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.70565/71.29400. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.51066/71.20161. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.36006/71.10992. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.14846/71.01237. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.91229/70.90536. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.80850/70.79037. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.61223/70.66669. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.33231/70.52487. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.08121/70.37179. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.98375/70.21535. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.85697/70.04439. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.64119/69.87496. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.39776/69.68991. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.16504/69.48563. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.03364/69.27668. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.77201/69.05769. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.58654/68.84460. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 67.29185/68.63713. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 67.08746/68.43690. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 66.92444/68.23867. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 66.78746/68.04575. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 66.45164/67.84616. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.31418/67.63988. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.12641/67.44034. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.99499/67.25009. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.70933/67.05943. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.71888/66.86966. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.48359/66.68997. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.32617/66.51309. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.08667/66.33424. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.00199/66.16412. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.00208/65.99060. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.78401/65.81538. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.69535/65.63948. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.50233/65.45664. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.40108/65.26467. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.25187/65.07136. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.06578/64.85526. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.13835/64.63400. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.84320/64.40016. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.69395/64.16468. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 63.62678/63.92709. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.53213/63.67269. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 63.22380/63.41490. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.95029/63.14986. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.86247/62.88160. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.61821/62.60426. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.70990/62.34286. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 62.15262/62.07891. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.95255/61.82821. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.79682/61.59930. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.62750/61.40532. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.27461/61.21695. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.21836/61.03931. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.25282/60.87186. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 60.92552/60.73323. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.86632/60.59842. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.63505/60.44967. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.60560/60.29810. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.44202/60.17529. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.35062/60.06443. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.40591/59.96986. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.23859/59.85781. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.21322/59.76070. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 60.23724/59.65672. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.25262/59.56560. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.96214/59.50019. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.77606/59.43223. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.90616/59.34010. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.94186/59.24338. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.69376/59.15286. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.71708/59.09767. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.78539/59.04551. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.74309/58.98047. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.55716/58.92695. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.56983/58.86461. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.54861/58.79018. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.42420/58.70953. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.49992/58.64776. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.26181/58.57075. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.25580/58.49500. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.46501/58.41649. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.32773/58.34997. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.30045/58.33120. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.03798/58.27404. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.07556/58.25599. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.15220/58.19643. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.09988/58.16425. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.15573/58.10203. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.98488/58.05751. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.85458/58.04552. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.87957/57.98920. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.66882/57.94696. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.72267/57.86491. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.79146/57.80228. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.57795/57.78322. Took 0.32 sec\n",
      "ACC: 0.59375, MCC: 0.22677868380553634\n",
      "Epoch 0, Loss(train/val) 70.73005/72.51403. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.48965/72.30167. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.27788/72.08625. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.08457/71.86010. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.85803/71.61285. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.59907/71.34427. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.40395/71.06106. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.14353/70.75639. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.84129/70.45014. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.58771/70.15213. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.25136/69.87279. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.94577/69.61596. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.64859/69.38980. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.36327/69.18964. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.09293/69.01266. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.85046/68.85410. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.61509/68.70884. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.37834/68.56800. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.04345/68.43649. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.85901/68.30717. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.58320/68.17099. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.40344/68.03034. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.20688/67.87907. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.99029/67.71677. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.69458/67.53727. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.46331/67.35088. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.31619/67.16579. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.12061/66.99611. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.86764/66.83871. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.68134/66.69822. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.40292/66.57594. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.17442/66.46554. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.98000/66.36768. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.74132/66.28000. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.69972/66.20209. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.41336/66.13041. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.44054/66.06242. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.43841/66.00807. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.23644/65.96180. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.03960/65.91805. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.95359/65.88873. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.85119/65.85980. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 61.89919/65.82410. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.79872/65.79378. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.61630/65.77268. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.58043/65.75829. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.59396/65.73552. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.51156/65.72378. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.44107/65.71543. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.43061/65.69257. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.34436/65.67531. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.36150/65.67775. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.23913/65.65930. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.23637/65.64661. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.16899/65.64565. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.25005/65.63650. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.18458/65.62455. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.98304/65.60863. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.06500/65.60097. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.91299/65.59114. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.09030/65.56007. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.04419/65.54454. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.94618/65.54668. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.99695/65.54474. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.82113/65.53953. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.97653/65.53672. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.86212/65.52818. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.84382/65.51583. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.92133/65.50681. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 60.65377/65.47252. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.85168/65.45282. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.64054/65.45171. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.77166/65.45505. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.49828/65.43840. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.73901/65.41529. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.58314/65.40314. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.63404/65.39055. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.54105/65.36083. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.53784/65.33857. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.53965/65.29306. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.50556/65.24747. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.44156/65.23070. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 60.48568/65.18745. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 60.40167/65.13614. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.36992/65.05171. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.37809/64.96947. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.30724/64.84184. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.16786/64.69227. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.17153/64.53674. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.07821/64.38515. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.92861/64.20284. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.85739/64.09402. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.72614/64.03082. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.87405/63.96703. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.63077/63.92081. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.71410/63.87896. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.54552/63.87494. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.68667/63.83852. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 59.63072/63.83345. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.51455/63.78912. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.09341218537003596\n",
      "Epoch 0, Loss(train/val) 70.89860/70.22900. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.82431/70.21364. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.73188/70.19175. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.61561/70.17027. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.49003/70.14327. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.39328/70.11536. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.25132/70.08043. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.11378/70.04279. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.00500/70.00047. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.85594/69.95791. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.84576/69.90767. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.70228/69.85594. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.65566/69.80542. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.52022/69.75828. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.45905/69.70813. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.31333/69.65375. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 69.22824/69.59386. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 69.18019/69.53729. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 69.10281/69.48144. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.98885/69.42294. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 68.97998/69.36443. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 68.86473/69.30016. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 68.78683/69.24473. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 68.73156/69.18968. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 68.67384/69.12793. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 68.51565/69.06419. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 68.42666/68.99692. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 68.40605/68.93917. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 68.28138/68.86937. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 68.16280/68.79525. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 68.10197/68.72321. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 68.05328/68.64743. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 67.93260/68.57388. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 67.79791/68.51265. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 67.65540/68.45908. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 67.58021/68.39935. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 67.39319/68.34225. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 67.24022/68.25826. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 67.08418/68.17764. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 67.00031/68.11121. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 66.83896/68.06279. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 66.68764/67.99554. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 66.46243/67.94900. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 66.47238/67.94290. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 66.15131/67.97266. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 66.11783/68.01963. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 66.05701/68.05797. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 65.84285/68.09399. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 65.86448/68.10205. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 65.62628/68.10347. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 65.52552/68.12244. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 65.29096/68.10532. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 65.30291/68.07518. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 65.14472/68.06121. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 65.08330/68.05850. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 64.93874/68.02991. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 64.95185/68.00263. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 64.80154/67.90725. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 64.64189/67.81425. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 64.68384/67.74761. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 64.57186/67.67290. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 64.44368/67.57129. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 64.44334/67.46368. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 64.24052/67.36829. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 64.20578/67.28148. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 64.13356/67.22764. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 63.96669/67.09366. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 63.91414/66.97274. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 63.93467/66.86951. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 63.89654/66.75706. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 63.79933/66.65374. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 63.76655/66.52607. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 63.49284/66.44407. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 63.45831/66.36913. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 63.38410/66.31163. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 63.48712/66.62353. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 63.21322/67.08930. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 63.26963/66.90116. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 63.06943/66.58448. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.91804/66.41242. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.84174/66.31361. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 62.69840/66.25166. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 62.51348/66.14148. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 62.42584/66.03211. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.36379/65.97482. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.13882/65.90704. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.10678/65.78147. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 62.16059/65.76696. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 62.08489/65.66318. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.96451/65.72082. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.85180/65.57327. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.73529/65.57696. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.81669/65.52237. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.64635/65.44536. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.59351/65.40200. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.45918/65.32018. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.41442/65.29885. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 61.32424/65.20158. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 61.30844/65.04308. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.25445/65.07200. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.046373889576016826\n",
      "Epoch 0, Loss(train/val) 70.21119/70.29489. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.05097/70.15315. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.84038/70.01120. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.70765/69.85918. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.55291/69.69601. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.39367/69.52402. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.18712/69.33453. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.95919/69.13893. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.80744/68.95206. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.67109/68.77411. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.45546/68.60743. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.23295/68.44895. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.10045/68.29414. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.94480/68.14221. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.78602/67.98464. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.49246/67.82118. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.24909/67.65308. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.14164/67.48833. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.89100/67.31445. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.61182/67.12378. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.42067/66.90721. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.27376/66.65394. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 66.11231/66.37471. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.79976/66.11024. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.54965/65.87009. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 65.35637/65.64296. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.09518/65.42828. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.01813/65.20944. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.74924/65.01273. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.36444/64.81390. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.20699/64.61396. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.03103/64.39005. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.90559/64.22777. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.68399/64.11053. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.66304/64.02728. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.29151/63.91082. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.34597/63.90501. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.17515/63.83526. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.06581/63.82957. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.98899/63.84165. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.76723/63.86016. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.79053/63.90088. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.66626/63.98997. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.62460/63.92922. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.50430/64.08318. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.32881/63.94573. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.29401/64.07738. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.36568/64.02413. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.06175/64.11028. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.10403/64.06167. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.99459/64.09987. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.93712/64.09052. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.91022/64.14480. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.73333/64.05327. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.76425/64.20834. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.68304/64.04774. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.51782/64.21562. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.42553/64.12177. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.51610/64.29443. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.23763/64.15176. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.42257/64.33931. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.15993/64.33647. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.18578/64.28808. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.18909/64.10242. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.97611/64.16416. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 61.08033/64.05742. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.88545/64.05552. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.82733/63.80500. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.82213/63.76701. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.79309/63.52869. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.67939/63.60019. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.53765/63.37544. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.55296/63.51252. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.65568/63.42127. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.44739/63.46947. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.34866/63.39230. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.36897/63.43113. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.25692/63.29651. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 60.08847/63.32831. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.23601/63.27588. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.12392/63.34940. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.20308/63.05956. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 60.00994/63.35570. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.93256/62.88186. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.99694/63.25935. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.96918/62.80692. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.94870/63.22618. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.75944/62.90570. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 59.69340/63.23237. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 59.81520/62.78947. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.81413/63.20203. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.71288/62.78816. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.70042/63.24697. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 59.51927/62.76607. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.53637/63.16872. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.47950/62.82218. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.40217/63.08934. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.50376/62.96431. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.40261/63.03904. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.32385/63.02014. Took 0.32 sec\n",
      "ACC: 0.390625, MCC: -0.19282872818393804\n",
      "Epoch 0, Loss(train/val) 71.39102/70.42113. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.10701/70.07795. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.86619/69.76982. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.61716/69.47034. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.38735/69.17886. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.13365/68.88075. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.84321/68.58189. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.58832/68.26675. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.38975/67.94599. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.04775/67.60316. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.86979/67.23930. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.56263/66.84386. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.33782/66.49692. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.03680/66.15273. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.79071/65.83640. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.49791/65.56770. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.36966/65.32967. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.24685/65.13373. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.93343/64.95650. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.73761/64.79832. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.57179/64.65865. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 66.32201/64.53609. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.17008/64.42180. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.13186/64.32246. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.98985/64.24887. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.77571/64.18939. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 65.75094/64.15189. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.61971/64.20143. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.42039/64.35859. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.31989/64.50304. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.16217/64.56465. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.03857/64.53307. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.97681/64.47238. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.78903/64.39311. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.72756/64.30133. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 64.52116/64.22170. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.39737/64.15358. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.30072/64.09561. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.10355/64.07778. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.95872/64.06292. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.65630/64.04772. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.51973/64.04196. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.23324/64.07723. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.04469/64.11026. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.95407/64.21893. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.91346/64.21239. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.63020/64.13248. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.41149/64.11711. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.38762/64.19701. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.38741/64.33105. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.18608/64.63659. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.19776/64.85186. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.05379/65.87128. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.97498/65.09317. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.98841/65.35774. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.80238/65.24803. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.66582/65.26244. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.66672/65.42296. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.59488/65.00802. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.45712/66.07750. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.34199/65.97427. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.40217/64.84170. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.27983/65.64883. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.19612/64.40376. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.06579/64.79996. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.17525/64.40611. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.14315/64.61089. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.89336/64.68515. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.92258/65.02600. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.74075/64.40952. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.89660/65.33549. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.70867/65.45905. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.65645/64.24548. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.48691/64.31094. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.55045/64.24605. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 60.20209/64.02162. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.34602/64.47623. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.31613/64.28607. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.21279/64.05943. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.27716/64.07502. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.17845/63.95792. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.12791/64.18748. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.02831/64.14568. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.09432/63.87948. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.90487/64.37971. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.69017/64.52512. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.51061/63.87541. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.69984/65.02789. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 59.34727/63.71346. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.35275/63.40725. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 59.41541/63.63348. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 59.17653/64.84371. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.18037/65.13758. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 59.11197/64.42205. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.09098/63.91858. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.95192/63.73114. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.82628/65.25636. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.78977/63.77348. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.79854/63.68447. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.63024/65.29083. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.17926701731725506\n",
      "Epoch 0, Loss(train/val) 70.38527/69.05611. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.05081/68.87400. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.76465/68.70782. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.45559/68.54794. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.16944/68.38734. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.89864/68.22421. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.55522/68.04267. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.12750/67.84319. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.69918/67.60932. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.34282/67.33492. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.76396/67.01459. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.27838/66.65012. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.68274/66.23318. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.16231/65.78443. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.45345/65.31775. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.09107/64.87079. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.61026/64.47108. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.02402/64.15037. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.70629/63.85028. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.36371/63.57318. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 61.90603/63.31078. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 61.60211/63.06158. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.26373/62.83184. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.01469/62.63066. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 60.52255/62.46070. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 60.29261/62.30893. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.19827/62.14985. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.06427/62.02563. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 59.79260/61.94202. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.58481/61.86378. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 59.40652/61.82528. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.43037/61.77549. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 59.17886/61.71060. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 59.02340/61.67505. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 58.88724/61.61824. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 58.87012/61.55820. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.89833/61.51579. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.72560/61.45829. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.85312/61.42383. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 58.79896/61.39808. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 58.82989/61.37135. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 58.41321/61.35448. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 58.43744/61.34303. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.53321/61.29354. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.34570/61.25317. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 58.46163/61.25365. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 58.20900/61.21514. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.23136/61.13717. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 58.11563/61.09346. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.97630/61.02056. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 58.16596/60.95825. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.02922/60.92478. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.80657/60.88145. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.86274/60.80297. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 57.56884/60.72984. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.57278/60.65585. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.75054/60.57931. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 57.48404/60.51733. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.50501/60.44302. Took 0.34 sec\n",
      "Epoch 59, Loss(train/val) 57.36218/60.39837. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 57.48091/60.34830. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 57.38813/60.29199. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 57.22590/60.21754. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 57.13123/60.20578. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 57.13786/60.14208. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.17472/60.08068. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.00846/60.06121. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 56.91523/60.06025. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 56.98982/59.97425. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 56.92901/59.89568. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 56.66027/59.83902. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 56.68689/59.74502. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 56.73426/59.68213. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.66486/59.58462. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.66289/59.50615. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.43050/59.40534. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 56.38947/59.36467. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.29258/59.19170. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.22924/59.10027. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.25877/59.07603. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.15557/59.00062. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.05373/58.77583. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.23893/58.63277. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.13425/58.58627. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 55.93913/58.46775. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.98311/58.39916. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 55.84670/58.31889. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 55.62159/58.25229. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.60894/58.24989. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.76161/58.15483. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 55.41865/58.09892. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.55901/58.10766. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.43339/58.08034. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.35425/58.12549. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.23139/58.06681. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.27108/57.99833. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.01181/57.97102. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 55.14415/58.07248. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 55.00436/58.17469. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.02662/58.13093. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.21442250696755896\n",
      "Epoch 0, Loss(train/val) 70.21808/70.68375. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.96707/70.51329. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.78446/70.35325. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.53215/70.19664. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.32649/70.04298. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.14009/69.89159. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.92965/69.74184. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.66696/69.59098. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.46743/69.43328. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.21908/69.26600. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.03377/69.08675. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.77831/68.88975. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.54604/68.67388. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.38524/68.43601. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.17119/68.18212. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.80213/67.91053. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.60169/67.63600. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 66.28527/67.36825. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.97097/67.11201. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.70142/66.86482. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.45475/66.62935. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.05733/66.40075. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.78054/66.18337. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.60690/65.97663. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.18827/65.78075. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.92092/65.59028. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.71527/65.40526. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.44333/65.21590. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.18527/65.05753. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.98023/64.90592. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.74650/64.76157. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.58741/64.63207. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.36217/64.52412. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.14754/64.43317. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.04924/64.35870. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 61.83552/64.29953. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.73398/64.25856. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.61570/64.22673. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 61.57511/64.21533. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.51588/64.21693. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.41664/64.22803. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.33289/64.24419. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.21591/64.27704. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.15326/64.33286. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.11625/64.39503. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.04945/64.42301. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.86224/64.45581. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.99328/64.48404. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.96844/64.53230. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.80978/64.57942. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.91244/64.62716. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.64737/64.67021. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.63405/64.66422. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.61023/64.71312. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.42655/64.70737. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.34092/64.73930. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.53513/64.71966. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.40187/64.74490. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.41295/64.75118. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.39017/64.76235. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.30803/64.79082. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.27265/64.74845. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.24465/64.78201. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.23565/64.78038. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.15814/64.76979. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.20700/64.80393. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.03927/64.72728. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.22820/64.83408. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.09281/64.69546. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.02918/64.86439. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.95680/64.64500. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.93667/64.90078. Took 0.35 sec\n",
      "Epoch 72, Loss(train/val) 59.84819/64.51858. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.89373/64.89249. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.91109/64.61713. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.95865/64.88715. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.80051/64.69666. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.67666/64.87470. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.73786/64.97250. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.59577/64.92834. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.58230/64.78247. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.65415/65.17267. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.39267/64.95271. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.48502/65.12867. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.51101/64.88654. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.31563/65.44387. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.34382/65.23608. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.36410/65.39777. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.30511/65.12660. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.26764/65.26746. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.10744/65.29070. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.16756/65.29528. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.06908/65.53777. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.16488/65.33127. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.99234/65.65981. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.16161/64.57376. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.03242/65.63911. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.07876/64.68467. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 58.95910/65.56106. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.06911/64.43045. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: 0.009523809523809525\n",
      "Epoch 0, Loss(train/val) 70.58495/70.65881. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.41919/70.52467. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.27940/70.37606. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.16809/70.21130. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.97036/70.02892. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.81134/69.82179. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.63957/69.59742. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.41973/69.35622. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.22852/69.08551. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.00592/68.79591. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 68.77538/68.48766. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.48945/68.17442. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.25876/67.85575. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.03053/67.53267. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 67.70788/67.21620. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.44886/66.91924. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.12099/66.61414. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.92737/66.32457. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.54747/66.03135. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.28148/65.72906. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.10984/65.44601. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.82230/65.17422. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 65.59811/64.91866. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 65.39860/64.68764. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.18865/64.46964. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.94691/64.25695. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.77839/64.05375. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 64.54610/63.85723. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 64.38808/63.70819. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.16572/63.62035. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 64.00211/63.56321. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.95200/63.53338. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 63.78865/63.51324. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.68940/63.46052. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.60137/63.44323. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.24574/63.43618. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.01784/63.39921. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.98035/63.38685. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.84301/63.39642. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.75665/63.38371. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.67031/63.37599. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.54410/63.36479. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.50553/63.30999. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.38503/63.24603. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.31239/63.21168. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.19455/63.17543. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.91735/63.07356. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.01337/62.98797. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.90203/62.90453. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.74288/62.84113. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.66644/62.75898. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.60787/62.67735. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.50104/62.61489. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.54207/62.47754. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.22993/62.42640. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.16050/62.34431. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.36171/62.24851. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.01163/62.14754. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.13825/62.07355. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.01070/62.00333. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.83969/61.92566. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.81722/61.83779. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.79393/61.79311. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.75650/61.69403. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.65048/61.61590. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.66097/61.54963. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 60.60404/61.48449. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.41393/61.47926. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.50920/61.41589. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 60.49860/61.31609. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.42612/61.29585. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.12728/61.25560. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.19770/61.22890. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.30330/61.18420. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.06390/61.13974. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.17907/61.15820. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.05950/61.11626. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.08875/61.09203. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 60.01203/61.16261. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.99637/61.08194. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.91320/61.03658. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 59.81315/61.01021. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.78794/60.99890. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.56606/61.03045. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.74534/61.02457. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.71450/61.04552. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.55990/61.15169. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.53592/61.19905. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.54387/61.20972. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 59.51555/61.09414. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.51325/61.10776. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.39557/61.27778. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.43537/61.25698. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.22526/61.26474. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.29691/61.32600. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.09866/61.35491. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.14076/61.31517. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.14368/61.39714. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.08763/61.36152. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 58.94443/61.43810. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.04636325549680435\n",
      "Epoch 0, Loss(train/val) 70.14915/70.08901. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.89144/70.18093. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.72463/70.28694. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.46044/70.38572. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.26329/70.47338. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.10228/70.56039. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.86108/70.64392. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.70720/70.72694. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.35203/70.81568. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.21849/70.89986. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.03247/70.97341. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.90657/71.03574. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.75365/71.08763. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.61812/71.11542. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.54993/71.12483. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.35900/71.11436. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.19864/71.10085. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.09956/71.08122. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.97388/71.05769. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.85373/71.03178. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.76708/71.01029. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 66.65537/70.97725. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.51015/70.94404. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.28311/70.91235. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.32660/70.86069. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.19329/70.78299. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.95501/70.73656. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.91727/70.68679. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.67852/70.64835. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.86025/70.61832. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.72746/70.58778. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.65387/70.55125. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.67981/70.50946. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.43702/70.46335. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.32758/70.40756. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.31014/70.34874. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.21297/70.28095. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.31852/70.22221. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 65.03740/70.15370. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 65.08465/70.07330. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 65.01648/69.97816. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.81038/69.89356. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.91481/69.79516. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.75694/69.72073. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.60887/69.62805. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.73653/69.55396. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.66496/69.48472. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 64.38090/69.40675. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.53188/69.35661. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.42268/69.30634. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 64.43671/69.26621. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 64.38851/69.23116. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 64.39023/69.19266. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 64.20405/69.15687. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 64.13385/69.11024. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 64.07076/69.07127. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 64.00445/68.98969. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.88607/68.93958. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.95642/68.88284. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.80718/68.84386. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.77324/68.79601. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 63.62651/68.77818. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.42775/68.71881. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.49262/68.72691. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.42165/68.70039. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.36147/68.72639. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 63.19859/68.74486. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 63.23761/68.71111. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 63.25086/68.75087. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 63.03235/68.76138. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.97742/68.74592. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.88694/68.70258. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 63.05188/68.70856. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.83679/68.71669. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.67431/68.72710. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 62.77613/68.80962. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.64212/68.85887. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.71767/68.83275. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.67185/68.89524. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.51521/68.96013. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.37415/68.87765. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.58861/68.87418. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 62.55679/68.92368. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 62.34508/68.79712. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.26434/68.81632. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.41569/68.90556. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.26249/68.79157. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 62.33929/68.89895. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 62.13721/68.68864. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 62.36050/68.87650. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 62.17078/68.59154. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 62.13667/68.78534. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 62.05398/68.84860. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 62.05406/68.79296. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.86734/68.78990. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.84453/68.73995. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 61.95048/68.83297. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 61.92477/68.82531. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.87753/68.36670. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.99967/68.72504. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.015051045257357716\n",
      "Epoch 0, Loss(train/val) 71.36673/70.62949. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.08201/70.35715. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.85024/70.08849. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.55080/69.82115. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.27828/69.54686. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.00163/69.27422. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.68161/68.98755. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.43051/68.69663. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 69.11169/68.39408. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.77758/68.08217. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.57511/67.76552. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.31989/67.44359. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 68.03321/67.10675. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.64472/66.75547. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.41895/66.39602. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.07811/66.00740. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.77776/65.59943. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.38790/65.18207. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.01783/64.74990. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.61282/64.30449. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.31523/63.86203. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.81772/63.41775. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.41244/62.97000. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.11774/62.52655. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.77423/62.08338. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.42924/61.63440. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.11191/61.19798. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.86457/60.77611. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.61229/60.42913. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.34168/60.12661. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.12747/59.87066. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.83371/59.62102. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.58816/59.40661. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.56883/59.18762. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.36449/58.99669. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 61.25850/58.83244. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.32976/58.68465. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.02692/58.53680. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.05363/58.38900. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.96055/58.28735. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.84863/58.18914. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 60.54069/58.09814. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.55434/58.00706. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.63099/57.95065. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 60.64574/57.86308. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.61172/57.81048. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.43388/57.71194. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.20894/57.64041. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.34607/57.58700. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.09680/57.53823. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 60.23064/57.50166. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.10141/57.44078. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.13609/57.36741. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.07745/57.36768. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.91351/57.26651. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.89873/57.26289. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.85881/57.18628. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.78081/57.13134. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.67546/57.07215. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.77961/57.00726. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.60298/56.94580. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.45011/56.87920. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 59.59751/56.85725. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.58475/56.80899. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.44215/56.77339. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.36608/56.76937. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.37929/56.68673. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.40467/56.67488. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.34177/56.65240. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.42106/56.60248. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.32940/56.59361. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.17950/56.55426. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.25691/56.53251. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.31978/56.51299. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.02739/56.47289. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 58.89917/56.44286. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.98097/56.42226. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 59.01408/56.43265. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.12644/56.42610. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.01285/56.42443. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.97485/56.40825. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.94915/56.39338. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.83671/56.39016. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 59.10423/56.36839. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.94270/56.37323. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.71021/56.36722. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.96330/56.35764. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.63571/56.32138. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.69584/56.28957. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 58.68791/56.26311. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.68473/56.23485. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.66862/56.23171. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.66743/56.22171. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.55963/56.20391. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.62668/56.19405. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.58050/56.17154. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.56104/56.14503. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.60267/56.11700. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.33082/56.07030. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 58.21705/56.04025. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.199172695523003\n",
      "Epoch 0, Loss(train/val) 71.04076/72.06777. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.57621/71.85729. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.22946/71.63753. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.84633/71.40945. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.47663/71.17495. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.09645/70.91632. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.71419/70.64289. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.40265/70.36189. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.96235/70.05067. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.68808/69.72603. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.27757/69.36742. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.91247/68.96321. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.50902/68.51091. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.12824/67.99353. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.70091/67.42082. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.25791/66.78928. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.73293/66.10091. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.30561/65.34380. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.64959/64.50330. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.96768/63.58670. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.20384/62.65891. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.70194/61.82332. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.30514/61.14252. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 60.93407/60.56769. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.68619/60.06855. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 60.37047/59.60152. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.08493/59.12359. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 59.90151/58.67398. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 59.69258/58.31325. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.45172/58.02835. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.27051/57.79738. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.03716/57.60179. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.14601/57.42865. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 58.84819/57.26659. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.91037/57.11305. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 58.65608/56.93350. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 58.58378/56.69340. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.57902/56.49210. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.29441/56.20903. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 58.15295/55.98988. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.00472/55.87380. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.06125/55.80757. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 57.85783/55.73627. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 57.88655/55.68038. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 57.96228/55.71951. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.75167/55.76090. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 57.72507/55.74993. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.53697/55.69200. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.52354/55.64877. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 57.54247/55.61394. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.56887/55.57127. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.38835/55.61703. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.47916/55.49378. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.34473/55.57358. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.41903/55.44939. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.26244/55.44576. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.25624/55.39157. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.03742/55.46223. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.09948/55.42560. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.11668/55.34682. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.14967/55.42769. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.19140/55.45628. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 56.85102/55.34570. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 56.93206/55.35585. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.75871/55.28756. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.85799/55.26944. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 56.79237/55.19193. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.05890/55.23394. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 56.74721/55.25846. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 56.88106/55.19735. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.61917/55.16859. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.65928/55.19945. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.85722/55.10009. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.60386/55.18195. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 56.81207/55.16595. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.53161/55.20798. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.61383/55.17024. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.52085/55.17120. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.53711/55.13261. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 56.42807/55.17569. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 56.49012/55.19544. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.50239/55.14613. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.35276/55.23574. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.45945/55.19531. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.37522/55.29897. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.45555/55.22986. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.32352/55.31992. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.33882/55.27897. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.31306/55.36416. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 56.40698/55.23789. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.11044/55.34081. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.14609/55.27988. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.19678/55.39679. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.11567/55.38238. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.99315/55.37686. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.93028/55.46885. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.96762/55.42714. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.03551/55.49224. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.12445/55.47467. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.86823/55.51183. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: 0.007296160858188733\n",
      "Epoch 0, Loss(train/val) 70.32186/72.32660. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.85615/71.92869. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.41534/71.51523. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 68.95253/71.08006. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.49065/70.63501. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.01429/70.16447. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.48683/69.66935. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 66.91949/69.13918. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.25053/68.55894. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 65.54118/67.93773. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 64.85778/67.31750. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 64.34433/66.72863. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 63.84636/66.17027. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 63.53871/65.67506. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 63.29424/65.24196. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 62.91161/64.84277. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 62.67723/64.49704. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.52615/64.15279. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.37560/63.81878. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.13002/63.49674. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.09223/63.18279. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.88386/62.88237. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 61.75078/62.62139. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.49674/62.40106. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.33309/62.19326. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.17877/61.97980. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 61.11440/61.77810. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.87743/61.58463. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.73054/61.38911. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.68647/61.19240. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.33990/61.00152. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 60.41717/60.81942. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 60.18755/60.64466. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.08902/60.47716. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.95567/60.31535. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.93868/60.15628. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.88575/60.01962. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 59.83870/59.88838. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.74926/59.74786. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.55885/59.61253. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.54368/59.47314. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.45274/59.34284. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.45184/59.20341. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.36891/59.06604. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.33938/58.93419. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.27497/58.81141. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 59.27394/58.68863. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.01468/58.56565. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.11158/58.45238. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.93990/58.33908. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.91441/58.22789. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.73870/58.11913. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.89239/57.99436. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.78608/57.88887. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.67819/57.79095. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 58.53633/57.70178. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.38040/57.61159. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.49937/57.49467. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 58.29153/57.38083. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.28034/57.27455. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.25217/57.17273. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.21529/57.05270. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.16707/56.93832. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.14640/56.82503. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.08010/56.72218. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.81297/56.58640. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.61811/56.47717. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.91659/56.37365. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 57.68333/56.27055. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.60068/56.17404. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.48037/56.09049. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.37467/56.01972. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.47540/55.91440. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 57.19315/55.82085. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.38873/55.77596. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.14867/55.71354. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 57.18283/55.62640. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.04936/55.52714. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.97526/55.47968. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 56.94441/55.45317. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.86686/55.38398. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.84826/55.31199. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.65816/55.29643. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.57362/55.21854. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.71278/55.21224. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.41713/55.14139. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.32357/55.12175. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.40622/55.29077. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.31738/55.10527. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.25302/55.35920. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.15306/55.21912. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.15036/55.22831. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 56.16479/55.14992. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 55.94244/55.20204. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.93448/55.06880. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.93367/55.12282. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.68781/54.88467. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.63181/55.04824. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.56301/55.00857. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.51874/55.08715. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.0592864861199925\n",
      "Epoch 0, Loss(train/val) 70.64775/70.61838. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.30268/70.30226. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.07081/69.98876. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.77186/69.66293. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.50449/69.32377. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.20803/68.96564. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.80335/68.58084. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.50207/68.17229. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.12661/67.74097. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.66944/67.28690. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.31126/66.82632. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.85668/66.36749. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.52977/65.90450. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.12141/65.43774. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.69728/64.94745. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.27565/64.43847. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.85561/63.91019. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.31705/63.37785. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.85381/62.88936. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.58966/62.45413. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.07725/62.07000. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.68143/61.74230. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.46367/61.48077. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.19509/61.27522. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.00154/61.08593. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.89426/60.89970. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.77110/60.75066. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.36757/60.65437. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.26368/60.55969. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.06506/60.46217. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 61.03140/60.39225. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.75267/60.32790. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.77111/60.26128. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.72246/60.18710. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 60.51507/60.12196. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 60.42299/60.06439. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.18316/60.01222. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.13184/59.97812. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.17776/59.92454. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.95722/59.85402. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.08682/59.78782. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.90528/59.73773. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.83108/59.69651. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.84591/59.65116. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.64386/59.65076. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.69474/59.62505. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.62614/59.57565. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 59.67487/59.53465. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.55863/59.49232. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.28621/59.44658. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.46127/59.42633. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.41171/59.38332. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.57279/59.34869. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.31374/59.31953. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.10715/59.30698. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.21888/59.26188. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.13983/59.24023. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.00503/59.22255. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.99050/59.17337. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.81606/59.14336. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.99818/59.14116. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.94220/59.10835. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 58.81396/59.05493. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.77209/59.00130. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.61714/58.97326. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.68114/58.94279. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.61189/58.93483. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.62201/58.91341. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.58890/58.88575. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.37020/58.86631. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.32147/58.86700. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.47580/58.87082. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.35533/58.87983. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.29513/58.87423. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.42353/58.88822. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.22337/58.90681. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 58.22184/58.91281. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.19641/58.93214. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.11071/58.95181. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.04723/58.94062. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.90063/58.95525. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 57.91341/58.97353. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 57.93955/58.97824. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.92394/58.97308. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.82794/58.99984. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.83881/59.00358. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.80086/59.00932. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.85636/59.05211. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.85308/59.03961. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.93632/59.03289. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.60153/59.03397. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.80864/59.04472. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.82546/59.10672. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.71720/59.08193. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.53262/59.06390. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.59347/59.08237. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.49609/59.09159. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.50310/59.09687. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.54386/59.10338. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.63366/59.09342. Took 0.32 sec\n",
      "ACC: 0.671875, MCC: 0.267850612545664\n",
      "Epoch 0, Loss(train/val) 70.16673/69.83134. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.96794/69.62773. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.77640/69.42004. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.56695/69.20091. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.37285/68.95897. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.17190/68.69556. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.90339/68.41067. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.64221/68.08793. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.29478/67.72492. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.00914/67.32546. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.61160/66.88549. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.22636/66.41889. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.87249/65.95712. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.43054/65.51814. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.18236/65.11909. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.91276/64.77536. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.46499/64.51135. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.23953/64.31252. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.04047/64.16172. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.76948/64.03684. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 64.66802/63.95742. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.39128/63.90109. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.30773/63.84835. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.10801/63.79969. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.96072/63.76419. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.87864/63.74042. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.64788/63.72878. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.69442/63.73791. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.45411/63.75042. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.32446/63.78193. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.29303/63.84883. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.04081/63.90328. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.11472/63.98272. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.80222/64.00424. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.74571/64.01830. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.49070/64.07381. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.56022/64.06259. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.53089/64.11700. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.19124/64.14566. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.14982/64.09970. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.09074/64.17406. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.97955/64.15132. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.88058/64.17015. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.09266/64.13502. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.73046/64.19028. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.67188/64.14973. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.56604/64.10889. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.47506/64.06928. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.50205/64.10400. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.48338/63.94183. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.37684/63.90102. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.21860/63.85318. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.24982/63.83989. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.23960/63.75653. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.11004/63.69799. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.87655/63.58699. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.97864/63.80810. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.64437/63.42371. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.77266/63.42670. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.77317/63.54776. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.53577/63.27694. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.49834/63.60498. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.28078/63.21700. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.26570/63.56558. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.21892/63.13708. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.27659/63.47433. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.29435/63.09919. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.16980/63.47684. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.14665/63.03634. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.11663/63.53783. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.90355/63.01600. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.19125/62.93686. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.72356/63.24165. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.75993/62.91023. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.74171/64.27322. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.90590/62.84858. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.78470/63.34053. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.54587/63.04131. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.75825/62.86673. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.40904/63.33758. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.36389/62.84836. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.71285/63.28638. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.45076/62.96497. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.40600/62.83442. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.23486/63.12217. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.29511/62.89354. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.01509/63.20816. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.19265/62.86187. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 59.15697/63.10754. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.99019/62.82116. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.98524/62.97647. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.80694/62.58882. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.79315/62.94236. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.54239/62.61507. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.89601/63.24541. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.51482/62.51691. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.55595/63.32124. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.33788/62.43036. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 58.53999/63.31924. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.35614/62.31843. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.019557778346917184\n",
      "Epoch 0, Loss(train/val) 69.80708/69.83044. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.30407/69.50395. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 68.80938/69.17479. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 68.28405/68.83433. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 67.78331/68.46981. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 67.18832/68.07219. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 66.49222/67.64472. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 65.82457/67.19299. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 65.02913/66.73026. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 64.19716/66.38210. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 63.32346/66.07037. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 62.56375/65.82574. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 61.97770/65.62229. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 61.33950/65.39719. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 60.88692/65.16470. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 60.54207/64.87712. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 60.05925/64.56374. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 59.72099/64.25338. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 59.62891/63.96526. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 59.30127/63.71984. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 59.05249/63.50100. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 58.78287/63.30895. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 58.75631/63.13162. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 58.44744/62.96814. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 58.57858/62.82352. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 58.31468/62.68469. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 58.27022/62.55902. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 58.31192/62.43934. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 58.10662/62.32457. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 58.00553/62.22674. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 57.86131/62.13188. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 57.91075/62.03712. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 57.93768/61.93343. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 57.78365/61.83120. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 57.72142/61.72769. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 57.53723/61.63992. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 57.59038/61.55971. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 57.51995/61.46766. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 57.27639/61.35238. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 57.32613/61.24202. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 57.15744/61.10071. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 57.13122/61.02948. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 57.21891/60.88100. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 57.15125/60.77777. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 56.80057/60.65052. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 56.61237/60.47657. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 56.68753/60.42527. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 56.69055/60.23071. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 56.61195/60.14600. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 56.49404/60.01462. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 56.31265/59.92893. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 56.31389/59.82846. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 56.23586/59.75465. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 56.05097/59.65682. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 56.05613/59.59437. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 55.91207/59.51891. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 55.84582/59.46899. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 56.07253/59.41154. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 55.71010/59.36465. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 55.60059/59.30892. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 55.69757/59.25477. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 55.59511/59.18060. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 55.32176/59.13290. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 55.36411/59.05765. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 55.25145/59.00070. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 55.13313/58.95054. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 55.16267/58.85272. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 55.12951/58.77066. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 54.88942/58.74104. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 55.11174/58.67419. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 54.94792/58.58142. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 54.64785/58.49186. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 54.74608/58.41365. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 54.56631/58.30504. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 54.51376/58.20944. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 54.51927/58.11258. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 54.50222/58.01550. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 54.61143/57.87533. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 54.41040/57.74054. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 54.57163/57.59256. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 54.24680/57.53142. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 54.15131/57.41117. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 54.19631/57.36465. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 53.94649/57.24612. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 53.90166/57.18768. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 53.80171/57.12009. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 54.00542/57.05407. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 53.85310/57.13610. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 53.73484/57.00587. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 53.78098/56.94909. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 53.93866/56.85395. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 53.56772/56.79341. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 53.72425/56.78449. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 53.54409/56.80033. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 53.50101/56.68769. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 53.54664/56.69379. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 53.47069/56.53824. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 53.30161/56.50223. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 53.22232/56.47149. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 53.23001/56.27794. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.006424925662032356\n",
      "Epoch 0, Loss(train/val) 70.44399/71.03338. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.24277/70.96591. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.98760/70.89061. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.77677/70.78833. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.56537/70.65239. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.28648/70.46823. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.99580/70.23038. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.63444/69.91937. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.32638/69.54534. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.78482/69.12157. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.30982/68.69151. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.95928/68.31504. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.37467/67.99271. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.96009/67.72846. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.51200/67.51801. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.20118/67.34915. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.84194/67.16874. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.52005/66.95804. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.26034/66.70840. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.98531/66.39388. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.85480/66.03950. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.67827/65.78894. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.45932/65.59744. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.28159/65.45628. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.23850/65.31855. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.02613/65.19839. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.94961/65.08670. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.96300/65.00839. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.83187/64.93484. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.81505/64.86934. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.67356/64.82306. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.67398/64.79407. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.55593/64.77572. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.36288/64.74589. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.38304/64.68409. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.36292/64.61149. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.18681/64.57200. Took 0.34 sec\n",
      "Epoch 37, Loss(train/val) 62.18218/64.57366. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.04925/64.51877. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.97635/64.49893. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.85792/64.49013. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.72611/64.40992. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.53590/64.30472. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.47868/64.37798. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.41062/64.24934. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.15614/64.25950. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.15253/64.14928. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.20904/64.14809. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.01537/64.05104. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.95923/63.69572. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.70198/63.71083. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.86709/63.29572. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.67243/63.16370. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.66311/62.84881. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 60.59841/62.53664. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.29468/62.47300. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.37288/62.19714. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.17438/61.89011. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.18859/61.60760. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.98386/61.49254. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.04654/61.32600. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.78598/61.25484. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.99908/61.20068. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.59160/61.04823. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.69751/60.52976. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.57854/60.21010. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.31101/60.13766. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.19536/59.93798. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.10854/59.78334. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 59.08150/59.60521. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 58.78956/59.52995. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.93128/59.52502. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.80729/59.43624. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.75071/59.49081. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 58.68689/59.47559. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 58.50039/59.63237. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 58.31309/59.32151. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.35583/59.21288. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.48607/59.27036. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.41482/59.35384. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.21632/59.47306. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.13789/59.58743. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.02269/59.47976. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.98457/59.03458. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.05865/58.90905. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.91200/58.98648. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 57.89608/59.14053. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.96607/59.54070. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.00741/59.72480. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 57.63965/59.46027. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 57.50811/59.16571. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 57.51333/58.99983. Took 0.34 sec\n",
      "Epoch 92, Loss(train/val) 57.71477/59.32241. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.54362/59.61665. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.42234/59.38190. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.38078/59.12542. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.45138/59.27308. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.42273/59.65682. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.55786/59.41075. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.29155/58.99150. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.14349000645205595\n",
      "Epoch 0, Loss(train/val) 70.49088/70.08788. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.31576/69.83503. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.10508/69.56598. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.86213/69.26482. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.62992/68.95068. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.34057/68.64178. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.02768/68.35143. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.75344/68.08401. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.41676/67.84617. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.12905/67.62492. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.83188/67.42747. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 67.62001/67.23920. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.39620/67.06474. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.15682/66.89369. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.88728/66.71619. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.75727/66.53989. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.53543/66.37479. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.46452/66.21272. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.26207/66.05360. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.14833/65.87984. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.89553/65.71046. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.75879/65.56935. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.56112/65.45829. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.58594/65.37370. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.25135/65.29804. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.26096/65.22485. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.97746/65.12721. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.92146/65.02056. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.65068/64.87700. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.54590/64.75202. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.28843/64.58152. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 64.32267/64.32504. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.89494/64.08143. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 63.74262/63.76312. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.51376/63.51811. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.39237/63.26097. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.27784/63.05249. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.22340/62.85065. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.03734/62.59918. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.83406/62.38559. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 62.76231/62.21947. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.66113/62.17568. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.74139/62.05342. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.52157/62.05702. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.51030/61.95790. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.57646/61.92307. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.25419/61.86461. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.13817/61.81917. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.19434/61.86164. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 62.06759/61.80466. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.12185/61.82030. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.18523/61.73257. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.04674/61.72118. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.97478/61.77968. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.92751/61.69212. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 61.82060/61.62770. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 61.82435/61.61517. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.89486/61.62269. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.78551/61.71427. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.62583/61.58123. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.77010/61.70805. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.63248/61.80903. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.62677/61.63004. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.52358/61.69195. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.57233/61.75019. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.47667/61.55816. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.47585/61.81370. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.30686/61.67963. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.42741/61.68273. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.33838/61.59994. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.35764/61.54239. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 61.32369/61.49011. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.21406/61.29816. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.27588/61.25211. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.21985/61.32145. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.24203/61.49422. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.12484/61.38563. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.94914/61.27426. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.04457/61.45674. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.13138/61.21190. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.89522/61.49525. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.82233/61.29652. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.90176/61.20341. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.78656/61.15270. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.66486/61.14937. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.70891/61.24604. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.72284/61.12583. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.70334/60.98871. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.03416/60.99518. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.67838/61.64904. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.65656/61.25521. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.61382/61.44923. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.48134/61.43609. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.43482/61.15471. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.56122/61.28812. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.33271/61.16354. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.55423/61.35632. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.43321/61.32324. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.35019/61.37000. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 60.37119/61.33206. Took 0.31 sec\n",
      "ACC: 0.5, MCC: -0.04144706094183282\n",
      "Epoch 0, Loss(train/val) 70.90423/70.84670. Took 0.31 sec\n",
      "Epoch 1, Loss(train/val) 70.74390/70.77631. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.58661/70.70985. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.47358/70.64574. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.32685/70.58067. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.14246/70.51715. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.01170/70.44592. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.83598/70.37013. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.69048/70.28844. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.50978/70.19321. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.28488/70.08274. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.10200/69.95335. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.84824/69.80453. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.59673/69.62858. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 68.29388/69.42442. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.00751/69.20079. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.67205/68.94028. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.29708/68.65262. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.07377/68.33142. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.57773/67.96100. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.26204/67.52583. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 65.70321/67.05533. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.32154/66.59550. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.01328/66.17710. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 64.55553/65.80193. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 64.32555/65.48599. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.14811/65.21099. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.85418/64.96579. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.62391/64.74571. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.51183/64.54546. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.44321/64.37371. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.23061/64.21622. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.09560/64.07461. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.05353/63.95620. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.93329/63.84755. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.79642/63.75546. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.85405/63.66450. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.70765/63.59435. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.76375/63.53130. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.62349/63.46817. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.52157/63.42105. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.72834/63.38037. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.66768/63.33968. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.49935/63.29674. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.47604/63.26486. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.24040/63.23476. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.32645/63.21169. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.38151/63.19541. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 62.19718/63.17765. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.08807/63.15809. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.34325/63.15066. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.29335/63.14104. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.19408/63.13844. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.29413/63.13756. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.15875/63.13564. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 62.21908/63.14068. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.22227/63.14343. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.00560/63.15116. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 62.14257/63.15686. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.28308/63.15532. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.13929/63.17422. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.09178/63.18956. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.18436/63.19250. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.06730/63.19603. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.93676/63.20928. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.95158/63.22493. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.97362/63.22958. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.87019/63.23949. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.91451/63.25153. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.91033/63.25637. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.87296/63.27469. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.91269/63.28633. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.89014/63.29783. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.83037/63.32867. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.76709/63.35596. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 61.77750/63.35997. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.72850/63.37236. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.61981/63.37588. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.88646/63.37983. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.96308/63.38209. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.76333/63.40630. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.67963/63.41711. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.62346/63.41624. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.75261/63.41973. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.49948/63.44776. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.65277/63.47994. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.58982/63.48829. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.60708/63.48323. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.63807/63.50604. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.65204/63.52131. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.60537/63.52702. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.44034/63.53459. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 61.61499/63.55593. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.53705/63.58007. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.48567/63.58417. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.46936/63.60838. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.57775/63.61237. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.67750/63.60877. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.49232/63.60285. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.52173/63.58147. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.010419719766238846\n",
      "Epoch 0, Loss(train/val) 70.76015/68.87198. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.60751/68.75945. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.42195/68.64304. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.26837/68.52161. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.09505/68.39979. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.94323/68.27177. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.77629/68.14056. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.54236/68.00223. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 69.31533/67.85008. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.16936/67.69536. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.88244/67.53754. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.54573/67.36678. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.22484/67.18620. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.86539/66.98944. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.48270/66.77222. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.07221/66.52813. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.67101/66.26184. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.28167/65.97368. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.79269/65.66153. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.47502/65.34777. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.33518/65.05394. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.02771/64.78648. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.82749/64.55789. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.63339/64.36904. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.42530/64.22757. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.45639/64.14343. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.30508/64.08642. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 64.27577/64.01936. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.08089/63.97465. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.04794/63.88645. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.97373/63.79020. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.70642/63.67899. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.76450/63.57706. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.65400/63.45486. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.69337/63.35279. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.48214/63.22958. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 63.51970/63.13234. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.25281/63.04572. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.24963/62.93929. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.13749/62.89521. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.15415/62.77768. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.06613/62.66584. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.10309/62.59177. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.07346/62.58796. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.96297/62.54262. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.83785/62.43919. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.83995/62.40534. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.81948/62.33883. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 62.62310/62.28915. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 62.65152/62.29041. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.62170/62.18641. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.37031/62.06342. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.31297/62.13146. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.34689/62.12222. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.28278/61.91972. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.22832/61.89846. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.13670/61.92312. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.14946/61.77446. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.97096/61.67007. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.04873/61.61372. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.87935/61.66068. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.87992/61.44482. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.71001/61.43885. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.69513/61.39942. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.61129/61.43192. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 61.65229/61.24427. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.52632/61.18850. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.51360/61.20621. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.38083/61.05845. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.43545/61.26822. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.40306/61.29112. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 61.34443/61.07754. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.20805/61.15768. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.22398/61.17345. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.28670/61.10373. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 61.10265/60.86700. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.05377/61.12506. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.04551/61.06806. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.94302/60.98185. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.95262/61.11696. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.94735/61.08200. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.78899/61.05152. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.71707/60.97518. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.68717/61.04159. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.75325/61.22422. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.62328/60.74170. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.64493/61.06065. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.53236/60.92332. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.63286/61.07246. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.53888/60.94903. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.52148/61.05090. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.42425/61.03357. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.39564/60.70859. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 60.35904/61.01998. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.27087/60.87797. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.25781/60.58506. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.24691/60.98810. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 60.11367/60.77458. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 60.18776/60.72900. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.11403/60.34999. Took 0.32 sec\n",
      "ACC: 0.328125, MCC: -0.31142879922688105\n",
      "Epoch 0, Loss(train/val) 70.06079/71.33781. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.86239/71.32658. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.65127/71.29990. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.43118/71.27184. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 69.23132/71.24883. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.08896/71.23077. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.88701/71.21423. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.62580/71.19524. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.51939/71.17178. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.30231/71.14794. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.17584/71.11864. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.04089/71.07307. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.86729/71.02241. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.74895/70.98082. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.58098/70.93266. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.42711/70.87000. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.30418/70.79615. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.23495/70.72099. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 67.04269/70.63939. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 66.94659/70.54710. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.76673/70.42923. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.64831/70.30326. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 66.53669/70.17915. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 66.42672/70.04681. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.31384/69.91458. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.07629/69.74579. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.91879/69.57843. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 65.85301/69.40593. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 65.65713/69.25504. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.59482/69.10228. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 65.50258/68.93416. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 65.39269/68.78294. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 65.21395/68.59718. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 65.04792/68.38600. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 65.03485/68.18422. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 64.77686/68.00913. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.92911/67.85770. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 64.62252/67.67874. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.59951/67.47188. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.46251/67.29594. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.42985/67.13879. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.33493/66.98431. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.37702/66.85759. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 64.15466/66.70699. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.04705/66.55970. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.10830/66.41522. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.94541/66.30672. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.99758/66.15125. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.93309/66.02945. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.81806/65.95020. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.66059/65.89488. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 63.60438/65.79977. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 63.63864/65.71523. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.57570/65.65813. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.53039/65.60490. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 63.52594/65.53809. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.44048/65.51045. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.42155/65.49023. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.30449/65.44936. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.27687/65.45712. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.22770/65.41660. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 63.15187/65.39575. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.10889/65.39870. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 63.08783/65.38899. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.94782/65.37043. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.87375/65.33713. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.82295/65.34845. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.75273/65.38593. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.72924/65.32909. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.71205/65.32427. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 62.81070/65.37682. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.64305/65.35878. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 62.59189/65.31490. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.53179/65.31908. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.58511/65.35243. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.45021/65.38447. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 62.43453/65.35915. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.46962/65.41267. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.29548/65.41702. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.34402/65.38318. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.40906/65.36372. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.28622/65.36662. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 62.19681/65.40152. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 62.23967/65.42841. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.17327/65.42489. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.04418/65.45489. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.22163/65.44985. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.98494/65.48052. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 62.04341/65.47120. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 62.15306/65.51339. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 61.82763/65.56205. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 62.03513/65.53275. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.87207/65.54305. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.80650/65.56608. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.78584/65.56616. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.68127/65.54278. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.64862/65.53637. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.70416/65.52090. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 61.60716/65.51257. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.47835/65.51236. Took 0.31 sec\n",
      "ACC: 0.65625, MCC: 0.36309228459184417\n",
      "Epoch 0, Loss(train/val) 70.32634/69.78664. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.11263/69.54977. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.92037/69.29600. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 69.71927/69.02137. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.45613/68.71803. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.21831/68.38182. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.93832/68.00867. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.63072/67.58569. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.25291/67.11278. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.92274/66.59960. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.48993/66.04507. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.08398/65.45900. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.64785/64.84834. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 66.24523/64.22440. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.83356/63.59233. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.39458/62.96694. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.02580/62.35331. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.67207/61.79168. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.24259/61.31029. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.02110/60.91822. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.71659/60.59288. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.51314/60.33084. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.31137/60.11273. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.18693/59.92996. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.98640/59.78988. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.79879/59.68711. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.92983/59.59514. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.65335/59.51450. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.76130/59.45510. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.69005/59.40015. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.58383/59.33991. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 62.53463/59.28607. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.45652/59.23742. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.33643/59.17895. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.33650/59.12650. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.42798/59.09473. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.21888/59.06009. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.31046/59.02566. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.08635/58.98036. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.15855/58.95098. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.21896/58.92986. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.97364/58.89387. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.06130/58.86346. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.87211/58.81577. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.87954/58.76952. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.83057/58.73448. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.83399/58.70792. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.81244/58.67310. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.75897/58.62860. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.70399/58.59303. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.62679/58.56235. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.50812/58.51943. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.56103/58.47745. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.48785/58.43484. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.52240/58.39436. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.38417/58.35271. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.34035/58.30968. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.47344/58.28102. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.27790/58.23537. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.35664/58.17478. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.22813/58.10157. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.17248/58.06671. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.07369/58.05745. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.05386/58.02942. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.00176/57.97569. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.97053/57.93503. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 60.89351/57.92553. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.03699/57.86435. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.87007/57.83023. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.82946/57.87012. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.79475/57.80724. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.75838/57.83474. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 60.63642/57.78341. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.70539/57.76058. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.60052/57.76411. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.55658/57.72729. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.60230/57.67563. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.59907/57.67430. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 60.58791/57.73878. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.47898/57.63292. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.54971/57.69224. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.35927/57.65705. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.39168/57.67496. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.30635/57.70489. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.30954/57.62799. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.23274/57.62876. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.18338/57.60890. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.36634/57.65930. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 60.24225/57.58715. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.12531/57.53815. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.25296/57.60792. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.07521/57.44767. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 59.99470/57.61117. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.29146/57.55641. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.03330/57.50761. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.86132/57.49253. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.93691/57.45535. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 60.10094/57.54351. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.09023/57.40751. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.02915/57.54895. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.07881104062391008\n",
      "Epoch 0, Loss(train/val) 69.65211/70.91962. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.40701/70.66011. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.11705/70.38665. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 68.87646/70.09028. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.58309/69.77384. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.23504/69.43674. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.90457/69.08536. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.55273/68.72569. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.19277/68.35303. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.88726/67.97320. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.56857/67.59386. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.13160/67.21304. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 65.89141/66.82580. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.47386/66.43513. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.16109/66.05110. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.85583/65.68092. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.58721/65.32293. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.25881/64.98150. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.98602/64.65678. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.75532/64.36011. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.56753/64.08295. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.37823/63.82401. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.17451/63.57680. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.88151/63.34205. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.95230/63.11932. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.60949/62.90940. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.54139/62.71292. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.39847/62.51414. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.31307/62.33273. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.00563/62.15278. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.03904/61.98543. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.87342/61.83075. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.72247/61.66872. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.69681/61.51529. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.48317/61.37799. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.48099/61.24957. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.47242/61.13003. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.38653/61.01971. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.25322/60.92044. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.04360/60.83637. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 61.23353/60.75694. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.92963/60.67862. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.92041/60.61210. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.84418/60.54309. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.77080/60.47572. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.67126/60.39205. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.54220/60.31037. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.62614/60.24126. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.54698/60.18746. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.42243/60.16127. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 60.23164/60.14503. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.16000/60.09996. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.96896/60.09727. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.85982/60.07905. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.79226/60.08337. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.69264/60.05992. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.62418/60.06622. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.52067/60.05878. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.48221/60.05716. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.47821/60.09484. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.34397/60.12442. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.38996/60.09555. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.21441/60.10828. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.21571/60.12174. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.18318/60.11368. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 59.16935/60.08775. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.93323/60.07579. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.03562/60.07119. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 59.02483/60.05757. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.83810/60.08574. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.93842/60.05593. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.74567/60.03312. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.81612/60.01794. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.68398/59.98145. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 58.75744/59.94189. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.72813/59.99036. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 58.66755/59.95902. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 58.54768/59.93020. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.58849/59.92353. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.51604/59.86344. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.49791/59.88521. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.18769/59.90237. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.43737/59.86266. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.29223/59.84291. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.35810/59.85673. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.26919/59.74239. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.32266/59.67687. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.12405/59.70915. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.11358/59.69532. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.14156/59.72599. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.97731/59.64120. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.10631/59.71692. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.10016/59.63874. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.88603/59.68842. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.95724/59.63481. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.73593/59.72844. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.78392/59.66735. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.61205/59.63491. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.77432/59.69139. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 57.74292/59.67907. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.08606629658238704\n",
      "Epoch 0, Loss(train/val) 70.59001/70.51119. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.41811/70.44198. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.27825/70.37696. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.16452/70.30374. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.00770/70.21603. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.86894/70.11952. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.70407/70.00622. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.56379/69.87586. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.27809/69.72111. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.02865/69.54240. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.73169/69.33981. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.30533/69.09613. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.85015/68.78096. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.06762/68.28708. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.50425/67.54061. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.93615/66.73752. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.43802/66.16133. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.18371/65.80469. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.92405/65.57249. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.74937/65.39024. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.54390/65.24742. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.30083/65.10965. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.15827/64.99167. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.21849/64.90697. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.03791/64.82596. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.05457/64.73484. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.80522/64.63214. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.62487/64.52546. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.71677/64.43153. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 63.69889/64.32378. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.48692/64.22388. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.44127/64.12435. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.40906/64.02385. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.36138/63.92210. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.40405/63.82702. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.19307/63.73077. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.14293/63.65268. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.13531/63.59126. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.92305/63.51765. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.08307/63.43952. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 63.06273/63.36214. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.78134/63.29701. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.79720/63.24292. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.77344/63.19894. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.88099/63.13771. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.80391/63.06371. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.71380/62.99923. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.52995/62.96550. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 62.46612/62.91256. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.36526/62.85105. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.45935/62.79793. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.46350/62.74022. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.29089/62.69408. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.44383/62.66619. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.24414/62.63260. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 62.13805/62.59668. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 62.44392/62.55962. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.39163/62.52462. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.31601/62.47728. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.12633/62.44338. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.24114/62.44223. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.20121/62.40539. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 62.30983/62.36147. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.86253/62.29292. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.89926/62.26410. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 61.95526/62.27790. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.95659/62.25904. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.00241/62.22230. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 61.97112/62.18437. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.88519/62.16307. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.89687/62.13415. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.81638/62.12463. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.84885/62.10037. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.67332/62.04611. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.78382/62.02276. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.64792/62.01694. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.64502/61.97439. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.70305/61.92881. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.65161/61.90533. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.69404/61.85214. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 61.74597/61.83269. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.38641/61.85275. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.51622/61.82171. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.48274/61.77403. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 61.46397/61.79266. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.52826/61.77293. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.28216/61.73775. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.49236/61.68776. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.39690/61.62238. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 61.44759/61.58175. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.35147/61.55441. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.25691/61.50060. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.12460/61.45633. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.09556/61.45244. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.24624/61.40084. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.02412/61.34484. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.30072/61.28288. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.04310/61.24375. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.10438/61.18919. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.17752/61.20950. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.09423188886809433\n",
      "Epoch 0, Loss(train/val) 70.89467/71.13747. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.73198/71.10792. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.58027/71.08846. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.46027/71.07866. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.28755/71.07355. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.13752/71.07458. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 70.02278/71.07712. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.83536/71.07733. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.68085/71.07513. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.48375/71.06071. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.30429/71.03393. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.07527/70.99934. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.90622/70.96288. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.68868/70.91926. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.34810/70.87153. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 68.14869/70.82191. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 67.83119/70.77139. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.54155/70.71365. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.27183/70.64969. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.97082/70.59178. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 66.71331/70.54198. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.39740/70.49864. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 66.08061/70.45689. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.83103/70.42284. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.72489/70.39594. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.47713/70.38884. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.15360/70.39725. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.05610/70.40816. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.84180/70.42803. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.54357/70.46450. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.57995/70.51105. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.36472/70.55536. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.30184/70.59954. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.01792/70.63412. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.96798/70.64465. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.77567/70.65752. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.59824/70.66399. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.59234/70.68475. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.43434/70.69270. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.49580/70.68510. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.40972/70.68021. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.16466/70.68877. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.29488/70.71886. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.20783/70.74621. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 63.12359/70.77143. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.97359/70.79896. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.01171/70.81791. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.81067/70.83911. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.89186/70.89103. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.81271/70.91434. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.69976/70.94727. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.38090/70.98344. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 62.63167/71.00363. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.52026/71.00504. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.40421/70.99456. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.44483/70.97360. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 62.35310/70.99503. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 62.23947/70.95581. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.15902/70.93028. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.22419/70.93456. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.06654/70.95004. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.02129/70.90469. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.96783/70.92308. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.93597/70.90965. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.02781/70.87191. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.96849/70.90359. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.77073/70.88415. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.92865/70.85226. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.78544/70.88280. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.82200/70.86511. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.00270/70.89281. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.71885/70.84209. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.60613/70.78472. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.49358/70.77493. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.65841/70.73891. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.60051/70.81122. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.40781/70.74326. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.48004/70.70258. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 61.52775/70.66312. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.41914/70.68382. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 61.49189/70.63228. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 61.23622/70.62952. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 61.35308/70.56444. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.31842/70.54888. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.17566/70.54704. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.15699/70.50359. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.22574/70.47621. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.16942/70.45941. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.02602/70.42146. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 60.98187/70.35942. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.14636/70.32224. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.90604/70.27056. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.90041/70.16400. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 60.82860/70.15036. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.83568/70.08313. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.86264/70.03172. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.86782/70.04001. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.79950/69.89107. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 60.70967/69.80112. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.75685/69.72949. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.18071682129971953\n",
      "Epoch 0, Loss(train/val) 70.82491/69.99038. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.69694/69.91582. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.59363/69.83096. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.44528/69.72961. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.31385/69.60379. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.15866/69.45181. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.99731/69.26564. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.81432/69.03529. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.62103/68.76517. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.34304/68.43673. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.06786/68.05214. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.69989/67.61413. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.32215/67.14050. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.79272/66.66634. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.32030/66.20508. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.71068/65.77619. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.10660/65.40345. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.55016/65.08482. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 65.03978/64.84741. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.56763/64.61638. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.34416/64.41212. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.16573/64.21868. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.99814/64.00520. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.59412/63.81264. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.59654/63.62440. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.45855/63.44851. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.41811/63.27338. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.19981/63.10584. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.10238/62.93551. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 63.21845/62.75020. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.01244/62.57971. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.01995/62.39627. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.00821/62.21972. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.77952/62.02359. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.69393/61.81937. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.65017/61.63795. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.36167/61.46632. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.54251/61.30760. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.37010/61.14241. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.97485/60.98322. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.04624/60.85133. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.95791/60.71472. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.96235/60.58124. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.67549/60.44687. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.73832/60.32229. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.65997/60.22541. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.61112/60.16752. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.50351/60.10415. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.43039/60.06883. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.34870/59.96208. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.22853/59.89235. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.25788/59.92915. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.18686/59.81954. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.13503/59.80136. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.09286/59.83074. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.92311/59.73348. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.85961/59.76747. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.90408/59.70606. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.68788/59.72261. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.67508/59.71365. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.69109/59.65125. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.66497/59.59894. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.48270/59.63445. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.53722/59.57474. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.53080/59.50513. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.43135/59.45290. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.29228/59.53967. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.18191/59.43764. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 60.23275/59.52173. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.10541/59.33139. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.25154/59.32005. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.94110/59.29679. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.02429/59.33017. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.01184/59.24079. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.99385/59.17039. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.88951/59.21352. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.78848/59.12056. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.66874/59.22365. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.80259/58.95760. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.83684/58.94532. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.63169/58.95351. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 59.61291/58.95333. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.54376/58.92448. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.56650/58.85078. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.54604/58.84282. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.29632/58.86243. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.31431/58.87503. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.45056/58.70852. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.31325/58.73067. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.24278/58.56089. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.17546/58.48602. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.31664/58.49568. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.23442/58.39388. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 59.13041/58.37590. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.82589/58.24420. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.92495/58.27321. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.88590/58.12571. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.95789/58.06755. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.66158/57.97782. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 58.68545/57.99646. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.1271849058234485\n",
      "Epoch 0, Loss(train/val) 70.29621/69.64010. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.99861/69.36327. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.77767/69.10671. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.41289/68.86372. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.18144/68.63372. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.82176/68.41313. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.49483/68.19650. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.21111/67.97377. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.79023/67.74168. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.43250/67.49924. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.04504/67.23518. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.64172/66.95206. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.30188/66.65092. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.85332/66.34187. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.43327/66.03122. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.08777/65.73652. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.75611/65.48025. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.34773/65.23350. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.01787/64.98993. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.57985/64.74434. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.46848/64.50335. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.12560/64.26686. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.77923/64.02757. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.53792/63.80611. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.09566/63.60203. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.05110/63.43739. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 61.73233/63.32035. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.63225/63.24466. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.60126/63.19324. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.32762/63.16756. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.21776/63.17282. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.18426/63.21292. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.10137/63.25128. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.91217/63.32372. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.89884/63.39777. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.84426/63.42393. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.86057/63.44128. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.71033/63.44824. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.52353/63.43885. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.59380/63.43760. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.45568/63.44103. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.35352/63.43829. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.39911/63.40355. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.41265/63.37017. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.32323/63.33042. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.20815/63.25417. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.04984/63.21164. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.99123/63.10426. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.08274/63.09086. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.03590/63.01767. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.03411/62.93732. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.95600/62.93284. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.81562/62.83657. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.83751/62.79208. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.75824/62.78386. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 59.70534/62.72261. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.77029/62.67200. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.67888/62.63635. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.62447/62.61371. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.63268/62.54162. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.55082/62.52235. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.46594/62.49697. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 59.51636/62.47299. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.39304/62.44257. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.39557/62.41452. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.28377/62.37578. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.38326/62.27513. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.33427/62.24821. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.27685/62.19341. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.23217/62.17600. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.28259/62.09435. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.14758/62.09291. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.09993/61.97447. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.08979/61.97188. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.18535/61.94288. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.06040/61.95098. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 59.03568/61.88738. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.95967/61.90027. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.97671/61.85404. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.77863/61.83099. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.87843/61.70068. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.84094/61.68606. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.96690/61.67030. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.74884/61.66361. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.85772/61.60582. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.66008/61.54213. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.67943/61.51937. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.69746/61.48344. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.63495/61.45111. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.66746/61.45324. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.60862/61.38657. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.59379/61.33411. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.56979/61.32156. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.46114/61.30696. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.54812/61.24770. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.53402/61.21686. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.52826/61.19429. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.47329/61.15839. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.41157/61.14960. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.38144/61.08611. Took 0.33 sec\n",
      "ACC: 0.4375, MCC: -0.03013774920513892\n",
      "Epoch 0, Loss(train/val) 71.60384/72.03751. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.33949/71.83777. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.17041/71.66073. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.93347/71.50244. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.68007/71.35403. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.53570/71.20434. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.26009/71.04554. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.99661/70.87508. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.75481/70.67989. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.44508/70.45464. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.12337/70.18278. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.71752/69.84745. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.23775/69.43245. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.80154/68.91952. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.30756/68.32704. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.79171/67.70070. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.28012/67.09729. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.90775/66.57398. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.48602/66.14773. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.15399/65.79210. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.93084/65.50023. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.61274/65.24947. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.31888/65.02901. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.18502/64.82442. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.86506/64.64776. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.66643/64.48439. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.48917/64.32716. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.35878/64.17245. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.09068/64.03069. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.93799/63.89677. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.66807/63.77037. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.57441/63.65350. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.42588/63.53385. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.25543/63.41623. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.12507/63.30046. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.85076/63.18942. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.69769/63.07154. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.56392/62.95045. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.40895/62.83908. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 61.33166/62.73173. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.12577/62.63321. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.02632/62.54145. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.88808/62.45319. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.67603/62.36945. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.60880/62.28486. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.51220/62.19954. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.49884/62.13438. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.39238/62.06145. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.18809/61.99058. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.13597/61.92054. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 60.03458/61.85036. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.90563/61.81488. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.87659/61.76526. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.77131/61.69839. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.63050/61.65456. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.55884/61.60527. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.29314/61.55542. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.38361/61.50802. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.28736/61.46432. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.16816/61.41619. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.08879/61.37630. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.03141/61.31416. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.86298/61.26490. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.89822/61.21331. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.79936/61.16692. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.87983/61.12167. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 58.61524/61.08299. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.49966/61.04131. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.51688/61.03030. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.34815/60.97194. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.33537/60.97031. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.28412/60.92008. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.23821/60.87896. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.20809/60.87408. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.08428/60.86652. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.94512/60.83955. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.97609/60.82095. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.97617/60.80310. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 57.98567/60.78153. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.72315/60.76194. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.64134/60.76075. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 57.70564/60.76377. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.51430/60.77190. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.58413/60.76118. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.53551/60.72104. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.62579/60.73432. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.41060/60.72688. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.56629/60.74150. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 57.48338/60.73443. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.45770/60.75153. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.45299/60.71771. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.39521/60.74894. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.10962/60.73623. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.19887/60.75835. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.09297/60.75626. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 57.26499/60.76227. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.15182/60.74734. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.06988/60.76389. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.96411/60.77383. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.83594/60.76974. Took 0.31 sec\n",
      "ACC: 0.484375, MCC: -0.01654402580491889\n",
      "Epoch 0, Loss(train/val) 69.63927/70.08562. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.35680/69.87458. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.09426/69.64554. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 68.84373/69.40427. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.58415/69.15008. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.22272/68.88311. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.93895/68.60370. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.57555/68.31825. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.16893/68.02876. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.83423/67.73821. Took 0.34 sec\n",
      "Epoch 10, Loss(train/val) 66.35848/67.44595. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.03472/67.15683. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.51082/66.86432. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.05153/66.56668. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 64.52408/66.26242. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.22161/65.94652. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.69019/65.69382. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.16698/65.43595. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 62.73260/65.17290. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.34636/64.91463. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.07823/64.66679. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 61.65898/64.43954. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 61.35265/64.21535. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.32680/64.01161. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.13607/63.85469. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 60.90076/63.70726. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.87215/63.58855. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 60.67282/63.48042. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.51550/63.36715. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.38435/63.25335. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.26777/63.17274. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 60.17207/63.10630. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 60.03749/63.06387. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.01295/63.02388. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.89929/62.96189. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.81585/62.89276. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.86605/62.83735. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.58485/62.79125. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.61013/62.74530. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 59.49117/62.70523. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.40441/62.67401. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.34807/62.63439. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 59.43967/62.60938. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.30381/62.64281. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.29578/62.62213. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.98161/62.57979. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.07635/62.51321. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.17300/62.49876. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.11836/62.46171. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.24475/62.44747. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.94422/62.42970. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 58.86386/62.39009. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.70407/62.38697. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 58.62488/62.37839. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.73788/62.41774. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.60295/62.36666. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.58295/62.28879. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.43994/62.25263. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 58.52848/62.22607. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.44853/62.19460. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.34561/62.16296. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.44928/62.10990. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.11944/62.03931. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.13745/61.96963. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.21256/61.96259. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.22742/62.02139. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 58.02683/61.93499. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.94194/61.83707. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 57.93323/61.76167. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.91310/61.82632. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.05396/61.75461. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.81395/61.73116. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.88967/61.74618. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.55269/61.74147. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.68407/61.83706. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.53499/61.75553. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.54238/61.82925. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 57.37670/61.85255. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 57.27619/61.88469. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.27096/61.90160. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 57.12229/61.59515. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.03721/61.51672. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.00252/61.16251. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.86554/61.26660. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.78522/60.89387. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.75413/60.91820. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.71872/60.74039. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.68622/60.52623. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.48382/60.38243. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.45216/60.22008. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.16556/60.16617. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.45591/61.47115. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 56.54722/60.67416. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.15467/61.03819. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.27849/61.74362. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.38120/60.89505. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.03051/61.12766. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.04337/61.03315. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.11843/60.51403. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.94718/60.18162. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) 70.97893/70.73225. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.81448/70.65064. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.66120/70.56713. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.50870/70.47691. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.32768/70.37204. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.22123/70.25941. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 70.04959/70.13307. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.84590/69.98357. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.68269/69.82198. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.52384/69.65359. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.33877/69.47282. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.05449/69.28742. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.81945/69.09321. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.52686/68.89674. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.28164/68.71185. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 67.94477/68.53854. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.60025/68.36963. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.24984/68.20518. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.88308/68.04010. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.53881/67.86606. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 66.27281/67.66377. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.89503/67.43945. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.57767/67.18839. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.33210/66.92320. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.08047/66.64120. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.04370/66.38069. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.83790/66.14703. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.76068/65.92603. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.49470/65.72675. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.38845/65.52039. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.25031/65.30960. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.09615/65.11983. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.75042/64.89787. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 63.72624/64.68572. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.63462/64.48278. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.50443/64.25607. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.37593/64.00747. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.03594/63.79912. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.91640/63.61541. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.85151/63.42760. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.75201/63.32731. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.59916/63.23604. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.45327/63.17421. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.36995/63.10200. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.34499/63.08135. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.34988/63.03873. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.23833/63.04272. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.29391/63.02055. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.19804/62.97194. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.08437/62.88644. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.19355/62.88415. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.02241/62.89169. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.02573/62.87771. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.01527/62.82150. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.92538/62.76984. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.89081/62.72178. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.98021/62.65863. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.75306/62.61931. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.74341/62.65821. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.79011/62.68610. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.71691/62.65283. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.61164/62.65606. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.73930/62.63248. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.63188/62.62049. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.64102/62.61440. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.46933/62.55516. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.54296/62.43044. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.64619/62.48394. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.60961/62.46709. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 61.39085/62.43813. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.46640/62.48339. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.35037/62.44339. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.24597/62.44285. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.44966/62.39377. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.18799/62.33007. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 61.18321/62.26950. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.31386/62.31958. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.24138/62.29406. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 61.05494/62.33455. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 61.25527/62.33350. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 61.08006/62.30737. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.09911/62.32881. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.83816/62.26356. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 61.02583/62.38554. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.82387/62.48379. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 60.90921/62.51767. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.99746/62.54310. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.94990/62.54483. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.71618/62.34837. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.82915/62.42925. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.59634/62.44455. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.71679/62.45840. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 60.61371/62.50106. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.57326/62.49083. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.59111/62.43650. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.64964/62.46677. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.56686/62.58958. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.62577/62.62970. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.50892/62.48957. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.46249/62.61682. Took 0.33 sec\n",
      "ACC: 0.375, MCC: 0.050964719143762556\n",
      "Epoch 0, Loss(train/val) 70.49397/69.60709. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.30010/69.37794. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.05946/69.14843. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.90754/68.91636. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.67555/68.67770. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.49706/68.43002. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.22884/68.15739. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.98605/67.85542. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.72126/67.51635. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.36989/67.11777. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.93802/66.62209. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.39417/65.99902. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.80551/65.25440. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.15114/64.42062. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.26671/63.51892. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.42132/62.60484. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.68770/61.79163. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.11903/61.12089. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.55056/60.57430. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.07792/60.11752. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 61.93535/59.72776. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.73717/59.38554. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 61.38606/59.08115. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.14423/58.81632. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 61.03972/58.61374. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 60.84629/58.45991. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.82847/58.33072. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 60.60923/58.21619. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.53795/58.11090. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.51550/58.01099. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 60.40495/57.92223. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 60.38987/57.83936. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.21793/57.75589. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.01484/57.68024. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.31709/57.60616. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.01801/57.53398. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.96417/57.46225. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 59.85302/57.39024. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 59.85847/57.32320. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 59.88656/57.25449. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 59.84209/57.18727. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.74075/57.11880. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.74138/57.05045. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.45171/56.98221. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.51790/56.91584. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 59.58709/56.84585. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.45436/56.77313. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 59.54013/56.71002. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.16588/56.65738. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 59.22897/56.59467. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.23138/56.51543. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.05202/56.44299. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.12223/56.37157. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 58.95819/56.30815. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 58.97298/56.22301. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 58.86332/56.13109. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 58.70447/56.04862. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.57676/55.95827. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.57819/55.83721. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.39011/55.71264. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 58.35962/55.55735. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.18696/55.37057. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 58.21339/55.19213. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.10897/54.98882. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 57.85106/54.80900. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.82839/54.61138. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.75954/54.45610. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.78348/54.31204. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.74099/54.13910. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.45753/53.95153. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.43112/53.82996. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.27947/53.58453. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 57.27768/53.54757. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 57.18367/53.41246. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.00035/53.35253. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.07530/53.16393. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 57.01668/53.04129. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.94776/52.93353. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.79861/52.79616. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 56.77986/52.74867. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.73062/52.61661. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.69434/52.58672. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.70477/52.46406. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.58511/52.38839. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.34817/52.29176. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.59109/52.24358. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.33923/52.21714. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.23728/52.11687. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.21118/52.02866. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.41689/51.84385. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.16845/51.98216. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.01982/51.74828. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 55.89491/51.61168. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 55.86458/51.56036. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.68939/51.43295. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.74483/51.39328. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.69664/51.32825. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.31038/51.25919. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.49903/51.27337. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.33384/51.12790. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.1735539817003297\n",
      "Epoch 0, Loss(train/val) 69.91510/71.01473. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.69095/70.76443. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.45198/70.48364. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.17852/70.18097. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.82695/69.83173. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.46129/69.43791. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.02053/68.97543. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.47854/68.44273. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.87065/67.85724. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 66.21216/67.25479. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.47147/66.62111. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 64.85691/65.95332. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 64.17545/65.26173. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 63.54749/64.56824. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 62.96027/63.86935. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 62.45600/63.16805. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 61.93785/62.52605. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 61.50881/62.05878. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 61.17210/61.72577. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 60.92212/61.45091. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 60.56571/61.22482. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 60.45758/61.02380. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 60.37509/60.83467. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 60.09015/60.65371. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.11370/60.47348. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 59.91366/60.30079. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 59.68797/60.13504. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 59.57098/59.98614. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 59.42991/59.83186. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.39800/59.69653. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 59.02044/59.59459. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 58.97878/59.50037. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 58.81955/59.39819. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 58.71456/59.31726. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.65413/59.22214. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 58.42036/59.11838. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 58.31981/59.02024. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 58.20762/58.88783. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 58.22688/58.82237. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 58.11550/58.65379. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.12565/58.63905. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 57.87713/58.47870. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 57.85556/58.47903. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 57.72294/58.50428. Took 0.34 sec\n",
      "Epoch 44, Loss(train/val) 57.69257/58.40166. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.44543/58.30462. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 57.52339/58.23970. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 57.39386/58.19341. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.37630/58.28330. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.23452/57.98272. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.19234/58.13627. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.19955/57.96302. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 57.19935/57.98388. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 57.04127/57.82626. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 57.04337/57.81649. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.13805/57.79049. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 57.11302/57.83450. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 56.92571/57.70531. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 56.76638/57.71890. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 56.71233/57.54918. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 56.74014/57.44940. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 56.63708/57.40463. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 56.74522/57.39903. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 56.52718/57.51104. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.38451/57.50900. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 56.41496/57.44092. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 56.52813/57.42106. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 56.21496/57.41424. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 56.34780/57.36788. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 56.20932/57.41531. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 56.27873/57.36198. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 56.17316/57.29054. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 56.27437/57.30138. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.21349/57.28270. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 56.14510/57.27841. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.20443/57.40789. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.08726/57.76764. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.23750/57.93163. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 56.04406/56.87033. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.03684/56.68353. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.13508/56.95913. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 55.83762/57.23431. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 55.72172/57.30450. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 55.70787/57.32349. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 55.82599/56.99535. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 55.66023/56.78250. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 55.64213/56.92467. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 55.48817/56.83646. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.65615/56.98238. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.55337/56.96168. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 55.54325/56.91107. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 55.41723/56.89937. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.44088/56.97982. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 55.44606/56.96875. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.33944/57.03210. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.32843/57.07335. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.38592/56.97098. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.32089/56.42939. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.41072/56.37086. Took 0.34 sec\n",
      "Epoch 99, Loss(train/val) 55.13754/56.30450. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.13064015512799124\n",
      "Epoch 0, Loss(train/val) 68.63209/69.35571. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 68.19424/68.97380. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 67.66659/68.56135. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 67.14029/68.11344. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 66.62533/67.61650. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 65.84750/67.05340. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 65.09423/66.41891. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 64.22559/65.71449. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 63.13196/64.94809. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 62.19365/64.14443. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 61.27611/63.34274. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 60.74079/62.59148. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 60.16370/62.00458. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 59.68216/61.51307. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 59.28901/61.06793. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 59.06473/60.74888. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 58.87665/60.50708. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 58.73233/60.28691. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 58.41076/60.09438. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 58.37039/59.93247. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 58.21650/59.79068. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 57.94605/59.65773. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 57.95525/59.51516. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 57.86514/59.37585. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 57.65951/59.26253. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 57.58116/59.18101. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 57.34208/59.09247. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 57.23058/58.98946. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 57.22419/58.86916. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 57.09800/58.75950. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 57.06981/58.65179. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 56.86983/58.56481. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 56.73341/58.48561. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 56.66509/58.41817. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 56.56733/58.36460. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 56.51698/58.31164. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 56.32350/58.25739. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 56.35365/58.23147. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 56.26597/58.20345. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 55.94895/58.15563. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 56.00910/58.09619. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 56.02935/58.02485. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 55.94936/57.96519. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 55.73931/57.94559. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 55.69702/57.90759. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 55.63091/57.84436. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 55.50961/57.80524. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 55.41142/57.77559. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 55.41903/57.74778. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 55.26672/57.71465. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 55.26442/57.67289. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 55.17448/57.65739. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 55.11402/57.65536. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 55.09154/57.61640. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 54.74072/57.57890. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 54.94336/57.57117. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 54.71161/57.56115. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 54.71533/57.57228. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 54.94865/57.57787. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 54.57491/57.48530. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 54.58882/57.50008. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 54.49338/57.47180. Took 0.34 sec\n",
      "Epoch 62, Loss(train/val) 54.54671/57.46009. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 54.27841/57.46548. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 54.34509/57.50451. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 54.35015/57.52153. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 54.22018/57.51791. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 54.19811/57.45757. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 54.12029/57.56477. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 54.18574/57.50918. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 54.07918/57.55491. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 54.04841/57.56176. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 54.04799/57.54979. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 53.98371/57.57534. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 53.97323/57.57718. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 53.73172/57.55965. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 53.90260/57.56694. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 53.83310/57.53802. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 53.72495/57.52953. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 53.79617/57.46870. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 53.80170/57.53404. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 53.61762/57.47734. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 53.87809/57.42363. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 53.57488/57.45332. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 53.55447/57.35017. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 53.57058/57.42107. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 53.49400/57.37130. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 53.39775/57.26904. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 53.45267/57.27793. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 53.54068/57.23270. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 53.36483/57.21099. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 53.29428/57.13450. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 53.29213/57.14301. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 53.43339/57.17765. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 53.23167/57.12531. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 53.19310/57.02038. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 53.26967/57.07580. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 53.15923/57.15592. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 53.09716/57.14457. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 53.29626/56.97567. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.13211031413252305\n",
      "Epoch 0, Loss(train/val) 71.47351/72.27697. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.22848/72.10278. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.96074/71.92818. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.63704/71.75211. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.36682/71.57285. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.13462/71.38018. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.83937/71.17866. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.57114/70.96313. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.27218/70.73437. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.92574/70.49049. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.58498/70.22565. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.19431/69.93337. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.78096/69.60361. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.38839/69.22692. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.88204/68.79350. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.31973/68.29297. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.64478/67.70863. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.91477/67.03740. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.40630/66.30441. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.75249/65.54263. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.09528/64.77522. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.42684/64.04454. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 62.10004/63.39861. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.63702/62.85186. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 61.27953/62.39628. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.12912/62.02059. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.76970/61.69196. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.47210/61.39975. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.36486/61.13462. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.31066/60.89985. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 59.96129/60.67768. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 59.78934/60.48233. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 59.66166/60.30167. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.79530/60.12076. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.47681/59.94694. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.33091/59.80137. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.29286/59.66812. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 59.37004/59.53081. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 59.28571/59.37848. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 59.26720/59.28524. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 58.99123/59.25944. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.98320/59.18949. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.80822/59.13543. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 58.86671/58.98203. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 58.42323/58.88241. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 58.55430/58.88239. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 58.64999/58.82206. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.36339/58.72378. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 58.43178/58.68670. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.46080/58.57375. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 58.20881/58.51451. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 58.09644/58.43324. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 58.14167/58.31241. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 58.13696/58.43861. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 58.09435/58.31030. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 57.98430/58.36914. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 58.09465/58.18421. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.04030/58.18356. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.90175/58.13554. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.97303/58.08197. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 57.67933/58.15508. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.86422/58.07517. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 57.70777/58.01347. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 57.63371/57.95953. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 57.66350/58.15443. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.85333/57.88549. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.62199/58.01320. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.57339/57.86472. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 57.59038/58.05646. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.55855/57.75141. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.35166/57.95378. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.58780/57.85846. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 57.53868/57.91713. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 57.23118/57.83242. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.23465/57.95654. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.33346/57.79174. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.25696/57.81476. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.34289/57.78168. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 57.31176/57.87528. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 57.20546/57.94704. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 57.04023/57.79138. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.21601/57.77881. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 57.11792/57.90201. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 57.08695/57.84974. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.19108/57.86396. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.06604/57.77492. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 57.00069/57.80801. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.17238/57.94104. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 57.00203/57.75404. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 57.09638/57.91314. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.05810/57.85032. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.01370/57.71823. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 56.89667/57.82793. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.88730/57.88924. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 56.90588/57.86095. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.78240/57.80633. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 56.78250/57.80304. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 56.63826/57.74602. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 56.74951/57.73048. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 56.62995/57.76655. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.027392713453777272\n",
      "Epoch 0, Loss(train/val) 70.64461/71.46445. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.17691/71.30758. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.70606/71.14934. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.24696/70.97978. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.72809/70.79719. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.18603/70.60188. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.65302/70.39389. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.13932/70.17818. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.61645/69.95787. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 66.22177/69.74098. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 65.79874/69.52702. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.41041/69.31355. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 64.95088/69.10094. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 64.52439/68.88713. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 64.10845/68.66543. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 63.77144/68.44169. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.41993/68.20625. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.08890/67.96405. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.83115/67.71040. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.59145/67.44701. Took 0.34 sec\n",
      "Epoch 20, Loss(train/val) 62.28953/67.16411. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 61.97431/66.87098. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 61.66591/66.55244. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.54441/66.20258. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 61.24774/65.82816. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.03612/65.41682. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.62256/64.98211. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 60.54145/64.52407. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.31307/64.06389. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 59.96089/63.60510. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 59.54135/63.12875. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 59.38588/62.63659. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.15027/62.15398. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 58.75921/61.67481. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.71755/61.22511. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 58.47713/60.82019. Took 0.34 sec\n",
      "Epoch 36, Loss(train/val) 58.16120/60.47341. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 57.98670/60.16044. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 57.79800/59.88102. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 57.87214/59.63148. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 57.48776/59.40096. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 57.40492/59.18166. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 57.33881/58.95721. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 57.02310/58.72046. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 57.10847/58.48006. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 56.82099/58.24626. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 56.58508/58.03383. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 56.49221/57.84964. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 56.34366/57.68805. Took 0.34 sec\n",
      "Epoch 49, Loss(train/val) 56.15453/57.53049. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 56.14455/57.38348. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 55.87403/57.24259. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 55.73885/57.12311. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 55.58919/56.98540. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 55.60271/56.84811. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 55.35616/56.72771. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 55.36393/56.62342. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 55.17120/56.50350. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 54.97672/56.34498. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 54.90740/56.19766. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 54.81269/56.09482. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 54.82866/56.00921. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 54.62775/55.89648. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 54.68949/55.82506. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 54.52381/55.70726. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 54.55266/55.60985. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 54.36418/55.55519. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 54.46201/55.44515. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 54.34077/55.34077. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 54.40882/55.28684. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 54.09187/55.22908. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 54.13985/55.12427. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 54.02321/55.04499. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 53.95300/54.96766. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 53.98899/54.89807. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 54.03387/54.79758. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 53.88126/54.72689. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 53.71781/54.69100. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 53.56161/54.66043. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 53.88106/54.58477. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 53.79786/54.49023. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 53.54580/54.44664. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 53.31747/54.41415. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 53.49628/54.35646. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 53.32222/54.31730. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 53.22821/54.26743. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 53.23600/54.22231. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 53.12422/54.12550. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 53.30313/54.03776. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 52.82352/53.99154. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 52.86457/53.89460. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 52.84676/53.88819. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 52.81801/53.89582. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 52.75276/53.88684. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 52.67064/53.94988. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 52.58626/53.89367. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 52.53751/53.72598. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 52.44005/53.69661. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 52.46215/53.61527. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 52.44267/53.57484. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.031761346610716945\n",
      "Epoch 0, Loss(train/val) 71.26797/70.38185. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.09370/70.34675. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.96763/70.30394. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.79587/70.25636. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.67017/70.19933. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.49827/70.13112. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.37937/70.05264. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.20926/69.97117. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.05291/69.88986. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.87618/69.81082. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.70919/69.73775. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.43670/69.67442. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 69.25890/69.62247. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.01450/69.57951. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.73293/69.53819. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 68.38379/69.48930. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 68.09163/69.42023. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.61563/69.31229. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 67.09108/69.14235. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.61489/68.89001. Took 0.34 sec\n",
      "Epoch 20, Loss(train/val) 66.11788/68.57401. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.67291/68.25098. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.29442/67.94908. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.98408/67.67661. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 64.70190/67.43972. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.52689/67.23620. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.21164/67.07133. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 64.04143/66.92593. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.90237/66.79346. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.86828/66.67602. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 63.70585/66.56647. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.54235/66.46732. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.60291/66.37166. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 63.38534/66.28188. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.19609/66.19585. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.13965/66.11654. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.96560/66.03875. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.91366/65.96159. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.95070/65.89329. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.83475/65.82677. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.78919/65.76758. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.85641/65.70744. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.60221/65.64788. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.59839/65.58884. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.52947/65.53468. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.55369/65.47939. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.43121/65.42663. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.41537/65.37082. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 62.34874/65.32152. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.32517/65.28518. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.28595/65.24870. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.21468/65.21064. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.06761/65.16550. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.13053/65.12302. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 62.01815/65.08159. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.98553/65.05004. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.74692/65.03821. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.98063/65.01093. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.79864/64.96598. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.71450/64.96010. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.78081/64.94421. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.77080/64.93125. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.57071/64.93875. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.43976/64.90320. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.46458/64.87688. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 61.53912/64.86711. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.32293/64.84955. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.32088/64.81822. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.21158/64.81786. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 61.09527/64.81243. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.22615/64.77410. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.91292/64.76619. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.00247/64.78986. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.98537/64.82896. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.89964/64.82666. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.83471/64.81959. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.82792/64.81252. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.81857/64.80971. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 60.56306/64.81213. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.60855/64.81618. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.65142/64.85023. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.41847/64.87054. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.41606/64.93464. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 60.38745/64.98473. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.32058/65.00706. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.24965/65.06009. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.30683/65.09364. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.04765/65.14240. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 60.14530/65.21801. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 59.96067/65.26776. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.06891/65.28452. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.94354/65.30778. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 60.06609/65.28141. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 59.82876/65.32632. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.77570/65.34492. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.72273/65.41833. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.60150/65.40901. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 59.55235/65.35835. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 59.59999/65.35104. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.46720/65.29181. Took 0.33 sec\n",
      "ACC: 0.578125, MCC: 0.19856113239375686\n",
      "Epoch 0, Loss(train/val) 69.29303/67.58408. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.03929/67.25494. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 68.77329/66.90956. Took 0.34 sec\n",
      "Epoch 3, Loss(train/val) 68.53273/66.55566. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.27855/66.18802. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.01497/65.80547. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.64070/65.40589. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.29973/64.97809. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.89204/64.53367. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.47235/64.07542. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.02934/63.61251. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 65.58359/63.15362. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 65.12755/62.70866. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 64.72585/62.27597. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.13761/61.84529. Took 0.34 sec\n",
      "Epoch 15, Loss(train/val) 63.58987/61.42253. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.10402/61.07867. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.78940/60.80512. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.54536/60.61656. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.15500/60.46492. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.00569/60.33826. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 61.64196/60.23156. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 61.56145/60.14272. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.37409/60.08917. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 61.28536/60.06129. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.01528/60.03440. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.99417/59.99300. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 60.96867/59.93116. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.84189/59.86072. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.69586/59.79010. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 60.67065/59.70084. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.61495/59.58452. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.52482/59.45523. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.42184/59.27442. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.39407/59.04180. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.14365/58.81147. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 60.31224/58.57794. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.17802/58.38585. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.17230/58.24669. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 59.95858/58.15314. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.00816/58.08393. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.86858/58.01553. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 59.89375/57.96679. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.69486/57.92233. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.76002/57.87022. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.80587/57.82992. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.68180/57.79090. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 59.45853/57.75371. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.52285/57.71991. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.43095/57.68212. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.43372/57.65000. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.26415/57.62253. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.30668/57.58358. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.45833/57.53553. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.15741/57.49398. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.15239/57.47862. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.28489/57.42235. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.10920/57.35667. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.03907/57.30338. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.03853/57.20131. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.08470/57.13206. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.97156/57.10532. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 58.96176/57.07363. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.81086/57.01155. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 58.74454/56.94485. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.62218/56.88339. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.55004/56.82771. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.63476/56.77299. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 58.40404/56.68484. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.32876/56.58022. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.30688/56.53093. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.28941/56.45622. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.26219/56.43010. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.14476/56.28220. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.94201/56.09618. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.92443/56.09504. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 57.87215/55.99101. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.72960/55.86812. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 57.62178/55.71729. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.71253/55.65016. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.60517/55.62863. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 57.40050/55.46965. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 57.45086/55.34025. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.16319/55.25750. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.19310/55.14651. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.12550/55.10327. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 57.09547/55.05253. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.07574/54.99298. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.87671/54.89801. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.81619/54.80992. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.79040/54.77082. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.79117/54.57793. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 56.73353/54.55722. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.55105/54.43842. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.25037/54.42631. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.41865/54.25900. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 56.45490/54.34654. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.42525/54.24386. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.16097/54.24276. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 56.27495/54.14102. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.08606629658238704\n",
      "Epoch 0, Loss(train/val) 70.65503/70.23490. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.39672/70.13239. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.29871/70.03658. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.14817/69.93474. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 69.96582/69.82717. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.79400/69.71777. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.61737/69.60394. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.39818/69.48737. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.23859/69.35861. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.07964/69.22490. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.88103/69.09018. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.65459/68.94943. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 68.39329/68.80272. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.11709/68.65040. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.95349/68.49628. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.81194/68.34487. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.56200/68.19254. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 67.43595/68.04216. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.12677/67.89311. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.04232/67.74509. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.75498/67.59641. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.63931/67.45018. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 66.44590/67.30551. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 66.35388/67.19411. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.20382/67.11105. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.04456/67.03038. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.86459/66.95525. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.63119/66.88675. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.63036/66.82742. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.48594/66.77454. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.31197/66.74167. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.19567/66.71140. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.17546/66.68503. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 64.98515/66.65793. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 64.80950/66.63628. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.90615/66.61819. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.74306/66.61642. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.72874/66.62232. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.57252/66.62380. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.55549/66.59401. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.52400/66.59090. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.37415/66.58746. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.24510/66.56594. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.30675/66.55361. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.21639/66.54807. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.17903/66.54736. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.04623/66.55968. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 63.98757/66.58257. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.95015/66.61514. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.88851/66.65672. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 63.86709/66.70803. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.96722/66.71944. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.82840/66.78397. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.65872/66.83859. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.57149/66.88862. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.59070/66.96500. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.64647/67.03276. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 63.61567/67.10583. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.46825/67.17223. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 63.42964/67.25424. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.29961/67.35913. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 63.16049/67.44298. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 63.11405/67.55105. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.95966/67.64995. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.23449/67.73104. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.92699/67.83907. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.95765/67.92265. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 62.85341/67.96514. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 62.78001/68.01632. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.75883/68.05748. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.53048/68.11501. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.53498/68.11642. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.50280/68.15993. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.48226/68.16102. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 62.53717/68.20794. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.46402/68.21885. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.29315/68.22125. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.39212/68.24287. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.32311/68.20108. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 62.07966/68.22061. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.14663/68.21620. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.17590/68.22330. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.97875/68.21642. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.99621/68.27904. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 61.86574/68.21497. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.90591/68.21748. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.81972/68.21539. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.69658/68.25177. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.78060/68.22528. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.68077/68.23366. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.64019/68.21130. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.64921/68.22678. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.47995/68.19712. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.32082/68.16241. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 61.58183/68.28293. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.61203/68.17907. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.58236/68.38559. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 61.71142/68.16457. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.36733/68.26045. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.54821/68.14367. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.008104408984731078\n",
      "Epoch 0, Loss(train/val) 70.31976/69.75166. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.10536/69.75509. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.94983/69.78030. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.77870/69.79700. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.62617/69.79847. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.41534/69.79278. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.19543/69.77965. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.95793/69.74660. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.68147/69.70206. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.45552/69.64289. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.24831/69.55768. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.99305/69.45061. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.70140/69.32100. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.42087/69.16975. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 67.11125/68.99800. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.77585/68.79564. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 66.51386/68.55553. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.23665/68.28496. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.89584/67.99100. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.56632/67.69423. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.25774/67.40429. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 64.92585/67.11122. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.74351/66.81787. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.50932/66.52421. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.28854/66.25277. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.10569/66.01926. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.03226/65.83317. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 63.88590/65.65182. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 63.70619/65.51158. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.62135/65.39037. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.61900/65.29321. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.37604/65.17776. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 63.37794/65.08118. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.28457/65.00892. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 63.34723/64.96052. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.34037/64.91296. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.08664/64.88046. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 63.09764/64.84652. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 63.08921/64.82413. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.02839/64.82192. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.89389/64.82521. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.94057/64.84222. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.83555/64.85533. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 62.94005/64.88319. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.73770/64.92749. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.66875/64.96896. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.61932/64.99200. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.51181/65.01916. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.54254/65.03852. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.44492/65.06867. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 62.57679/65.12961. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.31712/65.17730. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.42687/65.22292. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.30983/65.26034. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.31289/65.25958. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 62.26060/65.29433. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.17769/65.30822. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.09513/65.38753. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.07740/65.38864. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.07019/65.38081. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.97241/65.37163. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 61.87917/65.42879. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.88539/65.38097. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 62.08801/65.44597. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.86201/65.47984. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.75370/65.63832. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 61.79472/65.59635. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.74774/65.67617. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.79259/65.60693. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.80960/65.67797. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.56463/65.52515. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.69951/65.59821. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.74873/65.61059. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.54772/65.78720. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.63563/65.58391. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.56127/65.73407. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.50718/65.64415. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 61.63516/65.75470. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.46094/65.58494. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.56160/65.83470. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.24525/65.60400. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.56871/65.81405. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.36685/65.56112. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.41760/65.86587. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 61.25887/65.69051. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 61.39314/65.98624. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 61.32951/65.74026. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 61.34243/65.95174. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 61.23830/65.85514. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.34601/65.98157. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 61.19028/65.84378. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.21125/66.04472. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.22250/65.83192. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 61.23250/66.06472. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.27142/65.88120. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 61.13252/66.03809. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.09008/65.92177. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 61.14398/66.08022. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.90710/65.87431. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 61.18078/66.10815. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.025861699363244256\n",
      "Epoch 0, Loss(train/val) 70.49738/71.90301. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.30583/71.89020. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.04440/71.89133. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.78103/71.90472. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.57471/71.91633. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.35347/71.93613. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.03828/71.96558. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 68.83665/71.99419. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.60626/72.00522. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.34572/72.00523. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 68.08213/72.00703. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.80983/72.00874. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 67.59870/72.00819. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.32197/72.00169. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.97993/71.98383. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.66758/71.96744. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.43371/71.96185. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.17504/71.98705. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.95985/72.04234. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.69061/72.12119. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.51496/72.18900. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 65.27053/72.27592. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.19738/72.35478. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.99202/72.42680. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 64.95689/72.48856. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.68762/72.54780. Took 0.34 sec\n",
      "Epoch 26, Loss(train/val) 64.60388/72.60999. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.53132/72.65106. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.47720/72.68727. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.29010/72.72207. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.21056/72.76887. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.13316/72.80138. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.07742/72.81377. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.02800/72.81993. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.90178/72.83093. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.71199/72.84026. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 63.79208/72.87353. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.68464/72.87972. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.58140/72.85716. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.53347/72.84715. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.46658/72.83199. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 63.26538/72.82528. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 63.30361/72.80183. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 63.19240/72.77946. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.07675/72.75934. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.94725/72.75838. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.05035/72.72919. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.92117/72.69735. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.79088/72.64153. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.72427/72.60863. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 62.67543/72.55930. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 62.60762/72.51399. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.51049/72.43394. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.49030/72.36523. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.30612/72.30933. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.20921/72.23723. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 62.25771/72.12236. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.93367/72.09782. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.95679/72.08332. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.82882/71.95027. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.80419/71.88869. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 61.64623/71.85468. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 61.41393/71.79553. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.30154/71.79317. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.32031/71.83155. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 61.02893/71.74885. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.03367/71.70239. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 60.90176/71.85326. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.79651/71.86945. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.72109/71.86311. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.57602/71.93951. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.61228/71.89026. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 60.45535/71.89571. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.42728/71.70368. Took 0.34 sec\n",
      "Epoch 74, Loss(train/val) 60.45460/71.84210. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.25646/71.75158. Took 0.34 sec\n",
      "Epoch 76, Loss(train/val) 60.20726/71.79883. Took 0.34 sec\n",
      "Epoch 77, Loss(train/val) 60.13618/71.77758. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 60.16400/71.56314. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.04573/71.62448. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 60.07806/71.42159. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.08271/71.43892. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.84118/71.25325. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.89022/71.26118. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.74933/71.30270. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 59.69331/71.29768. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.72087/71.10741. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.68761/71.09309. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.62900/71.19701. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.40706/70.94572. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.44592/70.99870. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.49442/70.96040. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 59.41108/70.98378. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.36308/71.06367. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.16100/71.04498. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 59.13216/71.04909. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.27947/71.00497. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 58.99993/71.07262. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.08526/71.02232. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 59.08169/71.04180. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.018266554145039696\n",
      "Epoch 0, Loss(train/val) 71.06234/71.17445. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.92562/71.08538. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.74430/70.99846. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.58604/70.91234. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.35124/70.83080. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.19628/70.74472. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.02423/70.64970. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 69.83296/70.54432. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.62991/70.42513. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.50462/70.28665. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.26643/70.12429. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.06398/69.93669. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.80787/69.71938. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.56811/69.48637. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.32766/69.26152. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.08207/69.05556. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.84561/68.87601. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 67.58781/68.72691. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.37960/68.60546. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.22411/68.50226. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 67.13379/68.40692. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.87953/68.31223. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.71248/68.21765. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.58740/68.11845. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.46985/68.01785. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.26809/67.91617. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.15645/67.82360. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.90081/67.73936. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 65.69736/67.66869. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.56458/67.60371. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.40989/67.54179. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.22500/67.47845. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 65.00465/67.40117. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 64.80312/67.31325. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.59947/67.23122. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 64.31614/67.17179. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.23118/67.13928. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 64.08147/67.12727. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.93046/67.11390. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.91781/67.11906. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 63.71385/67.12424. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.55515/67.10594. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.58075/67.05976. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.47781/67.03130. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 63.42672/67.02097. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.21019/66.99747. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.21399/66.93705. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.07163/66.87137. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 63.03155/66.83405. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 62.97605/66.85078. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 62.85018/66.83685. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.83672/66.84010. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.71215/66.76427. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 62.60599/66.67589. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.60644/66.61887. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 62.52205/66.59290. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.52574/66.56408. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.36379/66.46750. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.27116/66.43023. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.30196/66.41518. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.19007/66.34055. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.12760/66.35416. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 62.04246/66.32298. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.93443/66.26553. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 61.84171/66.19916. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.92249/66.18832. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.78119/66.15400. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.71466/66.10492. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.63187/66.05102. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.49185/66.00054. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 61.53142/65.98648. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.30423/65.99501. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.41434/65.93617. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.29782/65.85980. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.30594/65.82860. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.20421/65.78383. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 61.07444/65.73586. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 61.09857/65.68918. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.05018/65.70882. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.00254/65.62607. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 60.95785/65.59628. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.06985/65.54843. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.86699/65.50301. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.89873/65.47042. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.68156/65.49345. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.68683/65.45179. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.77990/65.42621. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 60.67496/65.28403. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.58539/65.32396. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.55466/65.18439. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.36915/65.19122. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 60.43771/65.11270. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.33844/65.09783. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.39942/65.03829. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 60.22101/65.01618. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 60.21191/64.99084. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 60.02585/65.02391. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.13837/64.99981. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.08865/65.08802. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.10955/64.83076. Took 0.31 sec\n",
      "ACC: 0.5, MCC: -0.00700902994282404\n",
      "Epoch 0, Loss(train/val) 71.40067/72.13712. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.11462/71.78722. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.91808/71.45602. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.74399/71.10992. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.45052/70.76958. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.29073/70.45241. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.10264/70.13245. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.84911/69.82697. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.63129/69.54389. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 69.39592/69.27230. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.16920/69.01423. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.93113/68.77248. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.84998/68.54971. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.61394/68.33532. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.40007/68.12653. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.20557/67.90989. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 68.04568/67.69003. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 67.87653/67.46355. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.64177/67.21741. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.47323/66.94598. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.31512/66.65012. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.01366/66.32328. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.73265/65.96596. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 66.51935/65.60251. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.34205/65.23199. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 66.24386/64.85144. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.02759/64.47677. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.74631/64.09262. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.64718/63.73239. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.46388/63.38281. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.40933/63.03126. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 65.21378/62.67641. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.08426/62.27885. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.94258/61.84471. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.69543/61.38556. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.52213/60.92149. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.15539/60.49523. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.24133/60.15194. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.91633/59.89929. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.90588/59.80977. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.70876/59.67671. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.48761/59.42151. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 63.34598/59.33307. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.22632/59.24879. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.25877/59.05247. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.11714/59.03297. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.98153/59.02487. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.81538/58.87868. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.77143/58.66862. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.79020/58.61369. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.76441/58.44948. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.60233/58.54053. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.53805/58.20387. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.45431/58.22231. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.28393/58.07439. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 62.09759/57.85273. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.08522/57.81835. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.11452/57.69218. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.83123/57.53554. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.86302/57.44436. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.72042/57.36869. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.74398/57.28135. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.60663/57.27716. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.56091/57.15325. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.41415/57.05335. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.34731/56.95195. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.31929/57.20886. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.27203/56.97937. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 61.28202/56.72188. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 61.17979/56.75577. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.18431/57.02902. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.03560/56.83546. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.01581/56.68953. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.89737/56.58387. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.86114/56.60383. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.93431/56.67755. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.78992/56.81395. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 60.79912/56.68299. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.74364/56.61610. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 60.54733/56.60881. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 60.56029/56.61577. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 60.42370/56.74372. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.43898/56.70893. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.38728/56.69730. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.44591/56.65425. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 60.32977/56.64540. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.44017/56.54551. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 60.38041/56.65975. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.21261/56.77625. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.29648/56.72509. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.29537/56.63370. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.02311/56.66010. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.08207/56.72439. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 60.10114/56.87510. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 60.11150/56.88628. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.05962/56.74990. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.00539/56.56520. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.06885/56.69400. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.95358/56.94147. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 59.99247/56.77930. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.03688555567816588\n",
      "Epoch 0, Loss(train/val) 70.81393/70.94312. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.57884/70.73882. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.33320/70.53674. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.17131/70.33758. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.99585/70.14410. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.80323/69.95066. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.57256/69.74609. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.35191/69.52365. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.13230/69.28294. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.88559/69.01904. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.61749/68.72750. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.40622/68.40932. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.06739/68.06899. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.75144/67.69737. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.48639/67.29517. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.05651/66.86148. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.85841/66.39784. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.35991/65.89229. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.94229/65.33370. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 65.52814/64.72642. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.10487/64.06365. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.47235/63.37994. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.96883/62.70437. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.43310/62.08399. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.98319/61.52837. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.55672/61.08857. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.33571/60.77358. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.04005/60.49849. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.79832/60.22501. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.51000/59.96632. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 61.50577/59.73731. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.14732/59.52149. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.06812/59.32751. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.92890/59.16819. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 60.88995/59.05569. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.64863/58.96254. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 60.43290/58.88029. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.33477/58.83878. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.27196/58.82450. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.08893/58.83358. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.12406/58.84612. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.89410/58.86987. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.03626/58.95386. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.86745/58.98513. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.75345/58.96903. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.61374/58.96804. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 59.59671/58.88842. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.65326/58.90377. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.46050/58.89728. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.61542/58.82481. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.37414/58.82853. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.51058/58.83140. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.43968/58.79326. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.32634/58.73648. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.17857/58.75228. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.17708/58.67791. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.08453/58.66684. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.04535/58.59309. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.09868/58.53631. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.00991/58.40108. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 58.94551/58.29782. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.86659/58.17569. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.83667/57.98880. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.82093/57.98088. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 58.72372/57.92984. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.65383/57.73438. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.74417/57.84655. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.60310/57.74477. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.66513/57.59289. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.50849/57.72208. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.47838/57.61281. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.53354/57.38826. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.76023/57.71455. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.50299/57.45454. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.41998/57.45404. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.36618/57.61280. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.24477/57.34306. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.42916/57.42738. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.27813/57.49862. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.32090/57.27827. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 58.40127/57.47224. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.31336/57.33613. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 58.11882/57.40396. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.10259/57.25745. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.05498/57.25395. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.86376/57.44575. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.13381/57.23751. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.92298/57.21996. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.90757/57.23396. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.02195/57.29919. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.96664/57.25569. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.84456/57.25077. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.88622/57.30594. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.75482/57.21721. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.77083/57.23683. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.75627/57.26024. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.74753/57.27277. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.63016/57.26280. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 57.75203/57.27380. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.64911/57.42892. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.01654402580491889\n",
      "Epoch 0, Loss(train/val) 71.01785/71.03938. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.83164/70.97096. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.64567/70.90585. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.46664/70.84164. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.30373/70.77337. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.12807/70.69982. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.91947/70.61501. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.74676/70.51035. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 69.59513/70.38721. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.31680/70.24515. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.17268/70.08205. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.90641/69.89730. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.63142/69.69505. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.40742/69.47627. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.09205/69.24400. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.70613/69.01455. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.46587/68.79593. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 66.99203/68.59162. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.42832/68.41090. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.97228/68.22828. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.49223/68.01975. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.06071/67.75052. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.75632/67.39777. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 64.19494/66.98045. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.80957/66.52770. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.53036/66.09132. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.21158/65.71989. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.03181/65.38171. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.89202/65.07186. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.82704/64.81331. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.70720/64.60589. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.52339/64.41879. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.53261/64.23479. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.48509/64.09081. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.25355/63.95605. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.02515/63.82734. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.02751/63.72019. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.99304/63.60639. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.90035/63.50045. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 61.85496/63.39760. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.69241/63.28710. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.66895/63.18386. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.51169/63.06377. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.39763/62.94920. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.24422/62.80084. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.22655/62.65772. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.23306/62.65482. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.05884/62.50179. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.99228/62.39644. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.85781/62.23269. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.89918/62.21049. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.81705/62.10977. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.77645/62.17157. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.75871/61.99944. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 60.69720/62.03119. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.68729/62.05375. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 60.49118/61.97225. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.53046/61.99079. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.42226/61.96424. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.32799/61.89341. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.32101/61.90546. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.36346/61.87388. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.15331/61.94226. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 60.12212/61.83284. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.13674/61.83949. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.06753/61.80958. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.13533/61.85526. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.99252/61.78712. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 60.05372/61.77301. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.76829/61.76343. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.73662/61.77794. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.92145/61.73185. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 59.89707/61.77808. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.85669/61.70504. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.57708/61.75899. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.79088/61.73785. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 59.72071/61.70266. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.58019/61.71222. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.72361/61.68938. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.51354/61.73248. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.71587/61.69204. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.26681/61.74558. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.57725/61.64938. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.45256/61.73350. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.17907/61.68211. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.26096/61.65099. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.32146/61.66611. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.35977/61.63693. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.18823/61.64347. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.18886/61.70095. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.00926/61.61252. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.16590/61.65259. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.06950/61.66739. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.14596/61.61224. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.97972/61.64184. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 59.05470/61.62010. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.98669/61.68639. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.91184/61.62736. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.90856/61.64188. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.10251/61.62068. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.06950480468569159\n",
      "Epoch 0, Loss(train/val) 70.14632/70.44212. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.97186/70.34954. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.74917/70.25546. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.54995/70.15275. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.32565/70.03455. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.06839/69.90900. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.86147/69.76888. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.56161/69.62453. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.35177/69.46897. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.21405/69.30478. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.97064/69.13802. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.75529/68.96573. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.57117/68.79245. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.34232/68.61641. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.07790/68.44389. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.00174/68.26297. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.79880/68.08227. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.62464/67.90350. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.46438/67.73082. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.29667/67.54938. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 66.19028/67.35740. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.03903/67.17019. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 65.94319/66.96680. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.80173/66.76163. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.65259/66.55566. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 65.49649/66.34384. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.35372/66.13459. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.23217/65.91494. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.21622/65.69012. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.10097/65.46252. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 64.89659/65.24129. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 64.88142/65.01706. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.73082/64.80719. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.72809/64.64716. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 64.67806/64.50046. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 64.42459/64.35195. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.34973/64.19641. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.43043/64.04675. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.32159/63.90662. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.25081/63.75012. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 64.07112/63.60645. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 64.10344/63.47592. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.93268/63.36652. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.91531/63.26852. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.80013/63.16801. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.61303/63.06046. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 63.68307/62.91770. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.50692/62.78823. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.45854/62.64222. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.37600/62.54250. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.47515/62.44262. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.21463/62.35744. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.08359/62.27288. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.18319/62.21334. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.08148/62.14875. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 62.88904/62.06217. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.87575/62.08680. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 62.83060/61.99119. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.76408/61.99691. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.65320/61.93233. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.69173/61.96598. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.48478/61.90859. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.48427/61.90145. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.42692/61.90797. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.24011/61.81955. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.32921/61.89517. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.13227/61.84392. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.28326/61.86385. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.04343/61.89099. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.07745/61.88094. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.99734/61.86977. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.02696/61.86546. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.08403/61.83211. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.84353/61.80059. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.96662/61.82699. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.65896/61.87060. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 61.81438/61.77476. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.77272/61.69610. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 61.60565/61.72266. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.59235/61.71421. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.61591/61.71983. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.22846/61.69893. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.45474/61.68745. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.31265/61.65611. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.33390/61.74109. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.20927/61.54516. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.18852/61.60827. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.30543/61.64597. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.18724/61.55557. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.20088/61.58246. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.07756/61.56245. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.20685/61.34403. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.87591/61.59343. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.82197/61.52893. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 60.66713/61.31003. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.76310/61.33900. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.67267/61.06168. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.61094/60.86002. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.54400/61.05019. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.48978/60.88727. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.14977900439610384\n",
      "Epoch 0, Loss(train/val) 70.15882/69.21512. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.93548/69.01617. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.70612/68.81166. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.48284/68.60926. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.29701/68.40089. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.03429/68.18702. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.79906/67.96932. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.62250/67.74852. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.37849/67.51678. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.08961/67.28299. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.97418/67.04298. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.74126/66.80398. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.45966/66.56718. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.22250/66.33802. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.99544/66.11787. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.77193/65.90186. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.54302/65.69707. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.30898/65.50333. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.08493/65.31640. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 65.73370/65.13574. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.57600/64.96352. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.15699/64.80061. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.87454/64.65029. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.55299/64.52489. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 64.38613/64.42870. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.02974/64.34900. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.78478/64.28503. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.65918/64.23869. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.48507/64.18355. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 63.32846/64.14084. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.12202/64.08868. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.01370/64.13598. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.89989/64.14838. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.63897/64.20470. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.67079/64.22803. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.66134/64.28690. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.38811/64.28442. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.29280/64.31667. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.21924/64.35902. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.06618/64.38297. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.86469/64.42284. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.02172/64.46365. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.89016/64.48011. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.77256/64.50386. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.71516/64.49913. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.68309/64.51068. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.63335/64.53410. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.53881/64.52437. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.51829/64.53585. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.27179/64.52822. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.34069/64.53885. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.19318/64.53715. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.21558/64.56860. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.21802/64.52603. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.14457/64.50955. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.07810/64.45660. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.94245/64.47298. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.97378/64.39250. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.83258/64.42201. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.84685/64.34741. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.78832/64.36884. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.54981/64.31816. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.59700/64.26132. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.57018/64.22403. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.40636/64.26313. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.23549/64.21078. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.33013/64.19862. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.26691/64.14749. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.16839/64.14307. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.24301/64.08961. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.16082/64.06275. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.15401/64.13200. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.94855/64.05764. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.94585/64.05973. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.89963/64.08583. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.86257/64.06888. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.85380/64.09497. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.79780/64.06614. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.83971/64.01664. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.81318/63.93834. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.88137/63.91241. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.70753/64.00931. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.61443/63.95637. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.64504/63.97927. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.46516/63.86084. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.55068/63.85246. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.49110/63.87068. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.39080/63.87637. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.35721/63.87033. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.33603/63.82353. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.29350/63.88588. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.24302/63.93938. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.31892/63.81230. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.01090/63.96303. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.10799/63.86985. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.13347/63.88551. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 59.11895/63.96861. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.04902/63.78355. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.05678/63.86130. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.11217/63.89635. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.008104408984731078\n",
      "Epoch 0, Loss(train/val) 71.21357/71.28500. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.83405/71.00264. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.47519/70.71760. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.07366/70.42509. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.61430/70.11618. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.25633/69.79456. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.75131/69.45678. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.30304/69.09486. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.74151/68.69679. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.06127/68.23645. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.37865/67.72037. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 65.73242/67.17036. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 64.97223/66.60237. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 64.35243/66.03877. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 63.79591/65.47617. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 63.17876/64.94949. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 62.67479/64.45938. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.30473/64.03973. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 61.89541/63.70529. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 61.39481/63.39917. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 61.19859/63.11390. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 60.86539/62.83496. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 60.63015/62.55371. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 60.40464/62.26955. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.14533/62.00385. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 59.69508/61.76433. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 59.69294/61.54807. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 59.44618/61.35356. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 59.27586/61.22721. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 59.06272/61.13749. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 58.99357/61.05532. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 58.95665/60.97662. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 58.85740/60.88914. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 58.73293/60.78839. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.67017/60.69588. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 58.47794/60.61250. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.43538/60.51033. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 58.44305/60.39547. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 58.11378/60.29984. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 58.15111/60.16756. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 58.12104/60.07644. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.11631/59.95453. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 57.88026/59.85839. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 57.75715/59.77748. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 57.62565/59.68623. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 57.38774/59.59332. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 57.25961/59.47325. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.26186/59.33455. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.16699/59.24293. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 57.08672/59.16639. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 56.92928/59.05511. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 56.80485/58.97649. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 56.85705/58.97982. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 56.74363/58.96301. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 56.62875/58.89536. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 56.63621/58.88380. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 56.45713/58.84225. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 56.41372/58.78507. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 56.47643/58.82465. Took 0.34 sec\n",
      "Epoch 59, Loss(train/val) 56.34089/58.78727. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 56.16160/58.82602. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 56.21203/58.76200. Took 0.34 sec\n",
      "Epoch 62, Loss(train/val) 56.35325/58.82130. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 56.10348/58.78053. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.01361/58.76111. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 55.95656/58.79681. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 55.92971/58.78497. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 55.91882/58.76195. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 55.85721/58.71742. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 55.88944/58.71495. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 55.74151/58.73886. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 55.69172/58.69328. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 55.58417/58.67921. Took 0.34 sec\n",
      "Epoch 73, Loss(train/val) 55.48922/58.60629. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 55.53926/58.57518. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 55.33726/58.57295. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 55.48381/58.57460. Took 0.34 sec\n",
      "Epoch 77, Loss(train/val) 55.41599/58.61053. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 55.16488/58.60993. Took 0.34 sec\n",
      "Epoch 79, Loss(train/val) 55.21321/58.64508. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 55.14078/58.62926. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 55.05680/58.60636. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 54.99728/58.63698. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 55.07252/58.66100. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 55.18124/58.61610. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 54.79659/58.70713. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 54.93880/58.60948. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 54.83758/58.63401. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 54.74729/58.66544. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 54.71284/58.60351. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 54.73592/58.66594. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 54.53478/58.70829. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 54.51134/58.67290. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 54.55130/58.75723. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 54.77148/58.77328. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 54.55303/58.75313. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 54.50520/58.84826. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 54.39287/58.67522. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 54.32228/58.80464. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 54.42706/58.75883. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.1947010445067672\n",
      "Epoch 0, Loss(train/val) 69.73974/69.17152. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.44203/68.86157. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.13797/68.53778. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 68.80027/68.18661. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.47739/67.80537. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.11425/67.37173. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.69644/66.85890. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.06705/66.22762. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 66.42944/65.43709. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 65.63882/64.47086. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 64.68005/63.32093. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 63.87410/62.09289. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 62.95717/60.90164. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 62.19712/59.89237. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 61.57954/59.16140. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 61.11056/58.64298. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 60.66858/58.23359. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 60.42431/57.90253. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 60.20279/57.63225. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 59.84822/57.42004. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 59.67851/57.23902. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 59.47973/57.06773. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 59.42459/56.90153. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 59.28890/56.73803. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 59.10723/56.57544. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 58.85103/56.41565. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 58.73643/56.25016. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 58.60209/56.07792. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 58.48310/55.91491. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 58.40667/55.75294. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 58.08250/55.59204. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 58.03982/55.42609. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 57.98101/55.27009. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 57.84864/55.10170. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 57.63829/54.90359. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 57.42993/54.68774. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 57.35881/54.47855. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 57.37032/54.28577. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 56.97577/54.10226. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 56.99803/53.89571. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 56.72271/53.82780. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 56.66887/53.56994. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 56.53911/53.66689. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 56.46440/53.28669. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 56.27296/53.39926. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 56.22715/53.16930. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 56.15824/53.25564. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 56.08828/53.05543. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 56.01716/52.96451. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 55.82988/52.90278. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 55.75298/52.88853. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 55.63528/52.62902. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 55.71536/52.73616. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 55.56385/52.46567. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 55.44508/52.61321. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 55.34458/52.33772. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 55.42161/52.50299. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 55.25111/52.22126. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 55.12580/52.38507. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 55.20507/52.11917. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 55.08641/52.15021. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 54.92764/52.10894. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 54.85712/52.06319. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 54.92738/51.83152. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 54.79144/51.95585. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 54.80945/51.85656. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 54.77102/51.75748. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 54.61164/51.62252. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 54.59450/51.68810. Took 0.34 sec\n",
      "Epoch 69, Loss(train/val) 54.63463/51.57639. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 54.55064/51.49340. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 54.42445/51.40610. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 54.37473/51.35336. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 54.32301/51.42188. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 54.33985/51.11495. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 54.23777/51.20383. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 54.11237/51.12822. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 54.08867/50.99815. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 54.13321/51.13971. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 53.94872/50.82371. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 53.92222/50.85719. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 53.83318/50.80833. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 53.90103/50.72106. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 53.95961/50.72811. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 53.56255/50.61911. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 53.68673/50.55428. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 53.64669/50.46973. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 53.44281/50.39576. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 53.39170/50.36932. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 53.47249/50.24564. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 53.39951/50.26453. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 53.50870/50.16404. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 53.34905/50.11481. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 53.27664/50.00000. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 53.30989/50.01266. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 53.20720/50.00205. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 53.17672/49.92573. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 53.11785/49.89354. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 53.00659/49.80570. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 52.87468/49.84137. Took 0.32 sec\n",
      "ACC: 0.390625, MCC: -0.1886680513554908\n",
      "Epoch 0, Loss(train/val) 70.93033/71.65640. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.61906/71.45631. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.37254/71.26582. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.09832/71.08380. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.86707/70.91212. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.59131/70.74002. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.37417/70.56817. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.12262/70.39281. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.86295/70.20836. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.51131/70.00866. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.25811/69.79273. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.97041/69.54910. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.58971/69.27821. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.27642/68.97104. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.93694/68.63647. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.59398/68.26772. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.21322/67.86339. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.70590/67.43158. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.29041/66.96870. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.81600/66.48538. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.48282/65.98323. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.97213/65.46128. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.52305/64.90724. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.99341/64.34106. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.56160/63.83957. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.20588/63.36608. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.72004/62.94293. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.24496/62.58524. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.99507/62.27523. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.51678/62.02708. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 60.33348/61.83295. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 60.18398/61.66088. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 60.12527/61.49767. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.05282/61.36129. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.80262/61.22159. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.69804/61.09326. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.62940/60.97633. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.36851/60.87204. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 59.35801/60.76561. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 59.33821/60.67391. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.18678/60.58096. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.08659/60.47625. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.04585/60.37986. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.88950/60.29565. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.70642/60.23203. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 58.72601/60.17962. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 58.58761/60.11526. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.47676/60.05159. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.46932/59.96585. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.25912/59.85621. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 58.30097/59.74444. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.13167/59.63464. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.02947/59.52381. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.95966/59.42730. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.97078/59.33138. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.64177/59.26521. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.58562/59.17099. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.47899/59.11823. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.52785/59.05667. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.28619/59.01384. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.46731/58.93658. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.50997/58.89165. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 57.33534/58.84022. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 57.49585/58.80350. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.31460/58.76931. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.25796/58.73728. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.13700/58.69635. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.08689/58.65642. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.20601/58.63715. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.09060/58.60868. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.93876/58.59236. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.05033/58.56142. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.96717/58.54552. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.96681/58.52605. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.88138/58.51980. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.88305/58.51715. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.78860/58.50569. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.74369/58.44768. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 56.55231/58.42739. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 56.71476/58.39788. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.55494/58.37384. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.52500/58.34325. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.61531/58.33142. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.53380/58.42949. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.54363/58.44942. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.41559/58.43722. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.51176/58.45752. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.22152/58.27814. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.28634/58.32187. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.19771/58.39865. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.17981/58.53051. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.34345/58.22815. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.99752/58.42760. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.22280/58.25151. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.10601/58.33739. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.05164/58.39335. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 56.08139/58.40211. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.08764/58.46794. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 56.04877/58.47027. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.80145/58.53252. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.09341218537003596\n",
      "Epoch 0, Loss(train/val) 70.07490/70.85670. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.74316/70.59843. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.45637/70.30236. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.10902/69.97447. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.69140/69.60728. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.24285/69.20496. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.77916/68.77865. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.30567/68.30844. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 66.80906/67.79557. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.35088/67.26550. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 65.89666/66.73354. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 65.52457/66.21918. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.20568/65.72288. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 64.74928/65.26540. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 64.54105/64.85204. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.09895/64.48335. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.87949/64.14646. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.54386/63.84757. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 63.31593/63.58992. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.09078/63.39783. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.87700/63.23698. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 62.55317/63.09209. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.53797/62.97927. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.22676/62.88724. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.16465/62.83551. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 61.86394/62.86739. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 61.77259/62.92175. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.68512/62.82783. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.53774/62.76838. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.30193/62.74413. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.29751/62.79609. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.12850/62.80804. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.00142/62.77131. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.14532/62.75387. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 60.97566/62.74161. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.88945/62.74405. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 60.82471/62.71266. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.73049/62.71339. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.53392/62.72091. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.62719/62.74292. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.60267/62.69003. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 60.51278/62.67977. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.47500/62.68383. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.30958/62.64915. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.31538/62.56882. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.25499/62.46179. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.08884/62.37741. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.12673/62.28205. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.97113/62.16339. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 59.87194/62.08168. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.81835/61.99757. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.69862/61.91289. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.69307/61.84412. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.54396/61.76231. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.44872/61.69677. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 59.54854/61.67719. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.28149/61.65693. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.23464/61.53577. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.30915/61.47039. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.28078/61.40674. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.08266/61.35687. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.23020/61.29903. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.12023/61.22773. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.96487/61.17067. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 58.86993/61.11191. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.77647/61.11937. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.71274/61.07899. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.81558/61.05394. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 58.81136/61.00362. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.56765/60.97998. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.60518/60.92378. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.55348/60.96094. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.54204/60.83255. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.44573/60.89218. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 58.37729/60.81520. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.44738/60.79507. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.40866/60.73436. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.22730/60.74720. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.25954/60.66581. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.08167/60.61680. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.05460/60.56900. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.04368/60.54935. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.01987/60.49920. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.02094/60.55085. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.95503/60.41586. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.75812/60.44157. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.89936/60.36801. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.98378/60.33248. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 57.77921/60.38760. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.79065/60.25882. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 57.94792/60.23227. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.78038/60.26695. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.72343/60.18662. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.83210/60.14228. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.72620/60.13769. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.67484/60.11002. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.57538/60.10198. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.30660/60.08556. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.55429/60.07598. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.36945/60.05119. Took 0.32 sec\n",
      "ACC: 0.390625, MCC: -0.09400555777286816\n",
      "Epoch 0, Loss(train/val) 71.08536/70.61379. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.84240/70.43521. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.61042/70.25290. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.35546/70.06763. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.13243/69.87595. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.86602/69.67535. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.61857/69.46181. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.33438/69.23161. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.07487/68.97688. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.76666/68.69165. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.42916/68.37181. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.09743/68.01507. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.62390/67.61716. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.29321/67.19092. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.93268/66.75494. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.42973/66.32684. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.00530/65.91542. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.75850/65.55436. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.31452/65.24034. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.84578/64.96290. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.65250/64.72684. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.25883/64.55776. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.81108/64.43190. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.60764/64.36548. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.38997/64.31514. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.99146/64.26602. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.77913/64.20818. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.62340/64.14314. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.49204/64.06516. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.27576/63.98138. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.35257/63.91848. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.15645/63.87491. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.04899/63.82580. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.80639/63.77754. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.90277/63.73439. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.90691/63.68184. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.79617/63.62711. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.57558/63.58791. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.79041/63.54446. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.49592/63.51391. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.52170/63.50805. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.31928/63.49982. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.26076/63.55031. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.26566/63.66624. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.23818/63.86759. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.17173/63.99218. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.07721/64.08703. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.33455/64.20408. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.94938/64.24933. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.83418/64.19849. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.61149/64.09513. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.93189/64.16939. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.78616/64.19178. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.65592/64.15211. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.68151/64.01037. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.68436/64.09016. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.58310/64.06579. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.52861/64.07170. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.46899/64.08552. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 60.49707/64.14065. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.37367/64.13071. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.28100/64.26337. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.31876/64.29105. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.32157/64.25135. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.44246/64.31406. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.01220/64.25452. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.27906/64.21622. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.40935/64.17354. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.02939/64.15788. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.99719/64.05119. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.88143/64.07211. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.05652/64.03731. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.78878/64.12781. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.92891/64.12327. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.84069/63.96948. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.74332/63.94589. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.79496/63.83999. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.65880/63.83770. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.56130/63.67971. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.71022/63.82713. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.61890/63.75594. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.63581/63.66795. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.62252/63.58994. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.56389/63.60582. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.53784/63.66447. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.38716/63.33923. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.34511/63.63215. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.31421/63.40244. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 59.41876/63.70910. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 59.41911/63.45564. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.26380/63.63146. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.41245/63.22333. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.26281/63.98958. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.04801/63.53438. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.05393/63.40693. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.22769/63.42473. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.10370/63.57647. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.95790/63.28666. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.85897/63.52252. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.82050/63.25382. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.038395331411533284\n",
      "Epoch 0, Loss(train/val) 72.45884/72.18293. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 72.08958/72.00012. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 71.85546/71.81095. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 71.47901/71.61349. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 71.14331/71.40174. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.73204/71.17390. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 70.37474/70.93401. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.90786/70.68187. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.42810/70.42205. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.95414/70.16414. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.46526/69.91063. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.03980/69.66553. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.52651/69.43124. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.21575/69.20663. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.79059/68.98592. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.32089/68.77218. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.89294/68.57400. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.45486/68.40491. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.04285/68.26448. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.82289/68.19307. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 64.42957/68.13461. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.30597/68.08318. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.10987/68.03265. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.99134/67.98232. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.59711/67.92761. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.48213/67.85690. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.29249/67.76257. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.14301/67.63383. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.15868/67.45931. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.99719/67.23986. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.83613/67.03850. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.51419/66.90948. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.31207/66.85760. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.19645/66.79732. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.94939/66.66652. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.78617/66.42056. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.42560/65.85043. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.28120/64.84667. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.13760/63.93191. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.68288/63.39327. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.74375/63.00175. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 60.53382/62.74648. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.50521/62.58673. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.42372/62.45345. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 60.27878/62.35194. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.19617/62.26585. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.16657/62.19188. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.16171/62.14706. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.23622/62.12262. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.12171/62.09969. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.96759/62.06033. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.80830/62.03373. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.07460/62.00718. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.91060/61.99651. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.85667/61.96087. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.70760/61.92196. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.58196/61.89439. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.63744/61.87994. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.67474/61.86937. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.61976/61.85634. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.64052/61.83364. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 59.49982/61.83096. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.41899/61.83402. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.21291/61.79941. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.30061/61.78391. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.32840/61.78256. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.25116/61.76224. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.23869/61.74230. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.19760/61.73008. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 59.18474/61.71021. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.05470/61.69340. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.14759/61.65513. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.01010/61.65960. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.94999/61.62180. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.71321/61.61174. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.65596/61.59792. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.76905/61.60237. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.60931/61.59838. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.68541/61.61131. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.51282/61.60023. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.57755/61.60623. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.53200/61.60497. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.48084/61.65691. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.43135/61.62413. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.45893/61.65940. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.36485/61.65824. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.47376/61.64903. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.34175/61.60573. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.25728/61.63522. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.31359/61.68437. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.28556/61.74392. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.24482/61.73014. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.97753/61.76446. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.90789/61.77607. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.10332/61.72836. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 57.90228/61.71957. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.71792/61.72077. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.93876/61.72146. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.81577/61.73316. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.73211/61.69520. Took 0.33 sec\n",
      "ACC: 0.5, MCC: 0.0991956236158312\n",
      "Epoch 0, Loss(train/val) 70.13260/69.13333. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.90977/69.00677. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.65826/68.85554. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.41389/68.67731. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.17467/68.46830. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.93296/68.22533. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.61384/67.94608. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.37940/67.63618. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.03702/67.28622. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.66665/66.89891. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.25094/66.46436. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.77682/66.00099. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.28587/65.52779. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.78062/65.05206. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.08495/64.58527. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.58075/64.15443. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.09821/63.75454. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.61519/63.39309. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 63.10999/63.09039. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.73217/62.90188. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.20195/62.74464. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.69419/62.58811. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 61.51434/62.45438. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.06752/62.33105. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 60.90415/62.22198. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 60.82385/62.12263. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.62421/62.02230. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.52047/61.93444. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.41930/61.86116. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.34259/61.81501. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.26717/61.77167. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 60.39359/61.74156. Took 0.34 sec\n",
      "Epoch 32, Loss(train/val) 60.23122/61.68092. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.07101/61.64458. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 60.13021/61.59249. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.95640/61.53907. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.95970/61.51103. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 59.78862/61.43718. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.86306/61.36587. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 59.69405/61.29713. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 59.64961/61.16029. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.54210/61.09518. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.46976/61.01151. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.53169/60.88052. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.47412/60.80048. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 59.06869/60.73668. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 59.38901/60.64741. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.98607/60.64031. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.05872/60.60445. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.93908/60.53065. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 58.98946/60.45708. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.83554/60.48215. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 58.71932/60.45964. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 58.69156/60.42245. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 58.71559/60.33356. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.57698/60.36089. Took 0.34 sec\n",
      "Epoch 56, Loss(train/val) 58.59828/60.36135. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.65317/60.30220. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 58.41658/60.25187. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.38834/60.26850. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 58.19553/60.22623. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.19537/60.22984. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.20537/60.20483. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.15900/60.17267. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 58.03995/60.08665. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.99644/60.06531. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.91339/60.05127. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.01011/59.95827. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 57.75487/59.94489. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.87064/59.91111. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.64080/59.86300. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.67251/59.87924. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 57.53032/59.81900. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 57.50907/59.77925. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.30989/59.76637. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.40402/59.77837. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.51904/59.73852. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 57.12455/59.67356. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 57.14122/59.65735. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.00051/59.56783. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 57.06560/59.56422. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.71057/59.46672. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.91298/59.34542. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.98728/59.28438. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.68564/59.16741. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.57887/59.11829. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.46461/59.02100. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.37959/58.89515. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 56.31045/58.79457. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 56.45896/58.59742. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.23640/58.51433. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.11092/58.53187. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.16739/58.32026. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.13579/58.21272. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.05357/58.03994. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.02955/57.83883. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.68500/57.73934. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.80515/57.46335. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.77054/57.45537. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.64173/57.28777. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: 0.1817895918059258\n",
      "Epoch 0, Loss(train/val) 70.21389/70.63596. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.95515/70.43023. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.63485/70.21052. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.33870/69.97187. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.00571/69.71381. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.67196/69.44341. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.30391/69.17393. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.99053/68.90413. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.70214/68.64034. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.38344/68.37227. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.00579/68.10397. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.64547/67.82582. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.32384/67.55884. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.94137/67.28510. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.56791/67.01026. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.16325/66.74714. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.82707/66.50958. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.55346/66.31358. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.27413/66.14051. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.96569/65.97805. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.82341/65.82170. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.55539/65.64944. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.31357/65.49691. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.11947/65.34950. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.92193/65.21616. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.66702/65.07015. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.46989/64.92294. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.28758/64.79037. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.16786/64.67290. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.91507/64.57699. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 61.81830/64.49770. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.52519/64.42427. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.45158/64.35309. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.38487/64.27011. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.19237/64.19383. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.00131/64.12799. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.98144/64.05106. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.91820/63.98615. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.84671/63.91117. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.60549/63.83916. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.75784/63.77598. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.65004/63.72066. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 60.48143/63.67341. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.45552/63.61334. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.38270/63.57074. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.21553/63.53407. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.22470/63.50427. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.01103/63.48387. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.94073/63.51533. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.81604/63.64625. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.57936/63.92528. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.45773/64.32732. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.34023/64.62943. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.13288/64.27673. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 58.99667/64.71524. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.88720/64.75604. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 58.72477/64.84768. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.74595/64.67604. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.59050/64.77384. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.23717/64.51395. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.22481/64.62112. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.79937/64.52074. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 57.88429/64.45654. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.80947/64.33189. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.80210/64.26994. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.64204/64.14908. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.41372/64.08310. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.33302/64.00264. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.12945/63.93846. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.08203/63.84803. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.25535/63.74702. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.05287/63.69136. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.94646/63.65720. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.95116/63.60555. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.88569/63.48875. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.60235/63.46410. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 56.57294/63.40282. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.63732/63.32602. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 56.27508/63.36015. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.42513/63.24305. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 56.44702/63.18197. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.43984/63.13798. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.21192/63.09349. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.22932/63.05841. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.35668/63.05515. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.12155/62.98532. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 55.99690/63.01538. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.10197/62.91905. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 56.14094/62.97641. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.78350/62.91589. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 55.89395/62.91959. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.12640/63.02102. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.91018/62.53991. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.71128/62.93649. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.81573/62.52155. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.50746/62.75819. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.62503/62.56547. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.61080/62.75063. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.50763/62.52071. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.28635/62.75294. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.22034498977496858\n",
      "Epoch 0, Loss(train/val) 69.14006/69.35154. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 68.82595/69.19222. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 68.44617/69.01796. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 68.08263/68.82359. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 67.73494/68.60477. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 67.27545/68.35237. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 66.89314/68.06844. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 66.38091/67.74142. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 65.95085/67.38473. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 65.43803/66.99989. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 64.89946/66.59363. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 64.43017/66.18147. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 63.97315/65.80473. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 63.48901/65.43988. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 63.18768/65.07924. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 62.77635/64.71913. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 62.22149/64.36551. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 61.76201/64.03391. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 61.39146/63.74084. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 61.10776/63.49934. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 60.66390/63.28547. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 60.54325/63.12387. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 60.32189/62.98813. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 60.04099/62.85349. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 59.88052/62.72035. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 59.76266/62.60163. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 59.56709/62.48373. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 59.49947/62.36487. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 59.13474/62.24503. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 59.08741/62.13081. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 58.99086/62.02071. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 58.94863/61.91069. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 58.74202/61.79878. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 58.71646/61.69273. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.66548/61.58840. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 58.57122/61.48730. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.48664/61.39535. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.42123/61.30991. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.44290/61.22056. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 58.30348/61.14032. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 58.33089/61.06445. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.15136/60.98789. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 58.10794/60.91785. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 58.12408/60.84967. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.13600/60.77692. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.98435/60.70898. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 57.85250/60.65086. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.93185/60.60903. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.69641/60.56309. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 57.54541/60.51645. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 57.74592/60.47737. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.71398/60.44553. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.57981/60.41789. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 57.40299/60.39091. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 57.51295/60.35807. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 57.27633/60.33128. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.35519/60.32712. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 57.41313/60.28888. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.25717/60.28051. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 57.23601/60.26048. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.04126/60.25891. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 56.91753/60.25470. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.17630/60.26607. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 56.96888/60.27453. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 56.97150/60.28610. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.76164/60.27911. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 56.86532/60.30246. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 56.71090/60.31996. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 56.93037/60.34397. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 56.79999/60.35360. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.66683/60.33432. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.57253/60.34048. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 56.52667/60.31871. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 56.62119/60.32603. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.58445/60.29894. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.52135/60.33137. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 56.35918/60.33463. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.36648/60.32731. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.36801/60.33893. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.20655/60.35808. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 56.31062/60.41590. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.27387/60.43377. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.24380/60.40261. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.22260/60.44616. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.06941/60.50431. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.14567/60.55076. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 55.94264/60.61650. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 55.98516/60.58432. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.90346/60.39953. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 55.71719/60.57057. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 55.79972/60.44804. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.69151/60.16219. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.54250/59.99172. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 55.54833/59.91126. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.53115/59.84960. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.52833/59.82705. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.37227/59.71204. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.43301/59.71142. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.11114/59.70215. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 54.95944/59.73409. Took 0.33 sec\n",
      "ACC: 0.5, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) 71.03730/70.77561. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.85618/70.62776. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.69674/70.47332. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.50185/70.31488. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.39893/70.15430. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.22424/69.98496. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 70.02339/69.81440. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.86607/69.63705. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.74042/69.45132. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.47405/69.25212. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.33772/69.04390. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.15508/68.82957. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.90718/68.60603. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.77940/68.37737. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.59647/68.15424. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.41778/67.93271. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 68.12597/67.71309. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.94911/67.48922. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.73030/67.27283. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 67.50954/67.05906. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.33839/66.85284. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.06894/66.64927. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.87861/66.44785. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 66.64898/66.26128. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 66.54052/66.08278. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.46578/65.92479. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.26592/65.77318. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.24527/65.63579. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.15306/65.51712. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 66.10299/65.42009. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.94900/65.31570. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 65.91077/65.21120. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.74016/65.12656. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 65.76046/65.05518. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.58391/64.99065. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.51298/64.92207. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 65.39701/64.87107. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.32445/64.82747. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 65.20565/64.79229. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 65.21158/64.73624. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.94021/64.68534. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.89601/64.64391. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.83430/64.60565. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.81300/64.56666. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.57804/64.53559. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 64.53825/64.50565. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.40235/64.47723. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 64.28934/64.45127. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.36900/64.41828. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.11294/64.36831. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 64.12659/64.31428. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 64.06482/64.25398. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.91521/64.19630. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 63.79834/64.14053. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.57570/64.09502. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.68629/64.06783. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 63.66401/64.06647. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.64553/64.06664. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 63.46738/64.07684. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.36391/64.06015. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.40495/64.01145. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 63.23004/63.92964. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 63.22723/63.85468. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 63.11108/63.83337. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.96337/63.75491. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.00441/63.70973. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.83346/63.63460. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.80457/63.54724. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.67748/63.47423. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 62.79301/63.31398. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 62.58158/63.20586. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.55957/63.19110. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 62.33856/63.10162. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.40008/63.03107. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.37175/63.03903. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.09751/63.04026. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.11960/63.00086. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.07304/62.92486. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.98737/62.88546. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 61.79478/62.87963. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 61.82818/62.90849. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.83745/62.91865. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.64555/62.89368. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 61.80927/62.92710. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.65885/62.89074. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.63609/62.91632. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 61.60061/62.89869. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.46834/62.88041. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 61.56353/62.87191. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 61.48507/62.85952. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 61.35594/62.83620. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 61.24264/62.90202. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.23523/62.84454. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.32303/62.92051. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.18130/62.88670. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 61.09766/62.94326. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.86625/62.99227. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.01980/63.01106. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.86113/63.12967. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.94011/63.14495. Took 0.32 sec\n",
      "ACC: 0.609375, MCC: 0.18262637225482492\n",
      "Epoch 0, Loss(train/val) 70.91199/71.08426. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.63672/70.73974. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.35417/70.39122. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.06652/70.03333. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.74706/69.64719. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.41093/69.22747. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.08665/68.76770. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.76160/68.28062. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.38815/67.77029. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.99277/67.23383. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.52793/66.69011. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.10249/66.14225. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.70593/65.60938. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.25937/65.12172. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.66723/64.70001. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.43608/64.31861. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.99106/63.93415. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.48893/63.53614. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.02068/63.09389. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.55983/62.60737. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.20360/62.10247. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.57212/61.70238. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 62.31017/61.37236. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 62.02660/61.07719. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.82146/60.81347. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.56929/60.56688. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.34187/60.33828. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.20689/60.13744. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.11265/59.95831. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.06471/59.78581. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 61.10784/59.61919. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.92610/59.47077. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.75328/59.31416. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.71547/59.17076. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.70298/59.05068. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.75286/58.93122. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.49756/58.82201. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.47402/58.70117. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.48794/58.58769. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.26246/58.48075. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.25840/58.37295. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 60.24664/58.27103. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.12673/58.17067. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.19152/58.07573. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 60.00102/57.97651. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.94185/57.88339. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.69410/57.79283. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 59.89425/57.70785. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.70003/57.62929. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.68874/57.55133. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.51123/57.47787. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.55036/57.39869. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.54273/57.32224. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.39101/57.25244. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.16338/57.18710. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.24799/57.09953. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.06160/57.00630. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.81203/56.88365. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.87318/56.76477. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.72841/56.69318. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.57195/56.62608. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.52068/56.57185. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.34708/56.52916. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.51398/56.51962. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.33257/56.42701. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 58.43741/56.48293. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.36094/56.38993. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.90992/56.43769. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.17525/56.30216. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.68120/56.36702. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.74346/56.20217. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.65787/56.16887. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 57.84358/56.00022. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.68153/55.80420. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.33975/55.79932. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.41063/55.67121. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.12034/55.53159. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.45264/55.65946. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 57.36980/55.34552. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 57.12987/55.44698. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.87453/55.32560. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.18623/55.20637. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.65035/55.29052. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.76761/55.24220. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.78005/55.23172. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.51863/55.12844. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.41065/55.01314. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.29809/54.97109. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 56.39365/55.06005. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.29705/55.02304. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.36229/54.82797. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.27882/54.75222. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 56.13792/54.90054. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.95349/54.74947. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 56.04542/54.66185. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.04600/54.61143. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.88341/54.57708. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.87914/54.58675. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.98066/54.50200. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.94057/54.57600. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.13211031413252305\n",
      "Epoch 0, Loss(train/val) 70.70731/71.02315. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.43405/70.80549. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.24495/70.60072. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.00242/70.39187. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.76309/70.17885. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.57322/69.96323. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.33685/69.72718. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.11748/69.49445. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.88134/69.25000. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.68460/68.99954. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 68.44082/68.73859. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.20228/68.47749. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 67.86130/68.20040. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.63420/67.91647. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.35125/67.62366. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.07180/67.32629. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.85658/66.99980. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 66.60552/66.64591. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.31407/66.26797. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.86110/65.84811. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 65.61571/65.40962. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 65.31687/65.05722. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.12570/64.78603. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.94422/64.57031. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.83491/64.41432. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.64977/64.30808. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.52044/64.17068. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.57719/64.06751. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.37795/63.93542. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.46424/63.83735. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 64.24232/63.72511. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.16270/63.59472. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 64.07453/63.39791. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.98529/63.22766. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.80676/63.08633. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.80882/63.01344. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 63.70786/62.96004. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.72045/62.88762. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.53402/62.85487. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.70319/62.80112. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.56230/62.76395. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.38461/62.74403. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.39507/62.73451. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 63.33259/62.71934. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.28261/62.69610. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 63.18602/62.73246. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 63.12396/62.74712. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.11999/62.78409. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.92866/62.80849. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.97512/62.83959. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.94677/62.80584. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.93502/62.74412. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.00210/62.82394. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.92580/62.81595. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.74511/62.79165. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 62.73072/62.76560. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 62.81291/62.88123. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.57899/62.89635. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.54528/62.83556. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.47281/62.83139. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.39816/62.89535. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.32259/62.92805. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.27676/62.79255. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.22046/62.74651. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.27179/62.75420. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.12630/62.67680. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.21376/62.59255. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.94576/62.70319. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.11290/62.74639. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 61.88162/62.49505. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.86814/62.61589. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.78443/62.48020. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.73462/62.46881. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.77632/62.54839. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.73745/62.54056. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.59398/62.24125. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.54111/62.56733. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.53532/62.26857. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.53865/62.42843. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.33469/62.46725. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.36239/62.45770. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.32330/62.24751. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.24921/62.33089. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.18214/62.34611. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.17048/62.33780. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.98793/62.33143. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.98091/62.29627. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.80540/62.29086. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.87446/62.41700. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.88588/62.19636. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.82806/62.42602. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.66664/62.10358. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.71122/62.28077. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.55548/62.37481. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.55800/62.25740. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.53072/62.20390. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 60.45240/62.37748. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.35748/62.26740. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.32291/62.32068. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.35315/62.37036. Took 0.31 sec\n",
      "ACC: 0.515625, MCC: 0.06052275326688024\n",
      "Epoch 0, Loss(train/val) 70.28525/70.60399. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.00781/70.35899. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.72129/70.10887. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.48178/69.84749. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.18109/69.57513. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 68.94576/69.28853. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.62482/68.97523. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.28284/68.63975. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.88557/68.27477. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.46905/67.87866. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.03253/67.46636. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.58058/67.05430. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.22114/66.65062. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.77094/66.26218. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.30165/65.87272. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.95008/65.47768. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.51784/65.07773. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 64.19703/64.68532. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.07609/64.30849. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.71499/63.97307. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.42664/63.66890. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.04720/63.33868. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.91008/62.99199. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.65852/62.71545. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.42629/62.47156. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.31380/62.26001. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.00168/62.04471. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.88258/61.84726. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.68981/61.69567. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.55078/61.56379. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 61.47734/61.47563. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.17637/61.36123. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 61.10421/61.23708. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.16793/61.12177. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.75321/60.95766. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.70235/60.84474. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.65337/60.73385. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.59686/60.63263. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 60.30277/60.53643. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.34010/60.46085. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.17021/60.37373. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 60.11620/60.28876. Took 0.30 sec\n",
      "Epoch 42, Loss(train/val) 60.05744/60.21947. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.83736/60.08668. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.80281/59.96701. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.71016/59.85712. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.58752/59.75481. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.64900/59.66644. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 59.54884/59.56321. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 59.41623/59.46358. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.40778/59.35590. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.38109/59.25322. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 59.18303/59.19692. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.14460/59.14643. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.10096/59.08750. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.04291/59.00788. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.02707/58.94394. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.89303/58.85716. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.76517/58.83583. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.96743/58.79305. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.77299/58.72391. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.64690/58.65677. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.72155/58.66470. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.66626/58.64559. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.68559/58.60157. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 58.44698/58.57017. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.50726/58.57219. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 58.43114/58.52952. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.44538/58.47320. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.36512/58.43430. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.23399/58.42793. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.29929/58.43081. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.18743/58.39878. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.06988/58.35498. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.06991/58.31367. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.14740/58.26881. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.07852/58.21460. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 57.91943/58.22410. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.94796/58.15334. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.84074/58.19445. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.86345/58.19256. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 57.87463/58.18666. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 57.67275/58.14600. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.72232/58.17329. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.66365/58.12425. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.75015/58.15869. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.64521/58.14483. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.65942/58.15050. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 57.52227/58.12764. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.32293/58.06863. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.48266/58.14533. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.35834/58.08407. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.26413/58.17242. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.30050/58.09119. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.27207/58.10278. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 57.20337/58.08240. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.42847/58.09537. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.22873/58.05221. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 57.12906/58.12165. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.15723/58.01133. Took 0.32 sec\n",
      "ACC: 0.421875, MCC: -0.12022678317975014\n",
      "Epoch 0, Loss(train/val) 70.74663/71.64040. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.64686/71.60777. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.52259/71.57338. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.43000/71.54263. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.31983/71.51736. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.17361/71.49140. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.03595/71.46712. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.95169/71.44705. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 69.82331/71.42249. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.65631/71.40627. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.58243/71.38962. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.41736/71.37231. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.27473/71.35350. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.11134/71.32652. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.01261/71.30154. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.80094/71.27193. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 68.67061/71.23736. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.57378/71.20783. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.48190/71.18417. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.31382/71.15701. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 68.22926/71.13625. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 68.11744/71.12539. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 68.02002/71.12302. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.85084/71.12421. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 67.79276/71.13464. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 67.75393/71.14373. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 67.64318/71.14780. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 67.51849/71.14677. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 67.30828/71.14364. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 67.30302/71.14151. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 67.15667/71.13977. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 66.99631/71.14555. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 66.97664/71.14520. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 66.92753/71.14085. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 66.76371/71.13840. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 66.63307/71.13039. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 66.50050/71.10264. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 66.36751/71.07449. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 66.43065/71.03720. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 66.29989/70.99963. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 66.22421/70.96240. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 66.18581/70.90326. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 66.12809/70.83327. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 66.01973/70.78973. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 65.97739/70.74785. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 65.91099/70.67580. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 65.87512/70.61352. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 65.57333/70.56376. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 65.62250/70.54399. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 65.60617/70.50258. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 65.51790/70.47495. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 65.42838/70.44049. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 65.38645/70.41411. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 65.31713/70.38201. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 65.25348/70.35558. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 65.09375/70.32421. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 65.04489/70.28400. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 65.03471/70.24173. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 64.97949/70.22602. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 64.95640/70.20364. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 64.92658/70.16124. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 64.78589/70.13944. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 64.87042/70.12318. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 64.66707/70.06988. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 64.52764/70.02115. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 64.66029/69.97202. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 64.55009/69.90514. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 64.42023/69.84541. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 64.34328/69.75208. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 64.16043/69.64763. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 64.24568/69.57092. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 64.18282/69.47192. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 64.12941/69.34787. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 64.07369/69.26253. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 63.96219/69.14024. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 63.73901/69.03520. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 63.59604/68.94543. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 63.81267/68.87756. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 63.52007/68.81053. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 63.47998/68.72955. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 63.58607/68.68941. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 63.38124/68.65120. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 63.25416/68.54763. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 63.28265/68.46210. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 63.15208/68.40512. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 63.15985/68.36089. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 63.05826/68.40807. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 62.94699/68.18637. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 63.00152/68.15836. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 62.88681/68.23135. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 62.88006/68.14653. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 62.91714/68.03215. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 62.89010/67.97078. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 62.63900/68.05380. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 62.65053/67.94702. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 62.68898/67.83879. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 62.50875/67.99120. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 62.41573/67.83064. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 62.47564/67.73579. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 62.40140/67.90543. Took 0.32 sec\n",
      "ACC: 0.40625, MCC: -0.006137372169362703\n",
      "Epoch 0, Loss(train/val) 70.09370/70.03525. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.86649/69.90855. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.65943/69.77614. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.45148/69.64872. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.23814/69.51284. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.00441/69.36093. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.71560/69.18708. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.41801/68.97953. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.11383/68.73169. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.71983/68.44619. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 67.38690/68.13220. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.93005/67.80869. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.61816/67.49567. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.22489/67.19005. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.88305/66.89908. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.54805/66.61124. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.07554/66.31409. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.72282/66.04066. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.35979/65.85965. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.02323/65.70836. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.59423/65.57421. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.29183/65.45791. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.06115/65.36066. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.78099/65.27576. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.47144/65.20016. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.34667/65.13982. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.37473/65.09087. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.19627/65.03925. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.95071/64.99451. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.86934/64.95786. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.85655/64.92403. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.82108/64.89314. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.77027/64.86462. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.46320/64.83101. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.44164/64.80369. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 61.49601/64.78604. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 61.35895/64.77498. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.21190/64.74396. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.12390/64.71422. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.11025/64.69720. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.13065/64.68137. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 60.95540/64.68221. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 60.91778/64.68195. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.01575/64.67519. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 60.80842/64.67489. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.79541/64.67378. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.80284/64.68756. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.68859/64.67975. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.73065/64.66737. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.53551/64.67474. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.67407/64.69129. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.41636/64.68896. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.49684/64.68733. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 60.49587/64.69277. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.36287/64.67012. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.24230/64.64134. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.21975/64.60803. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.31811/64.59761. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.11270/64.58782. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 60.11616/64.59018. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.22360/64.55602. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.08920/64.51218. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.07229/64.51202. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.03512/64.51693. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.88360/64.49541. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.93904/64.46856. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.81304/64.39923. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 59.84233/64.37032. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.67818/64.33854. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.73017/64.37924. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.79153/64.34419. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 59.66459/64.27434. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.70964/64.20213. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.53406/64.16042. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.52812/64.12341. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 59.45088/64.11746. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.56112/64.09102. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.55087/64.05013. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.53003/64.04234. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.40925/64.04405. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 59.25610/64.00691. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 59.23515/63.96575. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 59.33789/63.88196. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.21603/63.88084. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.20753/63.90122. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.08208/63.92087. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.24350/63.86070. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.19019/63.85098. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.13585/63.81216. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.13814/63.80499. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 59.05337/63.76528. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.02111/63.77404. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 58.99986/63.75093. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.95467/63.71713. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.92564/63.67134. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.69209/63.69171. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.95468/63.71221. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.73876/63.73021. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.94278/63.69619. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.85029/63.65208. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.02858745114794397\n",
      "Epoch 0, Loss(train/val) 70.06089/69.69552. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.83520/69.54099. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.49784/69.38123. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.19169/69.20949. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.78792/69.01550. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.39562/68.79685. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.95965/68.54935. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.54093/68.26239. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.11212/67.94305. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 66.81288/67.60381. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.41933/67.25329. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 66.15835/66.88384. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.73598/66.50250. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.40595/66.11988. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.01202/65.75358. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.76913/65.39562. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.49730/65.04897. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.17514/64.70953. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.95134/64.37428. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.68931/64.06654. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.31122/63.75390. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.08942/63.46476. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 62.78438/63.15837. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 62.34641/62.87566. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.23991/62.64822. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 61.93993/62.47588. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.83801/62.34324. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.48354/62.24340. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.47755/62.15977. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.40179/62.08613. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.24637/62.00814. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.20457/61.92971. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.18713/61.83768. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.09074/61.74445. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.95681/61.65334. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.81414/61.57429. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 60.75562/61.50763. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 60.67011/61.44818. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.68984/61.38481. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.58393/61.31879. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.40179/61.27253. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.38015/61.20557. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.27248/61.12880. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.19413/61.09217. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.06055/61.05455. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 59.99485/60.96980. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.94023/60.92199. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 59.83346/60.85516. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.91476/60.76397. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.58087/60.71903. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.68204/60.61972. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.41876/60.56638. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.35541/60.49022. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.33644/60.39487. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.28546/60.32965. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.10993/60.22412. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 59.11691/60.14370. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.83791/60.10280. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.81127/60.05934. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.81336/59.99614. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.68507/59.95938. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.66270/59.94370. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 58.55053/59.87363. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.43885/59.86938. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.56139/59.82312. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.30566/59.84753. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.09893/59.79828. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.97933/59.81884. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.13355/59.77523. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.92799/59.69632. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.78340/59.61501. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.64481/59.50790. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.70798/59.37860. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.47136/59.33389. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.43482/59.25926. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.31502/59.17597. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.13545/59.08141. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.14528/58.95886. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 57.16931/58.92223. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.87397/58.83827. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.88318/58.80153. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.69796/58.77696. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.69415/58.60618. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.58013/58.69888. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.49499/58.61390. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.49727/58.64148. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.37677/58.68858. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.21889/58.63674. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 56.10665/58.53683. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.10380/58.49749. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.14736/58.51497. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.16812/58.25362. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.96565/58.19332. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.78445/58.27909. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.74328/58.16788. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.89678/58.05036. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.60505/57.97643. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.69421/58.02335. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.63120/57.80590. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.58503/57.55073. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: -0.018122009407318746\n",
      "Epoch 0, Loss(train/val) 70.53676/70.41961. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.34652/70.35896. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.20188/70.30812. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.06850/70.25858. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.91294/70.20314. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.79428/70.13406. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.62260/70.05345. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.44027/69.95846. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.22081/69.82668. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.99473/69.66273. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.73756/69.48569. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.50407/69.29919. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.20485/69.11805. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.92643/68.95242. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.66059/68.80507. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.34671/68.66766. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.18651/68.54280. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.95301/68.42355. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.69455/68.29784. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 66.54687/68.15508. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.31285/68.00418. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.18279/67.84385. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.93005/67.65850. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.78580/67.44678. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.41890/67.21896. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 65.39930/67.00441. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 65.12623/66.76979. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 64.99286/66.53867. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.80842/66.31975. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.49257/66.13255. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.45831/65.97050. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 64.35892/65.82276. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.23345/65.70668. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 64.12624/65.61127. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.14267/65.54060. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.98021/65.48313. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.03487/65.43679. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.89740/65.39380. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.71831/65.35428. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.75489/65.31486. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.59240/65.27113. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.68385/65.26051. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.60438/65.24609. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.47493/65.21973. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.54160/65.19143. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 63.51252/65.15809. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.43567/65.11769. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 63.46453/65.06947. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.51574/65.04401. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.56863/65.00839. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.34168/64.99068. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.21395/64.97125. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.37676/64.95467. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 63.14977/64.94296. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.24189/64.93966. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 63.17774/64.92918. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.16466/64.91562. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 63.07840/64.88233. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.05936/64.84339. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 63.12672/64.82519. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.92988/64.81008. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.91873/64.81799. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 63.01812/64.81249. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.97526/64.79667. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.89774/64.80677. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.00176/64.78001. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.92735/64.73618. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.96974/64.72033. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.82495/64.67905. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.95534/64.65723. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 62.74096/64.64549. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 62.76452/64.62206. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.72782/64.59505. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.75296/64.57120. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 62.86550/64.54646. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 62.66612/64.52464. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 62.73402/64.52392. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.66688/64.53019. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.69984/64.55545. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.58834/64.57418. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.63222/64.58029. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.40412/64.57489. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 62.63771/64.54895. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 62.51528/64.55315. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.47089/64.55103. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.61248/64.56909. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.43734/64.59633. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 62.55216/64.59157. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 62.49118/64.59991. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 62.42152/64.59849. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 62.46784/64.57683. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 62.45247/64.56540. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 62.43926/64.60619. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 62.36536/64.65890. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 62.30820/64.68654. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 62.32737/64.63290. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 62.32899/64.64718. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 62.32234/64.67947. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 62.12034/64.67884. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 62.29830/64.67957. Took 0.32 sec\n",
      "ACC: 0.421875, MCC: -0.08921796698522012\n",
      "Epoch 0, Loss(train/val) 70.33547/69.59589. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.10127/69.47186. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.87326/69.33517. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.60658/69.18509. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.35601/69.02009. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.05436/68.83677. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.72658/68.63486. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.38997/68.41617. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.03003/68.17821. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.70559/67.92728. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.30492/67.67017. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.94644/67.39480. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.57566/67.11615. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.22370/66.83148. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.93212/66.55033. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.58720/66.26712. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.19634/65.98419. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.95309/65.68450. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.62083/65.35644. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.34451/65.02737. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.14939/64.72130. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.74961/64.44839. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.50613/64.19013. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 63.14114/63.95928. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.95821/63.76946. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.58375/63.60451. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.44567/63.45638. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.06628/63.32018. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.02108/63.19054. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 61.82004/63.07285. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.65682/62.94921. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.51213/62.81533. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.50210/62.68750. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.40153/62.54461. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.17740/62.39561. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.99634/62.22849. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.02625/62.06875. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.72912/61.91205. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.69633/61.77269. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.66091/61.63765. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.52890/61.50120. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.43414/61.36402. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.26948/61.24699. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.24009/61.12802. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.22434/61.02501. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.14998/60.93671. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.95377/60.84586. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.93640/60.78802. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.72354/60.74078. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.71199/60.68530. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.60427/60.64128. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.60447/60.61078. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.49216/60.60014. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.61633/60.61160. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.44211/60.62587. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.29947/60.63150. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 59.31975/60.64968. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.19299/60.66374. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.29785/60.69258. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.04116/60.71072. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.12906/60.72056. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.11639/60.72864. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.86933/60.75050. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.83593/60.76955. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.07940/60.79306. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.76257/60.81227. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.88160/60.82394. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.65846/60.83280. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.68916/60.86866. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.77492/60.89842. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.60981/60.90852. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.65938/60.93942. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.50669/60.94484. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.49928/60.95195. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 58.55022/60.96968. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.34484/60.97573. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 58.44751/60.97957. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.48605/60.99443. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.36738/61.00426. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.33033/61.03328. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.20468/61.04610. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.21114/61.05983. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 58.24326/61.06520. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.18543/61.06795. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.00978/61.05126. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 58.17695/61.05787. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.01904/61.05469. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.10951/61.05505. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.03394/61.08359. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.90346/61.11207. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.93653/61.13911. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.71123/61.13542. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.84930/61.13992. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.87049/61.18173. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.72948/61.18676. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.80001/61.16206. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.80178/61.17526. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.57577/61.22103. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.59390/61.24691. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.62953/61.27222. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.1229526932416184\n",
      "Epoch 0, Loss(train/val) 72.15694/71.44450. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.81828/71.26342. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.51061/71.06453. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 71.16376/70.81809. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.78453/70.51354. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.31461/70.14503. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.86939/69.74863. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.38458/69.35308. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.84350/68.97260. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.44940/68.60565. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 68.06101/68.32037. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.72867/68.08476. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 67.34332/67.87769. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.08707/67.70813. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.81844/67.56712. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.50241/67.47337. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.29057/67.38891. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.89649/67.30135. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.63101/67.20859. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.19313/67.09193. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.90360/66.93749. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.56800/66.69373. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.32963/66.33152. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.93842/65.83031. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.69495/65.24433. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.46714/64.71481. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.14888/64.36533. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.00235/63.85629. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.67163/63.61654. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.69171/63.33164. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.58083/63.25718. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.43792/62.96528. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.29377/62.96725. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.29477/62.69544. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 62.17620/62.67750. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.11695/62.40396. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.99927/62.38173. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.87376/62.17104. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.92774/62.15704. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.66107/61.98006. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.77647/61.97858. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.63934/61.81816. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.59152/61.77352. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.46478/61.63292. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.41461/61.58072. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.43443/61.47150. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.40982/61.43212. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.32103/61.29513. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.25314/61.26014. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.21120/61.18001. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.02698/61.09800. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.14532/61.04886. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.78170/60.96251. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 60.99486/60.93710. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.90398/60.86533. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.90030/60.76529. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.78757/60.76078. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.75070/60.70832. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.63750/60.59466. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.58465/60.70367. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.70622/60.51952. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.48198/60.58020. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.38586/60.48192. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.39522/60.39421. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.38815/60.35947. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.38200/60.34948. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.27402/60.31140. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.25666/60.30746. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.29385/60.26480. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.12806/60.17196. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.04980/60.33841. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.16470/60.12540. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.02945/60.28775. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.99861/60.17088. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.07043/60.09425. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.94395/60.19649. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.00678/60.03664. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.00972/60.26998. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.98343/59.97033. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.73597/60.31457. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.80909/59.98975. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 59.76439/60.18073. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.80209/60.00317. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.74635/60.05235. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.79878/60.07303. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.66403/59.90071. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.47886/60.29727. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.60352/59.85829. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.66321/60.20039. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.46674/59.90091. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.64329/60.16329. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.43927/60.00595. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.46207/59.97821. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 59.48070/60.17983. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.55408/59.84366. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.44975/60.52070. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.34499/59.86460. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 59.40054/60.56356. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 59.43631/59.94267. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.18494/60.47267. Took 0.32 sec\n",
      "ACC: 0.421875, MCC: -0.18127975016079304\n",
      "Epoch 0, Loss(train/val) 70.21338/70.29117. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.78436/70.06623. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.42065/69.81854. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.09433/69.56924. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.71776/69.32249. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.38481/69.06586. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.96757/68.82076. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 67.66664/68.58636. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.33993/68.36189. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 66.97236/68.15067. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.65851/67.95891. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.32300/67.79025. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.86173/67.64230. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.64948/67.51084. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 65.23249/67.37824. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.69940/67.23030. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.38920/67.05787. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.11000/66.86794. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 63.82258/66.66682. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.53870/66.50839. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.33781/66.36028. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.10215/66.24604. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.85481/66.13525. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.68465/66.04759. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.59919/65.97653. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.58958/65.92442. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.28845/65.88728. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.19272/65.84904. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.11087/65.81565. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.91777/65.78035. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.92100/65.74752. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.76337/65.72143. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.75205/65.67779. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.63911/65.64426. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.55957/65.62401. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.42865/65.61157. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.24845/65.57281. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.20875/65.53745. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.13627/65.51835. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.06474/65.48586. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.04964/65.44752. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.87755/65.41179. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.83952/65.37820. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.88257/65.32008. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.60130/65.28599. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.54699/65.24800. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.46520/65.19958. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.54017/65.13801. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.41924/65.10950. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.28672/65.09042. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.37324/65.07977. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.25879/65.06987. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.25673/65.03044. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.03968/65.00976. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.98805/64.98087. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.01835/64.95773. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.03651/64.92079. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.97356/64.88297. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.94587/64.86392. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.76228/64.84714. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.92297/64.83780. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.68417/64.80566. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.64290/64.79150. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.59306/64.79898. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.48916/64.77435. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 59.50811/64.76620. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.38717/64.74348. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.28061/64.73418. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.25854/64.71569. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 59.06215/64.70909. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.03670/64.70592. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.98741/64.69607. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.97240/64.66933. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.77002/64.64487. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.88375/64.62206. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.85293/64.60484. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.73506/64.56338. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.64721/64.53023. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.62193/64.48180. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.45028/64.43024. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.48516/64.39368. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.48825/64.34843. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 58.31836/64.33115. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.30941/64.32037. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.46873/64.31461. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.27029/64.28927. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.18682/64.28699. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.00811/64.35271. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.07360/64.39667. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.99363/64.37302. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.80949/64.37530. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 57.99801/64.36256. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.87293/64.38924. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.71841/64.43608. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.54583/64.49615. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 57.69947/64.43522. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.65787/64.35368. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.41895/64.36140. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.35660/64.50471. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.37208/64.37022. Took 0.32 sec\n",
      "ACC: 0.640625, MCC: 0.2825430298229483\n",
      "Epoch 0, Loss(train/val) 70.63020/70.37654. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.27297/70.18459. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.84342/69.98158. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.39699/69.77092. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.94682/69.54994. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.46016/69.31853. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.94219/69.05742. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.35428/68.76548. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 66.83640/68.45277. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 66.12601/68.12636. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.43349/67.79565. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 64.60958/67.46284. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 63.86137/67.19657. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 63.09362/66.98087. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 62.34399/66.75408. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 61.84288/66.50524. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 60.98773/66.20773. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 60.59400/65.89825. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 60.27887/65.54953. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 59.93561/65.24592. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 59.59568/64.97128. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 59.35425/64.71063. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 59.04836/64.45779. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 58.71737/64.18991. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 58.69147/63.94508. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 58.56915/63.73076. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 58.37348/63.56569. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 58.26013/63.45626. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 58.18735/63.38096. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 57.88340/63.33215. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 57.83179/63.30227. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 57.71014/63.28298. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 57.70130/63.27389. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 57.61632/63.27631. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 57.44551/63.26133. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 57.38855/63.25888. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 57.18121/63.24046. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 57.16287/63.22203. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 57.09326/63.19982. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 57.01899/63.15747. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 57.13526/63.14528. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 57.06393/63.09921. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 56.92862/63.09255. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 57.08088/63.04168. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 56.94694/63.05280. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 56.82220/63.01973. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 56.89636/63.02921. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 56.74843/63.00274. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 56.65671/63.00031. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 56.72629/62.97520. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 56.61980/62.95154. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 56.75364/62.93860. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 56.62060/62.91814. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 56.42862/62.90162. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 56.53125/62.88954. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 56.33676/62.88763. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 56.43777/62.88661. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 56.36765/62.86628. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 56.38238/62.84126. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 56.48656/62.80432. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 56.25887/62.77163. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 56.31536/62.72538. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 55.90927/62.72016. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 56.06691/62.70939. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.01705/62.70753. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 55.96332/62.66169. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 55.54712/62.71170. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 55.79921/62.67963. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 55.69699/62.57539. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 55.60876/62.62967. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 55.52134/62.56129. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 55.60842/62.54046. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 55.37712/62.50311. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 55.48111/62.43788. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 55.29177/62.53533. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 55.46704/62.39257. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 55.18134/62.36668. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 55.25914/62.33904. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 55.36758/62.39457. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 55.30866/62.34013. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 55.10951/62.27685. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 54.90679/62.26568. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 55.04024/62.19340. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 54.94384/62.22132. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 54.76974/62.20967. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 54.74801/62.26636. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 54.60679/62.19799. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 54.66452/62.06567. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 54.94656/62.08934. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 54.67055/62.11918. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 54.54006/62.15094. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 54.58525/62.02970. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 54.58797/62.21918. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 54.47020/62.07380. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 54.50290/62.05643. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 54.53975/62.17710. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 54.41841/62.02867. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 54.29811/62.16361. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 54.35356/62.05325. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 54.29496/61.95375. Took 0.33 sec\n",
      "ACC: 0.578125, MCC: 0.22529024816220128\n",
      "Epoch 0, Loss(train/val) 70.99516/70.61572. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.86445/70.56204. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.78536/70.50338. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.67134/70.44637. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.58719/70.38251. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.47282/70.31639. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 70.32955/70.24047. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.24909/70.15689. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.11499/70.06922. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.98864/69.97923. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.86335/69.88174. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.69990/69.77335. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.63735/69.65720. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.41638/69.54140. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.27425/69.40888. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.14124/69.26608. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 68.86301/69.11640. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.73831/68.97084. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 68.53996/68.81721. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.35563/68.67065. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 68.20417/68.52655. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 67.94297/68.38940. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 67.68350/68.23344. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.41849/68.08599. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 67.20564/67.93332. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.95444/67.77211. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.58789/67.60716. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 66.36704/67.45100. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.08386/67.28491. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.88412/67.10790. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 65.59469/66.95578. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.39495/66.78219. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.28895/66.65421. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.17448/66.54178. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.90476/66.46085. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.84772/66.42747. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.65861/66.44336. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.61861/66.45110. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.53734/66.43672. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.40737/66.41938. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.35493/66.43074. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.26808/66.47839. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.99811/66.51843. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.94251/66.52005. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.95539/66.43378. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.69206/66.37799. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 63.75676/66.26476. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.46257/66.22009. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 63.28172/66.15742. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.18583/66.14573. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.05885/66.09122. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.93016/66.14652. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.93132/66.10489. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.71412/66.19133. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.59924/66.14276. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.45182/66.21897. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.57112/66.24880. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 62.34965/66.26926. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.16659/66.29465. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.04197/66.32050. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 62.00920/66.36201. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.72728/66.42875. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.57631/66.42352. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.50195/66.52311. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.34625/66.60866. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.44921/66.54961. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.21323/66.66443. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.15572/66.48669. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.03399/66.67234. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.78148/66.50580. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.80950/66.55772. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.70755/66.61462. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.56989/66.46366. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.48461/66.50484. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.41780/66.46610. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.40080/66.58665. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.24415/66.21417. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.36555/66.34099. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 60.10600/66.41600. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.04406/66.12684. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.06002/66.44424. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 59.81931/66.25396. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.98733/66.04304. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.95631/66.48006. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.77243/66.14780. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.72820/66.08278. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 59.62891/66.31612. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.47220/66.01752. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.43995/65.97736. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.25044/66.08216. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.28530/65.86298. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.38539/65.99178. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.26007/65.88640. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.16117/65.77548. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.18213/66.00004. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.08374/65.62466. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.07836/65.86636. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.05872/65.79065. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.88401/65.65073. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.86705/65.75940. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.03419927840283847\n",
      "Epoch 0, Loss(train/val) 70.70378/70.11191. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.48628/69.80816. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.19239/69.47679. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.89253/69.11950. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.57572/68.73458. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.22136/68.33439. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.89350/67.92130. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.52185/67.50682. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.14847/67.08149. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.73685/66.63907. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.19585/66.15067. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.60427/65.58545. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 65.80215/64.91934. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.00833/64.19528. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.12333/63.53657. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.38563/63.01460. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 62.82574/62.64511. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.40491/62.41708. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 61.87314/62.26678. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 61.53402/62.17974. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 61.21942/62.11225. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 60.99762/62.03133. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 60.84728/61.96326. Took 0.34 sec\n",
      "Epoch 23, Loss(train/val) 60.50608/61.88312. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 60.27360/61.79230. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 60.11328/61.67333. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 59.98868/61.54614. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 59.70440/61.42590. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 59.77206/61.30410. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.52734/61.17574. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.51369/61.06583. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.38783/60.90239. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 59.32186/60.80476. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.10861/60.74962. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.05822/60.65829. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.04655/60.60188. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.80816/60.57307. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 58.84589/60.46436. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 58.65747/60.38213. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.63143/60.27621. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.49069/60.27846. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.39917/60.18739. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 58.47632/60.12208. Took 0.34 sec\n",
      "Epoch 43, Loss(train/val) 58.22384/60.04276. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 58.20244/60.02935. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 58.19467/59.91919. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.19004/59.94498. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 57.99723/59.81220. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.06157/59.80608. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.84829/59.79757. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.81773/59.76310. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.69823/59.68237. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.67694/59.64759. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.49854/59.68130. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.64891/59.65293. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.46196/59.66817. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 57.49302/59.56116. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.36031/59.58059. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.52416/59.64092. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.30984/59.72552. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.19189/59.51416. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.04295/59.53095. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 57.04172/59.47081. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.00130/59.47298. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.90218/59.52920. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.77170/59.54679. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 56.82389/59.50686. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 56.69312/59.42686. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 56.57726/59.45191. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 56.50489/59.53444. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 56.57404/59.54073. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 56.41026/59.50475. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 56.52302/59.46899. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 56.31774/59.55965. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.39153/59.52504. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.28835/59.47336. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 56.23663/59.47365. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.29997/59.62182. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 56.17461/59.53579. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.10443/59.48220. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.14756/59.53159. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.16550/59.57750. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 55.96030/59.61432. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 55.77962/59.52962. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.08842/59.55237. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.92251/59.51748. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 55.80654/59.59549. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 55.68215/59.60391. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.75832/59.62154. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 55.99585/59.57930. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 55.73073/59.48611. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.60532/59.56193. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 55.59708/59.49645. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.58259/59.51970. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.54485/59.52268. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.33766/59.47240. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.52667/59.63282. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.64224/59.60455. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.35557/59.59029. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.16588/59.50046. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.07216878364870323\n",
      "Epoch 0, Loss(train/val) 70.27274/69.45640. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.02960/69.26492. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.82397/69.06444. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.59269/68.84600. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.40479/68.60606. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.15057/68.34357. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.85577/68.04875. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.56320/67.71299. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.22065/67.32767. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.84336/66.88352. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.44246/66.38998. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.91944/65.85333. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.56466/65.30350. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.17221/64.76225. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.72404/64.23777. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.32441/63.73882. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 65.00478/63.26798. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.60741/62.82604. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.15954/62.43891. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 63.94990/62.06698. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.58396/61.69050. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.16615/61.30118. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.71655/60.91920. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.36024/60.57567. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.99194/60.24727. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.64900/59.98013. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.44446/59.76334. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.24222/59.58680. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.97645/59.45277. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.96501/59.34855. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.65642/59.19514. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 60.51424/59.09860. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 60.57210/59.10325. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.29243/59.07376. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 60.25728/59.01279. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.02637/58.96118. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.97781/59.00438. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.00007/59.01994. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.83536/59.00990. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.63946/58.98338. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.85346/58.94999. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.72835/58.85847. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.53081/58.80801. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.58766/58.76354. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.58158/58.70119. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.41552/58.66554. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.32675/58.61967. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.42304/58.58182. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.26514/58.54792. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.28338/58.51968. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.25351/58.47560. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.27613/58.38971. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.03820/58.30624. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.02920/58.25748. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.03956/58.23026. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.03226/58.18457. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 59.09306/58.14362. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.91775/58.07774. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 58.81707/58.06902. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 58.82723/58.04014. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 58.68917/58.00203. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.64646/57.97269. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.59371/57.93629. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.66614/57.89759. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.64892/57.88242. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.62831/57.87147. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.57577/57.87337. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.49739/57.82891. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.49804/57.78994. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.52232/57.81785. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.48301/57.79969. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.48571/57.85545. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.41527/57.85939. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.31948/57.82008. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.28129/57.82970. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.19486/57.86239. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.13804/57.90752. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.18558/57.94283. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.16446/57.96032. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.04968/58.01033. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.19457/58.05784. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.08866/58.14389. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.02449/58.19055. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.93968/58.25482. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.91882/58.30407. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.92982/58.40653. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.90039/58.34172. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.90176/58.43896. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.78547/58.47548. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.83870/58.49228. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.70922/58.53572. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.77856/58.66665. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.61832/58.52230. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.64400/58.60605. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.60846/58.67673. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.65415/58.68582. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.57099/58.63584. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.47044/58.69059. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.46886/58.71315. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 57.49619/58.86646. Took 0.31 sec\n",
      "ACC: 0.390625, MCC: -0.21341610326458507\n",
      "Epoch 0, Loss(train/val) 70.32336/71.21687. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.09508/71.00623. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.85028/70.77606. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.62086/70.52454. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.33822/70.25394. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.06085/69.96287. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.75858/69.64323. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.47009/69.29788. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.11043/68.92633. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.79472/68.52409. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.38666/68.11969. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.03467/67.72246. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.70527/67.37465. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.39950/67.07928. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.10513/66.80247. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.83499/66.54404. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.57925/66.28384. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.24873/66.03010. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.00078/65.78860. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.83667/65.59553. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 64.48279/65.46113. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.25897/65.33755. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.21801/65.22765. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.94117/65.12525. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.82618/65.01807. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.61207/64.90964. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.44223/64.79591. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.25705/64.67061. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.20738/64.54749. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 63.09973/64.42043. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.83076/64.28941. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.75570/64.16852. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.50892/64.06121. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.47672/63.98446. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.27852/63.94664. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.20389/63.89878. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.11968/63.86239. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.91655/63.82611. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 61.83910/63.80087. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.76288/63.77528. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.62959/63.74732. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.46967/63.71189. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.38863/63.67373. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.27003/63.66408. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.26280/63.68805. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.11327/63.70950. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.93410/63.76078. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.95088/63.87071. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.73638/63.99523. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.79072/64.10060. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.71453/64.25362. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.66292/64.36092. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.69679/64.44469. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.60164/64.52665. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.46997/64.64110. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.38136/64.71065. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.33202/64.73837. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.32552/64.75635. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.21217/64.79107. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.08532/64.79506. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.21574/64.80289. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.05932/64.79856. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.92981/64.86113. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.91275/64.86019. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.91950/64.83337. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.68758/64.80912. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.73098/64.80812. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.77816/64.81245. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.77136/64.82440. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.66462/64.83978. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.43975/64.82074. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.45044/64.80974. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.47687/64.81522. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.30444/64.82021. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.16116/64.85457. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.03869/64.88406. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.11726/65.14706. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.01773/65.15742. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.97493/65.44014. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.83862/65.57836. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.86472/65.64197. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.62880/65.62886. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.67364/65.84082. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.60004/65.86857. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.53566/65.86016. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.57070/65.98353. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.43179/65.98392. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.48473/65.93033. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.52197/65.88702. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 58.29564/66.09485. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.35331/66.00902. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.18745/65.99628. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.14078/65.94339. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.34345/65.95893. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.08338/65.86266. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.04452/65.98543. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.16420/65.84195. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.88729/65.84422. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 58.00908/65.93732. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.08564/65.83275. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: -0.09759000729485331\n",
      "Epoch 0, Loss(train/val) 69.76415/69.88013. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.50109/69.73119. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.22500/69.56725. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 68.81564/69.38154. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.40294/69.17226. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 67.87568/68.94553. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.35614/68.68895. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 66.68828/68.37305. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.04737/67.97989. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 65.33161/67.51550. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 64.69408/67.01894. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 64.27594/66.53650. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 63.77393/66.09280. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 63.40761/65.69584. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 63.00939/65.33694. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 62.77641/64.99007. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 62.34382/64.67456. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 62.42438/64.39726. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.12666/64.12936. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.11628/63.87251. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 61.99859/63.63756. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 61.81060/63.42539. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.81392/63.22241. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 61.64478/63.02686. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 61.53699/62.86996. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 61.38752/62.73072. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.18140/62.59204. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.28697/62.44765. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.20769/62.33101. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.23863/62.22187. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.07492/62.11686. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.10116/62.03449. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.03097/61.96140. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.79996/61.89111. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 60.81459/61.85364. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.61664/61.81577. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.61620/61.79128. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.72836/61.79605. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.59218/61.80727. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.48322/61.80696. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.36328/61.81051. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.30783/61.82564. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.34974/61.83788. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.14485/61.86388. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.28580/61.88680. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.10118/61.89646. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.91988/61.92374. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.90453/61.94749. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.99521/61.94608. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.04689/61.95834. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.08978/62.00044. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.88382/62.00909. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.77417/62.01287. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.65810/61.99487. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.59211/62.01068. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 59.49930/61.97174. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.46118/61.95279. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.44430/61.96423. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.28637/61.94888. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.28628/61.94298. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.27987/61.90275. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.20101/61.90520. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 58.93584/61.85331. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.88292/61.80027. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.86841/61.80685. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.90476/61.72359. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 58.61983/61.68361. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.63982/61.62475. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.46818/61.61900. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.50227/61.58932. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 58.15358/61.57173. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.11528/61.57899. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.07994/61.53041. Took 0.34 sec\n",
      "Epoch 73, Loss(train/val) 58.05748/61.54219. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.93667/61.45581. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.82857/61.49908. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 57.83449/61.42282. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.57555/61.53481. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 57.64093/61.34158. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.49229/61.42258. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.35987/61.46798. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 57.36774/61.27306. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.11179/61.30237. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.97200/61.06027. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.71527/61.12540. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.32420/60.85400. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.27988/61.31076. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.59379/60.95205. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.15112/61.26093. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.91367/60.67599. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.11842/62.52525. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.41884/61.60047. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.48317/60.07286. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 55.86608/60.52672. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.42677/61.45512. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.46773/60.69010. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.10753/60.37628. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 54.78202/60.34744. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 54.69093/61.72059. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.19240/59.79726. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.264887162657459\n",
      "Epoch 0, Loss(train/val) 70.64809/70.14603. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.33855/69.98383. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.08480/69.82752. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.84857/69.66427. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.52344/69.48242. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.16636/69.27965. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.79527/69.04089. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.43838/68.77715. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.01853/68.50382. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.59989/68.21901. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.23829/67.93631. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.87706/67.65726. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.35653/67.36507. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.11669/67.05869. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.56175/66.73734. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.29229/66.42538. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.91340/66.14300. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.52401/65.88401. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.27821/65.65307. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.90005/65.44870. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.60559/65.26079. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.37803/65.09011. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.07163/64.91579. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.88650/64.75389. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.66387/64.60542. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.45927/64.45615. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 62.05693/64.31180. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.97935/64.14551. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.68926/63.94381. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.63373/63.71966. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.37542/63.47521. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.16112/63.21684. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.01487/62.95295. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.77787/62.71916. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 60.61496/62.48536. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.59060/62.28609. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 60.35851/62.13787. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.24409/62.00568. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.12350/61.88403. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.13477/61.77467. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.94620/61.65208. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.73024/61.54211. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 59.70840/61.42403. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.64200/61.31445. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.57049/61.20900. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.51797/61.11377. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.58419/61.04851. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.42482/60.98286. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.16578/60.88579. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 59.39571/60.83871. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 59.19058/60.77747. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.17383/60.68556. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.04392/60.58792. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.13359/60.55285. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 58.90040/60.55017. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.93202/60.53408. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.81770/60.52022. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.77087/60.50481. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.78275/60.42662. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.76424/60.41813. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.63848/60.39558. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.76259/60.37928. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.53963/60.36517. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.59509/60.35192. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.51386/60.33796. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.49357/60.38721. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 58.28724/60.37956. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 58.50808/60.36200. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.35505/60.34628. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.33259/60.29170. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.18240/60.26778. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.13149/60.26325. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.16487/60.27966. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.16133/60.28968. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.34762/60.29256. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 58.18508/60.30908. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.03979/60.27574. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 57.82534/60.27777. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.93641/60.29976. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 57.90348/60.23735. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.96656/60.19141. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.93767/60.20166. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.74006/60.21670. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 57.82005/60.22494. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.74936/60.16943. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.64846/60.14885. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.88430/60.16170. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.54672/60.15507. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.62450/60.15520. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.60334/60.10244. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.46708/60.02594. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.75109/60.03950. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.60732/60.08582. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.57282/60.07944. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.39292/60.07966. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 57.50167/60.09734. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.46993/60.09576. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.42004/60.00386. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 57.41280/59.97792. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.24285/60.01984. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.12225843615495345\n",
      "Epoch 0, Loss(train/val) 70.56889/70.62402. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.30474/70.33551. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.07273/70.03004. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.82381/69.68829. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.49635/69.29599. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.18441/68.83135. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.77803/68.27255. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.33005/67.59496. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.76481/66.78181. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.14298/65.85207. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.46921/64.85114. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.76886/63.83100. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.04103/62.85098. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 64.22104/61.99202. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 63.58906/61.31162. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 62.97396/60.84909. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 62.61017/60.55168. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.03331/60.27792. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 61.78387/60.02547. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 61.43841/59.76385. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 61.29987/59.47277. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 61.17053/59.18721. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 60.88860/58.91500. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 60.62987/58.65338. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.48799/58.33702. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 60.33269/58.12354. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.32270/58.01307. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.29503/57.91868. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.19423/57.82653. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.02884/57.72849. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 59.83286/57.68999. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 59.71491/57.69953. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 59.69541/57.71841. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 59.71397/57.74609. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.54154/57.64595. Took 0.34 sec\n",
      "Epoch 35, Loss(train/val) 59.53358/57.60326. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.45952/57.58292. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.45651/57.61258. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 59.38535/57.81348. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.19646/57.72079. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.19057/57.58572. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.07399/57.56485. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.98100/57.51258. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.85981/57.42081. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.77461/57.36155. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 58.72403/57.30051. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.73546/57.15907. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.46778/57.10146. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.52179/57.05894. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.40094/56.99546. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.35634/56.85532. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.35326/56.71970. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.00957/56.59829. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.24433/56.50995. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 58.05195/56.45028. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.87353/56.31937. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 57.86043/56.15570. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.64221/56.13519. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.64939/56.05704. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.69811/56.00742. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.76206/55.96219. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.60842/55.87048. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.44284/55.79671. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.36725/55.71041. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 57.42722/55.62794. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.48280/55.53485. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.23085/55.50874. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.24847/55.46377. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.04540/55.36751. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 56.96277/55.27597. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.04465/55.25014. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.25210/55.17661. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.96849/55.14959. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 56.82937/55.10971. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 56.85417/55.04266. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.66453/55.01418. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 56.76017/54.92728. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.77333/54.88551. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.69762/54.81458. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 56.62874/54.82739. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.55885/54.77626. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.57630/54.77723. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.42711/54.72223. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.29693/54.69761. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.22682/54.62894. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.26082/54.64599. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.29211/54.59098. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.10437/54.62743. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.22727/54.54728. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.21022/54.54325. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.17788/54.50288. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.06996/54.47122. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.19178/54.45028. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 55.98221/54.39861. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.00692/54.40697. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.99530/54.39114. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.88784/54.37505. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.86567/54.36222. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.76292/54.31918. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.59423/54.29616. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.04011426554254583\n",
      "Epoch 0, Loss(train/val) 70.42394/70.10202. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.24628/69.97936. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.06130/69.85754. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.91298/69.73449. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.76540/69.61179. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.59097/69.48556. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.45393/69.35182. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.22716/69.20052. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.10029/69.03260. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.89828/68.84944. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.66149/68.64181. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.47507/68.41068. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.20551/68.14481. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.80127/67.83577. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.49362/67.49151. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 67.25666/67.13922. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.90748/66.82015. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.64558/66.54286. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.36158/66.29116. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.13530/66.04837. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.83508/65.81594. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.69990/65.59646. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.41982/65.40517. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.20611/65.22279. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.00786/65.02039. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.75876/64.83357. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.68878/64.64761. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 64.54625/64.47647. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.48274/64.33391. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.22283/64.17583. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.20588/64.06165. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.86903/63.92690. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.89633/63.80946. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.76516/63.70240. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.69119/63.56059. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.49761/63.44463. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.43674/63.33831. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.25681/63.23170. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 63.10251/63.11095. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.94733/63.03476. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.80733/62.94550. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.70359/62.87239. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.41294/62.78653. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.36014/62.74512. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.23906/62.64178. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.91268/62.55444. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.21155/62.42276. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.99660/62.29905. Took 0.34 sec\n",
      "Epoch 48, Loss(train/val) 61.97692/62.21803. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.81620/62.11918. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.73584/62.03149. Took 0.34 sec\n",
      "Epoch 51, Loss(train/val) 61.46445/61.95344. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.45637/61.85357. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.51995/61.71901. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.28535/61.70840. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.51064/61.61627. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.30692/61.55486. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.19012/61.46342. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.07838/61.39948. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.07819/61.34212. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.00660/61.32074. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.04217/61.15759. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.87025/61.13226. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.85542/60.98969. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.75406/61.02251. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.62732/60.95797. Took 0.34 sec\n",
      "Epoch 66, Loss(train/val) 60.75354/60.87270. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.54073/60.87254. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.63638/60.78975. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.24763/60.80192. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.66614/60.67279. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.35970/60.76184. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.36881/60.58108. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.20242/60.62918. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.16993/60.56668. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.01295/60.60981. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.11072/60.50742. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.07129/60.59584. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 60.08479/60.50482. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.01452/60.46504. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.04576/60.40041. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.73432/60.43009. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.87751/60.43225. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.74071/60.48801. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.92178/60.33821. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.60974/60.40993. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.67094/60.35847. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.52222/60.40216. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.63463/60.35563. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 59.46909/60.34252. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 59.40679/60.31225. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.40705/60.29622. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.33923/60.27739. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 59.38760/60.26815. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.27458/60.22089. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.16227/60.17299. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.33093/60.21575. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 59.29800/60.20338. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.17653/60.07634. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.10547/60.09727. Took 0.33 sec\n",
      "ACC: 0.609375, MCC: 0.1886680513554908\n",
      "Epoch 0, Loss(train/val) 70.28473/70.67416. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.87792/70.68543. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.48718/70.69134. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.08467/70.69445. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.79271/70.68783. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.47578/70.67524. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.01128/70.65419. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.58364/70.62655. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.20182/70.59682. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.71696/70.55619. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.36704/70.50104. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.02715/70.42526. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.76508/70.33038. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.30281/70.21775. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.09532/70.08739. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.90497/69.93745. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.74933/69.77100. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.42543/69.58582. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.29120/69.37933. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.09178/69.15151. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.76678/68.89994. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.76361/68.62412. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.47534/68.33185. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.44416/68.01199. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.24310/67.66934. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.97366/67.30838. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.94391/66.93052. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 62.51555/66.56140. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.42902/66.21159. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.26055/65.88830. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 61.98821/65.60877. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.73261/65.33923. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.37148/65.07979. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.13910/64.81667. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.02238/64.57459. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.50890/64.35896. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.58599/64.15139. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.13536/63.96203. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 59.91588/63.77272. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.91709/63.58436. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.53097/63.42021. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.35356/63.25528. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.20171/63.09668. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 58.84852/62.94025. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 58.88664/62.79120. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 58.48814/62.66269. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 58.52271/62.55205. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.20012/62.44123. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.06012/62.35833. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 57.80854/62.25434. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 57.77789/62.17598. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 57.50434/62.11636. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 57.43134/62.04754. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.17540/61.97435. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 57.10581/61.88214. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 56.95816/61.81942. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 56.83892/61.75641. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 56.76750/61.66455. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 56.68285/61.53801. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 56.45899/61.44530. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 55.94322/61.16927. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 55.92913/60.86904. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 55.42629/60.70795. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 55.06137/60.49422. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 54.82360/60.33499. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 54.84117/60.09057. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 54.56553/59.96741. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 54.30091/59.97849. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 54.15573/59.72319. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 53.72848/59.67159. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 53.79550/59.60034. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 53.89741/59.51925. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 53.49419/59.51007. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 53.35647/59.04765. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 53.23382/59.29199. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 53.32063/59.02087. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 52.97532/58.71658. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 53.22874/58.50459. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 54.97134/59.90236. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 54.82514/58.76267. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 52.79510/59.06485. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 52.94494/58.80527. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 52.62633/58.56984. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 52.37816/58.32355. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 52.43319/58.09761. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 52.45214/58.04889. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 52.18024/57.86307. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 52.14425/57.63135. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 52.22116/57.60094. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 52.25008/57.63070. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 52.57558/57.58448. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 52.16097/57.84885. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 51.81671/57.65113. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 51.86335/57.18669. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 51.41906/57.29736. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 51.19095/57.31748. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 51.17268/57.30511. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 50.92795/57.22360. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 50.90738/57.19145. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 50.88915/57.00138. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: -0.0023098630955841236\n",
      "Epoch 0, Loss(train/val) 71.97764/71.18803. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 71.61509/70.66537. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.31022/70.15521. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.96499/69.63025. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.68589/69.07220. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.30242/68.47095. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.92588/67.82611. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.51072/67.14282. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.00151/66.42557. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.50392/65.70293. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.99234/64.99243. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.31568/64.26476. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.70790/63.51324. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.08695/62.76562. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.38353/62.06001. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.83904/61.43301. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.26372/60.87744. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.93177/60.36513. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 63.40923/59.86732. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.76798/59.39332. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.37423/58.94552. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 62.11091/58.55975. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.91004/58.23697. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.59121/57.93493. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 61.15473/57.67037. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.09381/57.42551. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.98196/57.19655. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 60.75949/56.98663. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.59925/56.79845. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.45352/56.62746. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.27568/56.46435. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.07831/56.31261. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 59.98749/56.17038. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.82086/56.03293. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.58451/55.89128. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.36173/55.74525. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.51437/55.58572. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 59.21408/55.41221. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 58.99244/55.20156. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.59289/54.93623. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 58.36999/54.67678. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 58.05466/54.42373. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 57.92970/54.21859. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 57.73261/54.04443. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 57.60933/53.92577. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 57.33332/53.85571. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 57.18590/53.79883. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 57.18405/53.73966. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 57.13654/53.68975. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 56.92831/53.65815. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 56.92546/53.63113. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 56.94696/53.60580. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 56.88091/53.58515. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 56.76314/53.56656. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 56.74217/53.55179. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 56.56596/53.54910. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 56.56076/53.53919. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 56.41058/53.53205. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 56.39865/53.52339. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 56.44764/53.47467. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 56.49126/53.45456. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 56.33740/53.45457. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 56.36705/53.40862. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 56.36342/53.40024. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.03951/53.39064. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 56.34314/53.38065. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 56.11473/53.32821. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 56.03932/53.32386. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 56.10042/53.29654. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 55.98603/53.26533. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.04130/53.24292. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 55.90223/53.22276. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 55.99647/53.20661. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 55.89824/53.20737. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 55.97937/53.17652. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 55.93727/53.14341. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 55.88919/53.13183. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 55.73096/53.12318. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 55.73277/53.10093. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 55.85952/53.07304. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 55.67101/53.04525. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 55.63913/53.02399. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 55.80010/53.00704. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 55.75574/52.99174. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 55.68184/52.98297. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.65767/52.96061. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 55.59745/52.93915. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 55.81687/52.90775. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 55.44251/52.86750. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.45457/52.85764. Took 0.34 sec\n",
      "Epoch 90, Loss(train/val) 55.79242/52.83816. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 55.48837/52.82267. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.55954/52.79308. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 55.50536/52.76229. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.55556/52.72554. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.41942/52.68562. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.47049/52.65594. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.38335/52.61758. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.50414/52.59451. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.39472/52.58035. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.3158500236078181\n",
      "Epoch 0, Loss(train/val) 70.51296/70.69112. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.26169/70.40352. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.97237/70.09643. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.66508/69.75464. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.33981/69.35586. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.00267/68.89536. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.52131/68.35593. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.03867/67.72047. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.42457/66.97791. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.75884/66.13312. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.05564/65.21001. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.26565/64.20963. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 64.60150/63.13781. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 63.93802/62.09948. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 63.11982/61.08447. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 62.57945/60.14711. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 61.77306/59.33365. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 61.00915/58.62470. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 60.50191/58.02608. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 60.04982/57.53360. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 59.52525/57.14576. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 59.31814/56.84009. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 59.20634/56.59091. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 59.31137/56.39233. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 58.85584/56.22670. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 58.78654/56.08140. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 58.66739/55.95214. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 58.61939/55.83820. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 58.70678/55.74094. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 58.52290/55.66036. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 58.44545/55.58911. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 58.32229/55.52311. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 58.36594/55.46302. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 58.15861/55.40741. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.19299/55.35695. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 58.22450/55.30988. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.11006/55.26583. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.15026/55.22517. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 57.95400/55.18589. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 57.81909/55.14931. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.00689/55.11703. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.19083/55.08924. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 58.06218/55.06243. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 57.99848/55.03735. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 57.88828/55.01376. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.96534/54.98977. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 57.99022/54.96710. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.87489/54.94667. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.68903/54.92679. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.83044/54.90853. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.81514/54.89581. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 57.79738/54.88259. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 57.64215/54.87040. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 57.58130/54.86301. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.62802/54.86280. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 57.74086/54.87397. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.59433/54.88031. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.69102/54.83968. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.44863/54.84579. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.50429/54.82536. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.47510/54.80168. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 57.35791/54.77617. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.39313/54.76317. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.35020/54.69523. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 57.32394/54.68739. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.40325/54.64421. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.34762/54.61500. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.15369/54.58532. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.34383/54.55497. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.18460/54.53986. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.18381/54.51624. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.91963/54.49715. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 57.08578/54.47723. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.94843/54.43893. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.03376/54.43787. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.00414/54.41320. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.01131/54.40578. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.82428/54.36217. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 56.93670/54.34676. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.07056/54.32445. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.10393/54.30991. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.05718/54.28408. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 56.96463/54.28457. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.91762/54.24466. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.84960/54.23742. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.94169/54.20829. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.70282/54.19286. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.88764/54.16521. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 56.86823/54.16124. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 56.70993/54.12939. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.83934/54.12582. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.71758/54.09188. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 56.74885/54.07253. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.59222/54.04662. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.65529/54.03024. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.53202/54.01111. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.63004/54.00341. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.60956/53.95938. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.54633/53.95636. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.49160/53.92968. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.11020775375559676\n",
      "Epoch 0, Loss(train/val) 70.40110/71.32918. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.25863/71.21219. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.11521/71.10387. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.97591/70.99422. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.79198/70.88008. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.60396/70.76496. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.41032/70.63335. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.26570/70.48077. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.05111/70.30481. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.77600/70.09364. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.47827/69.84229. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.14718/69.54181. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.79840/69.19080. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.46671/68.81664. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.04671/68.43642. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.65549/68.07047. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.21545/67.73431. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.89845/67.43815. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 65.66104/67.16666. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 65.43930/66.92616. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.26131/66.71241. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.10997/66.52069. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.96354/66.35115. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.72558/66.20000. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.73453/66.06080. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.52083/65.94029. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.48001/65.83007. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.61392/65.73338. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.39065/65.63925. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.32770/65.54512. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.14400/65.45386. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.22523/65.37900. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.14048/65.30733. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.16264/65.24500. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.16137/65.18767. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 64.04585/65.12159. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.92244/65.06068. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.95868/65.00154. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.96511/64.94173. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.85348/64.87676. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.80633/64.79889. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.79494/64.71444. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.70220/64.62881. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.72179/64.55425. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.54354/64.49171. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 63.56856/64.43883. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.54237/64.38491. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 63.61072/64.33266. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 63.34228/64.28510. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 63.38230/64.24934. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 63.52779/64.22498. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.28868/64.21346. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 63.42166/64.21719. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.23487/64.20479. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.23444/64.20543. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 63.19864/64.20309. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 63.03299/64.19912. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.95027/64.19166. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.12548/64.19674. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.09744/64.20033. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.91032/64.20013. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.93752/64.19674. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.79176/64.18925. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.82953/64.18686. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.72459/64.19565. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.79200/64.18707. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.66868/64.20460. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.60118/64.19884. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.42651/64.20778. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.35260/64.19485. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 62.41354/64.21778. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.21548/64.24660. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.16111/64.23967. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.06718/64.23567. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.10662/64.20470. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 62.04847/64.21237. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.91759/64.14831. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.93431/64.18772. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.91932/64.13411. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.74424/64.24956. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 61.70486/64.17104. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.63513/64.21571. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 61.63261/64.13177. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.50641/64.12938. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.43891/64.09825. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.26342/64.08554. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 61.19323/64.12596. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.23520/64.07755. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.23450/64.10984. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 61.08333/64.07731. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 61.03304/64.10126. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.93126/63.97623. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 60.73048/64.06799. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.68301/64.11231. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.51298/64.06023. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 60.47601/64.10854. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.38332/64.08956. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 60.28689/63.93534. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.25257/64.04076. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.22505/63.93616. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.14285714285714285\n",
      "Epoch 0, Loss(train/val) 70.69699/70.52431. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.55407/70.29022. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.42233/70.04649. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.25920/69.78469. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.09408/69.51784. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.96161/69.24929. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.79843/68.96509. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.64906/68.66884. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.39133/68.36879. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.23961/68.05774. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.99005/67.74120. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.78495/67.42120. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.54259/67.09228. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.28024/66.74249. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.99574/66.36893. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.65824/65.96598. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.34282/65.54462. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.79066/65.13116. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.38891/64.79117. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 65.96637/64.52624. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.46351/64.27331. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.09311/64.09343. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.78706/63.94244. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 64.74272/63.81565. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.73282/63.69815. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.38814/63.59390. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.25235/63.51085. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.39231/63.43302. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.17500/63.36230. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.31836/63.28973. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.00334/63.21884. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.81495/63.14310. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.90946/63.07871. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 63.86000/62.99629. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.74865/62.91784. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.80031/62.84115. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 63.62334/62.77768. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.67626/62.72081. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.61028/62.66928. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 63.43186/62.61352. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.48449/62.57637. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.51813/62.53528. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.37240/62.47875. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 63.28381/62.42787. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 63.24472/62.38982. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.27546/62.34439. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.24654/62.28907. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.29221/62.23577. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.13973/62.19605. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.20044/62.15990. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 63.16592/62.12510. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.01007/62.07751. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.16890/62.04393. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.99133/62.02647. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 62.96831/61.98748. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.81727/61.95404. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 62.89496/61.92619. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.87217/61.89977. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.74002/61.87386. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 62.68987/61.84723. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.79095/61.82755. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.73321/61.80066. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.53928/61.78047. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 62.56244/61.75413. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.56960/61.73051. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 62.55022/61.70923. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.46628/61.68528. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.52664/61.66400. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 62.41551/61.64540. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.57614/61.62752. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.37267/61.60845. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.30636/61.59480. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.54263/61.56263. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.06648/61.52961. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 62.25775/61.50435. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.21429/61.48539. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.20405/61.46467. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.11979/61.45268. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 62.02385/61.44360. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.25862/61.41783. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 61.94220/61.40107. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.10499/61.40594. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.84728/61.39083. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 61.95020/61.37163. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.95462/61.34070. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 61.85414/61.32365. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.88675/61.32283. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 61.71586/61.29827. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 61.71062/61.28085. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.82766/61.27928. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 61.75503/61.27401. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 61.77610/61.26847. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.61760/61.27999. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 61.65996/61.24552. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.41377/61.23004. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.48755/61.23043. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 61.60345/61.22450. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 61.27958/61.21224. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.44234/61.20160. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.33103/61.18351. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.1630980846658687\n",
      "Epoch 0, Loss(train/val) 70.02506/70.32806. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.71580/70.07735. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.43823/69.79274. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.14800/69.47105. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.79145/69.11584. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.37316/68.74063. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.97096/68.38029. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.51529/68.05411. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.96254/67.77866. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 66.60408/67.56389. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.20177/67.39706. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 65.81726/67.27005. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.63953/67.17280. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.25495/67.10483. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 64.83990/67.06530. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.88009/67.04223. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.57348/67.03400. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.25283/67.02541. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.20961/67.02023. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.14604/67.02303. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.83234/67.02637. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.86199/67.02988. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.75855/67.03293. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.64052/67.04662. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.53162/67.05415. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.45952/67.05838. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.46738/67.06111. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.22032/67.05197. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.25223/67.03610. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.15277/67.02373. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.17066/66.99626. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.05689/66.96378. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.03332/66.93065. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.95549/66.91180. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.95395/66.90697. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.79210/66.86642. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.88582/66.82742. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.80070/66.78488. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.69241/66.75143. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.70990/66.71985. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.58947/66.68150. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.63908/66.68555. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.47402/66.65541. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.35742/66.61080. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.48242/66.58778. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.41951/66.56785. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.41854/66.51412. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.20175/66.46581. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 62.17137/66.44496. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.20462/66.41460. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.19386/66.34482. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.07619/66.29828. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.00942/66.22681. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.01394/66.18372. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.03543/66.14389. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.90836/66.11186. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.93454/66.06254. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.75774/65.99944. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.80606/65.95910. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.96997/65.91649. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.63857/65.88683. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.73335/65.84867. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.54317/65.77483. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.53957/65.70766. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.52260/65.68771. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.69004/65.67912. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.46498/65.69788. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.66717/65.66451. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.54628/65.62949. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.34985/65.67100. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.57533/65.60257. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 61.29887/65.60997. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.34670/65.60972. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.12443/65.58373. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.44432/65.58504. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 61.19841/65.59084. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 61.16868/65.63885. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 61.01294/65.66928. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.93300/65.69782. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.83340/65.81812. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 61.07785/65.78618. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.01738/65.94714. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 60.74586/65.86855. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 60.92486/65.89690. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.77795/65.90279. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 60.64698/65.87930. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 60.65835/65.95885. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.57630/65.95657. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.42282/65.97361. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.47331/65.96973. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.46562/65.98350. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.64744/66.04667. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.45434/66.04029. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.27861/66.07761. Took 0.34 sec\n",
      "Epoch 94, Loss(train/val) 60.35210/66.04932. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 60.46210/66.00313. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.17411/66.01865. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 60.28239/65.96047. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.13829/66.01189. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 60.09167/65.98322. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.09759000729485331\n",
      "Epoch 0, Loss(train/val) 70.36206/69.99405. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.06456/69.92775. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.80300/69.84731. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.51280/69.74987. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.17470/69.62353. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.79122/69.46256. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.34189/69.25069. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.87350/68.97707. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.27640/68.63021. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.55608/68.21722. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.81604/67.80756. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 65.22418/67.46883. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 64.74976/67.21130. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 64.33952/67.06178. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 64.07992/66.93564. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 63.75722/66.79910. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.38083/66.65765. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.13064/66.49752. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.87952/66.33110. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.51678/66.15767. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.27155/66.00284. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.97773/65.85817. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 61.80225/65.70004. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.64567/65.55173. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.53969/65.41279. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 61.44190/65.27461. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.27640/65.14413. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.09147/65.02635. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.17581/64.92011. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.90957/64.82638. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 60.90828/64.73714. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.87543/64.65057. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.67570/64.56715. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.68746/64.47350. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.62662/64.37464. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.78860/64.28174. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 60.46891/64.19017. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.60452/64.09566. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.30935/64.01340. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.45269/63.95496. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.43206/63.91752. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 60.22016/63.88718. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.25747/63.86938. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.20474/63.83704. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 60.05844/63.80764. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.97477/63.81063. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.02288/63.81115. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 59.86110/63.78386. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.00394/63.74310. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.88856/63.76439. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.06998/63.77269. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.80255/63.72963. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.86749/63.70014. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.83986/63.68559. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.78885/63.70316. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.77992/63.70036. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.70219/63.65925. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.63679/63.65208. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.70272/63.64791. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.57123/63.65014. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.64151/63.59102. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 59.53064/63.55293. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.40899/63.56963. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 59.78212/63.51387. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.57143/63.50402. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.51657/63.46688. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.24235/63.43708. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.37264/63.43032. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.52952/63.41109. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.58840/63.37364. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.20975/63.33702. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.33741/63.29762. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.22470/63.30262. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.42312/63.31564. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.17118/63.30426. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.02402/63.27538. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 59.12575/63.25677. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.00892/63.24323. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.99227/63.17351. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.92547/63.14443. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.00541/63.10812. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.84011/63.10595. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.03520/63.07251. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.08726/62.99362. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.03931/62.97719. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.87401/62.97469. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.66362/62.92232. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.81245/62.86418. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.55370/62.84439. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.52004/62.82906. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.78256/62.81017. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.66175/62.78859. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.62457/62.76470. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 58.78163/62.72759. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.62114/62.73566. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.51983/62.71735. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.33437/62.66159. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.60232/62.62992. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 58.50805/62.63720. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.48685/62.63108. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.03883678186903087\n",
      "Epoch 0, Loss(train/val) 70.84971/70.89490. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.54177/70.69012. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.27221/70.47740. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.04243/70.25826. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.74380/70.03304. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.50543/69.79299. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.20859/69.53439. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.84990/69.24980. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.49041/68.93489. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.16226/68.58887. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.64877/68.20096. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.24483/67.77153. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.69649/67.31406. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.13376/66.85065. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.80888/66.40900. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.22754/66.00409. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.93738/65.63706. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.47709/65.30839. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.26072/65.01505. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.04326/64.75263. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.83081/64.51967. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.69037/64.31192. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.31770/64.12299. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.10326/63.95071. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.90938/63.78437. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.75338/63.62864. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.52463/63.48803. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.30015/63.38792. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.18547/63.31955. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.22071/63.28153. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 61.93410/63.25590. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.68674/63.23774. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.65899/63.20907. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.61257/63.18255. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.36905/63.16707. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 61.40154/63.15802. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.25328/63.16554. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 61.14107/63.18720. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.11666/63.20743. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.83901/63.22245. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.88735/63.22268. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 60.64929/63.22483. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.63524/63.23261. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.71647/63.19646. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.42391/63.15033. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.35928/63.13559. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.42356/63.11386. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.27555/63.11751. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.20552/63.13395. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.91288/63.08472. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 60.03603/63.08587. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.83278/63.04604. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.89054/63.01302. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.90611/63.02384. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.67477/62.97321. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.63542/62.93696. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.48437/62.95370. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.33281/62.93527. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.35798/62.87450. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 59.35404/62.83889. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.16914/62.77183. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 59.30034/62.77118. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 59.11803/62.75864. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.08706/62.69443. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.04176/62.71336. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.99927/62.64174. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.97840/62.54020. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.92639/62.52018. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 58.61328/62.50765. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.53844/62.49072. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.84555/62.42063. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.50077/62.44137. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.57668/62.43198. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.30357/62.35010. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.51664/62.26590. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.45651/62.25560. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 58.43161/62.21474. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 58.41071/62.14944. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.30000/62.12306. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.21385/62.07848. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.05215/62.06111. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.02910/62.04027. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.16099/62.00396. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.93628/61.99840. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.87711/61.99820. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.94133/62.00928. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 57.95957/61.99138. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.70518/62.00927. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.00352/62.01008. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 57.71349/61.98743. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 57.78830/61.92958. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.59226/61.89000. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.47694/61.88845. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.53498/61.89658. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.47519/61.88317. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 57.39085/61.86229. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.42016/61.85596. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.35852/61.83630. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.25726/61.83316. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.32878/61.79734. Took 0.32 sec\n",
      "ACC: 0.5, MCC: -0.05013806979968223\n",
      "Epoch 0, Loss(train/val) 70.00953/70.66593. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.70084/70.31342. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.34236/69.94934. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 68.96332/69.56458. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.60211/69.16499. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.10157/68.74088. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.68804/68.29329. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.12866/67.83437. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 66.69535/67.36876. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.09906/66.89423. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.66876/66.39812. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 64.93391/65.85152. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 64.27291/65.19939. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 63.59605/64.38611. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 62.65685/63.38860. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 61.60259/62.27758. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 60.69861/61.22163. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 59.92772/60.21666. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 59.17720/59.33565. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 58.59589/58.63209. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 57.91374/58.12818. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 57.67407/57.78006. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 57.35201/57.49930. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 57.07237/57.25758. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 56.85940/57.08364. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 56.65544/56.89080. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 56.49107/56.72116. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 56.44827/56.52349. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 56.34473/56.35967. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 56.08632/56.20267. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 55.91861/56.10131. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 55.72913/55.93847. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 55.60409/55.85180. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 55.57864/55.72189. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 55.48472/55.62545. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 55.33791/55.53356. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 55.31108/55.46922. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 55.26338/55.41047. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 55.17527/55.33266. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 55.05660/55.27340. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 54.81394/55.24463. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 54.75651/55.17368. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 54.55950/55.12988. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 54.62175/55.08208. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 54.43086/55.07126. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 54.35169/55.04170. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 54.38134/55.00603. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 54.20575/54.96349. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 54.12809/54.94009. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 54.08599/54.91945. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 54.00901/54.85846. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 53.92600/54.79424. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 53.94775/54.74446. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 53.87762/54.72435. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 53.53683/54.68469. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 53.74219/54.60880. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 53.56804/54.57957. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 53.51725/54.55741. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 53.42079/54.47670. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 53.50059/54.41273. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 53.23810/54.37944. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 53.21129/54.34662. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 53.17589/54.30723. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 53.26510/54.27884. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 53.07050/54.30130. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 53.05925/54.23621. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 52.88259/54.17841. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 52.71934/54.16217. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 52.96789/54.17654. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 52.70947/54.13441. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 52.75031/54.14321. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 52.51578/54.08118. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 52.34372/54.09037. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 52.40152/54.08424. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 52.56208/54.07832. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 52.13953/54.07788. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 52.27117/54.02040. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 52.17887/54.09355. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 52.15679/54.15421. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 52.16805/54.19954. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 51.97264/54.14577. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 52.01660/54.05779. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 51.78238/54.19236. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 51.86654/54.20282. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 51.92026/54.19376. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 51.68008/54.14008. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 51.56081/54.20736. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 51.67253/54.18048. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 51.67431/54.23025. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 51.59131/54.27726. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 51.37805/54.18578. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 51.42695/54.32257. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 51.31391/54.18260. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 51.21108/54.34761. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 51.17974/54.21463. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 51.21721/54.31855. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 51.28764/54.23906. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 51.12123/54.33738. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 51.19137/54.39242. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 50.89874/54.22501. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.13966885537786003\n",
      "Epoch 0, Loss(train/val) 70.58588/70.56979. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.28923/70.20908. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.90200/69.84003. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.56175/69.47241. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.17138/69.11073. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.84643/68.76146. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.47022/68.41511. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.10179/68.08176. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.73180/67.75864. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.30297/67.45036. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.87326/67.15211. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.49746/66.85316. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.07183/66.54526. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.63120/66.22417. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.06499/65.87511. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 64.69884/65.47982. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.13620/65.04121. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.54010/64.56358. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.04960/64.10201. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.62519/63.70131. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.11162/63.35300. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 61.73884/63.03531. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 61.35322/62.74673. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.04261/62.56118. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 60.77449/62.29744. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 60.50987/62.04410. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.22287/61.76876. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 59.96672/61.50996. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 59.74714/61.26284. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.50624/61.01299. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.35702/60.76000. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.11944/60.52265. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 58.95772/60.33158. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 58.91244/60.15228. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.71882/60.00472. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 58.48214/59.84862. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.37828/59.70765. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 58.29769/59.56236. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.17292/59.43982. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 57.99971/59.31585. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 57.92024/59.20103. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 57.71847/59.06691. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 57.74404/58.94700. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 57.72442/58.84700. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 57.52122/58.71746. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 57.39133/58.59920. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 57.21853/58.50618. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 57.11112/58.35924. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 56.98366/58.25611. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 56.92140/58.11943. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 56.88057/57.97113. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 56.74179/57.82648. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 56.75891/57.78847. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 56.50784/57.67733. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 56.45872/57.62092. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 56.34677/57.52608. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 56.27492/57.45084. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 56.27322/57.43037. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 56.13059/57.36880. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 56.02955/57.30912. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 56.02680/57.18051. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 55.91915/57.12023. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 55.70522/57.09337. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 55.89917/57.04128. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 55.56332/57.01884. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 55.60255/56.98528. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 55.50504/56.95177. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 55.43994/56.93120. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 55.38579/56.92684. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 55.38947/56.85916. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 55.38614/56.77292. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 55.28654/56.77168. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 55.22280/56.76513. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 55.20722/56.72290. Took 0.34 sec\n",
      "Epoch 74, Loss(train/val) 55.11870/56.66503. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 55.28129/56.67811. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 54.97967/56.63222. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 54.92483/56.65596. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 54.78487/56.63573. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 54.89110/56.56449. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 54.66697/56.59888. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 54.82535/56.62015. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 54.76468/56.58587. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 54.67371/56.51229. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 54.61973/56.46672. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 54.46806/56.56967. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 54.59717/56.50645. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 54.46036/56.42580. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 54.27189/56.40224. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 54.39617/56.58229. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 54.16169/56.50220. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 54.31485/56.40943. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 54.18048/56.40745. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 53.92645/56.44695. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 53.99842/56.46371. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 53.95771/56.44925. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 53.63621/56.43169. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 53.72184/56.48211. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 53.69340/56.48859. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 53.70070/56.50307. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.03688555567816588\n",
      "Epoch 0, Loss(train/val) 71.22833/70.76204. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.99780/70.52172. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.77427/70.29685. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.61701/70.06191. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.39632/69.79492. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.17214/69.47839. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.90635/69.10088. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.62533/68.66548. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.32929/68.20190. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.89930/67.76337. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.49662/67.39462. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.12986/67.11693. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.77333/66.90766. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.37214/66.74963. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.16399/66.63562. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.80576/66.56872. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.58491/66.54387. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.24493/66.50462. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.03809/66.44910. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.85042/66.38322. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.57099/66.29826. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.49287/66.19033. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.45941/66.06673. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.18921/65.91359. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.96161/65.71519. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.70982/65.48693. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.57885/65.23573. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 64.53622/64.99238. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.42825/64.79103. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.26829/64.62132. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.10407/64.48687. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.98356/64.38348. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.70951/64.31104. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 63.88293/64.27886. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.77847/64.26093. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.55959/64.24885. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.66880/64.21621. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.53518/64.18165. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.43185/64.16418. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 63.50742/64.14419. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.38998/64.13012. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.42728/64.10863. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 63.40368/64.11477. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 63.48971/64.11902. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 63.30417/64.10468. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.27429/64.10042. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 63.32234/64.09503. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.41390/64.08263. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.22697/64.06671. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 63.24511/64.06637. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 63.20424/64.08311. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.08974/64.09008. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.94612/64.08054. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.05896/64.07523. Took 0.34 sec\n",
      "Epoch 54, Loss(train/val) 63.10514/64.06051. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.01945/64.02827. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.99935/63.99582. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 62.81345/63.97379. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.87344/63.94354. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 62.75517/63.91324. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.56500/63.86493. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.68789/63.83023. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.55373/63.80933. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.42710/63.75605. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 62.44057/63.72997. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.11274/63.71967. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.09580/63.67931. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.08733/63.64557. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.86680/63.64011. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 61.93952/63.59753. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.82656/63.57163. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.61066/63.56305. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.58701/63.54344. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 61.64826/63.51561. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.31098/63.47078. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.33775/63.44807. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 61.16924/63.39457. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.17044/63.38869. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.16622/63.35925. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.84700/63.34022. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.79169/63.36406. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.85279/63.36191. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.55992/63.36454. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 60.53355/63.34919. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.32583/63.32851. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 60.26356/63.28447. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 60.21367/63.25016. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 60.20865/63.17140. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.11279/63.10212. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 59.93424/62.95747. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 59.81168/62.75767. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.79133/62.62294. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.63795/62.35966. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 59.51485/62.08205. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.62698/62.14088. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.33572/61.84810. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.21234/61.74045. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.20188/61.83664. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.82165/61.63872. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.02970/61.61268. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.05420213225174926\n",
      "Epoch 0, Loss(train/val) 70.53472/69.46616. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.26494/69.10616. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.98549/68.70574. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.68320/68.24377. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.35912/67.69287. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.04173/67.02637. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.59441/66.23517. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.06110/65.32507. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.53790/64.35232. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.97824/63.38506. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.40006/62.46792. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.80493/61.64050. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.23089/60.99051. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 64.66376/60.42023. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.09322/59.91558. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 63.70266/59.46378. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.41758/59.09612. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 62.86024/58.79380. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 62.65426/58.54305. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.38321/58.34452. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.16422/58.18690. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.99933/58.06040. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 62.00466/57.95324. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.91709/57.86533. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.85923/57.79890. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 61.57107/57.73265. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 61.61251/57.67527. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.54153/57.63186. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.36343/57.59235. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.30765/57.55326. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.36039/57.52247. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 61.32047/57.48827. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 60.92117/57.44950. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.18422/57.40928. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 60.81311/57.37031. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.76998/57.33762. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.90933/57.30221. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.83852/57.26970. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.92169/57.23849. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.72254/57.20585. Took 0.34 sec\n",
      "Epoch 40, Loss(train/val) 60.78135/57.17206. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 60.61849/57.13829. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.64018/57.10881. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.30047/57.07412. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.26767/57.04183. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.37247/57.01082. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.38873/56.97435. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.30908/56.92685. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.18456/56.87676. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.05809/56.83695. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.15916/56.78215. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.99258/56.72037. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.01439/56.67645. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.06467/56.64243. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.76770/56.57677. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.90096/56.50703. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.61086/56.45336. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.66461/56.41415. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.62517/56.35838. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.60264/56.27317. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.53674/56.21690. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.48752/56.13710. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.43794/56.07751. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 59.36095/56.04001. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.45286/56.03066. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.46652/55.97457. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.27725/55.91752. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.42034/55.89974. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.48327/55.85006. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 59.24079/55.77834. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.24126/55.77483. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 59.12525/55.71614. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.11307/55.75994. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.99506/55.66658. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.98535/55.59870. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.81474/55.71319. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.77488/55.68190. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.88020/55.43176. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.78215/55.46285. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.81996/55.39394. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.86209/55.45535. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.64340/55.49909. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.43623/55.36148. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.59545/55.40379. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.51071/55.45966. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.53532/55.39676. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.39127/55.26902. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.43039/55.32803. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.37847/55.34887. Took 0.34 sec\n",
      "Epoch 89, Loss(train/val) 58.23087/55.22104. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.27702/55.13098. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.15731/55.18779. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.19331/55.14929. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.05245/55.34364. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.14222/55.11879. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.11489/55.07581. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.85538/55.10263. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 58.04499/54.94271. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.90821/55.27515. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.89343/55.16965. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: 0.0724209915984799\n",
      "Epoch 0, Loss(train/val) 70.37164/70.04734. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.00862/69.79224. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.73040/69.51874. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.39854/69.23076. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.02788/68.92648. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.74224/68.61438. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.37056/68.28764. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.94339/67.95415. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.57927/67.60592. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.25699/67.24566. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.79108/66.87383. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.32181/66.48521. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.88394/66.08447. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.50217/65.67989. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 65.00020/65.28836. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.59500/64.92531. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.04064/64.60967. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.57264/64.33944. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.20328/64.11179. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.93495/63.92416. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.83004/63.78496. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.52127/63.66275. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.23990/63.55678. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.24720/63.46854. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 62.03235/63.38905. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 61.93927/63.32319. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.67015/63.26889. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.66757/63.22714. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.59291/63.20087. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.38702/63.18796. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.32795/63.18141. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 61.20237/63.17674. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.15843/63.16937. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.14420/63.16440. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.99218/63.15694. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.95896/63.14399. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.92497/63.12289. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 60.93523/63.09430. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.86899/63.06513. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 60.67518/63.03225. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.64230/62.99165. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.65059/62.94890. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.61165/62.90807. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.43604/62.86861. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.47003/62.82780. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 60.44352/62.79995. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.39056/62.76638. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.48607/62.74310. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.42605/62.71409. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.22110/62.66249. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.31982/62.61189. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.25515/62.57352. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.13874/62.54344. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.25384/62.48810. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.17454/62.44910. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.08309/62.41290. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.96393/62.37858. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.04611/62.34968. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.88128/62.34188. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.84925/62.33725. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.98240/62.32263. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.82982/62.28276. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 59.91356/62.25839. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.83321/62.23082. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 59.89863/62.19732. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 59.75710/62.18687. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.83527/62.16215. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.76863/62.14360. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.57785/62.14492. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.53062/62.12886. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.56744/62.11622. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.57560/62.11391. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.61504/62.08352. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.65321/62.05694. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.50017/62.05740. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 59.50154/62.05521. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.43640/62.04951. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.44593/62.02917. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.48437/62.01558. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.55317/62.01455. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 59.43390/62.00248. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.40051/61.99481. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.37381/62.00131. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.17765/61.98698. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 59.13611/61.97762. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.29594/61.99017. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.24723/62.01331. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.09879/62.01610. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 59.18762/62.00256. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.15566/61.99601. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.08297/61.96914. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.99437/61.94563. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.06311/61.93911. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.11862/61.94492. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 59.14137/61.93815. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 58.93971/61.93291. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.90734/61.91745. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.81154/61.91043. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.95618/61.89484. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.01437/61.87013. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.22836131621923617\n",
      "Epoch 0, Loss(train/val) 70.28178/70.55086. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.06487/70.40658. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.82297/70.25340. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.62452/70.08870. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.38172/69.91467. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.09430/69.73169. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.81243/69.52779. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 68.51113/69.30556. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.17990/69.06801. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.82700/68.80405. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.41573/68.50974. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.09152/68.18446. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.61921/67.81610. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 66.14499/67.39893. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.60283/66.94671. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.01067/66.48628. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.40873/66.03075. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.90195/65.62553. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.50471/65.28040. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.01339/64.99490. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.65553/64.75925. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.28048/64.60180. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.02475/64.47060. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.84432/64.36034. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.70818/64.25957. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.57904/64.17708. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.60754/64.10652. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.51679/64.00928. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 61.33478/63.90345. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.20744/63.79337. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.14140/63.67616. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.02755/63.52418. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 60.91705/63.38365. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.93738/63.21382. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.89950/63.08530. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 60.69331/62.92316. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.77803/62.79569. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.81461/62.67828. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.73477/62.56610. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.52074/62.47378. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.58286/62.37430. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.54840/62.28809. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.37126/62.20082. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.35209/62.10363. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.33329/62.00098. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.33583/61.86993. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.25015/61.79571. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.18701/61.65105. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.07137/61.50147. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.90523/61.42141. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.96285/61.25694. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.81000/61.09044. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 59.80013/60.97971. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.82692/61.06558. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.73235/61.00144. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 59.66114/60.80332. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.59376/60.71760. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.50610/60.77482. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 59.55347/60.60963. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.46968/60.54655. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 59.44037/60.59461. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.32964/60.35471. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.31942/60.31164. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.36033/60.28580. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.24028/60.21488. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.22718/60.15505. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.17406/60.09354. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.06472/60.05468. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.05411/60.00223. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 59.05575/59.99095. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.89156/59.89372. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.97279/59.86374. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.79992/59.82052. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.84332/59.80318. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.91702/59.73082. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.83569/59.71112. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 58.66409/59.67776. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.74429/59.63932. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.82433/59.62413. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.64531/59.58445. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.54079/59.55078. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.44756/59.56100. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.46895/59.64997. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.52802/59.49588. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.38037/59.59872. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.31502/59.49637. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.31642/59.59734. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.28214/59.56225. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.26760/59.55297. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.13965/59.61845. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.08183/59.56121. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 58.17849/59.58386. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.05901/59.59161. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.84800/59.56985. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.92158/59.61596. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.85534/59.60763. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.72543/59.56015. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.94278/59.50142. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.88346/59.55531. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.80245/59.69949. Took 0.33 sec\n",
      "ACC: 0.5, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) 70.33577/70.46839. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.14015/70.36454. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.93494/70.25633. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 69.71871/70.14250. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.46624/70.01553. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.20419/69.88039. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.94745/69.73374. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.61990/69.56378. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.27292/69.37746. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.93467/69.17442. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.52428/68.94892. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.17566/68.69644. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.69863/68.40263. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.28770/68.07717. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.88591/67.71137. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.48305/67.29254. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.03377/66.79671. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.70278/66.22839. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.17150/65.56898. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.52399/64.78735. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 63.17235/63.96652. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 62.57882/63.16034. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.13982/62.46864. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.65676/61.84317. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.31771/61.22267. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 60.89554/60.57273. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.67064/59.90711. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.47869/59.37106. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.36442/58.98451. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.13873/58.71789. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 59.88162/58.53040. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.63040/58.42987. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.71433/58.31234. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.65919/58.30996. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.32901/58.21272. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.14734/58.18525. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.18736/58.20590. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.87199/58.24467. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.64873/58.20866. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.51751/58.08106. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.52918/57.90570. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 58.46503/57.89241. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.35742/57.88934. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.02937/57.69584. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 58.13018/57.64589. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.83697/57.53358. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 57.87057/57.48418. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.52625/57.34691. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.42014/57.22739. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.44548/57.07646. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 57.29364/57.08446. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 57.24753/56.87086. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 57.16158/56.81649. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.23595/56.91223. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.12162/56.69858. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 56.96613/56.63554. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 56.93330/56.65532. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.03189/56.45809. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 56.83848/56.36932. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 56.70209/56.57535. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 56.68702/56.35524. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 56.52740/56.19431. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 56.42668/56.15229. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 56.40436/56.34954. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.57905/55.97699. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.45657/56.06525. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 56.25857/56.23845. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 56.21344/55.87358. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 56.06832/55.85078. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 56.03353/55.94307. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 55.90379/55.86337. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 55.97060/55.77103. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 55.81378/55.66871. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 55.83954/55.56420. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 55.82957/55.39925. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 55.60973/55.65153. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 55.55665/55.56905. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 55.63549/55.49750. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 55.48141/55.33031. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 55.57906/55.24585. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 55.45497/55.07319. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 55.38918/55.38934. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 55.40031/55.36945. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 55.39364/55.14677. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 55.16309/54.87056. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.26824/54.89769. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 54.97486/55.32186. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 55.04327/54.89008. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.00826/54.77956. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 54.84930/54.84627. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.07390/55.24330. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.00086/54.69914. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 54.83720/54.67763. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 54.93473/54.82117. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 54.83167/54.98703. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 54.61609/54.81609. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 54.58335/54.64519. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 54.79991/54.84381. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 54.55697/54.75603. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 54.36308/54.71940. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.06900399154039837\n",
      "Epoch 0, Loss(train/val) 70.41942/69.99287. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.16257/69.77701. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.94487/69.54625. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.66376/69.29628. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.46788/69.04363. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.21592/68.78481. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.98653/68.52576. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.76434/68.26633. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.53211/68.02518. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.23751/67.78517. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.95661/67.53093. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.58166/67.25553. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.15443/66.94880. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.76428/66.59023. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.22541/66.14388. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.69811/65.61995. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.06302/65.02520. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.50345/64.39658. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.11669/63.79282. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.72280/63.25428. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.52878/62.74773. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.15473/62.29720. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 62.97258/61.90343. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.00200/61.58100. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.57842/61.32904. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.60079/61.08792. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.32901/60.88029. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.32090/60.66473. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.30935/60.49752. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.06232/60.31805. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.83057/60.16199. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 61.83296/60.00214. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.88349/59.85938. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 61.84610/59.75980. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.44323/59.63337. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.33774/59.51130. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.27912/59.41973. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.33987/59.33337. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.91816/59.23883. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.02447/59.13709. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.84708/59.05799. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.53113/58.96961. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.66387/58.91847. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.39647/58.83010. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 60.35758/58.76657. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.22768/58.66959. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.14634/58.59297. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.06241/58.50236. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.99540/58.40481. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 59.77022/58.32179. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.65941/58.26708. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.34231/58.18483. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.39586/58.11490. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.50045/58.05424. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.24240/57.96377. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.14628/57.87133. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.17714/57.81061. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.92079/57.76109. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.97250/57.69854. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.85311/57.65464. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 58.81697/57.56002. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.80682/57.57504. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 58.47644/57.50558. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 58.64758/57.47778. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.52928/57.40953. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.46478/57.37812. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.37711/57.35569. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.09250/57.26661. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 58.27006/57.30248. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.26051/57.22649. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.17627/57.19704. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.02918/57.10024. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.15476/57.00089. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 58.01832/57.05817. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.87205/57.02775. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.75117/56.93876. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.77875/56.93547. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 57.70413/56.90404. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.82093/56.84528. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.59295/56.83841. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.22066/56.80832. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.63129/56.74969. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.51476/56.71424. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.47664/56.70297. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.52410/56.68929. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.40684/56.62123. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.25631/56.59711. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.49332/56.53287. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.25724/56.56176. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.18538/56.55405. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.11440/56.52462. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.29053/56.47027. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.16616/56.46639. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.21425/56.44596. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.02083/56.41655. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.12994/56.40966. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 56.82819/56.46539. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.08153/56.68014. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.95166/56.66167. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.00620/56.54380. Took 0.32 sec\n",
      "ACC: 0.40625, MCC: -0.16324595240672599\n",
      "Epoch 0, Loss(train/val) 70.36508/69.24154. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.94967/68.82887. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.56424/68.41890. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.15612/68.00237. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.75250/67.56573. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.31253/67.11157. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.92039/66.62466. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.45928/66.10448. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.94102/65.52496. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.40201/64.86694. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.78609/64.11661. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.19574/63.27309. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 64.59755/62.35675. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 64.05157/61.41508. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 63.36557/60.45421. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 62.65945/59.47123. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 62.08155/58.47400. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 61.57584/57.46923. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 60.83335/56.46981. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 60.17791/55.45293. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 59.45398/54.44659. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 58.76694/53.49689. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 57.98254/52.64608. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 57.51087/51.91445. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 57.03206/51.32257. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 56.50636/50.85883. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 56.10320/50.49676. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 55.71360/50.20912. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 55.50868/50.00604. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 55.29736/49.84259. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 54.90041/49.71560. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 54.92070/49.64160. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 54.65192/49.68245. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 54.49167/49.80447. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 54.28100/49.73961. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 54.13279/49.64072. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 53.87388/49.54629. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 54.03862/49.51835. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 53.67229/49.50988. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 53.65514/49.43284. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 53.47327/49.34651. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 53.38359/49.31408. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 53.22352/49.33686. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 53.19797/49.33458. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 53.02970/49.26686. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 53.00859/49.21264. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 52.77399/49.32201. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 52.88250/49.14464. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 52.84603/49.25700. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 52.52224/49.09204. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 52.64146/49.23010. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 52.60273/49.16581. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 52.52404/49.10418. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 52.42731/49.13988. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 52.43998/49.13653. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 52.31964/49.00332. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 52.25741/49.19621. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 52.34488/49.08758. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 52.09272/49.20115. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 52.19501/49.04592. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 52.11137/49.07623. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 52.01497/49.14602. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 51.99702/49.03571. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 51.98656/49.06668. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 51.84562/48.94909. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 51.88388/49.14171. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 51.76426/48.95648. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 51.84450/49.08031. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 51.71142/49.01580. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 51.74311/48.89584. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 51.64921/48.92334. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 51.54282/48.88220. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 51.48153/49.00944. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 51.48750/48.84700. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 51.54977/48.91777. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 51.34971/48.75756. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 51.46953/48.88874. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 51.38173/48.77944. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 51.17185/48.78011. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 51.15977/48.76425. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 51.19111/48.74319. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 51.13138/48.72755. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 50.95496/48.69682. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 51.10189/48.64135. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 50.95188/48.55785. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 50.89353/48.63408. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 50.88727/48.45037. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 50.97084/48.50174. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 50.78373/48.36727. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 50.78928/48.43023. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 50.82073/48.28711. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 50.62107/48.26574. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 50.69464/48.20811. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 50.66860/48.18106. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 50.51459/48.29342. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 50.49330/48.00371. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 50.46634/48.15046. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 50.43977/47.97394. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 50.46484/48.18357. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 50.34727/47.96183. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: 0.031199984310868976\n",
      "Epoch 0, Loss(train/val) 70.87994/70.47076. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.61451/70.35211. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.30999/70.23948. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.05030/70.12991. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.78657/70.01411. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.48340/69.89825. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.22760/69.77968. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.96943/69.65176. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.81381/69.52719. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.51665/69.39772. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.33177/69.25941. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.12452/69.10530. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.83934/68.93776. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.65182/68.75108. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.48351/68.53508. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.12073/68.29430. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.89161/68.01848. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.65976/67.71283. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.24659/67.46494. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.02480/67.23304. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.83462/67.00122. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.60737/66.77203. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.37296/66.55912. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.15913/66.37324. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.12457/66.24692. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.84935/66.13377. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.69555/66.03476. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.59803/65.95760. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.45094/65.86605. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.34468/65.75330. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.16393/65.62740. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 64.09549/65.48466. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.90586/65.34081. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.79800/65.18456. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.73949/65.02441. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.66556/64.89496. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.34943/64.77075. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.24642/64.66281. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.14380/64.56473. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.11272/64.50208. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 62.91222/64.43739. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.91888/64.37976. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.94362/64.33913. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.79943/64.30946. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.69836/64.29565. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.69598/64.26476. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.81119/64.22858. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.60874/64.20217. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 62.64273/64.17856. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.48431/64.15296. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.63324/64.12097. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.39698/64.07858. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.27087/64.04996. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.38512/64.02939. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 62.36133/64.02158. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.20056/64.00422. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.04721/63.98040. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.26656/63.95099. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 62.06914/63.92168. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 62.20353/63.91227. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 61.96861/63.90828. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.09711/63.89333. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.95315/63.85635. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.82104/63.82319. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.78297/63.80638. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.84710/63.78968. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.79782/63.72276. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.75674/63.68995. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.83558/63.61550. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 61.80263/63.57094. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.62837/63.56434. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.69321/63.56566. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.72581/63.49726. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.69933/63.45168. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.54029/63.44139. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.49163/63.42331. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 61.59804/63.38456. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.67433/63.35516. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 61.43190/63.33064. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.47044/63.32655. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 61.52918/63.31129. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.51687/63.30217. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.41767/63.29134. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 61.34342/63.28255. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.23908/63.23095. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.26873/63.18606. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.26155/63.14180. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.18022/63.10518. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.22152/63.08466. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 61.23940/62.99173. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 61.21242/63.02150. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 61.12787/63.01868. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 60.97842/63.03116. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.09689/63.04617. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 61.12840/63.00008. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.01808/62.99032. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.97097/62.92598. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.94139/62.95873. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 60.89259/62.93960. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.89289/62.96524. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.0686780908582235\n",
      "Epoch 0, Loss(train/val) 71.08472/70.08755. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.78340/69.94707. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.49343/69.81231. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.24897/69.68846. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.97463/69.57028. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.70995/69.45174. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.42001/69.33020. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.14893/69.19405. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.85123/69.03728. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.56772/68.87004. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.18353/68.67566. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.80255/68.45014. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.45519/68.20153. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.98557/67.91154. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.55996/67.57316. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.07846/67.16843. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.48511/66.67708. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.97043/66.09235. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.35617/65.42215. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.77531/64.68698. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.09110/63.94137. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.59632/63.21258. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.96827/62.35472. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.54331/61.40982. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 61.01893/60.67254. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 60.73502/60.14127. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.45718/59.76341. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.15860/59.47371. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.02982/59.24283. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.82253/59.07962. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.68800/58.95366. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 59.55806/58.83909. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 59.41756/58.74320. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.42090/58.68288. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.33194/58.62749. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.22197/58.57789. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.23600/58.53529. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 59.19228/58.49652. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.05596/58.46428. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 59.09517/58.42792. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.96273/58.39361. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.94588/58.36629. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.91491/58.36991. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.66535/58.37613. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.66098/58.38971. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 58.57423/58.39101. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.52373/58.40466. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.31888/58.40581. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.42756/58.43545. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.36256/58.44440. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.35155/58.44243. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.25821/58.44719. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.20760/58.45835. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.95304/58.44300. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.86864/58.37482. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.96999/58.37414. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.79965/58.33614. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.71852/58.33625. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.70220/58.28727. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 57.69858/58.23689. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.55017/58.34633. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 57.62297/58.11977. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.36398/58.25511. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.25697/58.13353. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.31111/58.27056. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.14638/58.10693. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.07899/58.18877. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 56.97737/58.15298. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 56.96791/58.17061. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 56.89206/58.07954. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 56.98224/58.19623. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.68639/57.98518. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.86165/58.27559. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.65133/57.91893. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.69227/58.27711. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.79084/57.95414. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.54093/58.12538. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.47140/57.89320. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.47234/58.15118. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.48378/57.98337. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.37921/58.08609. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.53855/58.09897. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.30334/58.02952. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.25332/58.22297. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.25410/57.99805. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.15058/58.22682. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.30889/57.92270. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.21044/58.24530. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.92150/57.96283. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.12218/58.04192. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.97894/58.20771. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.94339/57.84695. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 55.90431/58.18333. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.88065/58.05219. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.97129/57.92451. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.81760/57.86072. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.72958/58.03063. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.75060/57.80810. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.79733/57.98070. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.62482/57.81186. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.049980989108788364\n",
      "Epoch 0, Loss(train/val) 69.99597/69.91416. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.66807/69.71323. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.36663/69.48289. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.03117/69.23799. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.68707/68.97868. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.26436/68.70020. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.79304/68.38191. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.25604/68.03986. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 66.71286/67.66196. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.17216/67.27558. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.56780/66.91758. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 65.11338/66.62400. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 64.75859/66.37383. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 64.46394/66.14771. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 64.09481/65.94838. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.78088/65.82180. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.56802/65.66398. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.41018/65.50478. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 63.26577/65.36073. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.92426/65.27037. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.72355/65.19149. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.78596/65.13270. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.61081/65.08152. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 62.54444/65.03286. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.47168/64.96693. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.58252/64.90111. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.48729/64.83585. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.20616/64.78992. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.15697/64.72311. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.18902/64.66720. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.15422/64.61503. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.19569/64.54403. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.02859/64.51726. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.97569/64.49377. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.86999/64.42635. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.89755/64.36066. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.82570/64.32591. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.69912/64.28465. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.61906/64.30602. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 61.54397/64.20863. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.54374/64.21571. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.63746/64.06084. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.32152/64.03715. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.41618/63.93133. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.24559/63.96621. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.34429/63.84771. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.45265/63.93145. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.12884/63.83632. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.12794/63.80167. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.22284/63.82823. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 60.99275/63.78953. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.78084/63.60746. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.97169/63.68764. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.73916/63.65963. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.59593/63.71436. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.64923/63.67787. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.53205/63.67083. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.65085/63.65317. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.49581/63.72773. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.65316/63.91091. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.25143/63.78374. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.39449/64.03159. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.30579/63.57885. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.41188/63.99163. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.19190/63.18285. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.22627/63.19341. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.10794/63.11422. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.98693/62.55247. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.04141/62.23689. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 59.84125/61.99973. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.64387/61.45027. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.79319/61.29452. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.41938/60.96804. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.42109/60.80320. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.25280/60.47968. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.03557/60.57949. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 59.02841/61.09499. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.21103/60.44349. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.90588/61.18851. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.79338/60.22200. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.72154/60.89432. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.61650/60.34635. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.46722/60.12183. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.39936/60.37315. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.31178/59.92874. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.31082/60.02143. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.20844/59.82028. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.00221/59.91156. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.06086/60.17915. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.14328/59.46983. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.89564/60.70824. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.26519/60.33005. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.99244/59.03562. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.86840/58.89752. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.97127/59.83398. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.54755/59.93570. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.56970/60.16542. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.64672/60.04039. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.74507/60.10398. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.74496/59.89756. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.008104408984731078\n",
      "Epoch 0, Loss(train/val) 70.49319/70.17926. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.26556/70.03699. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.07801/69.87611. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.87287/69.71319. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.63848/69.53439. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.34705/69.34355. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.13441/69.15540. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.74067/68.95539. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.43209/68.73682. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.00698/68.51437. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.54954/68.27651. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.00669/68.01913. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.56512/67.75938. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.91548/67.53955. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.27710/67.36750. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.70603/67.22739. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.13405/67.10556. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.78054/66.97786. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.42522/66.88329. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.05027/66.80641. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.73891/66.74371. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 62.68619/66.69235. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.51091/66.65643. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 62.16896/66.59821. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.07348/66.55472. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.08302/66.54327. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.03917/66.51961. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 61.88528/66.50973. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.63529/66.47739. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.60172/66.45767. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 61.56347/66.47140. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 61.49951/66.48525. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.47886/66.52310. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.32712/66.53416. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.27647/66.57791. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.09847/66.60892. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.07208/66.64292. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.91775/66.72225. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.90996/66.77003. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.88951/66.84003. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.77753/66.88511. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 60.77952/66.91715. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.59295/66.91866. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.61479/66.94968. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.50953/66.95538. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.49444/66.96636. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.39877/66.97543. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.46065/66.97288. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.40562/66.99004. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.35401/66.98978. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.34591/66.99332. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.30958/67.00359. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.12123/67.00884. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.17975/67.01264. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.07780/67.01176. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.07325/67.01964. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.95625/67.04297. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.82370/67.05927. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.93810/67.08672. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.94485/67.09169. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.75263/67.10460. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.89240/67.13474. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 59.73301/67.14389. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.82670/67.16886. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.60026/67.18171. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 59.79571/67.18726. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.71164/67.20243. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.60370/67.22583. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.59899/67.23568. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.48704/67.26504. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.48699/67.28124. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.39883/67.29536. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.29824/67.27378. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.51018/67.28239. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.50460/67.26877. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.18784/67.29298. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.12348/67.30163. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.28725/67.29216. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.21080/67.27641. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.18402/67.25290. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.29538/67.23090. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.06400/67.21985. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.86553/67.22552. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.88215/67.20318. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.17291/67.16473. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.96697/67.13365. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.90463/67.08834. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.94225/67.06926. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.77841/67.03262. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.85352/67.00924. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.62650/67.02412. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.64921/67.02397. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.70617/67.01147. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 58.57170/67.01406. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.63088/67.02868. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.56165/67.04135. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 58.39414/67.05599. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.52213/67.06245. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.61468/67.07440. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.24248/67.10168. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.13010726223589664\n",
      "Epoch 0, Loss(train/val) 70.08021/69.61740. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.82221/69.33761. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.53970/69.02084. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.22288/68.66740. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.86472/68.25651. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.44458/67.78088. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.96871/67.24083. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.40188/66.62914. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 66.86143/65.96187. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 66.27349/65.39096. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.68694/64.85834. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 65.15616/64.37374. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 64.73795/63.95653. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 64.29787/63.61142. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 63.81435/63.32403. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.54909/63.08471. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.11727/62.93238. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.90555/62.80589. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 62.84997/62.72735. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.73659/62.67075. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.51132/62.63256. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.50872/62.58382. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.24303/62.53253. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.37514/62.49604. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.22735/62.44753. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.34526/62.40100. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.16771/62.35176. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.95877/62.31298. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.05221/62.26305. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.87835/62.20319. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.90745/62.15116. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 61.87615/62.09729. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.84929/62.01729. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 61.73200/61.92725. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.77305/61.83363. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.64305/61.69897. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.63709/61.50040. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.65808/61.22031. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 61.39919/60.83763. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 61.28698/60.44913. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.21059/60.34895. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.13239/60.19796. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.08245/60.03227. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.08782/59.89927. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.93473/59.85690. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.87702/59.74873. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.65618/59.65598. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.72583/59.62793. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.59166/59.54687. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.44447/59.51424. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.39440/59.37328. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.23783/59.29029. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.01512/59.43239. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 60.09660/59.43708. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.09710/59.40916. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.91706/59.46896. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.86690/59.29328. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.71734/59.38898. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.67565/59.23082. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.82439/59.29549. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.64222/59.24081. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.57134/59.21819. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.54839/59.19584. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.32791/59.18133. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.31327/59.06094. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 59.27700/59.05080. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.22545/58.98220. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.06513/58.85643. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.07863/58.95779. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 59.02930/58.82264. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.03632/58.79789. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.95466/58.76363. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.04571/58.71253. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.89422/58.62671. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.86049/58.54935. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.73733/58.63647. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.79240/58.51141. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.71133/58.51267. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.72904/58.44664. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.70669/58.45750. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.54174/58.41969. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.58578/58.39089. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.65922/58.30269. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.61559/58.38450. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.38318/58.32698. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.50581/58.25542. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.08517/58.22960. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.44838/58.26648. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.35990/58.15800. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.23327/58.18003. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.30198/58.13334. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.29652/58.13728. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.18143/58.07454. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 58.01913/58.02882. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.08117/58.02771. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.13602/57.98249. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.10239/57.92527. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.89294/58.01495. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.99479/57.89202. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.99201/57.89483. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.03688555567816588\n",
      "Epoch 0, Loss(train/val) 70.73173/70.64922. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.59369/70.66410. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.46863/70.68188. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.35230/70.70741. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.25474/70.74387. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.12822/70.78349. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.97843/70.82584. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.88096/70.87080. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.75450/70.90990. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.60061/70.95069. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.46492/70.98570. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 69.33824/71.02499. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.19916/71.06178. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.08266/71.08394. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.91340/71.10139. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.78197/71.10324. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.60021/71.09505. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.41364/71.06883. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.26484/71.02493. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.08212/70.96305. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.92280/70.87013. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.75502/70.74490. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.54654/70.59451. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.33631/70.44141. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 67.15893/70.26980. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.94033/70.07179. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.87794/69.87104. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 66.75093/69.70387. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.55669/69.54390. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.33359/69.41088. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.22550/69.33875. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 66.15269/69.24751. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 66.04212/69.20129. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 65.99839/69.17921. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 65.78161/69.14500. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.69291/69.08936. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.59994/69.03918. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.54971/69.00595. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 65.57012/68.97782. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 65.26534/68.95349. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 65.19176/68.89075. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 65.17676/68.79968. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 65.30958/68.76553. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 65.05026/68.66354. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.92767/68.55977. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.84248/68.49148. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.84793/68.43167. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 64.71972/68.35633. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.66530/68.31551. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 64.60353/68.29351. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 64.56723/68.28803. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 64.56741/68.25697. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 64.41673/68.24930. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 64.47683/68.15978. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 64.32420/68.02863. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 64.26127/67.95702. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 64.33956/67.96188. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 64.30811/67.97124. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 64.06570/67.89941. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 64.08515/67.80621. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 64.07847/67.67953. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 64.00327/67.64626. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.88606/67.63184. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.80203/67.56900. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.74195/67.55503. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.74788/67.53661. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 63.69643/67.50391. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 63.53712/67.43985. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 63.57305/67.36655. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 63.55106/67.33743. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 63.53560/67.32764. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 63.35837/67.29590. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 63.32568/67.21811. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 63.17716/67.20199. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 63.25099/67.18393. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 63.04612/67.08601. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.91195/67.06152. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 62.97783/67.01595. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.79729/66.91501. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 63.03590/66.89001. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 62.72789/66.80915. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.85273/66.71621. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 62.77356/66.66666. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 62.66286/66.62210. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.46968/66.59007. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.65124/66.49630. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.58077/66.42476. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 62.33241/66.48798. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 62.54369/66.47057. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 62.36338/66.33838. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 62.35859/66.34363. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 62.29541/66.30025. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 62.46049/66.23051. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 62.33513/66.30803. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 62.41827/66.24625. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 62.01271/66.16453. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 62.15573/66.17522. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 62.19246/66.12074. Took 0.30 sec\n",
      "Epoch 98, Loss(train/val) 62.09153/66.15011. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 62.13376/66.03954. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.07710592627016746\n",
      "Epoch 0, Loss(train/val) 70.82536/70.83692. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.55540/70.64125. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.29722/70.43690. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 69.99211/70.20596. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.71023/69.94592. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.30452/69.64410. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.90613/69.28177. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.52583/68.82836. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.06656/68.26296. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.45145/67.55295. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.90957/66.70238. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.16888/65.83844. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 65.64066/65.03994. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.04244/64.32790. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 64.55865/63.77366. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 64.11305/63.31297. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.66051/62.89918. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.25671/62.51989. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.83248/62.18040. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.49567/61.84970. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 62.07229/61.54354. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.77198/61.25492. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.56345/61.00069. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 61.21930/60.78155. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.99048/60.61049. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 60.62942/60.43150. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.47811/60.33878. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.39531/60.20722. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.04770/60.16250. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.94387/60.09366. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.89580/60.06130. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 59.67428/60.06195. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.58660/60.03163. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.31969/60.02929. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.25027/60.04061. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.21220/60.04577. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 59.10356/60.06357. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.93012/60.07997. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 58.91021/60.10156. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 58.79021/60.10658. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 58.84728/60.10434. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.71756/60.11143. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.64940/60.16854. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.54104/60.16895. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.43397/60.22039. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.40651/60.19224. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.38144/60.20370. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.23898/60.23588. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.12812/60.23454. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.00433/60.25815. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 58.00046/60.26943. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.96413/60.30669. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.89292/60.34130. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.84918/60.36576. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 57.83995/60.43743. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.69342/60.43060. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.57202/60.48389. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.49094/60.53572. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.46082/60.59559. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 57.60061/60.62067. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.31076/60.70246. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.27276/60.75280. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.12231/60.75922. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 57.09177/60.84309. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 57.18099/60.88578. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.97121/60.91620. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 56.92146/61.00628. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 56.83608/61.00434. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 56.79335/61.01084. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 56.59552/61.06842. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.63181/61.03649. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.81438/61.06425. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.65270/61.09645. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 56.57854/61.09044. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.54684/61.11734. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.53154/61.13261. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.33371/61.15973. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.34956/61.21110. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.33465/61.21111. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.32539/61.22617. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 56.04053/61.23896. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.15294/61.24104. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.17888/61.24499. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.02317/61.24799. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.11755/61.25828. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.01264/61.25293. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 55.97042/61.25969. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 55.83325/61.22578. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 55.80991/61.21584. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.93976/61.22079. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 55.70256/61.22131. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.70024/61.24713. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.80190/61.24638. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.70093/61.22667. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.63995/61.23666. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 55.57403/61.22939. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.48388/61.22845. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.59525/61.25272. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.39745/61.20163. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.46469/61.17739. Took 0.31 sec\n",
      "ACC: 0.546875, MCC: 0.14060420405767388\n",
      "Epoch 0, Loss(train/val) 69.69122/70.78719. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.43914/70.66712. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.20994/70.53274. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 68.97404/70.39244. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.64878/70.24658. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.33296/70.08824. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.01578/69.92014. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.71798/69.75088. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.38341/69.57812. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.08169/69.40628. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.63083/69.23265. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.23702/69.04590. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.86104/68.84391. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.52195/68.62373. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.17864/68.39429. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.80694/68.16800. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.47700/67.94649. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.17110/67.73893. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.78966/67.53461. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.53603/67.34048. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.21011/67.16698. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.18792/67.01069. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.98784/66.86246. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.67945/66.72285. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 62.56564/66.59664. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.42963/66.49137. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.36709/66.42080. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.18861/66.36794. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.07193/66.32142. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.03074/66.27882. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 62.01347/66.24627. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.03112/66.21518. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.63928/66.18804. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.78708/66.18470. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.60196/66.14572. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 61.54252/66.10889. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.44818/66.12151. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.44275/66.12412. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.32603/66.04398. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 61.38130/66.00058. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.10056/66.00275. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.02972/66.00536. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.08000/65.97821. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.87916/65.95660. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.91905/65.95303. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.92379/65.91785. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.89238/65.91687. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 60.86221/65.88322. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.85879/65.86697. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.61720/65.83518. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.77227/65.81637. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.77748/65.84032. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.62995/65.83753. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.61982/65.79745. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 60.49316/65.78440. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.61468/65.76531. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.59062/65.73202. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.52569/65.71252. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 60.48013/65.69865. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.36230/65.69725. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.51115/65.71037. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 60.32239/65.67837. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.21780/65.63751. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.42344/65.62976. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.26269/65.62155. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 60.24093/65.61124. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.32060/65.59402. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.32775/65.60133. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 60.12750/65.62295. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.15017/65.62181. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.23924/65.61898. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.15261/65.60561. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.02441/65.60986. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.09709/65.57548. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.07253/65.57817. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 60.15047/65.58643. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.03492/65.58701. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.02991/65.55195. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.88136/65.54527. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.90501/65.53390. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 59.89685/65.51878. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.95492/65.52203. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.82929/65.50147. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.95985/65.50830. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.94968/65.48742. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.64832/65.47260. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 59.75600/65.48952. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.65575/65.49953. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.74008/65.47118. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.89093/65.43318. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.71397/65.44101. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.83412/65.47034. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.54455/65.46404. Took 0.30 sec\n",
      "Epoch 93, Loss(train/val) 59.57956/65.45485. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.68668/65.42897. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 59.70773/65.45848. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.49901/65.45990. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.69581/65.45053. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.65491/65.43269. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.37570/65.48750. Took 0.32 sec\n",
      "ACC: 0.375, MCC: -0.33268447056752387\n",
      "Epoch 0, Loss(train/val) 70.67574/70.99023. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.45715/70.78362. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.13852/70.57220. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.87452/70.35478. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.63133/70.12889. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.29947/69.90304. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.08309/69.67683. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.71444/69.44916. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.45263/69.21526. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.11648/68.97372. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.67744/68.73170. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.31336/68.49072. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.92380/68.24959. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.56719/68.00281. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.25373/67.75323. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.92278/67.49788. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.57642/67.23397. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.23530/66.95972. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.06931/66.68430. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.84758/66.40837. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.56869/66.14121. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.42621/65.87938. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.04741/65.62477. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.81352/65.37991. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.72689/65.15953. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.44650/64.96992. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.30642/64.81420. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.01143/64.70833. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.77297/64.66324. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 62.61820/64.60998. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.46598/64.55051. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.26686/64.48209. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.17934/64.40739. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.98763/64.32287. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.22032/64.22890. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.01526/64.13181. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 61.82901/64.03368. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.66358/63.92506. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.51482/63.82243. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.63624/63.70950. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.47450/63.59310. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.53175/63.48527. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.24842/63.38198. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.29049/63.28347. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 61.16511/63.19569. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.85373/63.10531. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.98265/63.03156. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.97246/62.96047. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.79740/62.91090. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 60.70334/62.86773. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.86786/62.82398. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 60.63107/62.78875. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.47658/62.75801. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.72197/62.72976. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.42212/62.70595. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.34649/62.67982. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.24607/62.65516. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.22363/62.62561. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.27050/62.60395. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.00304/62.58226. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.17432/62.55990. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.15231/62.54257. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 60.04714/62.52430. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.94231/62.50130. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 59.93897/62.47635. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 59.88639/62.45507. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.82049/62.44214. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.87550/62.41450. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.77007/62.40263. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.60390/62.38254. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.64085/62.37960. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.69593/62.35455. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.56614/62.34976. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.38498/62.32467. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.48503/62.30227. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.42501/62.27801. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 59.40010/62.25586. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.46796/62.24841. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.35605/62.23644. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 59.35250/62.20908. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.18389/62.18524. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.16748/62.15776. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.14460/62.12552. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.22223/62.13615. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.14358/62.10661. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.11094/62.07365. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.98360/62.07289. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.09143/62.06562. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.79926/62.04164. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.91682/62.01082. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 58.94026/62.00111. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.90485/61.98891. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 58.79472/61.96651. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.86729/61.95418. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.86066/61.95782. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.82114/61.91169. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.76962/61.91474. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.62073/61.86690. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.58407/61.85488. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 58.63879/61.83759. Took 0.31 sec\n",
      "ACC: 0.546875, MCC: 0.05718335949618505\n",
      "Epoch 0, Loss(train/val) 70.81607/70.18561. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.53919/69.98244. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.30389/69.79287. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.02080/69.60889. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.80435/69.42390. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.54390/69.22825. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.24203/69.02258. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.95588/68.80691. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.70606/68.58926. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.37597/68.37263. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.12096/68.15740. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.83796/67.94728. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 67.56502/67.74268. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.32162/67.53605. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.10940/67.32852. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.81917/67.12025. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.69321/66.92075. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.34650/66.72904. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.28961/66.54676. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.15884/66.37251. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.91731/66.21803. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.81009/66.07053. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.54594/65.93172. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.47869/65.80840. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.27073/65.69703. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.17752/65.60105. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.03880/65.51521. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.72567/65.43123. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.73613/65.34841. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.56716/65.26848. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.38607/65.22282. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 64.26830/65.17092. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.17323/65.12207. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.99517/65.07115. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.86154/65.01881. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.73599/64.95813. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.65636/64.90022. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.60926/64.85331. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.58374/64.81553. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 63.48334/64.76855. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.49142/64.72236. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.33727/64.68445. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.16765/64.65624. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 63.28764/64.62800. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.25911/64.60345. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 63.19747/64.57869. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.14737/64.54737. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.97962/64.52203. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.18758/64.50486. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.05298/64.48495. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.98530/64.45462. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.01109/64.42959. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.00712/64.41734. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.15241/64.40163. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.80196/64.39085. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 62.73829/64.37463. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.69369/64.35923. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.70372/64.34230. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 62.67345/64.32607. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.81307/64.31483. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 62.49158/64.29520. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.49138/64.27045. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 62.56147/64.26031. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.42069/64.25217. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.45871/64.24829. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.51571/64.24763. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 62.44181/64.25089. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.46995/64.25933. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 62.42754/64.27658. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.39031/64.27942. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 62.37360/64.27432. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 62.38893/64.28062. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.28800/64.29239. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 62.33696/64.30003. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.34986/64.31318. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.34612/64.32474. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.20206/64.33017. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.15845/64.33615. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 62.10419/64.34737. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 62.04483/64.34321. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.06326/64.33947. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.31242/64.34557. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 62.09202/64.35217. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 62.07826/64.35316. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 61.94846/64.35345. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.17951/64.35824. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.04026/64.37302. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 61.98280/64.38884. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.97119/64.39018. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.99246/64.38235. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 61.91781/64.38631. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.74786/64.38731. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 61.88013/64.39043. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.83500/64.39011. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.88858/64.40253. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.79744/64.40587. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.71731/64.40039. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 61.73321/64.39616. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.76038/64.38518. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.79959/64.37103. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: 0.01698823971458752\n",
      "Epoch 0, Loss(train/val) 70.92956/70.45094. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.56128/70.23373. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.19731/70.00964. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.85153/69.77168. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.46693/69.52257. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.05394/69.26507. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.63533/69.00127. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.22884/68.73166. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.77580/68.45345. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.32578/68.16870. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.82827/67.86880. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.47562/67.56213. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 65.98284/67.23894. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.64843/66.89925. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.31984/66.56162. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.09261/66.22052. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.65918/65.88091. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.45680/65.54971. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.15170/65.22884. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.96759/64.89908. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.71157/64.58149. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.47763/64.26793. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.36723/64.00585. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.15752/63.80802. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 62.92766/63.63716. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.64737/63.48576. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.45193/63.35212. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.24339/63.25451. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.98391/63.19129. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.92898/63.13194. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.60288/63.07308. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.32840/63.01656. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.12025/62.96025. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.08121/62.90680. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.01104/62.85023. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.85509/62.79775. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.79550/62.75011. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.63613/62.70457. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.45828/62.66328. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 60.28420/62.62681. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.19309/62.59314. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 60.26446/62.55769. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.17457/62.52405. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.14002/62.49766. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 60.02722/62.46181. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.93773/62.43414. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.67567/62.40884. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.51665/62.36221. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.37950/62.31388. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.43614/62.24724. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.42049/62.16511. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.17647/62.08218. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.04272/61.99031. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.15760/61.89662. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.13905/61.80095. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.69917/61.71284. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.84319/61.63007. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.74465/61.54632. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 58.52900/61.44486. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.60210/61.34985. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.51359/61.30729. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.39855/61.16967. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.33190/61.12714. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.10957/60.87252. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.94427/60.72273. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.03523/60.62698. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.00205/60.51942. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.97507/60.20715. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 57.84929/60.19684. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.72149/59.90386. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.54696/59.82195. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.60173/59.80589. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 57.45648/59.60494. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.38096/59.58366. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.35862/59.45597. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.21597/59.48818. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.99528/59.36007. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.11711/59.34190. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.95120/59.29943. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.79400/59.30339. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.70609/59.25790. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.85329/59.14985. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.67734/58.99475. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.65402/58.98596. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.45633/59.17628. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.44323/59.57367. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.36945/59.07995. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.23730/58.75619. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.21195/59.08759. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.22987/59.24394. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.25230/59.38373. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.24514/59.04487. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.64562/59.00368. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.79870/59.14781. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.91907/59.26824. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 55.88459/58.49175. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.96485/59.02100. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.81078/59.36951. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.43472/58.66029. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.37190/58.15903. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: -0.019518001458970664\n",
      "Epoch 0, Loss(train/val) 71.12357/71.22312. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.97053/71.04443. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.77393/70.86870. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.58178/70.69133. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.44610/70.51559. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.22806/70.33942. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.08122/70.15408. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 69.86929/69.96548. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 69.67559/69.77479. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.49013/69.57083. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.24414/69.36597. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.03229/69.15754. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.75132/68.94176. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 68.50838/68.72716. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.29949/68.51686. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.03191/68.31392. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.81982/68.11704. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.55743/67.92821. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.24890/67.74013. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.07555/67.54752. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.82019/67.36055. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.54471/67.17440. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.35751/66.99030. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 66.17895/66.81334. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.89735/66.63982. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.69593/66.46568. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.56545/66.30746. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 65.36574/66.16077. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.18140/66.02656. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 65.00841/65.90823. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.91336/65.79973. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 64.72277/65.71089. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.54155/65.64335. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.38582/65.58546. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.19864/65.53452. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.12398/65.47751. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 64.05073/65.44653. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.78173/65.42369. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.73859/65.37791. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 63.65295/65.33036. Took 0.30 sec\n",
      "Epoch 40, Loss(train/val) 63.41029/65.27753. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.42616/65.23888. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.31123/65.20427. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.13256/65.15414. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.05972/65.11405. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.85303/65.06654. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.81620/65.01382. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.80092/64.89804. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.58052/64.83098. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.50523/64.67482. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 62.47813/64.49187. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.37544/64.34344. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.21808/64.25994. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.17296/64.22408. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 62.07382/64.18739. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.91711/64.15448. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.94860/64.12054. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.75399/64.09963. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.70294/64.06993. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.56934/64.04008. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.73370/64.02295. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.52364/63.98776. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.22238/63.98744. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 61.52546/63.93363. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 61.37513/63.92460. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.46083/63.88481. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.14572/63.85289. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.15382/63.80357. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.10245/63.77359. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.10284/63.75077. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.97357/63.71763. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.95063/63.69796. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.82030/63.71318. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.80318/63.65793. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.75913/63.64562. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.75861/63.61589. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.70671/63.58305. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.62563/63.54881. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.53472/63.56996. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 60.64141/63.48710. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 60.37537/63.51152. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.45873/63.44731. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.34949/63.50442. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.32531/63.45607. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.20463/63.46413. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.27350/63.47989. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.29728/63.43571. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.19084/63.46564. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.14094/63.39199. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.18171/63.42022. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.01330/63.37127. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.98397/63.38382. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.02411/63.37522. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.95704/63.38521. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.81480/63.33401. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.79970/63.32152. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.84125/63.29450. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.81751/63.22215. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.71887/63.19562. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.65251/63.23148. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.045322786711889926\n",
      "Epoch 0, Loss(train/val) 71.58347/69.97872. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 71.28936/69.69849. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.89941/69.41840. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.61393/69.13513. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.30791/68.84132. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.93395/68.54408. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.60332/68.24548. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.25096/67.94579. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.95276/67.64687. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.54586/67.34245. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.12286/67.01976. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.66681/66.69453. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.16791/66.34491. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.58758/65.93713. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.98052/65.44125. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.30161/64.82230. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.63181/64.02915. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.81665/63.10007. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.40290/62.13382. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.57538/61.24575. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 61.95775/60.49350. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.36731/59.78917. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 61.01413/59.11446. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 60.41785/58.42578. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.14530/57.87540. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 59.89803/57.48458. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 59.45872/57.18542. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 59.50090/56.94703. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 59.20557/56.74590. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.04982/56.58311. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.02142/56.45036. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 58.95097/56.32347. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 58.83362/56.21793. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 58.70925/56.09923. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 58.42240/55.97268. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 58.44778/55.82868. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 58.30730/55.70469. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.08830/55.57088. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.19071/55.43839. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 57.93715/55.39378. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 57.77323/55.25181. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 57.50779/55.20850. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 57.59089/55.13542. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 57.60160/55.10138. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 57.39940/55.11188. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.11770/55.12164. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 56.96635/55.17971. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 56.98335/55.21474. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 56.92236/55.21095. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 56.91529/55.22730. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 56.79138/55.22863. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 56.57404/55.23829. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 56.71017/55.22376. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 56.52905/55.27094. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 56.58573/55.22945. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 56.39694/55.28444. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 56.43564/55.34468. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 56.18143/55.39894. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 56.45348/55.47978. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 56.30478/55.60707. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 56.18858/55.76413. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 56.16026/55.79205. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 56.22656/55.84972. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 56.10040/55.89146. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 55.94693/56.01230. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 55.94121/55.99487. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 55.97425/56.00417. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 55.71936/56.10014. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 55.99474/56.13985. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 55.66501/56.06377. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 55.78284/56.11388. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 55.68726/56.12751. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 55.76858/56.11704. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 55.59610/56.17370. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 55.68721/56.05324. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 55.77697/56.10107. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 55.66882/56.03328. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 55.46573/56.02103. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 55.75896/56.05984. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 55.37709/56.00703. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 55.39366/56.04326. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 55.45227/55.99564. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 55.33433/56.05456. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 55.28524/55.97395. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 55.37242/55.94236. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.25378/55.95346. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 55.45292/55.89077. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 55.13963/55.87595. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 55.06500/55.82338. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 55.03564/55.82813. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 54.85471/55.73140. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.05770/55.69601. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 54.97046/55.57772. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 54.79836/55.67512. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.02006/55.59322. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 54.75814/55.63731. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 54.83982/55.58501. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 54.67388/55.61609. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 54.76838/55.56565. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 54.94526/55.64197. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.09216619992325613\n",
      "Epoch 0, Loss(train/val) 69.83453/69.74433. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 69.41666/69.33451. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 68.99906/68.84653. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 68.42756/68.26607. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 67.86227/67.58404. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 67.15257/66.78456. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 66.44185/65.88390. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 65.63546/64.94567. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 64.67779/64.11087. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 63.90189/63.33436. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 63.02799/62.66958. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 62.40585/62.10418. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 61.86901/61.59014. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 61.17629/61.09029. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 60.70578/60.60508. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 60.27051/60.15302. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 59.72893/59.73830. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 59.45284/59.40572. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 59.21238/59.12333. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 58.81561/58.87384. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 58.62331/58.64317. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 58.43214/58.43411. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 58.28837/58.23681. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 57.94440/58.05122. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 57.63929/57.88604. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 57.55546/57.75840. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 57.46246/57.64172. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 57.09592/57.51468. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 57.00940/57.39974. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 56.76406/57.28252. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 56.53412/57.17575. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 56.47937/57.06465. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 56.36590/56.95674. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 56.32820/56.85666. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 56.14466/56.76128. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 56.01231/56.66894. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 56.05710/56.59170. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 55.89184/56.51774. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 55.94334/56.45262. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 55.89813/56.39458. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 55.70783/56.32742. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 55.82835/56.28476. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 55.80287/56.29003. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 55.62762/56.22032. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 55.69043/56.32166. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 55.52902/56.17147. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 55.55876/56.18878. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 55.35390/56.21648. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 55.38825/56.12151. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 55.47419/56.03121. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 55.46326/55.98921. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 55.30779/55.87646. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 55.30238/55.82823. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 55.24139/55.78431. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 55.24510/55.70729. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 55.31855/55.65711. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 55.03080/55.59579. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 55.04501/55.57431. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 55.11325/55.53973. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 55.05659/55.45224. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 55.12066/55.41125. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 55.03420/55.41236. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 55.05751/55.38423. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 54.98616/55.30550. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 54.91236/55.26465. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 55.11935/55.30727. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 54.88736/55.19551. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 55.02631/55.12155. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 54.88550/55.08860. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 54.88680/55.09712. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 54.68752/55.05223. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 55.06064/54.97699. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 54.82862/55.00010. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 54.77856/55.00727. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 54.82243/55.00517. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 54.62885/54.99554. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 54.73136/54.95065. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 54.75165/54.96016. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 54.66687/54.96327. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 54.75145/54.87362. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 54.70067/54.88475. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 54.77586/55.00634. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 54.76526/55.02951. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 54.69379/54.96765. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 54.65899/54.79887. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 54.87977/55.19619. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 54.96393/54.81483. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 54.99409/55.06543. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 54.86863/54.76381. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 54.51343/54.81650. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 54.64298/54.72615. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 54.71735/54.86076. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 54.70706/54.77861. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 54.60546/54.89866. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 54.59421/54.84824. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 54.55485/54.81018. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 54.46532/54.81908. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 54.53399/54.72336. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 54.64503/54.83254. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 54.38733/54.82689. Took 0.32 sec\n",
      "ACC: 0.5, MCC: -0.021109792565893827\n",
      "Epoch 0, Loss(train/val) 70.79426/71.35393. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.53328/71.14866. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.32253/70.94850. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.09316/70.74872. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.78235/70.54789. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.50669/70.34970. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.28538/70.14603. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.96129/69.94759. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.76434/69.75832. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.41804/69.57780. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.15708/69.40380. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.87770/69.23470. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.54525/69.07663. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.23333/68.92589. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.94789/68.78822. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.69309/68.65638. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.32505/68.52350. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.09232/68.38938. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.70835/68.23856. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.57942/68.06487. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.14665/67.85350. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.79028/67.61158. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.44831/67.35169. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 64.13381/67.09075. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.96080/66.82480. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.59254/66.54591. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.34063/66.25360. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.05363/65.93180. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.75603/65.56848. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.55920/65.17575. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.25990/64.81753. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.00548/64.51698. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.66257/64.27467. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.41101/64.08580. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.35219/63.92656. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 61.28843/63.77840. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.02801/63.64281. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.79371/63.54269. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.86717/63.43748. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.80510/63.30853. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.68969/63.20362. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.76460/63.13615. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.59268/63.02542. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.58524/62.93137. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.49527/62.85005. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.47942/62.76216. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.40304/62.65892. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.15507/62.53954. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.27159/62.42704. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.06417/62.30488. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.11173/62.20016. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.97474/62.05729. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.97097/61.95926. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.78514/61.78595. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.85778/61.65439. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.83116/61.52957. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.55233/61.41658. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.68386/61.36801. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.44283/61.21785. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 59.37815/61.12602. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.36615/61.03896. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 59.33006/60.97218. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.33692/60.90619. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 59.34405/60.81274. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.04930/60.77294. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.05927/60.72417. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.03651/60.73555. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.05632/60.62281. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.96124/60.58432. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.00877/60.55087. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 58.85493/60.54960. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.82596/60.48448. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.90074/60.45771. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.78234/60.44982. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.68860/60.40434. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.61094/60.37082. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.46876/60.33491. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.61648/60.32464. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.43526/60.33875. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.53653/60.29113. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.35500/60.25155. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.55737/60.22644. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.59347/60.21247. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.21239/60.18605. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.31365/60.17475. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.48832/60.14710. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.52213/60.12048. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 58.25382/60.10688. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.31632/60.11630. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.22726/60.02990. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.14222/60.05308. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.18964/60.05585. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.19647/60.04311. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.22545/60.02526. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.19461/60.03532. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.00784/60.00595. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.16393/59.97765. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.11864/59.94170. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.08059/59.93428. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.90835/59.95929. Took 0.32 sec\n",
      "ACC: 0.5, MCC: -0.027192378737182915\n",
      "Epoch 0, Loss(train/val) 70.75983/71.00983. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.40454/70.76710. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.08116/70.51009. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.68807/70.23734. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.36046/69.94394. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.98589/69.62807. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 68.60852/69.28302. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.16655/68.90179. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.69838/68.47668. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.26828/67.99465. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.78753/67.46086. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.20553/66.87798. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 65.78197/66.25159. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 65.28310/65.59653. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.85731/64.91078. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.42834/64.20607. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.83429/63.46902. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.42716/62.69665. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.90808/61.90723. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.39441/61.08198. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 61.93485/60.32962. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.47389/59.76335. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.25900/59.43754. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 60.79298/59.29439. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.47166/59.20035. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 60.28463/59.11477. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.31776/59.04437. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.11978/58.97913. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 59.93999/58.90891. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.74221/58.81956. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.72637/58.71989. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.55872/58.60489. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.41662/58.49414. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.21241/58.38634. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.08099/58.27041. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.03858/58.17935. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.06447/58.08625. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.82839/58.00417. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.79120/57.93570. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 58.75489/57.86663. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.57059/57.80977. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.42650/57.75816. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.35147/57.71051. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.39690/57.66933. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.25589/57.63654. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.27757/57.60558. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.13512/57.58281. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.10224/57.57151. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 57.95383/57.55991. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.11157/57.54787. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 58.00662/57.54200. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.98806/57.53397. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 57.89743/57.52008. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 57.86527/57.51082. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.84441/57.51636. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.79328/57.51719. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.69933/57.49371. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.77366/57.45088. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.60408/57.44821. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.67125/57.44046. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.67132/57.43026. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 57.54399/57.43665. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.60024/57.45310. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.62002/57.44082. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.48729/57.44078. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.56669/57.48312. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 57.55159/57.47947. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.42184/57.45161. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 57.40305/57.46773. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.49126/57.47514. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.41709/57.49432. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.24586/57.52109. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.35596/57.53829. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.40405/57.52039. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.17450/57.53239. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.13703/57.54767. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.17339/57.52619. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.15015/57.54226. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.09424/57.56281. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.06453/57.55632. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.98271/57.51384. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.97259/57.56018. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.00565/57.54592. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.84736/57.52345. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.92985/57.56544. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.99108/57.57757. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.77774/57.57103. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.92807/57.64622. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 56.91588/57.65710. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.88819/57.60791. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.79166/57.56545. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.91176/57.44864. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.67679/57.52981. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 56.83688/57.64402. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 56.79078/57.59348. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.59573/57.52965. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 56.67181/57.56330. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.39505/57.56815. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.56541/57.54263. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.45894/57.51904. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.055997550008062294\n",
      "Epoch 0, Loss(train/val) 70.87241/70.26839. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.79630/70.26738. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.70984/70.26968. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.60963/70.26846. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.53527/70.26521. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.46839/70.26211. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.40167/70.26074. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.32186/70.25709. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.15964/70.25027. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 70.11786/70.25018. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 70.03825/70.24751. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.98903/70.24438. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.91203/70.24055. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.80693/70.22161. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.74216/70.20373. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.65869/70.18459. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 69.61997/70.15966. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 69.50756/70.13765. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 69.43505/70.11726. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 69.32188/70.08900. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 69.29273/70.05743. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 69.21773/70.03266. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 69.22490/70.00394. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 69.11947/69.97473. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 68.99547/69.93640. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 68.89637/69.90037. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 68.90562/69.87206. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 68.75436/69.83305. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 68.72155/69.79160. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 68.61235/69.74681. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 68.54123/69.70350. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 68.51086/69.65437. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 68.38352/69.59840. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 68.31715/69.54960. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 68.20018/69.49974. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 68.14942/69.43319. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 67.97666/69.37061. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 68.02815/69.29847. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 67.86892/69.21579. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 67.75621/69.13293. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 67.67828/69.04860. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 67.52713/68.97152. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 67.47354/68.88732. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 67.39509/68.79143. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 67.31460/68.69251. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 67.22742/68.57533. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 67.13848/68.47274. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 66.96860/68.36971. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 66.87969/68.26752. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 66.70869/68.16225. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 66.71629/68.07107. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 66.43147/67.95855. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 66.42388/67.86661. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 66.38889/67.77129. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 66.32803/67.70113. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 66.15720/67.62427. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 66.05112/67.57926. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 66.02438/67.49575. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 65.96495/67.42062. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 65.77014/67.36552. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 65.81012/67.30580. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 65.59456/67.27200. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 65.63175/67.19975. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 65.51422/67.17163. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 65.58220/67.16100. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 65.38821/67.16815. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 65.33480/67.15179. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 65.11821/67.14705. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 65.26217/67.15707. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 65.13536/67.20499. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 65.12417/67.19289. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 64.94598/67.12946. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 64.97152/67.09076. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 64.84410/67.05891. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 64.78248/67.10940. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 64.76051/67.11250. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 64.62638/67.11794. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 64.55124/67.10361. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 64.45481/67.13454. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 64.47543/67.08482. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 64.47642/67.09335. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 64.43309/67.07310. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 64.27300/67.10849. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 64.25861/67.13036. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 64.23782/67.13178. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 64.31638/67.06389. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 63.99646/67.09899. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 64.12486/67.02988. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 64.14843/67.06198. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 63.90188/66.99014. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 63.98105/67.01522. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 63.73506/66.97639. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 63.88933/66.99536. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 63.74184/67.01277. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 63.69216/67.01480. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 63.68580/66.98803. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 63.68400/67.03500. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 63.70408/66.98930. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 63.52551/66.99873. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 63.55937/67.13311. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.11065666703449763\n",
      "Epoch 0, Loss(train/val) 70.98641/71.08332. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.84184/70.92416. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.74376/70.76413. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.62517/70.60932. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.54714/70.45599. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.40304/70.29897. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.30993/70.13750. Took 0.34 sec\n",
      "Epoch 7, Loss(train/val) 70.18906/69.97080. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 70.05913/69.79581. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.94365/69.60077. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.81352/69.38186. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.68188/69.13599. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.46528/68.84692. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 69.23991/68.50315. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.03111/68.10470. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.82670/67.66109. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.45637/67.18237. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 68.19080/66.70634. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 67.90433/66.26930. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 67.67089/65.88133. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.36382/65.54156. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.12545/65.24677. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 66.86069/64.97813. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.59793/64.74427. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.38305/64.52333. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.20686/64.32397. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.98845/64.17085. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 65.85544/64.04938. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.67608/63.95739. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.52340/63.86084. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 65.44964/63.76481. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.26986/63.67162. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.07588/63.60667. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.12521/63.56045. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 64.91317/63.50198. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.80813/63.43583. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 64.73829/63.36939. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.56532/63.31850. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.55998/63.25091. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 64.57308/63.16924. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.33385/63.08284. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 64.22267/62.99532. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.03438/62.92159. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.85671/62.82918. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 63.70313/62.73834. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 63.74178/62.63435. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.50880/62.52086. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.57042/62.41836. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.34114/62.33822. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.25139/62.27156. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 63.13285/62.16747. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.02021/62.10635. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.87502/62.01808. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.76026/61.92513. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.65196/61.86017. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.73264/61.79636. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.57805/61.70575. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.51290/61.62043. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.38013/61.56182. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 62.24191/61.49233. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.12553/61.44042. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.05442/61.39492. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.02693/61.35670. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.03881/61.30119. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.73563/61.26195. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 61.74393/61.23043. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.77450/61.17860. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.67683/61.15203. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.51878/61.13002. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.48566/61.11194. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.21945/61.08266. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.31940/61.05198. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.26122/61.06959. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.22601/61.08620. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.14924/61.05383. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.00480/61.05376. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.91400/61.04473. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.82177/61.05900. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.84437/61.04356. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.82244/61.08019. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 60.75371/61.12025. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.71865/61.16486. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.53438/61.22562. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.39218/61.33309. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.47428/61.39075. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.26738/61.45152. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.22864/61.53842. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.25704/61.59264. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.00581/61.58203. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.97322/61.61601. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.88602/61.63569. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.86038/61.65271. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.85780/61.66526. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.76506/61.68298. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.74651/61.74368. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.51331/61.74182. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.50954/61.76887. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 59.47236/61.79397. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.35311/61.76285. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.35579/61.80093. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.13211031413252305\n",
      "Epoch 0, Loss(train/val) 70.65795/70.39044. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.37561/70.09119. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.19104/69.78131. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.86451/69.44670. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.53884/69.08965. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.28375/68.71021. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.90307/68.28493. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.51007/67.80871. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.08221/67.26440. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.62686/66.64639. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.06543/65.93433. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.30064/65.09887. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.50053/64.15105. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 64.56702/63.19231. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 63.63137/62.31057. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.00089/61.52369. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 62.25235/60.88284. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 61.67153/60.35900. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 61.21092/59.91531. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 60.69425/59.51513. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 60.33411/59.15281. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 60.09424/58.82211. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 59.70407/58.52789. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 59.53064/58.27747. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 59.39317/58.05754. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 59.13462/57.87021. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 58.99967/57.70639. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 58.94854/57.55406. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 58.60327/57.41791. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 58.60705/57.28674. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 58.46651/57.16238. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 58.45406/57.04064. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 58.60474/56.93629. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 58.20676/56.83882. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.25847/56.72873. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 58.21823/56.63272. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.10697/56.54685. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 58.17377/56.45578. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 57.95014/56.36879. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 58.00329/56.28516. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 57.99634/56.20015. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 57.86270/56.11706. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 57.71684/56.05594. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 57.74849/56.00053. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 57.79946/55.94349. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.71871/55.88676. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 57.63066/55.82145. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.78159/55.77340. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 57.67515/55.71149. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.54178/55.67602. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 57.43246/55.60578. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.43503/55.50343. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 57.45767/55.38919. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.26350/55.31668. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 57.46978/55.20931. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 57.39703/55.13012. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 57.22244/55.04738. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 57.21710/54.95064. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.09008/54.90619. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 57.18467/54.84663. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 57.13731/54.85172. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 56.98501/54.79054. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.03728/54.82317. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.09805/54.66132. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.93062/54.73679. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.99080/54.63664. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 56.82543/54.68895. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 56.98599/54.69584. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 56.91594/54.65574. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 56.76275/54.69531. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 56.85655/54.61872. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.52470/54.57167. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 56.69818/54.57533. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.58202/54.51142. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.60649/54.49505. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.58824/54.43996. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.72892/54.54127. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 56.47355/54.47492. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 56.44400/54.47503. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.38625/54.48559. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.23223/54.41740. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.48123/54.55694. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.45016/54.37409. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 56.25785/54.38414. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.17432/54.39078. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 56.22121/54.38573. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.33051/54.36959. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.17315/54.37338. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.14108/54.35832. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.01967/54.40316. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.03055/54.41584. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.00073/54.37043. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 55.91549/54.45778. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.06432/54.56492. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.93269/54.44196. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.87572/54.44964. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 55.77892/54.47141. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.82733/54.44242. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.77467/54.44495. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 55.66185/54.41875. Took 0.33 sec\n",
      "ACC: 0.421875, MCC: -0.17099639201419237\n",
      "Epoch 0, Loss(train/val) 71.40947/71.36964. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.21059/71.26698. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.97060/71.15425. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.74298/71.02800. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.52426/70.89027. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.18933/70.73541. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.87386/70.55904. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.39492/70.35347. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.96384/70.12129. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.42470/69.85414. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.81616/69.54984. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.33312/69.23354. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.89577/68.91547. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.48375/68.61655. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.00828/68.33584. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.76561/68.07597. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.54134/67.83655. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.18373/67.62187. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.07135/67.42574. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.92923/67.24269. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.82372/67.08423. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.58307/66.93265. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.46550/66.78282. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.35396/66.63908. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.18804/66.49192. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.03634/66.34289. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.95308/66.18695. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.68140/66.02052. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.69305/65.85203. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.29003/65.68305. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.10828/65.48882. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.91559/65.20103. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.74467/64.82887. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.59443/64.42476. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.39918/63.97403. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.30247/63.27489. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.13073/62.45192. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 61.70638/62.02921. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.77735/61.83553. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 61.59255/61.72516. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.38076/61.63490. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.49361/61.56654. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.44541/61.51057. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.41079/61.45826. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.28138/61.41116. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.44816/61.37436. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.15466/61.34364. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.15513/61.31118. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.05963/61.28159. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.11888/61.24869. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.97117/61.23232. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.95112/61.21740. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.96530/61.20173. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.02090/61.18174. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 60.89452/61.17264. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.96566/61.18130. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.78647/61.17416. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.82945/61.15700. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.83651/61.14997. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.69503/61.14914. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.80285/61.15237. Took 0.34 sec\n",
      "Epoch 61, Loss(train/val) 60.61414/61.14048. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.64601/61.12320. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.45107/61.12975. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.51656/61.13417. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.44993/61.11396. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.39833/61.09429. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.46406/61.06012. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.43200/61.05275. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.21573/61.03212. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.34342/61.00875. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.24926/60.99818. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.20518/60.97375. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.21364/60.94915. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.18905/60.91823. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.18973/60.87029. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.22272/60.87634. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.10109/60.84015. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.02300/60.79705. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.99499/60.78458. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.08401/60.75708. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.93025/60.73314. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.00735/60.70876. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.86119/60.66368. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.85643/60.64491. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.83792/60.64491. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.79204/60.62766. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.63416/60.59845. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 59.51460/60.57419. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.87491/60.55449. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 59.57059/60.50201. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.59093/60.49327. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.60295/60.47906. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.45136/60.49043. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.45616/60.46129. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.43139/60.43084. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.34754/60.41574. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.47702/60.38068. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 59.38011/60.36102. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.20326/60.25494. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.05464091115261005\n",
      "Epoch 0, Loss(train/val) 70.19006/71.32661. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.95507/71.22482. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.70815/71.11808. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.53490/71.00748. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.29403/70.88522. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.98753/70.75085. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.78007/70.60275. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.50228/70.42618. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.20621/70.21874. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.86897/69.98385. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.49677/69.73653. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.24762/69.47960. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.87583/69.22615. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.46167/68.99511. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.11310/68.77931. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.93043/68.57265. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.67700/68.37518. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.42016/68.19385. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 65.17958/68.01349. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.96122/67.83700. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.61996/67.65275. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.26067/67.46848. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.10416/67.28069. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.83199/67.08987. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.50283/66.90926. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.40454/66.73733. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.06655/66.56203. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.94168/66.38467. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.88937/66.22155. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.55392/66.08313. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.53822/65.96457. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.28494/65.86618. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.42811/65.79021. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.36142/65.71765. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.29587/65.65034. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.13848/65.58978. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.19203/65.52866. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.09171/65.46310. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.04216/65.39515. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.07909/65.33053. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.03705/65.26756. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.92586/65.20968. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.92348/65.14334. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.95629/65.06546. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.81264/64.98100. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.74981/64.89973. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.68490/64.82102. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.65477/64.74252. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.46509/64.67406. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.45429/64.59960. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.34986/64.52013. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.43960/64.44055. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.25535/64.37993. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.24025/64.29430. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.27075/64.23374. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.27875/64.14828. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.24287/64.12186. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.12192/63.99338. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.16952/64.00073. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.05969/63.73484. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.01674/63.89169. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.92314/63.62818. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.95634/63.68825. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.61354/63.54605. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.67620/63.52559. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.76244/63.44576. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.73982/63.28476. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.67789/63.43775. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 60.40904/63.23537. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.58529/63.32888. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.41529/63.20752. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.49310/63.16910. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.30200/63.13874. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.49543/63.13387. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.32324/63.15677. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.26153/63.00740. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.25435/63.01353. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.21070/63.05010. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.22766/62.65217. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.13867/63.06390. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.11376/62.80223. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.13432/62.60058. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.14488/62.81033. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.13325/62.96468. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.06643/62.71021. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.00732/62.68925. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 60.11118/62.84796. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.93651/62.73121. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 60.05317/62.68932. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 59.84556/62.57037. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 59.86427/62.37868. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.77886/62.44731. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.95125/62.19780. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.83814/62.72341. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.98579/62.16956. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.84439/62.66285. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.64092/62.28912. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.68017/62.66147. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.59555/62.00954. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.71078/62.61486. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.06508384946908037\n",
      "Epoch 0, Loss(train/val) 70.72540/71.76137. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.63196/71.74400. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.47906/71.71624. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.38297/71.69316. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.27875/71.67219. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.21678/71.64418. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 70.10240/71.61751. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.96238/71.59334. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.85663/71.56748. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.79825/71.53603. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.64954/71.50064. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.54035/71.45611. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.43583/71.40070. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 69.21763/71.33062. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.13111/71.24313. Took 0.34 sec\n",
      "Epoch 15, Loss(train/val) 68.97487/71.13070. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 68.70033/70.98607. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.43967/70.80754. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.14199/70.59683. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.87142/70.37320. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.62863/70.14822. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 67.18970/69.93150. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.96678/69.72295. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 66.72157/69.51888. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 66.42364/69.31954. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.06885/69.13198. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 65.93737/68.95785. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.63500/68.80273. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.35836/68.68117. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.01115/68.56105. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.72331/68.41574. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.41972/68.22993. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.35568/68.06001. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 64.01751/67.92006. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.71625/67.80795. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.57109/67.70747. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.44153/67.60864. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.36457/67.54218. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 63.34610/67.50006. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 63.18258/67.42729. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.98421/67.34520. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.04902/67.25214. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.97300/67.15860. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.93708/67.03063. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.81057/66.91380. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.82459/66.78705. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.58699/66.66047. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.49224/66.50443. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 62.45311/66.33117. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.45956/66.16562. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.31707/66.01075. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.20983/65.85064. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.22418/65.72165. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.07969/65.58076. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 62.06000/65.45221. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.95025/65.33276. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.83790/65.22731. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.81322/65.13903. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.76327/65.04966. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.59602/64.96804. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.58832/64.91442. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.58262/64.82593. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.37993/64.78034. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.47243/64.73675. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.31983/64.62256. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 61.43960/64.57303. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.20407/64.48242. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.17266/64.47728. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 61.13613/64.39521. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 61.09656/64.38725. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.12973/64.29787. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.13990/64.30156. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.00573/64.21375. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 61.05736/64.17725. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.86871/64.15037. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.85533/64.08958. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.80100/64.12062. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.83136/64.01676. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.62744/64.03062. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.72501/63.93018. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.75318/63.92845. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.61424/63.84110. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.68820/63.84329. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 60.53140/63.77636. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.36754/63.76744. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 60.29537/63.68922. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.40198/63.69748. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 60.26759/63.68089. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.22673/63.66525. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.18262/63.68781. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.05015/63.62019. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.10510/63.66367. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 60.06875/63.60354. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.37444/63.62336. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 60.00464/63.55494. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.93581/63.58169. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.06383/63.53779. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 59.83929/63.58911. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.94929/63.53998. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.86383/63.60941. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.15428278029593878\n",
      "Epoch 0, Loss(train/val) 70.76295/71.30537. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.53722/71.21277. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.36253/71.11647. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.16863/71.02021. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.01167/70.91971. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.84537/70.81593. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.64333/70.70742. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.34256/70.59317. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.12195/70.47923. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.84096/70.36708. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.56944/70.25080. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.31918/70.13538. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.93935/70.01459. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.50601/69.87273. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.23760/69.70056. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.75591/69.48276. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.28335/69.22512. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.84520/68.92937. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 65.41956/68.59567. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 65.15724/68.24052. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.82079/67.89031. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.38387/67.56618. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.31546/67.27008. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.98918/66.99545. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.75247/66.74487. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.65176/66.52468. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.61819/66.31836. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.47145/66.13272. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.23571/65.97561. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.10271/65.82827. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.11839/65.70146. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.06180/65.58937. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.85222/65.48544. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.89787/65.38487. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.85428/65.30011. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.71929/65.22215. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.58679/65.15337. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.58963/65.09030. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.38894/65.03407. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.45091/64.98150. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.29342/64.92226. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.35904/64.86717. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.30471/64.82156. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.23823/64.75995. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.05453/64.68539. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.05261/64.61704. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.91454/64.57877. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.79428/64.54060. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.74752/64.48987. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.66348/64.45206. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.79108/64.43922. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.81546/64.39615. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.53029/64.35188. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.54573/64.31039. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.41719/64.28999. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.51815/64.27876. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.44887/64.26505. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.35452/64.26681. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.47028/64.25017. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.30121/64.23313. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.27570/64.22498. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.24344/64.22107. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 61.22639/64.20428. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.17170/64.19787. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.10276/64.20815. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.01695/64.21986. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.88327/64.22023. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.94777/64.21907. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.88141/64.22073. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.04651/64.22714. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.80540/64.21751. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.80665/64.23576. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.74252/64.25282. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.75120/64.23772. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.66486/64.21564. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.74788/64.21191. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.63756/64.22662. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.56557/64.25735. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.49589/64.24812. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.66796/64.25583. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.52700/64.28234. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.33584/64.30615. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.29861/64.30692. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.55489/64.30432. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.41453/64.30920. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.32347/64.27317. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.30809/64.26847. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.14559/64.30307. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.35803/64.29627. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.16641/64.27258. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.16750/64.28315. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.13048/64.28050. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 60.06642/64.24610. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 60.10171/64.21031. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.22339/64.16999. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.99238/64.15398. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.04862/64.19597. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.03453/64.21528. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 60.00827/64.20252. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.93217/64.28814. Took 0.33 sec\n",
      "ACC: 0.59375, MCC: 0.1883201896480698\n",
      "Epoch 0, Loss(train/val) 70.62997/70.66862. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.22144/70.46602. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.84647/70.27418. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.46447/70.08242. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.99505/69.89687. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.52450/69.70702. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.94902/69.50664. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.32079/69.27892. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.60874/69.00674. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 65.82982/68.64616. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 64.90606/68.16640. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 64.01792/67.57020. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 63.28015/66.91228. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 62.51811/66.19576. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 61.84479/65.41851. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 61.23694/64.62527. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 60.59338/63.99129. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 60.20870/63.57853. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 59.81828/63.38174. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 59.58017/63.23529. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 59.29031/63.11813. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 59.08385/63.02365. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 58.80866/62.93170. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 58.85487/62.84632. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 58.62714/62.77258. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 58.53074/62.71480. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 58.51048/62.66334. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 58.32626/62.61189. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 58.30628/62.56382. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 58.07511/62.52063. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 57.93170/62.45929. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 57.91898/62.36407. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 57.87490/62.27750. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 57.79590/62.20060. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 57.58935/62.12141. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 57.64541/62.03452. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 57.36722/61.96284. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 57.44986/61.87642. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 57.26955/61.77713. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 57.14270/61.68735. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 57.15264/61.61565. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 57.08006/61.51091. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 56.93134/61.41971. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 56.92187/61.31281. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 56.83100/61.22398. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 56.70816/61.11426. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 56.78615/61.05576. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 56.75468/60.96541. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 56.69416/60.88282. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 56.76658/60.83731. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 56.53243/60.77586. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 56.42784/60.73287. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 56.48265/60.68533. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 56.31664/60.63704. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 56.34370/60.59097. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 56.13001/60.55882. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 56.04584/60.53307. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 55.99293/60.52566. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 55.94685/60.50733. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 55.87856/60.50961. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 55.76749/60.43910. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 55.79099/60.46443. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 55.66434/60.51830. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 55.66493/60.49238. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 55.59754/60.51232. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 55.47344/60.52136. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 55.52869/60.52453. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 55.35617/60.45690. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 55.33951/60.40752. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 55.26446/60.46423. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 55.21057/60.41808. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 55.27419/60.43689. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 55.29505/60.42522. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 55.25926/60.48825. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 55.05375/60.25653. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 55.20294/60.52388. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 54.91079/60.49234. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 54.80297/60.30756. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 54.97821/60.32394. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 54.78410/60.36441. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 54.84338/60.46116. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 54.64886/60.21755. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 54.62455/60.35180. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 54.52745/60.47474. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 54.61782/60.25505. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 54.56325/60.35557. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 54.58312/60.21663. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 54.47376/60.21467. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 54.46337/60.21601. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 54.52837/60.17142. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 54.27182/60.16378. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 54.36066/60.07447. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 54.40454/60.05843. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 54.45403/60.02989. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 54.35364/60.01645. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 54.45299/59.99103. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 54.43815/59.97459. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 54.15650/60.09099. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 54.19951/60.03067. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 54.20964/59.86927. Took 0.33 sec\n",
      "ACC: 0.578125, MCC: 0.12158607754020519\n",
      "Epoch 0, Loss(train/val) 70.72510/70.34622. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.45254/70.16992. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.22001/69.98868. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.92305/69.79563. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.69519/69.59133. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.35953/69.36438. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.00791/69.10894. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.65060/68.82388. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.27695/68.50278. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.90388/68.12919. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.48040/67.70111. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.98552/67.21410. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.65509/66.67818. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.00459/66.09862. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.40147/65.51205. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.01739/64.95767. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.33672/64.47287. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.87966/64.05853. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.50916/63.72250. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.29219/63.46919. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.88362/63.29137. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 62.83879/63.19353. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.45760/63.12429. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.21494/63.07860. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.10423/63.05320. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.98659/63.04328. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.08930/63.03988. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.71315/63.04148. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.65935/63.04906. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.48271/63.05995. Took 0.34 sec\n",
      "Epoch 30, Loss(train/val) 61.41846/63.07334. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 61.25302/63.08953. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.31615/63.09989. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.07275/63.10464. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.95895/63.10558. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.85534/63.10630. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.80303/63.10933. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.74288/63.11431. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.78796/63.12512. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.63100/63.13773. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.74933/63.14579. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.54364/63.15099. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.43389/63.15664. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.37250/63.15979. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 60.50991/63.16361. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.38663/63.16793. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.41667/63.17102. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.43056/63.17418. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.25162/63.17331. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.24126/63.17072. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.35201/63.16896. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.11159/63.16452. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.25393/63.15491. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.21990/63.14365. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.95278/63.12613. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.11765/63.11026. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.10398/63.09595. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.91099/63.07971. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.04135/63.05883. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 59.96351/63.03564. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.88958/63.00609. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 59.87636/62.99066. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 59.84988/62.99482. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.78205/62.97264. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.70465/62.96429. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.69986/62.95583. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.74104/62.94572. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.58624/62.94840. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.71526/62.93612. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 59.55411/62.91510. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.60781/62.87483. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.64379/62.85514. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.54859/62.83408. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.58021/62.79006. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.44760/62.80450. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.38992/62.80988. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.37062/62.79953. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.25169/62.81075. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.31978/62.80418. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.29905/62.81470. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.23708/62.84451. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 59.10206/62.83594. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.29038/62.82100. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.22409/62.84097. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.90642/62.84082. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.08248/62.82438. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.89125/62.87230. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.91436/62.88123. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.81160/62.86865. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.85969/62.86652. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.92025/62.87234. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.91997/62.86794. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.86916/62.87747. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.66310/62.86311. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.78783/62.90400. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.65070/62.92931. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.60488/62.94796. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.58006/62.95226. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.42463/62.98312. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 58.61615/62.96823. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.16043612574988464\n",
      "Epoch 0, Loss(train/val) 71.54599/71.49399. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.23053/71.31210. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 71.01651/71.13615. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.78443/70.95612. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.50162/70.77200. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.25731/70.57894. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.98024/70.37193. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.67654/70.15136. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.38876/69.91626. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.09009/69.67241. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.79864/69.41779. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.51569/69.15385. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 68.22677/68.88080. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 67.93051/68.59756. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 67.58172/68.29864. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.32548/67.98340. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.00040/67.64916. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 66.64803/67.29519. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.39087/66.92574. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.11399/66.54612. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.78176/66.15125. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 65.48419/65.74573. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.15703/65.34459. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.88877/64.94462. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 64.70963/64.60895. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 64.60613/64.27107. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.42010/63.95282. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 64.11295/63.63495. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.00734/63.35438. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.88067/63.11548. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.57061/62.89342. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.55722/62.69482. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 63.48349/62.52857. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.29423/62.37373. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.03458/62.22671. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.04390/62.08966. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.92381/61.99185. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.76854/61.89975. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.61946/61.81275. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.57267/61.68271. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.42757/61.56813. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.18106/61.48614. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.18936/61.38345. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 62.01634/61.26931. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.86540/61.18732. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 61.87531/61.11648. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.87655/61.02414. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 61.63821/60.93161. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 61.52130/60.83567. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.47824/60.73449. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.29019/60.61480. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.32978/60.49601. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 61.12340/60.41401. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.06925/60.28799. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.00681/60.16445. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.67471/60.04449. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.63515/59.95087. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.61633/59.88397. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.39654/59.83150. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.39547/59.80171. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.30855/59.78503. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.04627/59.75637. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 59.93629/59.70144. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.87205/59.64974. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.74189/59.59126. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.78983/59.50935. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.78943/59.38998. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.70617/59.30587. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.58127/59.27658. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.41385/59.20823. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.45013/59.13527. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.35344/59.06952. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.11292/58.95443. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 59.20713/58.94333. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.10077/58.90003. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.88276/58.83854. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.95730/58.76131. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.93862/58.68885. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.86797/58.61940. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.85811/58.59607. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.45694/58.53437. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.49386/58.58776. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.55693/58.52501. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.41873/58.53095. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.33012/58.45674. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 58.31762/58.58142. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.16942/58.53497. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 58.15190/58.47942. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.00626/58.56419. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.17131/58.41580. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.81374/58.53909. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.03792/58.39774. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.88200/58.49553. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.62547/58.33366. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.75106/58.45155. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 57.60460/58.36577. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.55092/58.43038. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.55905/58.39106. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.51498/58.39387. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.54026/58.39208. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: 0.029863035542303663\n",
      "Epoch 0, Loss(train/val) 70.69546/70.19160. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.48551/70.09002. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.25734/69.98649. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.03059/69.87834. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.82507/69.76900. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.52048/69.65029. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.28085/69.51826. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.95717/69.36817. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.66952/69.18924. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.35594/68.96731. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.04139/68.69239. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 67.58945/68.34696. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.06554/67.92152. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.57806/67.41287. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.89161/66.82394. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 65.27244/66.19159. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.71165/65.60913. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.03412/65.05064. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.61958/64.52295. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.09713/64.05204. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.71097/63.63778. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.28906/63.25899. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 61.98783/62.91623. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.67425/62.59027. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.64780/62.27502. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.21723/61.97512. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 61.06943/61.69756. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.94043/61.43975. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.64312/61.21171. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.56744/61.03814. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.48858/60.90951. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.30557/60.79409. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.39064/60.72581. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.36058/60.66848. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.24683/60.59858. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.24876/60.53214. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.99106/60.47115. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.02476/60.41573. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 59.98179/60.36423. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.97080/60.31695. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 59.87283/60.27402. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.00374/60.19948. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.76606/60.15890. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.75219/60.14529. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.74941/60.06223. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 59.68594/60.01762. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.48729/59.98111. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.46175/59.90648. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.40805/59.85103. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 59.43648/59.83463. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 59.51425/59.75031. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.39810/59.70671. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 59.28124/59.64269. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.28125/59.57419. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 59.21510/59.51465. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.05058/59.45985. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.00840/59.44395. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.92838/59.31417. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.86664/59.28642. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.70930/59.16397. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.76681/59.15120. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.75541/59.06717. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.47691/59.04270. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.52736/58.92666. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.49604/58.84900. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.35884/58.72533. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.33272/58.79168. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.20341/58.60936. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 58.11445/58.58467. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.06603/58.52798. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.08160/58.52280. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 58.00594/58.47094. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.92595/58.33715. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.84428/58.40641. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.85227/58.27920. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.87632/58.27519. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.64670/58.23222. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 57.58695/58.22011. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 57.61661/58.14397. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 57.43741/58.11412. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.47934/58.04891. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.37940/58.01699. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 57.34467/57.98370. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.47561/57.98534. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.27434/58.00008. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.19647/57.95157. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.30438/57.89928. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.23269/57.99805. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.24985/57.91079. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.14929/57.85671. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 57.13802/57.73969. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.11492/57.78234. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.05424/57.83769. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.12073/57.73831. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 56.97020/57.70130. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.94667/57.70207. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.83622/57.69747. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 56.90747/57.67179. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.79510/57.67565. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.75592/57.60085. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: 0.018122009407318746\n",
      "Epoch 0, Loss(train/val) 70.91595/70.33809. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.72147/70.13882. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.54686/69.94244. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.38605/69.73712. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.17739/69.51778. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.97929/69.27441. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.75318/69.00999. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.54339/68.72208. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.28592/68.39713. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.91630/68.02811. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.64978/67.61940. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.26528/67.15545. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.81547/66.62109. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.37067/66.01128. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.75591/65.31993. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 66.03221/64.55476. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.53960/63.75820. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.82552/62.97179. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.11103/62.27505. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.75438/61.70265. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.37888/61.25777. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 62.97700/60.89929. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 62.96425/60.65328. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.86321/60.47403. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.56428/60.33150. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.53666/60.22633. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.34010/60.12024. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.41942/60.04207. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.17274/59.96420. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.18093/59.90045. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 62.16306/59.83326. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.05739/59.77346. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.04209/59.71970. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.89499/59.66498. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.89752/59.61066. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 61.91551/59.56580. Took 0.30 sec\n",
      "Epoch 36, Loss(train/val) 61.81333/59.51980. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.67552/59.47772. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 61.74402/59.43692. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 61.71960/59.40527. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 61.56080/59.36813. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.71727/59.34668. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.51059/59.32857. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.48399/59.33194. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.37339/59.36426. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.33948/59.41505. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.28076/59.48223. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.15037/59.53634. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.06452/59.65911. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.93247/59.70426. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.90739/59.67101. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.94469/59.69201. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.89800/59.79500. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.76236/59.63704. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 60.59000/59.72281. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.66619/59.98462. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.45259/60.11567. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.34529/60.00299. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.36317/59.97587. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.31050/59.57286. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.13481/59.75788. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 60.04630/58.75877. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.06054/59.87386. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 59.93502/58.69039. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.96226/59.80002. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 59.82363/58.63877. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.79412/59.63300. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 59.68363/58.46777. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.79044/59.71850. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.55231/58.49078. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.49504/60.13037. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.47195/58.38762. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.51468/59.94505. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 59.26744/58.33537. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.31543/59.46651. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.27160/58.31904. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.29760/59.71891. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.23563/58.26935. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.06832/59.37812. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.28854/58.22209. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 59.07726/59.04012. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.06684/58.07997. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.92035/59.41138. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.00260/58.07387. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.91876/59.33755. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.94856/58.03186. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.98654/58.14665. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 58.87316/57.79621. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.69733/58.11758. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.63287/57.66415. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.54602/58.36880. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.68927/57.63242. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.59931/58.49156. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.70421/57.68242. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.53716/58.38739. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.66168/57.55046. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.44974/58.63271. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.55137/57.43982. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.40157/57.58583. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.37570/57.15363. Took 0.32 sec\n",
      "ACC: 0.390625, MCC: -0.09400555777286816\n",
      "Epoch 0, Loss(train/val) 71.01282/70.82224. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.87026/70.69491. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.74298/70.56742. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.65154/70.43616. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.51245/70.30192. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.40021/70.16116. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.27347/70.01418. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 70.13483/69.86497. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.00062/69.71908. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.81084/69.56725. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.69331/69.41398. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.53033/69.26289. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.42664/69.12096. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 69.21519/68.98613. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.01636/68.85957. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.86101/68.73853. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.70244/68.61901. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.48606/68.50642. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 68.28791/68.38535. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 68.17426/68.26473. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 68.03054/68.15049. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.96443/68.03213. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 67.74909/67.90905. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.63262/67.78239. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 67.49036/67.64720. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 67.30798/67.50311. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 67.20951/67.33977. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 67.19208/67.17027. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.95233/66.98001. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 66.71802/66.79304. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.64190/66.63239. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 66.50191/66.48419. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 66.43014/66.36047. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 66.33326/66.24979. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 66.36309/66.15250. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 66.08652/66.05625. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 66.06210/65.97588. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.77141/65.87971. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 65.75458/65.76799. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 65.69482/65.66335. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 65.59780/65.55125. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 65.65666/65.44384. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 65.47337/65.33511. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 65.35096/65.24788. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 65.31218/65.17316. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 65.14715/65.10450. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 65.13752/65.05332. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 65.08005/64.99940. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 65.05358/64.95110. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.99107/64.91637. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 64.90726/64.89629. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 64.91483/64.85691. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 64.60898/64.82423. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 64.67647/64.77663. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 64.53280/64.76154. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 64.64467/64.73865. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 64.59442/64.71955. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 64.57573/64.71420. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 64.49917/64.71231. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 64.29571/64.70033. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 64.35164/64.71887. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 64.30131/64.73605. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 64.26631/64.72060. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 64.30615/64.68912. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 64.23156/64.69951. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 64.09458/64.71333. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 64.23236/64.73931. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 64.02427/64.72057. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 64.00960/64.73236. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 64.08110/64.75534. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 64.07943/64.74255. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 64.04451/64.76727. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 63.92106/64.80026. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 63.79339/64.78166. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 63.86167/64.79109. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 63.96200/64.79405. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 63.94916/64.78206. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 63.83724/64.78883. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 63.79323/64.80298. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 63.62828/64.84438. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 63.73361/64.79892. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 63.70182/64.80786. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 63.50039/64.79852. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 63.57290/64.80874. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 63.49795/64.79420. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 63.51735/64.75266. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 63.35427/64.72732. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 63.37173/64.68165. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 63.38865/64.67239. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 63.37339/64.73589. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 63.31002/64.68896. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 63.16509/64.72912. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 63.27195/64.70559. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 63.32212/64.69751. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 63.05816/64.64929. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 63.19150/64.65071. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 63.19836/64.60822. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 63.11013/64.62927. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 63.11726/64.61564. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 63.05585/64.55484. Took 0.31 sec\n",
      "ACC: 0.453125, MCC: -0.0885319710087594\n",
      "Epoch 0, Loss(train/val) 71.01428/70.80277. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.93641/70.79559. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.80501/70.78583. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.69508/70.77624. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.59481/70.76862. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.49225/70.76550. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 70.40883/70.76187. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.29231/70.75748. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 70.16597/70.75173. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 70.06748/70.74875. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.94383/70.75025. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.83494/70.75291. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 69.69047/70.75610. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.56034/70.75578. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 69.41169/70.76198. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.24155/70.77351. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 69.14860/70.78806. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.97031/70.80526. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 68.76971/70.82175. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.61688/70.84961. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 68.45299/70.88206. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 68.25959/70.91154. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 68.09317/70.94846. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 67.86919/70.98576. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 67.70428/71.01797. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 67.48551/71.05907. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 67.38406/71.09824. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 67.21563/71.15434. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.95965/71.19371. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 66.74515/71.22059. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.61942/71.21865. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 66.45128/71.19521. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 66.29270/71.14854. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 66.06565/71.09789. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.98180/71.05168. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.83885/70.99919. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 65.68472/70.94997. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.52275/70.89894. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 65.45673/70.85289. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 65.41215/70.81313. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 65.22503/70.76771. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 65.31094/70.72964. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 65.20860/70.68905. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 65.14556/70.65510. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 65.14772/70.61855. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.99953/70.58488. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 65.06753/70.54884. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 64.78597/70.51174. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.79688/70.46680. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 64.75457/70.42206. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 64.66695/70.36996. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 64.69150/70.31924. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 64.55757/70.26633. Took 0.34 sec\n",
      "Epoch 53, Loss(train/val) 64.55774/70.21230. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 64.32526/70.15162. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 64.39459/70.07676. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 64.34975/69.99117. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 64.26540/69.91318. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 64.24442/69.85290. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 64.11459/69.77607. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 64.01336/69.68012. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 63.93589/69.61098. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.90981/69.55482. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.87110/69.49119. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.94532/69.41912. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.85680/69.36113. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 63.90933/69.29961. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 63.70024/69.24820. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 63.65035/69.20226. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 63.65151/69.11845. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 63.52228/69.01662. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 63.57248/68.97277. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 63.42659/68.94302. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 63.46305/68.89512. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 63.43681/68.84203. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 63.37495/68.76425. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 63.31022/68.71861. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 63.19421/68.66230. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 63.27536/68.61373. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 63.18994/68.55281. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 63.27168/68.53130. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 63.02699/68.49582. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 63.09990/68.44968. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 63.15771/68.40575. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 62.76569/68.36554. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.92237/68.35712. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 62.95189/68.36253. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 62.96011/68.34296. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 62.83755/68.30152. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 62.86521/68.29107. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 62.65333/68.25859. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 62.71175/68.26167. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 62.59787/68.25097. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 62.58699/68.23848. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 62.45589/68.21411. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 62.59797/68.16681. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 62.48374/68.15308. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 62.35323/68.11543. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 62.38083/68.10475. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 62.28186/68.10753. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: -0.0022259352109805924\n",
      "Epoch 0, Loss(train/val) 71.34706/70.91388. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.04538/70.66955. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.81155/70.42315. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.50681/70.16747. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.22829/69.89510. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.92125/69.59980. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.59413/69.26985. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.28327/68.89331. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.86711/68.45174. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.49837/67.93166. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.98096/67.31371. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.39762/66.59594. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.88175/65.80917. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.19623/64.96868. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.55042/64.09286. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.92091/63.20230. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.32354/62.32495. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.64443/61.48433. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 63.12042/60.71880. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.74883/60.09271. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.29397/59.57538. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.00294/59.16007. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.77432/58.80574. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.43635/58.47587. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.22921/58.14167. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.10021/57.80702. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.73709/57.50291. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.41996/57.24751. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.35812/57.04206. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.26383/56.87626. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.08399/56.74239. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.83918/56.63559. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.71963/56.55563. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.60547/56.50075. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.33170/56.47372. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.45917/56.45786. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.24882/56.43920. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.07575/56.38811. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 59.19661/56.34508. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.11836/56.31906. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 58.88865/56.27539. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.84993/56.26934. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.83073/56.26853. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.63926/56.22089. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.82135/56.18826. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.43510/56.12290. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.46854/56.08561. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.44626/56.05655. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.44429/56.02528. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.36211/55.94504. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.23647/55.92595. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.31424/55.84456. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.17920/55.74757. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 58.08284/55.72162. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.03317/55.61412. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.08048/55.59105. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 58.13336/55.60781. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.93543/55.60591. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.84591/55.52554. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.81302/55.44463. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 57.86086/55.41009. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.77719/55.45506. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 57.75849/55.38422. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.71884/55.35698. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 57.65838/55.28230. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.43835/55.32883. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.59031/55.26998. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.49154/55.33148. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.47292/55.24901. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.35132/55.24495. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.49607/55.27978. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.24463/55.22453. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 57.47858/55.17687. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 57.12455/55.22475. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.19968/55.12908. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.07740/55.15849. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.16679/55.10949. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.11103/55.04789. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 57.09520/55.06192. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.17568/55.01211. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.90460/54.98431. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.91482/55.03338. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.97437/54.93561. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.92234/54.86920. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.94883/55.00838. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.88299/54.88309. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.86085/54.93309. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.86818/54.89001. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.87389/54.85484. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.68573/54.93003. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.80778/54.95367. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 56.76929/54.80917. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.64349/54.95908. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.71224/54.78670. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 56.54676/54.71138. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 56.45158/54.95557. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 56.52790/54.77638. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.60042/54.84940. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.47811/54.78910. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.38326/54.79774. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.048647332992624304\n",
      "Epoch 0, Loss(train/val) 70.71556/70.14396. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.54919/69.96804. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.34232/69.79435. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.14724/69.62137. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.93394/69.44805. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.71714/69.26802. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.56280/69.08225. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.35126/68.88689. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.16951/68.68243. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.99013/68.46705. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.69971/68.23508. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.48263/67.97832. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.20298/67.70606. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.99784/67.41341. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.56924/67.10388. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.28877/66.76691. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.06062/66.40750. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.65936/66.02390. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.34219/65.59540. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 65.96438/65.15376. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.53865/64.73347. Took 0.34 sec\n",
      "Epoch 21, Loss(train/val) 65.31940/64.36703. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.90285/64.04638. Took 0.34 sec\n",
      "Epoch 23, Loss(train/val) 64.70524/63.75505. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 64.47575/63.49081. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.28974/63.24038. Took 0.34 sec\n",
      "Epoch 26, Loss(train/val) 63.89603/63.05359. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.78094/62.90572. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.68793/62.77437. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.42769/62.64182. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 63.25556/62.50221. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.95525/62.35643. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.90515/62.20388. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.72331/62.04902. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.60731/61.90343. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.36626/61.75655. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.30079/61.62006. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.25183/61.48519. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.08777/61.35325. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.12778/61.21530. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.87403/61.07748. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.91541/60.95743. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.76519/60.84173. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.85434/60.72084. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.50143/60.61430. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.47712/60.50888. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.25119/60.40515. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.41656/60.31063. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.16727/60.21202. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.21927/60.13178. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.00294/60.04854. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.96319/59.97216. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.06370/59.89140. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.83912/59.83160. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.92391/59.76140. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.63825/59.70034. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.63446/59.65117. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.35416/59.59835. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.53983/59.52146. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.39158/59.45901. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.21240/59.40058. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.16143/59.35128. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.04342/59.28387. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.13207/59.19239. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.15886/59.15225. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.02406/59.08538. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.84889/59.01701. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.82855/58.95036. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.92914/58.87218. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 59.53794/58.79848. Took 0.34 sec\n",
      "Epoch 70, Loss(train/val) 59.62038/58.72105. Took 0.34 sec\n",
      "Epoch 71, Loss(train/val) 59.70050/58.64956. Took 0.34 sec\n",
      "Epoch 72, Loss(train/val) 59.53823/58.58982. Took 0.34 sec\n",
      "Epoch 73, Loss(train/val) 59.58555/58.53251. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.49242/58.48891. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.33603/58.42082. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.28224/58.33809. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.24731/58.25983. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.36400/58.18386. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.27219/58.09813. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.07162/58.03162. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.04103/57.98252. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.00570/57.91806. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.87231/57.83516. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.82704/57.76691. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.96282/57.70448. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.64154/57.63379. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.84843/57.57230. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.77443/57.49779. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.62391/57.44803. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.63235/57.42712. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.52854/57.38322. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.49071/57.33859. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.47052/57.29553. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.21720/57.24495. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.19956/57.18262. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 58.26169/57.13079. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.29589/57.11469. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.08088/57.08381. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 58.19378/56.98806. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.12103753965825202\n",
      "Epoch 0, Loss(train/val) 70.50042/71.57851. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.34571/71.37697. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.10612/71.16302. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.91468/70.94662. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.74137/70.72316. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.51338/70.49248. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.29287/70.24043. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.03113/69.97498. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.76192/69.70409. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.49573/69.41644. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.11639/69.12509. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.76614/68.84769. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.45230/68.57962. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.10396/68.34090. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.76327/68.11742. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.39343/67.91103. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.16413/67.71584. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.82874/67.52694. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.61377/67.33620. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.35069/67.14550. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.06454/66.95631. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.79966/66.75368. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.68704/66.53027. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.52633/66.26706. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.28563/65.95810. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 64.08731/65.59002. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.86428/65.14359. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.74375/64.65504. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.47987/64.18442. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 63.22869/63.84952. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.30904/63.64713. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.09100/63.52695. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.99941/63.45712. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.89706/63.40383. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.80443/63.37785. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.71712/63.35253. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.54937/63.34522. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.42565/63.35442. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.45129/63.35940. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.40338/63.37436. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.32309/63.35997. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 62.22053/63.35551. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.02780/63.36061. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.89946/63.36850. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.88104/63.33636. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.77859/63.24115. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.72677/63.21844. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.79099/63.14491. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.52735/63.00717. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.45335/62.95676. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.22896/62.86245. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.20825/62.75092. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.15616/62.58461. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.02460/62.54966. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 61.07078/62.57931. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.05243/62.42374. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 60.66234/62.27004. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.58192/62.19684. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 60.52702/62.05947. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.49228/62.16572. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.36929/62.15134. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.17547/62.18186. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.02820/62.15955. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.03381/62.32424. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.09243/62.19592. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.01691/62.33205. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.94269/62.07131. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 59.80378/62.13144. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.75510/62.06482. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.56554/62.35596. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.59492/62.12747. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 59.52989/62.29540. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.45533/62.39455. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.35549/62.36380. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.41048/62.47895. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.22658/62.56670. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 59.15574/62.64430. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.04559/62.65436. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.17550/62.71488. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.97255/62.79532. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.01948/62.75045. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.72289/62.65269. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 58.79832/62.65378. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.70203/62.75406. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.54670/62.68518. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.41180/62.58046. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.63302/62.63635. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.44560/62.69147. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.47591/62.65785. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 58.28714/62.65968. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.34009/62.62149. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.26224/62.55125. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.39752/62.51563. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.12539/62.49090. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.09937/62.42793. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.10413/62.41122. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.93797/62.38560. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.81591/62.30495. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.89565/62.20556. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.87199/62.13049. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.12977983786586622\n",
      "Epoch 0, Loss(train/val) 70.51212/69.73782. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.28929/69.56551. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.04665/69.39853. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 69.82171/69.23055. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.59604/69.06527. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.34563/68.90033. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.11213/68.74393. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.91000/68.59431. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.64398/68.44645. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.34428/68.28991. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.18429/68.12775. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.84382/67.96227. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.65842/67.78226. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.35012/67.64051. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.13188/67.49643. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 67.00611/67.35047. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.83175/67.15140. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.53572/66.90961. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.34268/66.62915. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.29230/66.30982. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.95969/66.03259. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.81541/65.82188. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.67523/65.62541. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.51181/65.46173. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.27935/65.37270. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.16354/65.35922. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.11244/65.30934. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.98964/65.22850. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.83391/65.21582. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 64.73555/65.23199. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.53502/65.23057. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.42128/65.19237. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.33046/65.17563. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.25106/65.16148. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.98049/65.15919. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.84841/65.15716. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.91606/65.09387. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.61987/64.98457. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.44565/64.80850. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 63.18053/64.58787. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.88291/64.38866. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.69761/64.24916. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.33350/64.07099. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.14959/64.05165. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.85278/64.04737. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.75558/63.90388. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.55835/63.83484. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 61.38461/63.73633. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.20500/63.73392. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.06631/63.49477. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 60.96978/63.43388. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.69510/63.41025. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.65363/63.32665. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.57586/63.34750. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 60.36162/63.15761. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.29160/63.19912. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.23840/63.08952. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.23779/62.95414. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.03232/62.87023. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 59.86049/62.97024. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.81305/62.69102. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.62502/62.74524. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 59.59270/62.55376. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.64012/62.59010. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.40547/62.58409. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.30548/62.39450. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.36693/62.42880. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.24441/62.27851. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.09077/62.48012. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.03387/62.17975. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.15148/62.16206. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.03116/62.03655. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.92097/62.09163. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.80949/61.95942. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 58.74165/62.00389. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.65878/62.00933. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.79766/61.78762. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 58.50305/61.92163. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.36257/61.81099. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.49469/61.80141. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 58.36325/61.73923. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.33229/61.72349. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.28934/61.66404. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.15584/61.61466. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.11999/61.52299. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.12746/61.56123. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.97477/61.48791. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.12319/61.50358. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.92069/61.49820. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.81449/61.47416. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 57.79999/61.43361. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.62688/61.47933. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.78738/61.43931. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.62168/61.31776. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.50372/61.35011. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.45219/61.47185. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.42533/61.25948. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.25866/61.42268. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.28587/61.13337. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.24036/61.25665. Took 0.33 sec\n",
      "ACC: 0.59375, MCC: 0.3460009349544799\n",
      "Epoch 0, Loss(train/val) 71.33247/71.46294. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.23666/71.39624. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.04826/71.32435. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.90839/71.25607. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.78200/71.18813. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.63925/71.12557. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.47824/71.06390. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 70.31603/71.00639. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 70.14733/70.94910. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.98839/70.88592. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.89201/70.82489. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.73116/70.76104. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.55906/70.69469. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.31368/70.63676. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.13489/70.57542. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.89148/70.51867. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.65664/70.47253. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.38756/70.42336. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.18144/70.36737. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 67.89497/70.30655. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.73711/70.24284. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.38244/70.16118. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 67.19761/70.05798. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.96254/69.93392. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.86589/69.79839. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 66.54542/69.65640. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.32022/69.53905. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.05780/69.43456. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.92770/69.33855. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.69496/69.24059. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 65.55475/69.15331. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 65.45841/69.06423. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.24223/68.98405. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.12611/68.92719. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.00979/68.88275. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.85323/68.83456. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 64.72899/68.78278. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.59475/68.73435. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.56138/68.67199. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.28755/68.59379. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.15440/68.51826. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.02629/68.43563. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.91548/68.34901. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 63.64777/68.34216. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 63.38404/68.30859. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.12597/68.27236. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 63.04962/68.24409. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.73608/68.22591. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.70314/68.17730. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.59488/68.06091. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.50606/67.89616. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.46628/67.78261. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.35965/67.47504. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 62.28756/67.17957. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.23486/66.93507. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.19936/66.69130. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.03008/66.55025. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.89024/66.41174. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.06264/66.30215. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.76782/66.17242. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.72643/66.12029. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.67125/66.13898. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 61.66063/66.18373. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 61.56142/66.29275. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.52116/66.30327. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.31418/66.37013. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.33990/66.30258. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.31778/66.45920. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.16073/66.45015. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.05473/66.25114. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.14310/66.29346. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.95170/66.26170. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.13395/66.28180. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 61.05332/66.18746. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.78269/66.17339. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.88935/65.88419. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.70917/66.14983. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.70805/65.82165. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 60.68376/65.89961. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.49226/65.89820. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.61618/65.80072. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.51643/65.72691. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 60.55211/65.67734. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.45902/65.63618. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.31984/65.60332. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.35145/65.34277. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 60.36291/65.60645. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.31959/65.32240. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.13400/65.50462. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.17112/65.19769. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.18827/65.47678. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.21281/65.13974. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.19479/65.44336. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.08374/65.43481. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.12474/64.88602. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.14111/65.29974. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 59.97023/64.85640. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.03257/65.03951. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.98447/64.84348. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.87775/64.79377. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.1377749527404283\n",
      "Epoch 0, Loss(train/val) 70.77667/70.65029. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.57594/70.57624. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.42638/70.49734. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.22167/70.41510. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.05657/70.31646. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.83602/70.19178. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.63171/70.03872. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.42223/69.84653. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.14114/69.61266. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.96677/69.35607. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.64286/69.09484. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.38971/68.83630. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.09068/68.59750. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.73294/68.37854. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.48326/68.16338. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.27331/67.96134. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.98016/67.77052. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.70424/67.58562. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.52746/67.40652. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.29657/67.22415. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.01030/67.02677. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 65.81442/66.81748. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.54869/66.60031. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.39670/66.37338. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.07094/66.14529. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.93696/65.92574. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.59098/65.73335. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.48490/65.61295. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.34239/65.51274. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.01937/65.42621. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.02894/65.35418. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.80996/65.28563. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.78667/65.20671. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 63.53409/65.13681. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.41286/65.07626. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.29517/65.02351. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.27257/64.95699. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.06021/64.90764. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.94562/64.84631. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.85841/64.75839. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.58507/64.69753. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.67218/64.65184. Took 0.34 sec\n",
      "Epoch 42, Loss(train/val) 62.51274/64.58633. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.39419/64.50816. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.19490/64.42696. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.18281/64.35838. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.11302/64.30025. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 62.04667/64.19357. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.86695/64.13511. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.69253/64.04591. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.73352/63.91481. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.53487/63.83172. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.47809/63.79050. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.32076/63.72067. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.45910/63.64587. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.24145/63.53321. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.12301/63.45710. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.96462/63.36015. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.90280/63.29725. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.73025/63.20116. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 60.75063/63.10916. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.49774/63.03130. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.52575/62.87677. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.53984/62.82171. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.42117/62.71411. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.37713/62.62687. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.15647/62.54324. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.20781/62.45012. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.16931/62.36268. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.92760/62.37830. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.98041/62.35020. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.78787/62.22946. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.72272/62.18919. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.89569/62.14790. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.59970/62.09054. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.53321/62.02639. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.47197/61.90406. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.30639/61.91768. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 59.25430/61.80884. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.17554/61.74270. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.17767/61.61954. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.05860/61.63219. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.82409/61.44154. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.85018/61.46565. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.87042/61.32644. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.85727/61.45487. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.73250/61.13422. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.62596/61.19143. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.62651/61.24836. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.62441/60.88586. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 58.44123/60.91817. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.44771/61.09853. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.33517/60.70484. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.38743/60.76997. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.32948/60.69057. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.29187/60.71462. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 58.20461/60.63910. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.05329/60.76136. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 57.91828/60.79449. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.97954/60.71817. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.15196169394189366\n",
      "Epoch 0, Loss(train/val) 70.75804/70.71538. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.63063/70.68121. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.50729/70.65347. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.35071/70.62250. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.25862/70.58624. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.11129/70.55465. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.94567/70.52580. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.80947/70.50567. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.67114/70.48613. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.48918/70.46433. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.26689/70.44434. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.12215/70.42287. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.97220/70.40686. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.66549/70.39463. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.53905/70.37773. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 68.34892/70.35449. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.15628/70.33499. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.93449/70.31129. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 67.86076/70.27512. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 67.64496/70.22086. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.38618/70.15578. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.33034/70.09375. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 67.03625/69.98756. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.94813/69.86417. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.73857/69.77802. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 66.68509/69.67928. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 66.48358/69.56219. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 66.29932/69.45374. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.18779/69.35275. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.04128/69.27982. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.00728/69.22919. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.79301/69.12131. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.61560/69.07293. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.52740/69.08577. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.34574/69.13146. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.46360/69.11553. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.29405/69.12308. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.19482/69.12640. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 65.15156/69.21442. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 64.96835/69.28591. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 64.94162/69.33149. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 64.76606/69.35416. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 64.89237/69.28096. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.64354/69.26316. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.70288/69.26023. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 64.57000/69.19715. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.32665/69.08739. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 64.33870/69.02444. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.18485/69.00968. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 63.99999/68.94801. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 63.79459/68.83581. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 63.93923/68.77322. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.73254/68.65944. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.83616/68.53960. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.65420/68.41574. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.51095/68.29890. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 63.28230/68.15671. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.19698/68.02267. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.16818/67.89557. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.04183/67.78825. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.97456/67.66646. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.72223/67.55974. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 62.72648/67.47625. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.80471/67.39521. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.45203/67.31099. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.35833/67.28412. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.30145/67.19274. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.14643/67.20773. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.15568/67.16132. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.14103/67.13892. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.97971/67.11491. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.96209/67.06339. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.68449/67.04625. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.67774/66.98615. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.70883/66.99593. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.48235/66.92995. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 61.49335/66.93591. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 61.35473/66.90574. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 61.50843/66.86892. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.34958/66.86294. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.15366/66.84728. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.29906/66.81638. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.13401/66.79489. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.98183/66.77956. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 61.18024/66.75507. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.79808/66.76310. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 60.77874/66.71751. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.90400/66.69836. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.64790/66.64643. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.77673/66.73080. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.72106/66.72856. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.49832/66.72900. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 60.52759/66.74256. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.34736/66.69685. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.55001/66.71364. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.40263/66.73186. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.50573/66.71130. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 60.43444/66.71249. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.23392/66.75613. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.16504/66.69121. Took 0.33 sec\n",
      "ACC: 0.609375, MCC: 0.27185747308321606\n",
      "Epoch 0, Loss(train/val) 70.56224/70.94893. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.42581/70.85324. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.32854/70.76291. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.14285/70.66386. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.02135/70.55973. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.88313/70.44917. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.73778/70.32718. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.53174/70.18523. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.32909/70.02026. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.11381/69.82238. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.81563/69.57619. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.49883/69.27250. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.15398/68.90658. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 67.70389/68.48135. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.20309/68.03535. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.84846/67.61427. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.34016/67.24268. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.11846/66.92024. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.82795/66.63683. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.53311/66.38790. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.32419/66.16808. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.07333/65.97798. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 64.95029/65.80570. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.62560/65.65843. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.52041/65.55279. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.46059/65.45681. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.24867/65.37124. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.15797/65.30635. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.06887/65.24566. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 63.92253/65.17369. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.87682/65.10651. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.79476/65.03867. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.66953/64.98283. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.68310/64.92970. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.59248/64.88094. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.65053/64.83517. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.33653/64.78596. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.34355/64.74534. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 63.22507/64.71245. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.35460/64.68599. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.24605/64.65242. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.15019/64.61661. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.16685/64.58021. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 62.96118/64.56011. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.99223/64.52370. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.94785/64.47903. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.87322/64.45155. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.83122/64.42507. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.67143/64.38577. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.71145/64.34602. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.72019/64.31090. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.78750/64.28432. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 62.75442/64.25904. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.54252/64.23135. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.48272/64.20180. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.50684/64.17196. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.38636/64.14185. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 62.26696/64.09636. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.15305/64.06081. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 62.22365/64.03213. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.22871/64.00581. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.16205/63.95938. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.10829/63.92148. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.09808/63.87499. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 62.00557/63.82724. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.87995/63.77013. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.88191/63.70849. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.68422/63.65532. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.76453/63.58058. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.70582/63.50740. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.60163/63.43484. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.39079/63.33541. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.55644/63.24953. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.54081/63.18137. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.46148/63.11500. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.34496/63.06852. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 61.21982/63.01874. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.03403/62.96239. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 61.10596/62.85366. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.12845/62.79183. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.97439/62.75275. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.05238/62.73731. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 61.00474/62.67282. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.92987/62.61336. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 60.89347/62.59789. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 60.78413/62.56286. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.70494/62.50622. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.59627/62.47704. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 60.66640/62.44198. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.53328/62.39351. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.51429/62.34809. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.40420/62.33258. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.35851/62.29935. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.22108/62.26413. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.37602/62.23558. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.27452/62.25205. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.31010/62.16630. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 60.14518/62.17061. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.26290/62.16451. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 60.02875/62.14279. Took 0.31 sec\n",
      "ACC: 0.484375, MCC: -0.15422731972837422\n",
      "Epoch 0, Loss(train/val) 70.50613/69.69569. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.21087/69.28362. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.88787/68.87196. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.54073/68.44460. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.21724/67.99282. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.90066/67.51761. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.52439/67.00656. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.14962/66.45911. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.70105/65.88168. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.25363/65.27167. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.84741/64.66099. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 66.46668/64.09956. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.11274/63.60707. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.81762/63.19175. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.45634/62.82538. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.16947/62.48502. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.94886/62.16376. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 64.63906/61.86468. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.38260/61.58495. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.15165/61.31001. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.86657/61.01916. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.73025/60.71205. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.37205/60.37361. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.00496/60.00838. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.81523/59.64469. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.63266/59.30453. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.39278/59.00615. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.13058/58.73627. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.94459/58.49800. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.80916/58.27397. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.58133/58.03534. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.54107/57.78838. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.30733/57.52748. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.17102/57.24243. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.10289/56.94912. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.73922/56.62557. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 60.70500/56.29115. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.54738/55.95847. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.23038/55.63462. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.18623/55.33556. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.04059/55.05257. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.64684/54.78415. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.64076/54.56653. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.57260/54.38712. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 59.49270/54.26860. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.26851/54.18495. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.22265/54.10766. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.98647/54.04658. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.02064/53.99957. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 59.07778/53.97005. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.97957/53.91696. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.08122/53.86707. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 58.90566/53.82425. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.75435/53.79095. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.70337/53.74535. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 58.60559/53.69345. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 58.60605/53.65087. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.53575/53.60136. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.48236/53.54769. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.42083/53.50567. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 58.35547/53.46484. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.32449/53.41724. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.28122/53.35485. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.23125/53.29925. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 58.21239/53.25132. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.11153/53.19994. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.93307/53.16122. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.96287/53.10492. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.93013/53.06161. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.82851/53.03465. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.74966/53.01236. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.57066/52.99610. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.60260/53.00238. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.44143/53.02639. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 57.32871/53.02699. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.27420/53.08133. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.17250/53.06475. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.23561/53.17772. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.26439/53.11938. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 57.01776/53.19483. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.98362/53.21326. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.02297/53.37227. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.98533/53.38771. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.75358/53.57025. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.67180/53.75702. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.56312/53.77571. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.51339/53.81995. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.42373/53.73054. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.25762/53.87227. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.19917/53.63681. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.17339/53.75437. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.30295/53.80790. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 56.04582/53.74147. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 55.94442/53.67938. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.92137/53.73435. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.88781/53.72958. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.90764/53.77164. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.77624/53.55050. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.66628/53.74201. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.75444/53.66827. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: 0.0023098630955841236\n",
      "Epoch 0, Loss(train/val) 70.02250/70.10522. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.75331/69.91856. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.50005/69.70229. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.16387/69.45694. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.82233/69.17148. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.46329/68.83835. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.06725/68.44315. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.65645/67.97009. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.26570/67.41326. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.77485/66.76629. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.10070/66.03021. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.64680/65.25658. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 65.07967/64.48544. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 64.54115/63.74515. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.10179/63.06401. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.76599/62.47655. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.27340/61.97961. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.10980/61.58877. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.75928/61.28891. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.76458/61.08264. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.66182/60.92085. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.56230/60.78675. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.42711/60.68118. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 62.35124/60.59973. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.30108/60.53470. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.20040/60.46216. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.17935/60.38574. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.21389/60.32606. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.91240/60.27557. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.11168/60.21902. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 61.87609/60.17311. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.82958/60.13709. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 61.97464/60.10924. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.66922/60.07792. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.86725/60.04827. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 61.59642/60.01727. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.65516/60.00392. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.64107/59.98962. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 61.56389/59.98199. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.37923/59.96234. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 61.37766/59.94571. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 61.49118/59.94147. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 61.38159/59.96519. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.44272/60.00191. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.27647/60.05024. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.04826/60.11292. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.11643/60.14471. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.08470/60.16124. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.98866/60.17343. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.83066/60.15861. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.73458/60.11807. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.74465/60.10319. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.65185/60.07903. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.63525/60.04011. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.58370/60.00954. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.52214/59.94790. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.66200/59.80500. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.35357/59.78600. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.29439/59.82379. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.19457/59.80394. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.09381/59.80311. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.00549/59.78475. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.10023/59.87016. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.90915/59.73594. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.75586/59.74854. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.73600/59.63435. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.55880/59.50189. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.61166/59.68553. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.65398/59.40444. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.48038/59.39146. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.58219/59.13675. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.31072/59.47180. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.43642/59.13602. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 59.12924/59.06829. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.17798/58.86441. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.90571/58.95790. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.17984/58.62080. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.07931/58.79485. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.90229/58.49587. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.76296/58.57155. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.79915/58.31622. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.64467/58.38037. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.72044/58.23879. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.59174/58.10849. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 58.39073/58.11242. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.50761/57.85300. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.36875/57.94255. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.35131/57.74589. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.17756/57.57639. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.27189/57.69501. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.10642/57.38329. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.03141/57.43675. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.88951/57.49612. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.02724/57.29257. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.03300/57.02561. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.72635/57.32619. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.83521/56.97515. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.76999/57.01282. Took 0.34 sec\n",
      "Epoch 98, Loss(train/val) 57.66149/56.95656. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 57.73912/56.86158. Took 0.33 sec\n",
      "ACC: 0.4375, MCC: -0.07273929674533079\n",
      "Epoch 0, Loss(train/val) 70.72193/69.55839. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.52761/69.39258. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.25919/69.21416. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.04298/69.02620. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.83196/68.82585. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.57768/68.61150. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.32634/68.37166. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.11044/68.12314. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.83003/67.84444. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.55041/67.52194. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.24040/67.15472. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.83867/66.77534. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.50286/66.45961. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.98277/66.17689. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.70281/65.91209. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.39209/65.67139. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.18218/65.44450. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.98145/65.24078. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.73690/65.06789. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.46355/64.91619. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.45524/64.79109. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.18222/64.67514. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.14039/64.57099. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 64.88607/64.47652. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.82458/64.38386. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.63321/64.29465. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.52985/64.20355. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 64.50167/64.12143. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.41658/64.03394. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.30783/63.94288. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.30770/63.85641. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.17404/63.76893. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.00300/63.68306. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 64.04040/63.59834. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.96061/63.51921. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.85112/63.44915. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.79903/63.39333. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.88085/63.34828. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.65245/63.29989. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.59420/63.25237. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.51270/63.20208. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.35899/63.14608. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.31228/63.08493. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.43448/63.03153. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.15680/62.97664. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 63.15181/62.92446. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 63.20868/62.86352. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.02406/62.79650. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 62.86092/62.73081. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.92033/62.66902. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.93764/62.60599. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.83751/62.56808. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.71469/62.52223. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.46247/62.46168. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 62.66664/62.40485. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.51823/62.34630. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 62.57342/62.29194. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.56954/62.24095. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.47242/62.16861. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.49360/62.07854. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 62.34222/62.03444. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.18536/61.98122. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.27543/61.88955. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 62.16420/61.81004. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.09866/61.74740. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 62.10094/61.68405. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.91597/61.58227. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.90353/61.50629. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.97265/61.41602. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.61834/61.31609. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.55308/61.23764. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.57996/61.14366. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.27312/61.04430. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 61.30631/60.98820. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.25439/60.92000. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 61.35854/60.85970. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 61.18251/60.83024. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.08157/60.76774. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 61.11132/60.74927. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 61.15279/60.69255. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.98324/60.67650. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.91978/60.67152. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.80892/60.65830. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.95303/60.65497. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.66894/60.64534. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.70744/60.61655. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 60.52116/60.62065. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.56541/60.58179. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.57920/60.58936. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.33585/60.57158. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.80015/60.56900. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.41912/60.55466. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.42856/60.55251. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.33214/60.55295. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.18267/60.54150. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 60.08007/60.52821. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.31972/60.51824. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.24307/60.52003. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.19187/60.50469. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 60.23812/60.50081. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: -0.010693505400348576\n",
      "Epoch 0, Loss(train/val) 70.86731/70.83409. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.69457/70.71560. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.55135/70.60252. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.41419/70.48656. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.32250/70.37138. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.16720/70.25359. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.99312/70.13330. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.79167/70.01286. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.60400/69.88749. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 69.42615/69.75725. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.18959/69.62579. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.97017/69.48051. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.61898/69.32907. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.18806/69.16664. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.74369/68.98461. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.43603/68.76456. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.99151/68.50355. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.71199/68.24084. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 66.40570/67.98631. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 66.11449/67.73981. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.74592/67.50019. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.61878/67.27206. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.44415/67.06761. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.18077/66.91358. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.03611/66.80566. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.91526/66.70538. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.86727/66.60783. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 64.64496/66.51052. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.62263/66.40475. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.47731/66.31322. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.30592/66.23142. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 64.31396/66.15555. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.12790/66.06844. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 64.04584/66.00159. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.99079/65.93619. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.82222/65.86026. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.75936/65.79189. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.74377/65.70746. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 63.67356/65.61137. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 63.43161/65.53484. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.49186/65.45422. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.33843/65.38035. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.31555/65.29317. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.10946/65.19294. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 63.00743/65.10101. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.97098/64.97582. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.84949/64.85429. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.81274/64.72186. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.57256/64.55952. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.59414/64.41428. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 62.36355/64.23356. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.20168/64.01527. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.87739/63.91605. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.87028/63.71191. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.66524/63.60919. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.51231/63.38771. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.43695/63.29974. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.11840/63.16352. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.24807/63.07080. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.04211/62.95874. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.02649/62.88014. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.77480/62.83039. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.52195/62.70827. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.55463/62.71123. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.58962/62.51879. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.49567/62.59012. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.36056/62.41324. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.35628/62.36382. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 60.07484/62.24363. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.86891/62.19229. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.95607/61.98096. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.73461/61.86227. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.74425/61.76870. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.53489/61.65028. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.38011/61.39100. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.15582/61.16505. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.29609/60.65460. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.92779/60.56787. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.14847/60.26426. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.01148/60.18799. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.74068/60.09459. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.48528/60.00001. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.57571/59.82656. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.32619/59.73108. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.17993/59.60316. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.05161/59.55022. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.96493/59.47530. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.83622/59.36500. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.85934/59.43423. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.55570/59.42502. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.66518/59.05491. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.42692/59.15808. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.46625/59.15251. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.60296/59.18570. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.25154/58.93172. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.13961/58.81665. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.07156/58.81545. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.97641/58.92568. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.13497/58.82485. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 56.56723/58.79842. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.11834526708278773\n",
      "Epoch 0, Loss(train/val) 70.01637/69.75560. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.74447/69.61057. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.43940/69.45160. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.16168/69.27410. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.83650/69.06290. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.43963/68.80389. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.92040/68.49293. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.38434/68.12540. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.75804/67.69068. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 65.93809/67.19537. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.10359/66.64262. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 64.37784/66.07726. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 63.75440/65.56364. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 63.26588/65.16281. Took 0.34 sec\n",
      "Epoch 14, Loss(train/val) 62.82384/64.86246. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 62.38399/64.59561. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 62.05178/64.37413. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 61.76546/64.19815. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 61.40442/64.05952. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 61.25146/63.94688. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 61.17479/63.85392. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 60.92475/63.76931. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 60.72077/63.70174. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 60.70370/63.63567. Took 0.34 sec\n",
      "Epoch 24, Loss(train/val) 60.52142/63.58981. Took 0.34 sec\n",
      "Epoch 25, Loss(train/val) 60.47634/63.54618. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.24652/63.50711. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 60.30315/63.46721. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.06656/63.40839. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.06371/63.33196. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 60.07428/63.26892. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 59.95325/63.21870. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.94134/63.14506. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.74338/63.07131. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.71025/62.99796. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.66253/62.91866. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.69158/62.83577. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.51498/62.74775. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 59.57696/62.67251. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.44598/62.57335. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 59.38001/62.46347. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.44120/62.34666. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 59.30185/62.22174. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.31523/62.10344. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.36551/61.99354. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 59.06950/61.91250. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.12978/61.85604. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 59.16375/61.73592. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.03327/61.62583. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.95582/61.51291. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 58.86628/61.43259. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 58.89625/61.33589. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.78181/61.18430. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 58.57408/61.07284. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.61467/61.00922. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 58.45304/60.92407. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.46774/60.83614. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.32224/60.77086. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.33306/60.71257. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.26890/60.67885. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 58.17192/60.64199. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.07400/60.62027. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.11552/60.56854. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 57.86092/60.58338. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.74429/60.56079. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.63315/60.51851. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.55946/60.58645. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.45463/60.52867. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 57.18243/60.60230. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.28932/60.51532. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.15544/60.54772. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.00162/60.48304. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 56.81593/60.34484. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 56.82350/60.16484. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 56.59731/60.07085. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.38618/60.31355. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.60898/59.87160. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.41330/59.99741. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.29859/59.68403. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.00708/59.68697. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 56.22996/59.37183. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 56.00272/58.90162. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.05256/59.18298. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 55.72453/58.41319. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 55.55794/57.80978. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 55.42323/57.84527. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 55.63433/57.88715. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 55.20144/57.60102. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.35338/58.45477. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 55.39118/58.77529. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.65605/58.10796. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 55.99139/58.61318. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 55.50219/57.25733. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 55.39163/57.55994. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.40652/57.59504. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 54.99997/57.36815. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.07677/57.21358. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.06467/57.00235. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 54.75368/56.09260. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 54.89753/56.46001. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.04319917848286286\n",
      "Epoch 0, Loss(train/val) 71.49891/70.74916. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.23920/70.74203. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.96561/70.72217. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.71657/70.69278. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.43351/70.65369. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.17191/70.60352. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.82097/70.54594. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.41350/70.47869. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.99944/70.41579. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.52227/70.36792. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.94902/70.33963. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.46695/70.32813. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.73210/70.32032. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.99792/70.30410. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.21035/70.26915. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.48995/70.20499. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.05431/70.11108. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.60585/70.01384. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.15571/69.92245. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.77027/69.83435. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.41806/69.75201. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 62.20374/69.64306. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.84476/69.47244. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.49252/69.22520. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.25145/68.81613. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 60.91493/68.24109. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.54768/67.66936. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.40402/67.19324. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.08035/66.73907. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.76339/66.32780. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.60756/65.99752. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.35243/65.73450. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.22966/65.52683. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.36335/65.36651. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.06045/65.24441. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 58.90943/65.14117. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 58.81515/65.05727. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.75802/64.97626. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 58.61593/64.92941. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 58.64185/64.87445. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 58.53712/64.79855. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 58.37049/64.70580. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 58.43406/64.69099. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.50349/64.62855. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 58.26032/64.59249. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.22271/64.58135. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.28737/64.54225. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.25492/64.45223. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.99229/64.42273. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.09155/64.42375. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.07392/64.38142. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 58.05948/64.36659. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 58.02968/64.26466. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.87677/64.25137. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 57.87999/64.24026. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.73595/64.20496. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 57.82267/64.20063. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 57.69319/64.21439. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.67706/64.16918. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.54505/64.09459. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.55435/64.07588. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 57.46609/64.03780. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.53264/64.05516. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.45967/64.00029. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.30651/63.96722. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.39807/63.93550. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.27411/63.88149. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.16645/63.83305. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.25985/63.80027. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.25107/63.77176. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.03768/63.71164. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.19577/63.66754. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.09970/63.62940. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 57.15240/63.57709. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.90472/63.54268. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.96751/63.51425. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.79423/63.50889. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.76530/63.43976. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.86241/63.40313. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 56.75025/63.36092. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.96625/63.35695. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.60043/63.30116. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.55181/63.22795. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.57596/63.18505. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.36342/63.16281. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.34279/63.08134. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.35221/63.04428. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.33960/63.00144. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 56.44958/63.03451. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.11432/63.02741. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.24897/62.98944. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.05457/62.98583. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 56.01479/62.99013. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.07392/62.94162. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.75705/62.86193. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.77088/62.79223. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.69918/62.78790. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.68552/62.75656. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.39345/62.72935. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.46237/62.78527. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.025552902682603722\n",
      "Epoch 0, Loss(train/val) 70.65382/70.30008. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.45145/70.07650. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.23217/69.84110. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.04325/69.58525. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.87721/69.30706. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.67520/69.01765. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.42699/68.71790. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.21907/68.40203. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.94760/68.07342. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.68402/67.73379. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.49088/67.39045. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.20622/67.04137. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.83770/66.68246. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.54142/66.33510. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.13400/65.97739. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.95249/65.62458. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.59117/65.27393. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.33199/64.92314. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.03468/64.58114. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.74631/64.24243. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.41753/63.90958. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.12986/63.56641. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.86325/63.23424. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.75499/62.91955. Took 0.34 sec\n",
      "Epoch 24, Loss(train/val) 64.51601/62.64249. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.44079/62.42329. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.16619/62.25273. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.10950/62.08564. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.01683/61.94625. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 63.90293/61.80867. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.79522/61.70186. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.73514/61.60046. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.73991/61.52211. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 63.63515/61.42659. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.26686/61.33014. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.16819/61.23148. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.08724/61.13214. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.05299/61.03078. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.94725/60.89951. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.77371/60.74591. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.81512/60.52973. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.73979/60.39532. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.63586/60.31552. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.47445/60.25932. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.42418/60.18252. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.34445/60.09333. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.22871/60.11166. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.16654/60.07062. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.07282/60.03656. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.82609/59.99705. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.98452/59.96684. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.00054/59.93288. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.80596/59.92179. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 61.65035/59.89832. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.86021/59.92083. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.49328/59.93266. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.49886/59.91720. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.43747/59.91064. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.37032/59.94117. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.21877/59.98700. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.41957/60.01579. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.40888/60.06860. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.13401/60.07573. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.06102/60.09646. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.22717/60.18269. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.00197/60.26154. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.99751/60.67358. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.79365/60.86632. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 60.93915/61.20203. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.84629/61.44359. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.74628/61.46874. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.72961/61.69724. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.74159/61.90688. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.54615/61.97743. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.61952/61.55528. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.61037/61.78373. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.43068/62.01222. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.39945/61.96412. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.39168/61.86052. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.27830/61.94166. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.18871/62.01782. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.20094/62.00588. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.12356/62.00610. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 60.21500/61.91315. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.18542/61.79960. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 60.24609/61.87783. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.18856/61.92636. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 60.05340/61.91552. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.15612/61.91926. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.03107/61.85639. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.02929/61.85283. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.17199/61.81021. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.30717/61.74630. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 60.12805/61.84531. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.04610/61.79996. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 60.03068/61.81384. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.96897/61.84763. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.86290/61.80422. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.83203/61.75278. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.81844/61.77854. Took 0.32 sec\n",
      "ACC: 0.59375, MCC: 0.16608110589359998\n",
      "Epoch 0, Loss(train/val) 70.10206/70.14587. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 69.77261/70.15847. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.47187/70.16878. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.17111/70.17504. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.92028/70.17809. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 68.65684/70.17262. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.32312/70.15761. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.05642/70.12623. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.75833/70.08265. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.47084/70.02475. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.17800/69.94977. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.81389/69.87840. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.36606/69.79950. Took 0.30 sec\n",
      "Epoch 13, Loss(train/val) 66.00726/69.72401. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 65.67566/69.65652. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.36439/69.59925. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.99968/69.54762. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 64.75695/69.48957. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.42424/69.42260. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.11639/69.41085. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.92193/69.43307. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.75916/69.45661. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.52244/69.48584. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.25241/69.58450. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.12338/69.72221. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.01219/69.92117. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.75542/70.06497. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 62.66620/70.21041. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.64968/70.40381. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 62.45995/70.59351. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.21327/70.83598. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.08810/71.07278. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.92081/71.27452. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.70118/71.43119. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.60864/71.60294. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.58062/71.87366. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 61.36305/72.09277. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.15990/72.37463. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.19565/72.51562. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.13804/72.44144. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.11258/72.91032. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.84053/72.50603. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.77870/73.16795. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.63041/72.66332. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.54835/73.07168. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.50975/72.92575. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.39519/73.11404. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.30111/72.92939. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 60.24749/73.25738. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.22793/73.01034. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.19760/73.25390. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.14508/73.06820. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 60.10596/73.24793. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.94697/73.13227. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 59.94454/73.28002. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.90965/73.15300. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.74238/73.30301. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.83870/73.13564. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 59.75744/73.26329. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.68193/72.95097. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 59.84420/73.18952. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.70649/73.32677. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.52940/73.18179. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.42640/73.28105. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 59.51052/73.29163. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 59.39077/73.14472. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 59.29049/73.23859. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.39331/73.22129. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.32789/73.25341. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.30537/73.21873. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.25749/73.12827. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.12468/73.12315. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.12287/73.22443. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.19827/73.14394. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.06616/73.24788. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.04451/73.07980. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.09808/73.16343. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.83704/73.17995. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.83299/73.13324. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.73506/73.11551. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.92109/73.11903. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.85540/73.02386. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.97168/73.13589. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.70031/73.08664. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.71064/73.13747. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.62057/73.13264. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.69634/72.96945. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.66732/73.02401. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.67782/72.80420. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.60226/72.98141. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.58650/73.00239. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.50230/72.70760. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.61628/72.56591. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.44614/72.48850. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.39729/72.64729. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.38002/72.40517. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.29408/72.54210. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.29227/72.35719. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.17721/72.59068. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.22482/72.22649. Took 0.31 sec\n",
      "ACC: 0.4375, MCC: -0.11318329168362205\n",
      "Epoch 0, Loss(train/val) 70.50175/70.04399. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.17375/69.96556. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.91093/69.87877. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.69033/69.77556. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.40969/69.65321. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.10156/69.51054. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.79057/69.34995. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.45824/69.16455. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.13577/68.95522. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.78886/68.72147. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.44072/68.45706. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.92599/68.16495. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.62600/67.85589. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.27463/67.54691. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.84576/67.25437. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 65.48918/66.97398. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.20561/66.72351. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.89062/66.50650. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.45006/66.29898. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.06321/66.10224. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 63.58758/65.85522. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.19437/65.51995. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.57966/65.06126. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.99721/64.49069. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.66025/63.87593. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.36318/63.26397. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.75990/62.64801. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.54869/62.15059. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 60.37553/61.80758. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 60.25487/61.53717. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.89758/61.32579. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.66375/61.15772. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.45268/61.00446. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.36123/60.86850. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 59.23846/60.71025. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.33579/60.52638. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.88900/60.30708. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.68617/60.14973. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.59274/60.02994. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.48534/59.93989. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.35587/59.87803. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 58.36021/59.83405. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.16080/59.74566. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 58.09705/59.64336. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 57.94702/59.57450. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.01444/59.46397. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 57.92867/59.39038. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.77815/59.29479. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.72238/59.18071. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 57.66733/59.14434. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 57.63318/59.16001. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.69750/59.08745. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.39098/59.10252. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 57.49378/59.07994. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 57.35583/59.11699. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.39847/59.22378. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.28497/59.23293. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.16682/59.20370. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.15387/59.15823. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.09164/59.14096. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.29172/59.07345. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 57.14139/59.16371. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.10002/59.19372. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.09044/59.19098. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 57.11178/59.18499. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.93117/59.12926. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 56.92508/59.15562. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 56.85405/59.09470. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 56.75319/59.09513. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 56.81913/59.02473. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.68872/59.02127. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 56.90468/59.04283. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.76309/59.05473. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.84919/58.95654. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.70277/59.06512. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.66811/58.99750. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.82252/59.12818. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 56.71933/58.97774. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.58228/59.12380. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.61044/58.97268. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.27591/59.14929. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.53033/58.88204. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.46540/59.00354. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 56.38719/58.88214. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.23707/58.89050. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.44753/58.83176. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.44686/58.91306. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 56.46858/58.79659. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.29397/58.93497. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.45486/58.82341. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.32815/58.89915. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.39824/58.74174. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.08884/58.80095. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.33358/58.85136. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 56.19636/58.84936. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.13631/58.66580. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.15641/58.92230. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 56.12643/58.59832. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.14080/58.95667. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.99796/58.76069. Took 0.31 sec\n",
      "ACC: 0.546875, MCC: 0.06815142307594586\n",
      "Epoch 0, Loss(train/val) 70.67568/71.51141. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.41831/71.27849. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.23744/71.04524. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.97001/70.79646. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.72568/70.53761. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.49442/70.26093. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.21388/69.96461. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.91111/69.66617. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.59045/69.35281. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.33644/69.03001. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.97659/68.70045. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.59466/68.36694. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.37441/68.04559. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.99075/67.73827. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.70485/67.43937. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.38637/67.15257. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.13087/66.87395. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.93315/66.59052. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.68890/66.30475. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 65.44521/66.00668. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.14788/65.70191. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 64.87301/65.38958. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.67289/65.05849. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.52076/64.71471. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.18955/64.36739. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.85977/64.00206. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.55237/63.65265. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.29586/63.32376. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.05692/63.01978. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.74249/62.68637. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.60453/62.32771. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 62.12606/61.96366. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.91542/61.64536. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.50719/61.34889. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.15690/61.06957. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.79907/60.85275. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.74620/60.67871. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 60.53803/60.51401. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.34740/60.38719. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.28096/60.29501. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.20083/60.22511. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 60.08539/60.17718. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.12607/60.14000. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.85879/60.09335. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.99065/60.04252. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.79535/59.99231. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.74239/59.92960. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.64541/59.87916. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.65578/59.80754. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.60734/59.75387. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.53544/59.73443. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.58688/59.71427. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 59.50566/59.69662. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.36689/59.61819. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.38556/59.57519. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 59.24980/59.52214. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 59.26151/59.48544. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.26902/59.41495. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 59.21456/59.34841. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 59.29427/59.30317. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.99934/59.25936. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.02152/59.19552. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.07468/59.15266. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 58.88246/59.10508. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.80216/59.02221. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 58.97026/58.95601. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.85604/58.90196. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.77505/58.82227. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.80151/58.73380. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 58.79492/58.68290. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.71359/58.61621. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 58.65845/58.55349. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.48856/58.48043. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 58.45351/58.43899. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 58.36856/58.34003. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.34102/58.33745. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 58.44181/58.28457. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 58.44958/58.18635. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.28071/58.15863. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.14428/58.14900. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 58.18596/58.15355. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.14121/57.90405. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.09805/57.96918. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.00991/57.97191. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.01260/57.85738. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.96788/57.83519. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 57.89060/57.74862. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.06574/57.75068. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.74640/57.68916. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.84160/57.60809. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.75248/57.56845. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.78774/57.58967. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.75486/57.47861. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.84252/57.42611. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 57.71416/57.39885. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.61935/57.39549. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.61003/57.33933. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.65077/57.29308. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 57.37624/57.24329. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.47400/57.24448. Took 0.32 sec\n",
      "ACC: 0.6875, MCC: 0.33062326126679026\n",
      "Epoch 0, Loss(train/val) 70.45488/71.58220. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.18658/71.49818. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.89332/71.40784. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.63793/71.30626. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.33201/71.19749. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.05061/71.07815. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 68.76012/70.93863. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.50102/70.77628. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.12043/70.58605. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.78388/70.37392. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.39877/70.13910. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.12769/69.89983. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.61070/69.64219. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 66.24162/69.35632. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.95789/69.05106. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 65.70799/68.73237. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.48249/68.39412. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 65.00289/68.06845. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 64.89533/67.76823. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.56364/67.49573. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.44186/67.25775. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 64.12444/67.06501. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.91987/66.90243. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.75410/66.75643. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.72701/66.64703. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.42429/66.56967. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.14068/66.51492. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.95731/66.46071. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.82415/66.42618. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.75945/66.38287. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.53051/66.30879. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.44050/66.20733. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.42480/66.11546. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.27238/65.98337. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.14997/65.80977. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.02272/65.66184. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.84156/65.50349. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.83360/65.35806. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.71635/65.20709. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.60011/65.02991. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 61.62051/64.83144. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.48715/64.67345. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.41001/64.59606. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 61.39235/64.49461. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.41714/64.41259. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.38864/64.35928. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.19102/64.30151. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.25087/64.20218. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.99947/64.13656. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.09866/64.12007. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.07987/64.01714. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.07302/63.96988. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.98562/63.87398. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.01471/63.80033. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.03091/63.78091. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.96277/63.73008. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 61.02730/63.69762. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.80028/63.67060. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.98898/63.64890. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.78940/63.57230. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.79241/63.54538. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.73740/63.51815. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.70140/63.44777. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 60.65608/63.40379. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.81633/63.34082. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.64995/63.29981. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.66154/63.28926. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 60.69244/63.27937. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 60.54608/63.37810. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.64865/63.28780. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.52251/63.21547. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.49863/63.17974. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.56448/63.21462. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.61663/63.16923. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.70344/63.20007. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.38958/63.12972. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.54853/63.11057. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 60.44739/63.11720. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.31284/63.09623. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.20256/63.12722. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.15642/63.05079. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.23691/63.02681. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.31169/62.98157. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.19621/62.99705. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.15775/62.94428. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.21325/62.90557. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.00274/62.81594. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.99982/62.72612. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.11144/62.65003. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.98891/62.62271. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.93078/62.61063. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 60.02275/62.55580. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.89191/62.54796. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.90828/62.56428. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.86425/62.53455. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 59.81073/62.47879. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.86979/62.42349. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 59.72003/62.34875. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.60097/62.33985. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.69220/62.32249. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.06741998624632421\n",
      "Epoch 0, Loss(train/val) 70.72470/70.23401. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.40196/70.06935. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.14256/69.92440. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.90015/69.79704. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.66903/69.68237. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.43330/69.57020. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.21315/69.46493. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.09058/69.36089. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.80873/69.25472. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.63382/69.14136. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.37764/69.03130. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.15686/68.91158. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.96400/68.78645. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.68318/68.65993. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.46825/68.52480. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.24065/68.39659. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.08648/68.27449. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.90556/68.15597. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.68532/68.04264. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.43841/67.92875. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.27887/67.81988. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.07940/67.70251. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.94854/67.58511. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.78661/67.48441. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.66781/67.38500. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.45242/67.29507. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.28837/67.21561. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.15271/67.12650. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.13284/67.03825. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.81135/66.95260. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.74104/66.87206. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.63301/66.78447. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.48838/66.68559. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.27155/66.59012. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 64.15896/66.46897. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.96961/66.33901. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.66803/66.20538. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 63.70652/66.06691. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.61796/65.93714. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.40672/65.80317. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.16126/65.67520. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.87679/65.55480. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 62.76314/65.42059. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.62574/65.28001. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.38865/65.10693. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.02116/64.93124. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.50511/64.76196. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.18567/64.61723. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.85010/64.49698. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.54338/64.42110. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.34161/64.33950. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.03461/64.27032. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.92797/64.20576. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.70737/64.10292. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.54888/64.05062. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.42166/63.91176. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.10271/63.85476. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.97865/63.71552. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.88518/63.61924. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.67123/63.56199. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.55632/63.44183. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.25446/63.37237. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 58.21056/63.29207. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.12726/63.17425. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.94378/63.10621. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.83933/63.01937. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.84913/63.04083. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.73595/62.98084. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 57.48392/62.94193. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.41309/62.87552. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 57.37993/62.78944. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.34572/62.72354. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 57.15729/62.71119. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 57.37792/62.62421. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 57.16621/62.52296. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.96802/62.51836. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.98402/62.47672. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.05827/62.46257. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 56.91136/62.35690. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 56.71346/62.28099. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.71580/62.23991. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.70952/62.19242. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.65908/62.21955. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.64281/62.16784. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.60506/62.14152. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.57633/62.08850. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.48230/62.03590. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.32885/62.05503. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 56.42790/61.92492. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.15664/62.01799. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.31070/61.90345. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.37242/61.91187. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.36570/61.86502. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.26621/61.82737. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.97908/61.77572. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.11012/61.79108. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.12356/61.76046. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.92412/61.70457. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.99785/61.71436. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.78658/61.68388. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.13471563869719666\n",
      "Epoch 0, Loss(train/val) 70.82437/71.69891. Took 0.35 sec\n",
      "Epoch 1, Loss(train/val) 70.69142/71.70110. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.52751/71.71025. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.37821/71.72696. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.23262/71.74431. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.09198/71.76509. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.90426/71.79366. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.76480/71.82275. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.57620/71.85233. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.41545/71.88336. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 69.22937/71.90527. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.00123/71.92684. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.80094/71.94139. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.62140/71.94257. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.39877/71.92738. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.27351/71.89381. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.06222/71.84599. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.77373/71.77907. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.70957/71.70024. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.53805/71.61909. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 67.31928/71.52919. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 67.30363/71.42171. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.15815/71.30473. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.96385/71.17975. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.84746/71.04551. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.70686/70.87920. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.60323/70.69545. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.47870/70.50123. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 66.29594/70.30050. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.19889/70.10652. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.04972/69.91142. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.91746/69.72271. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.83889/69.54179. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 65.69314/69.35355. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.67960/69.16544. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.46576/68.99012. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.47189/68.81905. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.43053/68.66281. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 65.13833/68.49937. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 65.10391/68.34418. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.92865/68.18092. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.83780/68.04107. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.66783/67.90899. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.56156/67.81358. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.48617/67.73779. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.29209/67.67020. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.15127/67.65651. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 64.03436/67.61563. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 63.87685/67.62773. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.71595/67.66947. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.52441/67.75475. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.40933/67.83909. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.15897/67.93629. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.23929/68.02567. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.96369/67.98990. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.03731/68.01088. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.77707/68.17855. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.72698/68.38023. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 62.45121/68.50886. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 62.40427/68.51121. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 62.16363/68.63580. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.15741/68.71483. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.97553/68.81135. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.84947/68.68562. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.64942/68.69141. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 61.70733/68.77827. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.42637/68.76915. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 61.42267/68.67499. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 61.19120/68.74333. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.24584/68.63142. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.11788/68.58600. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 61.02430/68.59451. Took 0.30 sec\n",
      "Epoch 72, Loss(train/val) 60.80954/68.54092. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.75651/68.53395. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.74637/68.52439. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.63606/68.43781. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 60.67361/68.31856. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.57928/68.27598. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.32720/68.20638. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.11086/68.14973. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.36488/68.18651. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.19649/68.20477. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.15429/68.11325. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.10386/68.02748. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.00892/68.00783. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.98905/68.08115. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.73703/68.11469. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.64616/67.96526. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.61493/67.89502. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.50680/67.74718. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 59.50084/67.67526. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.26811/67.69427. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 59.13799/67.60356. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.29610/67.52302. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 59.05035/67.53647. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.93016/67.75589. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.91109/67.84911. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.70157/67.83045. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 58.43351/67.89165. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.34108/67.89070. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.10881399260327249\n",
      "Epoch 0, Loss(train/val) 70.79739/71.11074. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.49693/70.96208. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.24285/70.81111. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.97312/70.65585. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.71266/70.49898. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.42489/70.33535. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.14316/70.15965. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.79729/69.97764. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.41981/69.78705. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.99202/69.57977. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.60594/69.36034. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.18136/69.12849. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.75459/68.88283. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.40510/68.63172. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.98627/68.38737. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.54003/68.15056. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.19935/67.92347. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.75917/67.71510. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.23224/67.52896. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.96456/67.37861. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.54121/67.26202. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 63.30640/67.16707. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.01535/67.08575. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 62.81520/67.01409. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.45189/66.94500. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.33263/66.85562. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.22144/66.75967. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.97508/66.64854. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.96663/66.52431. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.79543/66.39729. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 61.63280/66.27586. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.52607/66.13998. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.46390/65.99644. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.22434/65.83456. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.20677/65.69758. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.99508/65.56551. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.96253/65.43036. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.90730/65.28912. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.94191/65.12294. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.62819/64.93633. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.53502/64.73975. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.57373/64.52976. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.39683/64.29108. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.30622/64.05466. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.04998/63.86995. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.83406/63.66233. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.73531/63.46662. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.41064/63.26544. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.26156/63.10135. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.28059/62.99099. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.14011/62.91547. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 58.97532/62.84413. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.09311/62.78148. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.83844/62.72046. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.68062/62.64910. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.72910/62.56475. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.76161/62.49141. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.46604/62.43785. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.55549/62.41961. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.46914/62.39079. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.37575/62.36694. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.45100/62.31838. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.37695/62.26609. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.13101/62.25327. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 58.14268/62.17349. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.19032/62.12007. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.05729/62.10434. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.99132/62.00681. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 58.11713/62.01371. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.96524/61.87733. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.01141/61.87140. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.91097/61.68449. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.81975/61.62813. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 57.69385/61.52534. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.81341/61.34708. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.70507/61.39101. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.59504/61.23430. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 57.58174/61.26675. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.55359/61.14877. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.45241/61.22631. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.41231/61.09419. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.30590/61.15406. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.34353/61.03020. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 57.28205/61.12625. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.20421/61.07276. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.29945/61.07318. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.15944/61.06177. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.23404/61.16310. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.22036/61.03903. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.02466/61.16853. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 57.05362/61.13593. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.95950/61.18287. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.76685/61.14742. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.99809/61.14461. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.86435/61.12326. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.86074/61.19406. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.70629/61.18657. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.77445/61.19434. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.60718/61.18271. Took 0.34 sec\n",
      "Epoch 99, Loss(train/val) 56.82083/61.17687. Took 0.32 sec\n",
      "ACC: 0.5, MCC: -0.06279669574154817\n",
      "Epoch 0, Loss(train/val) 69.85277/68.82008. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.61280/68.67493. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.40267/68.52467. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.24150/68.36505. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.99259/68.20873. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.75978/68.04838. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.61717/67.87490. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.26635/67.68973. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.14602/67.48739. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.83635/67.24603. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.54147/66.98499. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 67.25503/66.70133. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.00064/66.41988. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.64006/66.16931. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.31094/65.93501. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 66.11700/65.66459. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 65.89831/65.41126. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.57881/65.15115. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.53749/64.92094. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.31727/64.68510. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.12629/64.46649. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.95598/64.27431. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.87475/64.10944. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.74191/63.95070. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 64.65672/63.80473. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.39428/63.70539. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.44407/63.62321. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.40098/63.55362. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.31753/63.47889. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.10370/63.42023. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.04988/63.37422. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.03556/63.31675. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.92386/63.29063. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.82315/63.26311. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.85114/63.23415. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.73976/63.21462. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.56075/63.18604. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.53324/63.16843. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.47305/63.14609. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.50076/63.08218. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 63.49264/63.04843. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.39828/63.04290. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.26909/63.01598. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.13494/62.98005. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.15259/62.95852. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.11287/62.92045. Took 0.34 sec\n",
      "Epoch 46, Loss(train/val) 63.08512/62.87124. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.10911/62.86109. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 62.97814/62.83512. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.99348/62.80120. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.73225/62.77644. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.87708/62.74146. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.88192/62.69313. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.81446/62.65667. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 62.64468/62.64139. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.53875/62.62800. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.60337/62.59291. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.65015/62.55312. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 62.50058/62.52916. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.38920/62.50892. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 62.32405/62.47018. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.37786/62.43712. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.13236/62.40258. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.01941/62.38503. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.98513/62.36927. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.97058/62.32182. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.05318/62.25138. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.94614/62.22965. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.79560/62.20353. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.69838/62.18929. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.81800/62.17552. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.56785/62.12248. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.62257/62.05155. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.69916/62.02148. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.38464/62.00108. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.48149/62.00679. Took 0.34 sec\n",
      "Epoch 76, Loss(train/val) 61.37019/61.95792. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 61.32667/61.90379. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 61.39082/61.86178. Took 0.34 sec\n",
      "Epoch 79, Loss(train/val) 61.31583/61.81504. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 61.22065/61.82066. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.13785/61.82215. Took 0.34 sec\n",
      "Epoch 82, Loss(train/val) 61.26682/61.74936. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.04567/61.70683. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 61.07913/61.73574. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.02940/61.71410. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.04666/61.72127. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.98709/61.71384. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 60.90284/61.77741. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.85568/61.89273. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.84412/61.89263. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.71398/61.74109. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.84189/61.91658. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.70612/62.01748. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.57770/62.16637. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.60477/62.13460. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.68281/62.08300. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.48533/62.01776. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 60.30643/62.09478. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.39744/62.12648. Took 0.33 sec\n",
      "ACC: 0.578125, MCC: 0.12253577034896797\n",
      "Epoch 0, Loss(train/val) 69.67921/69.90710. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.48310/69.94102. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.24012/69.98466. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.05130/70.02618. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.77763/70.05289. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 68.53646/70.06436. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.23350/70.04779. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.92559/69.99944. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.60607/69.92934. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 67.25376/69.83222. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.85678/69.70401. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.48386/69.53638. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.15241/69.31630. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.71344/69.05330. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.34889/68.74190. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.01494/68.37539. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.68394/67.97577. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.39915/67.53837. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.20463/67.05647. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.00963/66.51028. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.73144/65.91978. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.50852/65.29472. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.43976/64.64772. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.23709/64.01582. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.93830/63.41016. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 62.82580/62.87294. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.72708/62.35501. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.58519/61.86362. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.56674/61.46849. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.44564/61.13291. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.17984/60.84598. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.29273/60.58820. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.13315/60.41216. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.00423/60.27504. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.95308/60.11916. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.94656/59.98660. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.82613/59.85454. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 61.80631/59.72120. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.63606/59.59077. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 61.68444/59.47205. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 61.53715/59.36548. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.45443/59.26230. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 61.64118/59.14242. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.39347/59.03922. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.40135/58.96268. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.09726/58.87933. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.20348/58.77846. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.03070/58.70108. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.15974/58.62230. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.01685/58.57384. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.08922/58.52577. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.91710/58.49568. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.75357/58.45987. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.82725/58.45097. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.72868/58.43806. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.76142/58.41830. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.68226/58.40786. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.69023/58.41515. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.62438/58.43596. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.65660/58.44123. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.52654/58.43365. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.40849/58.42267. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.43998/58.44334. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.38900/58.44974. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.58316/58.46979. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.24837/58.49943. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.31651/58.48736. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 60.28935/58.46540. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 60.16024/58.48724. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.34396/58.47338. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.22401/58.47423. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.22510/58.45566. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 60.30513/58.45351. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.05613/58.44542. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.96999/58.46008. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.95786/58.46212. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.91353/58.46524. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.07581/58.47726. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.96129/58.44362. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.80453/58.43025. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.00273/58.44312. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.77431/58.41832. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.86012/58.42556. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.57927/58.42511. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.76243/58.41965. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.73523/58.39004. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.62408/58.39094. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.62668/58.37048. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.49600/58.35679. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 59.38600/58.31032. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.32103/58.33538. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.63985/58.31569. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.69282/58.27894. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.53839/58.28752. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.39131/58.26074. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.38740/58.26408. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.34650/58.23357. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.65086/58.22509. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 59.25598/58.19630. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.38829/58.17955. Took 0.32 sec\n",
      "ACC: 0.5, MCC: -0.020601266687222692\n",
      "Epoch 0, Loss(train/val) 71.04944/69.72359. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.78442/69.65872. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.55681/69.59998. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.33058/69.53754. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.08348/69.47112. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.82211/69.40549. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.56876/69.33568. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.20965/69.23753. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.84534/69.08221. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.47022/68.86043. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.06759/68.57628. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.52410/68.23437. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.11798/67.85537. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.63985/67.46177. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.08065/67.12871. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.68033/66.83066. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.21017/66.54765. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.89412/66.28677. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.51494/66.04737. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.17026/65.83536. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.69611/65.64631. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.49037/65.48835. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.23621/65.35493. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.97052/65.23916. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.74739/65.14455. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.58217/65.08353. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.30680/65.05326. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.98929/65.04794. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.84237/65.03580. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.76681/65.02169. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.48262/65.01903. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.45782/65.04863. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.43679/65.08473. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.43806/65.12346. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.23334/65.16470. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.35821/65.20920. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.10548/65.25148. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.03876/65.29235. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.91062/65.33834. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.90156/65.36893. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.82112/65.39903. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 60.73791/65.44200. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.58181/65.48078. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.64656/65.52112. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.57671/65.55579. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.57212/65.60357. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.49366/65.65034. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.53925/65.68915. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.37291/65.72655. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.37546/65.76852. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.28313/65.79394. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 60.29990/65.82327. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.17840/65.85979. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.36291/65.86684. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.29919/65.92166. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.16551/65.95666. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.29225/65.99119. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 60.03222/66.04091. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.21009/66.11848. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.95403/66.18712. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.08843/66.24973. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.87364/66.25525. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.09392/66.26575. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 60.05338/66.31767. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.92044/66.42359. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.87492/66.44307. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.78226/66.43051. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 59.90932/66.48563. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.80235/66.54819. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.79011/66.57918. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.74895/66.61722. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.80549/66.61485. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.55519/66.51767. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.67095/66.60045. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.59600/66.65415. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 59.54085/66.59293. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.72310/66.60848. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.57627/66.56679. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.43827/66.62572. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.46050/66.62319. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.63409/66.57454. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 59.28709/66.57518. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.52411/66.56365. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.23776/66.56997. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.23391/66.55879. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.23191/66.51949. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.21472/66.50970. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.24092/66.49787. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.17966/66.54341. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.22865/66.55975. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.11669/66.54980. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.14942/66.59035. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.12111/66.64623. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.84623/66.63699. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.93646/66.60104. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.89926/66.49319. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.94147/66.71042. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.87407/66.75587. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.70187/66.62015. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 58.89522/66.73280. Took 0.33 sec\n",
      "ACC: 0.4375, MCC: -0.04054846624431496\n",
      "Epoch 0, Loss(train/val) 71.00726/71.68662. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.81381/71.43084. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.68260/71.15770. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.50502/70.87070. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.36079/70.56398. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.17324/70.23752. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.95490/69.87871. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.69915/69.48888. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.50284/69.08063. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.30253/68.65524. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.99067/68.19733. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.79682/67.72183. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.47456/67.23085. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.23664/66.74799. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.92048/66.31406. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.68479/65.93961. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.39732/65.61306. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 67.11618/65.32812. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.92562/65.07918. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.69077/64.85267. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.39423/64.64235. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.25472/64.45174. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.97074/64.25349. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.63615/64.03819. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.38053/63.79239. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 65.09295/63.50698. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.77751/63.19180. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.49032/62.87949. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.35632/62.60699. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.94433/62.35299. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.85120/62.11787. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.35797/61.89873. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.12072/61.69552. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 63.01523/61.52703. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.96171/61.39474. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.63789/61.27843. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.64421/61.16190. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 62.27393/61.05651. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.47409/60.97143. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 62.10157/60.88282. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.11824/60.79593. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.86148/60.72796. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.84446/60.67410. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.84257/60.62975. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.59512/60.59699. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.80981/60.55883. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.62709/60.52501. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.61380/60.50500. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.49781/60.48917. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.36186/60.47738. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.46179/60.47270. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.40213/60.47046. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.50026/60.46374. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.43121/60.45732. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.38462/60.43930. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.21408/60.41034. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.20399/60.38021. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.11346/60.34252. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.09962/60.30801. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.08102/60.27839. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.93129/60.25105. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.01834/60.21973. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.91768/60.19209. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.86832/60.17101. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.77440/60.15150. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.86867/60.13360. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.98459/60.10873. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.88849/60.08360. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.60541/60.04940. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.68434/60.00734. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.74596/59.97939. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.58952/59.93797. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 60.40157/59.90130. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.33864/59.86856. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.30410/59.82288. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.23762/59.78033. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.49191/59.75916. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.46108/59.71003. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 60.29959/59.68132. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.06856/59.65971. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.24504/59.63420. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.17235/59.56865. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 60.33519/59.50008. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 60.04179/59.46813. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.09474/59.44152. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.04734/59.40145. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.05008/59.36641. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 60.01882/59.33638. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.96415/59.29922. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.80497/59.25466. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.99325/59.24587. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.88387/59.23750. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.77103/59.18677. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.67955/59.13139. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 59.77734/59.11350. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.62108/59.09295. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.75011/59.03711. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 59.70718/59.00754. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.72390/58.94316. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.64418/58.91991. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.11215076988808788\n",
      "Epoch 0, Loss(train/val) 71.47310/71.68446. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.34192/71.61495. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.18495/71.55265. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.98710/71.49680. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.84098/71.45023. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.67366/71.40530. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.50560/71.36272. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 70.34120/71.31576. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.21437/71.26938. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 70.03407/71.22500. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 69.85816/71.17855. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.70289/71.12471. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.49977/71.05992. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 69.20149/70.98609. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.93989/70.90480. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.66790/70.80916. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 68.32810/70.67409. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.94629/70.48840. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 67.60432/70.21095. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.15384/69.78345. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.58313/69.15977. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.06180/68.32172. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.55323/67.33282. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.05213/66.37495. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.42208/65.55827. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.18113/64.92744. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.80681/64.43118. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.61283/64.05088. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 63.26366/63.74129. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 63.05537/63.47249. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.80837/63.23407. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.87440/63.05534. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.64046/62.92564. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.53920/62.81848. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.20607/62.72213. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.16803/62.62772. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.09911/62.54094. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.03977/62.46526. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.82971/62.39473. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.55246/62.31736. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.62130/62.24571. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 61.55897/62.16953. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.35762/62.08603. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.25127/62.00557. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.15855/61.92900. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.11540/61.84891. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.97062/61.77807. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.66722/61.69212. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 60.65393/61.59205. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.73705/61.52534. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.56858/61.46726. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.25741/61.40881. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.14071/61.33737. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.29237/61.29228. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.13620/61.23746. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.12556/61.16081. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 59.85102/61.11100. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.89373/61.04981. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.66934/60.99981. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 59.68009/60.96681. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.71518/60.90957. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.42273/60.83601. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.56157/60.78793. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.43258/60.72248. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 59.21812/60.66166. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 59.40826/60.60515. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.03368/60.59359. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.07306/60.51840. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.99610/60.46685. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.85311/60.39875. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.73706/60.36501. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.73441/60.31478. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.63380/60.25741. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.50206/60.19167. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.59934/60.15750. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.31693/60.15465. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.47659/60.09098. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.42244/60.06985. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.23454/60.04140. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.15287/59.96084. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.23127/59.91326. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.30159/59.96576. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.19843/59.89716. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.04900/59.92072. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.91640/59.80812. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.89944/59.93074. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.91821/59.79652. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.85643/59.77356. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.73868/59.78502. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.68513/59.75988. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.55730/59.78746. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.53395/59.65445. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.54115/59.70906. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.48827/59.83062. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.45514/59.79303. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.38900/59.86161. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.38356/59.75842. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.24447/59.61055. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.26104/59.64201. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.36935/59.76956. Took 0.32 sec\n",
      "ACC: 0.59375, MCC: 0.22677868380553634\n",
      "Epoch 0, Loss(train/val) 70.64598/71.10718. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.33762/70.85938. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.05998/70.61991. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.80956/70.38687. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.52025/70.16169. Took 0.34 sec\n",
      "Epoch 5, Loss(train/val) 69.27473/69.93551. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.01188/69.70564. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.75516/69.46623. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.43092/69.20840. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.19845/68.93273. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.84298/68.62777. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.59064/68.29359. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 67.22023/67.91991. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.82429/67.49182. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.47165/67.01152. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.94908/66.45209. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.42841/65.79646. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.80111/65.04115. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.13363/64.24355. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.59351/63.49693. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.98754/62.86790. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.50513/62.40083. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.15285/62.03276. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.81701/61.76827. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.56075/61.56129. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.38637/61.39679. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.11310/61.23320. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.88154/61.09671. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.63727/60.96094. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.55624/60.84193. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.36978/60.72811. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.23614/60.64312. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.03955/60.57915. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 59.89883/60.47370. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.86645/60.37645. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.60640/60.31896. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.75209/60.23052. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 59.52929/60.17998. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.42466/60.10620. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.18757/60.02230. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.18196/59.94733. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.28144/59.89775. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 59.10622/59.86421. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 58.96660/59.79479. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.86800/59.71582. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.69182/59.66109. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.61134/59.65116. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.53713/59.56916. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.41992/59.58573. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.42739/59.50731. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.29930/59.55032. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 58.26452/59.43576. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.05873/59.53968. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.03710/59.36684. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.07348/59.45097. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.10328/59.31849. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.93798/59.40131. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.77966/59.25278. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.82903/59.39807. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.82872/59.19505. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.60756/59.34141. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.52942/59.19075. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.52039/59.14994. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.38411/59.22103. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.31944/59.07611. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.23832/59.07202. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.17766/59.08281. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.11649/59.00364. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.12112/58.96723. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.06960/58.93845. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 56.88219/58.92441. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.65553/58.88460. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.70202/58.92679. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.63802/58.83251. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 56.56623/58.75075. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 56.47461/58.69388. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.53095/58.69978. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.21036/58.68246. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.26573/58.52840. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.18804/58.59214. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 55.97477/58.61335. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.06878/58.58477. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 55.91773/58.43433. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 55.93528/58.57139. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 55.79307/58.46569. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.68756/58.61588. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 55.60278/58.61248. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 55.42377/58.67317. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 55.52395/58.62699. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 55.31997/58.60951. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 55.22620/58.60677. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.32660/58.32061. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 54.98129/58.27979. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 54.96829/58.45683. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 54.79361/58.24670. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 54.64373/58.32763. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 54.52106/58.31857. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 54.55119/58.24538. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 54.32295/58.00261. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 54.26333/57.82024. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.03913053124059665\n",
      "Epoch 0, Loss(train/val) 71.89294/71.87554. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.65888/71.57521. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.43023/71.29337. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 71.26153/71.01984. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 71.00782/70.75583. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.84301/70.49653. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 70.64713/70.24092. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.46172/69.98601. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.25681/69.72157. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 70.07756/69.45163. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 69.87802/69.17433. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.63769/68.87888. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.44515/68.57278. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.20331/68.24454. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.01902/67.89915. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.68896/67.51906. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 68.45771/67.10743. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.13420/66.65715. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.88312/66.16347. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.52326/65.64086. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 67.24294/65.10061. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.86751/64.55620. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.51190/64.02038. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.08476/63.49683. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.58362/62.96868. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 65.33251/62.43715. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.80002/61.88630. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.32279/61.30782. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.85940/60.69702. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.24205/60.06026. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.52517/59.44015. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.26440/58.89160. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.74790/58.49146. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.29317/58.22110. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.26951/58.02517. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.10969/57.86254. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.76189/57.72334. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.75915/57.61251. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.65125/57.54573. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.61572/57.48646. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.43688/57.43763. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 60.60259/57.39396. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.51275/57.34755. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.35997/57.29267. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.15752/57.24116. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.20760/57.17878. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.98433/57.11243. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 59.94349/57.06831. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.99586/57.01550. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.00702/56.97734. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 60.01256/56.95410. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.01741/56.91733. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.05149/56.89770. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.75896/56.85072. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.62471/56.83913. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.74397/56.82823. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.64709/56.78631. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.77944/56.76849. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.56073/56.74695. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 59.48103/56.69210. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.74853/56.67047. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.55320/56.65357. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.39912/56.65861. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 59.61555/56.63585. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.36932/56.58315. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.52486/56.55914. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.49292/56.52715. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.39070/56.50327. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.35062/56.51413. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.08499/56.43882. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.25460/56.40163. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.15432/56.39391. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.24544/56.37835. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.27258/56.39882. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.28722/56.30712. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.10461/56.28758. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.16416/56.23376. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.26538/56.19304. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.08080/56.18465. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.07359/56.15033. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.82171/56.07364. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.81428/56.08487. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.96880/56.07075. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.89255/55.99648. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.88944/56.00328. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 58.69611/55.97059. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.83352/55.95239. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.81449/55.98794. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.73886/55.94785. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.63055/55.99969. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.57378/55.99073. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.33714/55.92620. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.60259/56.02451. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.58387/55.83798. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.59936/55.93753. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.46301/55.88691. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.57859/55.90504. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.50414/55.68399. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.40393/55.91127. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 58.26759/55.64846. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: -0.012312225225925604\n",
      "Epoch 0, Loss(train/val) 71.70797/72.71552. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.28551/72.44666. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.91359/72.16702. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.56057/71.87003. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.12480/71.54764. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.71670/71.19778. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.31375/70.81292. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.77952/70.39002. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.28730/69.90494. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.74743/69.34406. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 67.06046/68.68472. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.38322/67.90707. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.53802/67.03041. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 64.78005/66.08241. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 63.96554/65.13209. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.32421/64.21988. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 62.84510/63.37842. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 62.31302/62.67683. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 61.77667/62.10074. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 61.42827/61.56620. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 61.12824/61.06788. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 60.71926/60.61523. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 60.45768/60.24385. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 60.34875/59.89203. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.12036/59.56322. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 59.90240/59.25514. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 59.62086/58.96397. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 59.48196/58.71122. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 59.19664/58.47434. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.37866/58.24810. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.09137/58.03775. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 58.78588/57.82825. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 58.79564/57.60511. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 58.67790/57.39174. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.50520/57.18700. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 58.44094/57.00637. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 58.37262/56.83147. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 58.19146/56.67703. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.01833/56.54637. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 58.11959/56.44511. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 57.94211/56.37758. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 57.72653/56.34925. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 57.76702/56.30212. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 57.61850/56.21286. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 57.42431/56.17749. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.68626/56.13455. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 57.57111/56.11562. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.45399/56.07108. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 57.55265/56.08840. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 57.48799/56.04956. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.08530/55.92947. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.29898/55.94483. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 57.20776/55.94405. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.19356/55.81915. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 57.04980/55.86888. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 57.07856/55.83345. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 56.89064/55.74970. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 56.96740/55.69366. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 56.86915/55.72161. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.11974/55.68132. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 56.99615/55.65416. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.05581/55.59827. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 56.83347/55.61933. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 56.88699/55.63701. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 56.75131/55.57642. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 56.81614/55.49370. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 56.91044/55.51989. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 56.97008/55.53480. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 56.58282/55.48491. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 56.48533/55.40490. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.37141/55.46911. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 56.64657/55.40966. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 56.35114/55.21280. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 56.43819/55.29321. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.30424/55.29747. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.51004/55.24027. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.45435/55.14706. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.33071/55.20612. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 56.25334/55.08755. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.31124/55.06432. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 56.22333/54.98415. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.49696/55.02135. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.18644/55.05311. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.25350/54.90650. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.24707/54.87275. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.95864/55.00172. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.22797/54.74645. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.06908/54.85566. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 56.02866/54.78893. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.16599/54.86341. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.08046/54.68124. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.73189/54.77364. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.91496/54.86897. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.75718/54.61325. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.94882/54.67871. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.87285/54.67284. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.85931/54.68459. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.77001/54.57810. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.91933/54.58628. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.82727/54.54025. Took 0.32 sec\n",
      "ACC: 0.609375, MCC: 0.11090600481944489\n",
      "Epoch 0, Loss(train/val) 71.71318/71.17220. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.35380/71.01038. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.03836/70.84458. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.67699/70.67859. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.34452/70.51468. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.96200/70.34556. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.58440/70.16744. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.14356/69.97681. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.59755/69.77757. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.15329/69.58021. Took 0.34 sec\n",
      "Epoch 10, Loss(train/val) 67.56459/69.38530. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.05062/69.17437. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.62948/68.94871. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.16965/68.71458. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.56024/68.46002. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.10395/68.18489. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.58939/67.89565. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.11596/67.57560. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 63.63672/67.24838. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.99320/66.90932. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.45584/66.57363. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.05053/66.28062. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.65675/66.02296. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.26577/65.78001. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 61.12045/65.55707. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 60.93171/65.35303. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.59601/65.18806. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.52096/65.03195. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.35817/64.91378. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.13291/64.81523. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.12930/64.73945. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 59.96085/64.68052. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 59.80823/64.63454. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 59.70605/64.57990. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.55261/64.52644. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.32907/64.47380. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.25977/64.39452. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.32903/64.33332. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 59.20901/64.28088. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.96237/64.19359. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.78822/64.09617. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 58.86352/64.02615. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.73682/63.96331. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 58.79231/63.92051. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 58.42842/63.89413. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 58.40385/63.85328. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.32617/63.80651. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.20973/63.75209. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.18493/63.70831. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.25573/63.67272. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 57.98968/63.61328. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 57.93165/63.59204. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 57.99604/63.57576. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 57.90026/63.58279. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.73141/63.58040. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 57.94577/63.56846. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.76840/63.55062. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 57.73243/63.53524. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.53167/63.52813. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.46741/63.51934. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.47105/63.50140. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 57.42950/63.46407. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.40402/63.44851. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 57.40599/63.44796. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 57.16502/63.41927. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.21852/63.41225. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.23678/63.39091. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.33379/63.36909. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.11176/63.34386. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.23062/63.31937. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.24169/63.31578. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 56.96005/63.30921. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.15892/63.28040. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 57.19023/63.26497. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.88955/63.24245. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.91213/63.21563. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.97475/63.19976. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.93616/63.16585. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.88344/63.15487. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 56.80893/63.14253. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 56.90841/63.10416. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.71637/63.07126. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.92929/63.04958. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.79087/63.02032. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.67792/62.99077. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.63376/62.95300. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.81959/62.92249. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.51654/62.88808. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.89297/62.85205. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.58194/62.82137. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.71372/62.79999. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.59647/62.77598. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 56.31146/62.76044. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.51448/62.73322. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.50020/62.71737. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.63169/62.72095. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.55488/62.71019. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.40939/62.69738. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 56.35529/62.70138. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 56.25430/62.70265. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: -0.007040915115573488\n",
      "Epoch 0, Loss(train/val) 70.90710/71.33907. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.75151/71.18307. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.60493/71.02348. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.43797/70.85780. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.27105/70.67400. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.07835/70.46978. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.88300/70.23207. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.67226/69.96500. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.35716/69.66691. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.03056/69.34755. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.73812/69.01975. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.38042/68.69428. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.06387/68.36526. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.56708/68.02020. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.27674/67.64291. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.71494/67.20083. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.06278/66.63021. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.52889/65.90816. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.68315/65.12485. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 64.13619/64.48637. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.77203/64.09258. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.25126/63.83702. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.01570/63.63890. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.84914/63.46941. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.88012/63.30294. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.71245/63.16380. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.52602/63.03156. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.38281/62.89769. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.32736/62.77306. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.19821/62.64480. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.10182/62.52197. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.97084/62.39734. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.96421/62.28405. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.74511/62.15828. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.59399/62.04624. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.59918/61.93567. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.46308/61.83063. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.31354/61.71630. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 61.39273/61.60780. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.28302/61.48185. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 61.21406/61.33270. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.09326/61.21417. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.92287/61.10178. Took 0.34 sec\n",
      "Epoch 43, Loss(train/val) 60.93170/60.96988. Took 0.34 sec\n",
      "Epoch 44, Loss(train/val) 60.99013/60.84626. Took 0.34 sec\n",
      "Epoch 45, Loss(train/val) 60.65174/60.72425. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.45226/60.59038. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.49148/60.45237. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.29590/60.29153. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.27238/60.14685. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.11669/60.02518. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.99235/59.84906. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.94008/59.69627. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.79203/59.54552. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.73194/59.38200. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 59.49769/59.23462. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.60285/59.10276. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.32870/58.97228. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.26060/58.81927. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 59.13578/58.68122. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.12257/58.54501. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.85588/58.41179. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.96019/58.26391. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.82886/58.13638. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.68734/57.99942. Took 0.34 sec\n",
      "Epoch 65, Loss(train/val) 58.53523/57.82726. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.38900/57.68399. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.24293/57.56050. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.29276/57.38056. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.31107/57.23345. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.07364/57.12046. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.02283/56.99377. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.76577/56.84953. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 57.79013/56.81812. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.59959/56.70449. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.45545/56.61269. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.54611/56.49783. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 57.34351/56.33511. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.22523/56.42171. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 57.28307/56.22127. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 57.09881/56.16687. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 57.10638/56.07839. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.98779/56.03485. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.95288/55.86677. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.74990/55.95216. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.62327/55.92242. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.75927/55.75642. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.76766/55.77786. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.39969/55.64588. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 56.62736/55.77376. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.45044/55.54161. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.37120/55.75413. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.31911/55.44595. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.23162/55.51925. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 56.14563/55.65440. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.10266/55.44522. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 56.10564/55.36656. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 56.09869/55.59157. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 56.07158/55.39497. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.83959/55.36696. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.11056588493219922\n",
      "Epoch 0, Loss(train/val) 70.90777/70.74674. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.59288/70.54123. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.27095/70.32583. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.91661/70.08617. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.55228/69.82759. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.17220/69.53889. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.69935/69.19162. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.24258/68.76103. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.66843/68.23082. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 66.95859/67.61319. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.20508/66.93556. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.38575/66.22486. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 64.57307/65.52815. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 63.98913/64.88362. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 63.24716/64.33181. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 62.71300/63.87232. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 62.37755/63.48223. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 61.89892/63.15059. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 61.48499/62.85641. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 61.15515/62.58629. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 60.85629/62.35659. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 60.56935/62.12610. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 60.44923/61.96675. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 60.30449/61.85524. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 60.13472/61.74464. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 60.08040/61.64134. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 59.96399/61.57070. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 59.86975/61.50123. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 59.84488/61.42656. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 59.56449/61.37526. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.74079/61.31432. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 59.69282/61.26843. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.19798/61.18973. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 59.21789/61.16438. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.47022/61.11221. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.13217/61.06247. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.20306/61.03223. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 59.15445/60.99280. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.02023/60.94500. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 59.08219/60.92363. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.73528/60.85888. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 58.93681/60.80682. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.95998/60.77586. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 58.82046/60.70850. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.67366/60.67730. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 58.67743/60.63126. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.64585/60.59724. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.52612/60.51054. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.80056/60.45100. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.54760/60.39154. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.18524/60.34210. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.92910/60.25854. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.75141/60.21639. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 57.67040/60.16200. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.54918/60.06921. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 57.29496/60.09645. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.34569/60.05273. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 57.03577/60.00617. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 56.94426/59.95377. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 56.85692/59.92130. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 56.80269/59.86402. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 56.66886/59.79019. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 56.68308/59.78596. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 56.84551/59.68799. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.51975/59.67127. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.48787/59.60347. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 56.56531/59.61978. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 56.40424/59.51995. Took 0.34 sec\n",
      "Epoch 68, Loss(train/val) 56.33030/59.54737. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 56.20272/59.50198. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 56.26380/59.47985. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 56.14239/59.45052. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 56.21404/59.39384. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.05636/59.39189. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 55.97229/59.39093. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.03249/59.33286. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 55.94439/59.33915. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.23997/59.27920. Took 0.34 sec\n",
      "Epoch 78, Loss(train/val) 55.85010/59.28339. Took 0.34 sec\n",
      "Epoch 79, Loss(train/val) 55.84066/59.27955. Took 0.34 sec\n",
      "Epoch 80, Loss(train/val) 55.87727/59.21286. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 55.92854/59.24781. Took 0.34 sec\n",
      "Epoch 82, Loss(train/val) 55.88316/59.18091. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 55.78729/59.20939. Took 0.34 sec\n",
      "Epoch 84, Loss(train/val) 55.67356/59.18469. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 55.82090/59.17223. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 55.91928/59.16429. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 55.82066/59.14293. Took 0.34 sec\n",
      "Epoch 88, Loss(train/val) 55.50059/59.11566. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 55.67726/59.12584. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 55.53161/59.11328. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 55.51885/59.08620. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 55.26881/59.07818. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 55.50684/59.05997. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.28585/59.05347. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.36928/59.06136. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.33138/59.01697. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.49560/58.99870. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.20479/58.99912. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.22474/58.99440. Took 0.32 sec\n",
      "ACC: 0.359375, MCC: -0.16921000399116268\n",
      "Epoch 0, Loss(train/val) 70.77037/70.29870. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.43466/70.10054. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.07314/69.88636. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.65398/69.64523. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.29173/69.38109. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.88123/69.08667. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.37870/68.77155. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.93662/68.47043. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.46335/68.18732. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.84379/67.93401. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.30572/67.70886. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.72441/67.50819. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.14793/67.31971. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 64.67593/67.12331. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 64.14685/66.91770. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.75739/66.69290. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.40894/66.44485. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.85699/66.17616. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 62.60149/65.88150. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.35780/65.56496. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 61.89808/65.23883. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.61389/64.93611. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.51690/64.66329. Took 0.34 sec\n",
      "Epoch 23, Loss(train/val) 61.21889/64.41962. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 60.75421/64.18699. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 60.63768/63.96625. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.30376/63.75234. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.14680/63.54167. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.00033/63.33696. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.85011/63.15320. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 59.65215/62.99871. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.39413/62.84423. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.46933/62.70446. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.38453/62.59801. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.29708/62.47990. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.31159/62.38541. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.00402/62.31253. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.03651/62.19400. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 58.74836/62.08125. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.82511/61.93941. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 58.53971/61.81371. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.47011/61.55839. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 58.44313/61.27184. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.31496/60.99903. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 57.93531/60.81460. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.76635/60.61173. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 57.65611/60.31365. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.38418/59.04167. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 57.58645/61.35470. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.84023/60.50148. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 57.18668/60.25413. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.21759/58.54551. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.28079/61.05471. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.22940/58.37410. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 56.86268/60.25199. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 56.77505/59.40589. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 56.53234/59.30933. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 56.20886/58.97908. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 56.19688/59.62393. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 56.18819/58.37460. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 56.41445/60.53669. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 56.28481/58.41467. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 55.62057/58.64309. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 55.40180/58.91515. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 55.48965/59.41083. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 55.65983/57.76764. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 55.54231/57.81566. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 55.83692/59.23160. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 55.14004/58.59189. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 55.01464/57.64386. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 55.26992/57.78688. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 54.73215/57.55620. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 54.62416/57.62920. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 54.65558/57.84066. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 54.92609/58.20322. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 54.77100/57.71218. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 55.35901/59.23064. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 54.67494/57.02692. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 54.64545/57.10690. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 54.60887/58.50730. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 54.58460/57.15673. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 54.11052/57.06742. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 54.33453/57.87142. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 54.03761/57.66658. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 53.93396/57.05283. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 53.82270/57.32507. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 53.92574/57.35381. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 53.74832/57.24572. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 53.89666/57.44591. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 54.08705/57.32239. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 53.53124/56.58595. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 54.01731/57.40820. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 53.48888/57.19131. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 53.48800/56.45787. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 53.48449/56.82021. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 53.41532/57.01065. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 53.35655/56.96301. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 53.20998/57.10392. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 53.32426/56.97855. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 53.03118/56.15010. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.05419820128296849\n",
      "Epoch 0, Loss(train/val) 70.51335/70.14632. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.29181/70.02372. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.12633/69.89378. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.86487/69.75158. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.64078/69.60036. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.36976/69.42802. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.12955/69.24660. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.83685/69.03952. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.51179/68.81503. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.18586/68.57935. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.80738/68.33156. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.40979/68.07803. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.17513/67.82262. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.74602/67.56750. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.46848/67.30080. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.13883/67.02004. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.90705/66.72138. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.54258/66.40984. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.20036/66.08809. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.97761/65.74072. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.70151/65.44068. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.33226/65.19914. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.02167/64.98306. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.89192/64.78954. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.67799/64.61608. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.54267/64.46187. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.49633/64.31667. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.34855/64.18729. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.15356/64.05717. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.00339/63.93721. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.98239/63.81208. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.01007/63.66802. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.89489/63.49918. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.64809/63.31401. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.59378/63.15277. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.43655/62.96904. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.42594/62.76001. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.26064/62.53052. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.37157/62.29790. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.13310/62.09468. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.03467/61.91006. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.84214/61.73006. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.86006/61.54586. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.72081/61.35181. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.76246/61.16687. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.63768/60.97123. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.48213/60.76595. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.34188/60.56503. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.28520/60.36821. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.28519/60.18616. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.10850/60.03127. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.02269/59.89093. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.94413/59.73549. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.90829/59.61257. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.99799/59.48325. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.80164/59.35268. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.64991/59.25570. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.73598/59.16642. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.52236/59.08056. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.54832/59.00169. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.43548/58.95275. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.61289/58.92498. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.32195/58.84330. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.36516/58.82028. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.15624/58.76958. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.16540/58.68741. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.30461/58.67519. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.19493/58.60659. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.93772/58.63081. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.01220/58.54574. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.83081/58.39408. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.79290/58.42474. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.91510/58.34157. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.83391/58.43806. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.66208/58.22930. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.80816/58.25548. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 59.79409/58.19600. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.80330/58.22202. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.82289/58.14813. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.60670/58.22397. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.32953/57.98359. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.57472/58.13675. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.36369/57.85963. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.36188/57.80780. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.37790/57.84426. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.22995/57.69612. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.31597/57.76571. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.39748/57.58260. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 59.14292/57.68166. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.95629/57.69686. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.94449/57.75181. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.81650/57.71129. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.92205/57.84808. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.95606/57.86676. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.88480/57.74711. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.80800/57.54971. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 58.70561/57.43457. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.61449/57.38461. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.61655/57.18538. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.66426/57.16876. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.05567963265232692\n",
      "Epoch 0, Loss(train/val) 70.65523/71.40247. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.41648/71.13625. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.13526/70.86256. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.83301/70.58195. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.57439/70.28592. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.26852/69.96651. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.94862/69.62959. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.57689/69.26643. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.17374/68.87521. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.83510/68.45433. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 67.39096/67.99569. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.05762/67.50776. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.48506/66.97791. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.03172/66.41342. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.61280/65.83353. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.13289/65.20514. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.58587/64.52434. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.01718/63.78136. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.46673/62.99408. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.87928/62.29176. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.35614/61.74916. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.93291/61.40883. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.69324/61.16024. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 61.49525/60.99553. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 61.03673/60.87671. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 60.84044/60.75577. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.64562/60.60742. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.31528/60.44997. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.19217/60.28744. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 59.88941/60.13125. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.83622/59.98455. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.60936/59.81636. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 59.65191/59.63770. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.27308/59.50495. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.03313/59.36793. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 58.81226/59.22050. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.79100/59.07560. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 58.64113/58.92167. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 58.62593/58.77988. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 58.46291/58.64432. Took 0.30 sec\n",
      "Epoch 40, Loss(train/val) 58.26676/58.49603. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.14332/58.38153. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 58.01568/58.21703. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 57.96593/58.06850. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 57.78609/57.93630. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.46874/57.82477. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 57.41044/57.59184. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.48414/57.61216. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.03973/57.36848. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.09692/57.33394. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 56.99376/57.18354. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 56.67757/56.99704. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 56.72775/56.92897. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 56.51947/56.84856. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 56.39993/56.67908. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 56.36069/56.64388. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 56.19295/56.56818. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 55.97685/56.44384. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 56.09418/56.32743. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 55.96240/56.28765. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 55.90839/56.17142. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 55.72278/56.11273. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 55.51522/55.96053. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 55.58869/55.78086. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 55.45767/55.72858. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 55.23703/55.72263. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 55.12050/55.43820. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 54.99682/55.26965. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 54.87461/54.93224. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 54.69270/54.54569. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 54.49517/54.38163. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 54.18254/54.30756. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 54.05536/54.35369. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 54.11541/54.58550. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 53.80639/54.94918. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 54.13303/54.12532. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 53.69712/53.92303. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 53.44939/54.36137. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 53.40243/53.96837. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 53.18915/53.69777. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 52.96612/54.05993. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 53.10217/54.07178. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 53.20928/53.64977. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 53.03821/53.52251. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 53.25302/53.29189. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 52.90545/53.84187. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 52.89457/53.41385. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 52.93418/53.19115. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 52.65409/53.56343. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 52.41038/53.13760. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 52.48872/53.08642. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 52.05726/53.00209. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 52.30434/53.02436. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 52.15402/52.93733. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 51.95676/52.76832. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 51.89367/53.06395. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 51.97971/52.80297. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 51.78127/52.77894. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 51.75721/52.75782. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 51.87424/52.64675. Took 0.32 sec\n",
      "ACC: 0.40625, MCC: -0.1773241389867146\n",
      "Epoch 0, Loss(train/val) 70.39844/70.37541. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.21837/70.27367. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.04931/70.18879. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.90542/70.11845. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.83344/70.05976. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.69868/69.99505. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.50509/69.94440. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.29044/69.90530. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.18380/69.86877. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.03867/69.83722. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.88248/69.79339. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.75569/69.74085. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.59833/69.68037. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.40473/69.61706. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.29855/69.55501. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 68.14945/69.49638. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.03595/69.43412. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.93012/69.37479. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 67.77772/69.31586. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.69492/69.25971. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.61112/69.19275. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.46385/69.13455. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.35398/69.06687. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.24678/68.98901. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 67.13561/68.90856. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 67.09148/68.81698. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 67.04004/68.73875. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.87917/68.64213. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.86260/68.53048. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.72654/68.43251. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.62938/68.34579. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 66.46239/68.25536. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 66.45162/68.16226. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 66.33047/68.08120. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 66.25400/67.99629. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 66.23429/67.91123. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 66.02842/67.82648. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 66.01805/67.72086. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 65.88102/67.65424. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 65.79792/67.59727. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 65.71211/67.49914. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 65.63681/67.41501. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 65.62530/67.35278. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 65.52032/67.28616. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 65.36931/67.23211. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 65.44606/67.17503. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 65.23361/67.11859. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 65.12824/67.05514. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 65.09853/66.98358. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 65.09809/66.92811. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 64.98716/66.86241. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 64.88393/66.77983. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 64.92011/66.73869. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 64.68377/66.69789. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 64.76440/66.64538. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 64.56131/66.59241. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 64.50960/66.52860. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 64.47507/66.44443. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 64.47715/66.38853. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 64.33856/66.29245. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 64.25581/66.18063. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 64.24497/66.05607. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.88760/65.94529. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 64.02342/65.85293. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.78218/65.78322. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.67445/65.73980. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 63.68114/65.65488. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 63.53193/65.59097. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 63.41609/65.52090. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 63.27919/65.46687. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 63.15959/65.33688. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 63.10303/65.31389. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.85542/65.31323. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.74799/65.16293. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.64001/65.06687. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.58444/65.14187. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.56988/64.99915. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 62.33562/64.97453. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 62.28330/64.97229. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 62.13583/65.02451. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.08698/64.77650. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.23832/64.94682. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.75180/64.83758. Took 0.30 sec\n",
      "Epoch 83, Loss(train/val) 61.88470/64.80921. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.76822/64.92236. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.79750/64.66984. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.44842/64.71764. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.40764/64.89384. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.22754/64.80734. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.33220/64.80529. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.25348/64.38909. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.58855/63.87692. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 61.24648/65.00811. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 61.23076/64.86913. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 61.33827/64.79079. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 61.33116/64.13395. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.05978/65.02031. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 61.22754/64.66843. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.80212/65.08415. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 60.75588/64.79016. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: 0.041824288840651425\n",
      "Epoch 0, Loss(train/val) 70.29721/71.10760. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.01494/70.91618. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.78520/70.74400. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 69.55395/70.57235. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.30870/70.40289. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.11751/70.23193. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.80870/70.06186. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 68.53890/69.91222. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.29449/69.77798. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.13346/69.65552. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.82156/69.53017. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.50439/69.41160. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.31471/69.29426. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.05345/69.17228. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.72001/69.04484. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.31168/68.91859. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.02057/68.79076. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 65.78984/68.67261. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.44198/68.56123. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.18301/68.45941. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 64.98430/68.35912. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.70064/68.25970. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.50070/68.18063. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.38181/68.11896. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.18680/68.07084. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.04066/68.03674. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.97925/68.00557. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.81054/68.00132. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.79139/68.01539. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 63.61729/68.03004. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.48351/68.03558. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.49475/68.05862. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 63.40120/68.08215. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.34321/68.10464. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.23160/68.12132. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 63.14982/68.13743. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.13146/68.15469. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.08339/68.16290. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.99112/68.18005. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.02691/68.18579. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 63.00129/68.18081. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.82277/68.17071. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.82721/68.15906. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.65516/68.14288. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.76943/68.13293. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.73014/68.12214. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.47420/68.11230. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.63333/68.08745. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.50687/68.05230. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.49505/68.03342. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.40613/68.01199. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.36827/67.98802. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 62.29066/67.93275. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.21668/67.88255. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 62.09001/67.84793. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.01575/67.80128. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.96700/67.76051. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.91409/67.72784. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 61.75032/67.69765. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 61.67895/67.63715. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.72049/67.58773. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 61.54795/67.55736. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.43538/67.62542. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.27430/67.64346. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.39108/67.74886. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 61.41337/67.63171. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.16893/67.59901. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.14786/67.54525. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.95923/67.51941. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.02842/67.45774. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.89608/67.46393. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 61.01319/67.47294. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.84265/67.47021. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.68396/67.46064. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.81044/67.44722. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.71876/67.43983. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.79331/67.43555. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.57613/67.40842. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.65172/67.38116. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 60.47052/67.33591. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.55607/67.31761. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.37845/67.31384. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 60.33709/67.29240. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.31784/67.26212. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.35577/67.23386. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.21377/67.22444. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.15495/67.21365. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.06475/67.17091. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.13336/67.11407. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.96736/67.09603. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.95068/67.07886. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.00334/67.07030. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.82066/67.03765. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 59.82634/67.01634. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.91732/66.98127. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.72071/66.96235. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.70423/66.94939. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 59.55472/66.93458. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.68374/66.92323. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.60532/66.91341. Took 0.31 sec\n",
      "ACC: 0.484375, MCC: 0.06527939662729701\n",
      "Epoch 0, Loss(train/val) 70.46485/70.31602. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.15587/70.05998. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.90284/69.78751. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.56985/69.48935. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.19440/69.13884. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.76639/68.72577. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.27939/68.21570. Took 0.30 sec\n",
      "Epoch 7, Loss(train/val) 67.71344/67.61572. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.11842/66.95667. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.59633/66.31253. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.08537/65.73836. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.51121/65.24858. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.07715/64.84251. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 64.63730/64.49764. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.35059/64.19980. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.94383/63.93541. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.45698/63.69020. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.23734/63.46419. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.68783/63.25584. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.32642/63.06228. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.07259/62.94203. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 61.83733/62.83319. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.37345/62.72269. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.13442/62.61623. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.92411/62.51200. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 60.83418/62.41952. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.68212/62.33951. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.71832/62.26530. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.42235/62.19391. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.49960/62.13057. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.33432/62.06571. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 60.48196/61.99163. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 60.16737/61.93111. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.13208/61.87052. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 60.09350/61.82025. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.12334/61.74387. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.05891/61.68620. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.91186/61.65072. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.82652/61.58775. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.91043/61.58156. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.68293/61.50764. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 59.75280/61.45274. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.70680/61.44463. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.64470/61.39896. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.42404/61.35970. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.38061/61.30249. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.51274/61.25465. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.30877/61.25943. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.31008/61.20446. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.31195/61.17075. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.26119/61.13974. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.25201/61.11308. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.27606/61.10735. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.07567/61.06670. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.25808/61.03546. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.09604/61.02832. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.96094/61.00604. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.99883/60.97515. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 58.90165/60.95584. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.96305/60.94196. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.09514/60.91515. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.80351/60.90096. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.80114/60.88904. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.83191/60.88306. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.72262/60.85743. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.87157/60.83423. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.70470/60.81191. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 58.84230/60.79670. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 58.64232/60.78003. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 58.53787/60.77393. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.62428/60.76168. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.64311/60.75993. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.54524/60.76193. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.68993/60.74052. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.57472/60.72325. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.60491/60.72132. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.68272/60.68792. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.41601/60.76884. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.50998/60.66071. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.49234/60.66936. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.41021/60.66652. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 58.42248/60.64848. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.28382/60.62463. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 58.26941/60.69657. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.32921/60.60323. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.31343/60.64163. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.33869/60.60631. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.34822/60.63748. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.31947/60.60135. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 58.36246/60.61511. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.32269/60.56364. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.25119/60.59095. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.22951/60.55178. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.01133/60.53629. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.28592/60.53310. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.20642/60.50345. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.15404/60.53636. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.20606/60.53357. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.17167/60.49562. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.10923/60.50908. Took 0.32 sec\n",
      "ACC: 0.34375, MCC: -0.2742268345774339\n",
      "Epoch 0, Loss(train/val) 70.86225/70.56342. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.71905/70.48364. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.57615/70.40397. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.47216/70.32413. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.33653/70.24188. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.23275/70.15777. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.06968/70.06359. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.92184/69.96339. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.79223/69.85748. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.66753/69.74240. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.40065/69.61092. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.21861/69.46390. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.98109/69.29827. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.71042/69.11482. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.46346/68.91815. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 68.17200/68.70054. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.98978/68.46615. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.64258/68.22675. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.39595/67.97749. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.15841/67.71199. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.88883/67.41964. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 66.66903/67.09505. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 66.55964/66.74178. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.30190/66.37027. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.03486/65.96493. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.78484/65.54686. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 65.59371/65.14961. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 65.29644/64.77004. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 65.08811/64.46603. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 64.86504/64.25067. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.85845/64.16366. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 64.68731/64.10053. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.58610/64.05572. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 64.45692/64.02366. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.23459/64.00024. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.14338/63.98304. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 64.12385/63.96561. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.95065/63.96772. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 63.85833/63.96992. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.76016/63.96553. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.68580/63.94732. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.53493/63.91920. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.62234/63.88735. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.36355/63.85266. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.24680/63.80392. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.26427/63.74619. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.17338/63.69381. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.96140/63.62722. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.88164/63.53935. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.72410/63.46976. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.56153/63.38509. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.41008/63.31174. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.32236/63.25368. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.95573/63.17925. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.85437/63.10648. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.69150/63.04356. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.44677/62.98791. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.25479/62.97206. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.13344/62.91939. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.99721/62.86773. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.73012/62.80183. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.69924/62.69519. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.56047/62.59311. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.35103/62.60347. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.12708/62.54597. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.15044/62.50138. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.96787/62.52146. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.80183/62.37770. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.60638/62.42385. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.54613/62.38064. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.53365/62.28930. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.27076/62.25079. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.32485/62.16174. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.27642/62.25761. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.16034/62.22765. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.85045/62.29108. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 58.87042/62.32963. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.92663/62.23173. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.73435/62.39354. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.57697/62.46071. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.60539/62.55572. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.37830/62.48043. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.30722/62.39820. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.17198/62.54580. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.06460/62.79338. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.96512/63.08121. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.93606/63.10541. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.73520/63.04750. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.30080/62.99950. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.29352/63.02893. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.37885/63.02217. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.05820/63.07875. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.28161/62.95293. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.70604/62.13448. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.59464/63.34878. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 57.06086/62.74838. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.91917/63.02295. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 56.86986/62.92513. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.74106/62.95304. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 56.75396/62.92770. Took 0.33 sec\n",
      "ACC: 0.59375, MCC: 0.1807753815155468\n",
      "Epoch 0, Loss(train/val) 70.72547/70.55259. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.53756/70.45523. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.40082/70.36155. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.28692/70.27149. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.16553/70.17777. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.04378/70.08098. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.83551/69.97282. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.68838/69.84563. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.56400/69.70054. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.30193/69.52293. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.07322/69.29973. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.84975/69.03500. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.56735/68.70889. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.23948/68.33120. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.80408/67.93230. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.36345/67.58648. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.96289/67.36848. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.83701/67.20195. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.45896/67.06381. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.33604/66.94846. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.03515/66.84019. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.14583/66.74943. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.88202/66.67234. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.81467/66.59510. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.71350/66.52197. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.70305/66.45531. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 65.48588/66.38477. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.51877/66.31606. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 65.31560/66.25549. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.25814/66.18995. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.03302/66.12838. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.04763/66.07132. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.94674/66.01736. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.86847/65.95721. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 64.69381/65.90406. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.69304/65.85517. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.66344/65.80280. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.42515/65.74361. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.27812/65.69632. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 64.29141/65.63949. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.26528/65.56812. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 64.18580/65.51358. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 64.18323/65.46767. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 63.95194/65.41410. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.90486/65.37325. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 63.89020/65.37057. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.74018/65.33310. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 63.56676/65.31866. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.43925/65.28760. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.63133/65.27255. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.43969/65.31051. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 63.35855/65.27570. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.28307/65.24590. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 63.36765/65.23583. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.28917/65.23872. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.21974/65.26848. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.20210/65.25021. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 63.15854/65.26539. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.94889/65.28471. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.98738/65.20575. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 62.99003/65.17228. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.96444/65.14258. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.58871/65.03195. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.74306/64.86865. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.77104/64.85702. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.54825/64.78939. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 62.40246/64.75214. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.64652/64.63120. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 62.46868/64.58379. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.40277/64.51417. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.26583/64.47210. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.38850/64.38764. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.09116/64.37646. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 62.29470/64.26299. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.11047/64.34700. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 61.88703/64.12605. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.96548/64.44925. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.92285/63.99947. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.09532/64.43345. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.92545/64.00464. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.84772/64.12527. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.00369/63.90466. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 61.81603/64.10214. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.82767/63.80851. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 61.74951/64.14244. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.72652/63.69839. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.60127/64.04534. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.56918/63.67555. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 61.75863/63.89785. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.62591/63.61111. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 61.38374/63.77997. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.58602/63.57004. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 61.47296/63.64049. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.42058/63.53563. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 61.42182/63.58698. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.43061/63.48602. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 61.30731/63.53831. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.24696/63.43462. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.16378/63.47496. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.16621/63.38593. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.07559289460184544\n",
      "Epoch 0, Loss(train/val) 70.92745/71.64680. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.76198/71.53409. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.57362/71.41632. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.40854/71.28908. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.18437/71.14934. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.06630/70.99200. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.85805/70.80489. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.60798/70.59686. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.38134/70.36212. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.12762/70.10098. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.80751/69.81382. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.57740/69.50400. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.19855/69.16847. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.89050/68.82024. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.52807/68.46761. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 67.15469/68.11356. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.74042/67.78219. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.48867/67.48354. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.14898/67.21989. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 65.84615/66.98451. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.50610/66.76897. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.23045/66.54316. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.87056/66.30616. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.70690/66.03062. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.47143/65.71142. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.04279/65.35890. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.87516/64.97211. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.64887/64.57108. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.21428/64.19249. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 63.11853/63.93178. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.04309/63.66139. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.88518/63.47385. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.82165/63.28326. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.76419/63.11972. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.52017/63.06421. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.42931/63.04060. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.31943/62.98031. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.15280/62.96981. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.15469/62.95381. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.95876/62.93420. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.96173/62.91766. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.09297/62.97228. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 61.78774/62.88848. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.66208/62.95288. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.64041/62.93144. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.65677/62.88313. Took 0.34 sec\n",
      "Epoch 46, Loss(train/val) 61.55483/62.89660. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.43599/62.89078. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.36321/62.95919. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.40147/63.04520. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.40252/63.01120. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.29365/62.97721. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.24999/63.01137. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.15933/62.99350. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.04584/62.99104. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.00957/63.03053. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.04371/63.03815. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.01579/62.98750. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.05617/63.00370. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.93535/63.07927. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.77634/63.05116. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.72441/63.04249. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.84617/63.03900. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.73530/63.05462. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.75656/63.08409. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.74749/63.08198. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.63932/63.08372. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.57320/63.10163. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.63476/63.06592. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.54994/63.13135. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.59649/63.14872. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.47265/63.17408. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.48286/63.18719. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.48597/63.18709. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.37577/63.21709. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.22775/63.23611. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.26363/63.22421. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.16965/63.26487. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.20979/63.29116. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.30723/63.28611. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.17491/63.29881. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.16212/63.30307. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.19128/63.33329. Took 0.34 sec\n",
      "Epoch 83, Loss(train/val) 60.10022/63.38554. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.96422/63.39977. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 60.02997/63.42512. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.08775/63.42541. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.72871/63.43300. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.11105/63.41273. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.86352/63.44434. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.83572/63.48645. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.85279/63.45797. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.79268/63.50354. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.82251/63.52430. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.57980/63.55952. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.61690/63.57676. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.68015/63.56884. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.60626/63.62228. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.71427/63.62988. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.59926/63.63801. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.0686780908582235\n",
      "Epoch 0, Loss(train/val) 70.63194/69.82121. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.35192/69.50747. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.05637/69.19894. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.77435/68.89436. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.50700/68.59660. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.19461/68.29948. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.89635/67.99985. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.63832/67.69559. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.27851/67.38230. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.98284/67.06017. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.71404/66.72858. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.34692/66.37743. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.94908/66.00173. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.54331/65.59256. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.30595/65.15848. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.87968/64.68382. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.30355/64.16246. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 64.97439/63.60910. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.41033/63.04339. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.02740/62.50672. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.42789/62.02563. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 62.96809/61.62020. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.77092/61.29117. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.36872/61.02763. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.14198/60.83808. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.80657/60.71293. Took 0.30 sec\n",
      "Epoch 26, Loss(train/val) 61.49055/60.63265. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.50861/60.58502. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.17502/60.56444. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.18399/60.56185. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.95900/60.57763. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.67442/60.58804. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.68737/60.60028. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.53609/60.60905. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.32285/60.61456. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.15101/60.61665. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 60.21473/60.61869. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 59.98907/60.61493. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.06061/60.60623. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.09332/60.59848. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.88442/60.58507. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.72107/60.57239. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 59.67212/60.55378. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.71584/60.53634. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.70151/60.51694. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.46261/60.49829. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 59.54391/60.47443. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.48620/60.44705. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.35413/60.41578. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.33465/60.38006. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.33120/60.34383. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.35619/60.30072. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.22618/60.25797. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.27494/60.22242. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.06692/60.17955. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.08727/60.10232. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 58.84704/60.06713. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.04123/60.02916. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.91455/60.01870. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.80347/59.88859. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.63643/59.88272. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.47973/59.88691. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.49126/59.82584. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.44865/59.76284. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.44184/59.66390. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.47228/59.67056. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.43843/59.75819. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.36259/59.55521. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.15131/59.56663. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.21472/59.55115. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.09039/59.60315. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.99844/59.48485. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.08235/59.42080. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.04897/59.52089. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.93782/59.42772. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.95208/59.44353. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.95778/59.41213. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.88199/59.37527. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.86337/59.25512. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.59054/59.49598. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.78339/59.15585. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.71382/59.41336. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.73938/59.24238. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.58667/59.23295. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.58359/59.20017. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.56569/59.39180. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 57.67847/59.20212. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.61601/59.14546. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 57.63065/59.14381. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.44949/59.16283. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 57.39294/59.15059. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 57.57552/59.16848. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.53106/59.21683. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 57.34419/59.13344. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.33414/59.03046. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.18748/59.10374. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.27921/59.00549. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.30211/58.93349. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.10102/59.08952. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.24441/58.84424. Took 0.33 sec\n",
      "ACC: 0.5, MCC: 0.0820624619694061\n",
      "Epoch 0, Loss(train/val) 71.24471/71.22636. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.05288/71.10642. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.88392/70.99169. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.79287/70.87727. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.69428/70.76817. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.59241/70.66242. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.47454/70.56210. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.41765/70.46105. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 70.31449/70.35825. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 70.20168/70.25245. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 70.10266/70.14733. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 70.01188/70.03944. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.95194/69.92535. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 69.81685/69.80784. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.65749/69.68891. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.61103/69.57139. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 69.46093/69.46122. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 69.46553/69.35361. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 69.27920/69.24828. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 69.19702/69.14542. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 69.05300/69.04747. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 68.97147/68.94868. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 68.87527/68.85489. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 68.73004/68.75521. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 68.64928/68.64922. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 68.59007/68.53888. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 68.52777/68.43507. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 68.29860/68.33528. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 68.29188/68.23477. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 68.11879/68.13698. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 67.93991/68.03435. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 67.94137/67.93612. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 67.72960/67.84222. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 67.73371/67.75803. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 67.48389/67.68124. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 67.33955/67.60767. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 67.20361/67.53101. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 67.07179/67.45356. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 66.87921/67.36392. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 66.79076/67.27748. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 66.60482/67.18478. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 66.44399/67.09537. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 66.28614/67.00143. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 66.18570/66.90761. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 65.98087/66.83434. Took 0.34 sec\n",
      "Epoch 45, Loss(train/val) 65.68425/66.76612. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 65.67573/66.72637. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 65.38259/66.71617. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 65.34081/66.72252. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 65.25982/66.73682. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 65.06400/66.78272. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 65.04175/66.83936. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 64.77777/66.86687. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 64.67824/66.89213. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 64.63531/66.95230. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 64.41086/66.98882. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 64.40443/66.99921. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 64.26822/67.00813. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 64.39359/67.01138. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 64.12766/66.99317. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 64.21036/66.97507. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 64.05454/66.98354. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 63.91291/66.94305. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.94349/66.94561. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.75326/66.94443. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.84601/66.91296. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 63.65120/66.91742. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 63.67359/66.87058. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 63.72728/66.87388. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 63.53070/66.88646. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 63.51758/66.85825. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 63.52622/66.80792. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 63.48965/66.80563. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 63.42825/66.79840. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 63.46982/66.80009. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 63.36109/66.79688. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 63.21127/66.78427. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 63.27510/66.80524. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 63.29115/66.83878. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 63.03187/66.84429. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 63.13966/66.86208. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 63.23291/66.87633. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 62.99649/66.87170. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 63.09641/66.89283. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 63.18909/66.90282. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 63.01850/66.93559. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 62.72074/66.97519. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 62.81102/67.01320. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 62.81953/67.04947. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 62.77368/67.11614. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 62.69237/67.14277. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 62.77855/67.18687. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 62.67558/67.24938. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 62.67664/67.31439. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 62.61000/67.37081. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 62.58371/67.42716. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 62.71138/67.44161. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 62.59451/67.47559. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 62.49095/67.49287. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 62.34752/67.53230. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.08544439848099883\n",
      "Epoch 0, Loss(train/val) 70.47897/71.22246. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.18119/71.11396. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.90772/70.99252. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.63394/70.85075. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.37846/70.68810. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.06134/70.49662. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.74209/70.26977. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.42457/70.00734. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.00474/69.70175. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.62192/69.34959. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.15977/68.94866. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.73449/68.50131. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.34324/68.00290. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.93466/67.47695. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.58034/66.91684. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.14728/66.35143. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.91562/65.87311. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.75255/65.47368. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.40095/65.13950. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.25806/64.86002. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.19889/64.65024. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.12114/64.47475. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.05971/64.31282. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.92916/64.16978. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.81101/64.03446. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.77830/63.93176. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.56003/63.84981. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.44184/63.77348. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 63.62981/63.73600. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 63.70124/63.75190. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.28860/63.80518. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.27289/63.75384. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.25615/63.71607. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.11011/63.66239. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.05062/63.61243. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.13511/63.67768. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.10378/63.68911. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.90201/63.56843. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.93890/63.52065. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.80542/63.52861. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.94830/63.48104. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.80821/63.50135. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.85092/63.62621. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.57430/63.48112. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.76107/63.38827. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.59216/63.41683. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.54984/63.45581. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.56793/63.56749. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.54571/63.44299. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 62.43726/63.52544. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.31289/63.47636. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 62.36861/63.40619. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.32702/63.42233. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.22828/63.58568. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.22066/63.40040. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.02079/63.28330. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.09253/63.46572. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.98773/63.31038. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.92379/63.25869. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.99886/63.29755. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.96298/63.24525. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.83385/63.30236. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.65563/63.46994. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.82689/63.19157. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.67699/63.20065. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.67893/63.27336. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.66539/63.21476. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.61070/63.12717. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 61.54394/63.06766. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.54571/63.09377. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.55777/63.07300. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 61.34007/63.05107. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.29712/63.19762. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.39230/63.03432. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.28149/62.90882. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.27981/62.95419. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.29194/62.91871. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.19345/62.88566. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.23864/63.01774. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 61.20164/62.91900. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.08665/62.80806. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.04257/62.87349. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.16446/62.78663. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.99089/62.72718. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.97143/62.82504. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.10358/62.71515. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.88980/62.70712. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 60.90957/62.64293. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.84911/62.63342. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 60.90213/62.80506. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.93445/62.61857. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.81366/62.62708. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 60.79039/62.60416. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.66378/62.60828. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.82928/62.62032. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.55677/62.59958. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.63668/62.53372. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.64780/62.50232. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.59480/62.50224. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.56023/62.48999. Took 0.33 sec\n",
      "ACC: 0.546875, MCC: 0.11065666703449763\n",
      "Epoch 0, Loss(train/val) 71.23301/70.72882. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.94529/70.57082. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.66090/70.42196. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.47775/70.27669. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.19933/70.13867. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.94881/69.99924. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.73116/69.85636. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.49766/69.70801. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.22157/69.55266. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.93029/69.38760. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.65856/69.20927. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.36879/69.01277. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.08561/68.79314. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.75011/68.54036. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.45804/68.24720. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.11530/67.89627. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.82761/67.48614. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.32347/67.00855. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.83655/66.48106. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.25385/65.90747. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.79208/65.30628. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.20833/64.70088. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.68321/64.10261. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.99866/63.53648. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.40499/63.03030. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 61.85034/62.63159. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.57007/62.33107. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 61.21855/62.10290. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.04816/61.91198. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 60.94915/61.74737. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.86657/61.59781. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.64971/61.45167. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.61063/61.30838. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.28329/61.16384. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.09247/61.03164. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.92932/60.90228. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.87580/60.77356. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.94936/60.64387. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.74694/60.52740. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.53461/60.42442. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 59.34305/60.34867. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.43347/60.24963. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 59.17739/60.11905. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.99326/60.03722. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.07242/59.98412. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.79243/59.94136. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.60980/59.86115. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.71758/59.77812. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.54277/59.70435. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.44169/59.63836. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.42392/59.58280. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.39615/59.52144. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.11638/59.43674. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.24532/59.37561. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.06717/59.33974. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.93279/59.28212. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.80150/59.20467. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 57.83175/59.15412. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.86348/59.08920. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 57.59335/59.02713. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 57.65660/58.96152. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.60072/58.90830. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.67747/58.85336. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.46190/58.78801. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.36021/58.74966. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.26352/58.69517. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.21249/58.58829. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.08399/58.54486. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 56.94191/58.50166. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.06955/58.42146. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 56.91807/58.38566. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.90309/58.32755. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 56.81668/58.28564. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.84103/58.21600. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 56.70918/58.17928. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.72108/58.16274. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.63137/58.12986. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.58919/58.06023. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.44393/58.03268. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.52487/57.97647. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.44978/57.91990. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.40379/57.87402. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.20252/57.88728. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.38106/57.89154. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 56.32185/57.94548. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.35108/57.76224. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.08671/58.01439. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.00208/57.72084. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.92344/57.76303. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.16059/57.78036. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.82908/57.73977. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.85250/57.70803. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 55.82407/57.80149. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 55.74865/57.66204. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.69124/57.69273. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.83540/57.67374. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.54161/57.66078. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.67645/57.72656. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.60780/57.61966. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.50124/57.69780. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.04982728791224399\n",
      "Epoch 0, Loss(train/val) 70.52327/70.55753. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.30227/70.34588. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.10346/70.13448. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.87360/69.93593. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.63813/69.74467. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.43899/69.55514. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.16232/69.38222. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.93947/69.22505. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.67460/69.07928. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.40722/68.96169. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.16548/68.85761. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.91850/68.76250. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.58543/68.65321. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.36493/68.53996. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.00666/68.41386. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.67971/68.27959. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.50222/68.18098. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.12516/68.09078. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.91232/67.99235. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 65.66365/67.88805. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.34571/67.78282. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.18840/67.67252. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.93082/67.55862. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.74661/67.44914. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.45677/67.33327. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.27061/67.21270. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 63.98892/67.09181. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.88041/66.97202. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.69765/66.85880. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.47328/66.74158. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.43319/66.62822. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.13991/66.50235. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.97410/66.37214. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.84571/66.25225. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.82624/66.15136. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.60637/66.05949. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.57314/65.97511. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.52661/65.90934. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.41008/65.84691. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.49529/65.80167. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.52643/65.76805. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.42861/65.74348. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.17640/65.72217. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.09999/65.71126. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.11326/65.69308. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.09184/65.68269. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.96222/65.67480. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.91498/65.65603. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.92680/65.66014. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.86962/65.67146. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.71604/65.68107. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.72550/65.68362. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.75044/65.69981. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.62030/65.69371. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.81653/65.69134. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.56119/65.71994. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.60818/65.75334. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.44022/65.75449. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.39418/65.78932. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.51413/65.81951. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.24686/65.84261. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.17561/65.86819. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.34346/65.91251. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.23292/65.92881. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.10191/65.95899. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.24321/65.99470. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.28708/66.02165. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.19690/66.05293. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.03567/66.05184. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.10622/66.07635. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.15671/66.12056. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.98487/66.11842. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.92759/66.15627. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.01970/66.18140. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.88276/66.18816. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.84356/66.25157. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.82065/66.26778. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.95909/66.31749. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 60.94906/66.37859. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.79816/66.41795. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.63986/66.43431. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.65201/66.48989. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.66291/66.53260. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.56078/66.59261. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.63587/66.62576. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 60.70025/66.59306. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.47057/66.61815. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 60.58587/66.65803. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.28623/66.73297. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 60.40449/66.69366. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.22185/66.78161. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.45949/66.86019. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 60.31686/66.87206. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.38946/66.91656. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.33797/66.98077. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.33927/66.99622. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.35155/67.00908. Took 0.34 sec\n",
      "Epoch 97, Loss(train/val) 60.32276/67.06708. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 60.26621/67.14529. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.07706/67.13945. Took 0.33 sec\n",
      "ACC: 0.609375, MCC: 0.23466315646534902\n",
      "Epoch 0, Loss(train/val) 70.55426/70.82206. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.23957/70.57664. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.85552/70.33105. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.52327/70.06988. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.15435/69.79603. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.77587/69.50857. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.33762/69.20148. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.86599/68.87688. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.40538/68.52792. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.05996/68.15962. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.61315/67.74342. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.19923/67.29453. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 65.84247/66.84233. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.57978/66.36098. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.01642/65.86948. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.76174/65.37127. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.50652/64.86053. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.08725/64.32179. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 63.77428/63.77020. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.42204/63.28991. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.86549/62.83263. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.47711/62.39079. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.23169/61.93769. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.54803/61.48368. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.14824/61.07231. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 60.82681/60.68032. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.65952/60.28615. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 60.27327/59.89315. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 59.93865/59.51217. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.63508/59.24817. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.46909/59.04716. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.28314/58.90894. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.09529/58.79869. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 59.02690/58.71763. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.99713/58.66987. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 58.85202/58.62403. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.63656/58.60706. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.48926/58.56719. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 58.53870/58.57265. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.54522/58.61390. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 58.53586/58.65235. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.37183/58.64895. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 58.25219/58.61594. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 57.94928/58.61348. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 58.02902/58.63442. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.97583/58.68525. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 57.81453/58.73352. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.87015/58.81699. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 57.80913/58.88909. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.52775/58.94089. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 57.41779/59.05189. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.44235/59.10085. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 57.29802/59.13618. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.34808/59.15189. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.19031/59.14986. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 57.14317/59.19211. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 57.06711/59.22682. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 56.83878/59.27644. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 56.90560/59.30137. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 56.68524/59.28188. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 56.68099/59.27746. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 56.74769/59.31157. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 56.43642/59.30718. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 56.49566/59.30283. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 56.53088/59.33570. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 56.30305/59.36809. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 56.39124/59.38044. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 56.15484/59.40867. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 56.12891/59.43845. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 56.02395/59.48723. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.05327/59.49903. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 55.97258/59.50692. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 55.82950/59.55772. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 55.75608/59.66348. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 55.60745/59.69246. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 55.74921/59.71462. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 55.50776/59.70686. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 55.51464/59.77014. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 55.52503/59.83578. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 55.32459/59.88066. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 55.35645/59.93953. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 55.35377/59.98952. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 55.15471/59.96724. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 55.30754/59.94519. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 55.08555/59.98547. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 55.12692/60.04298. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 55.18184/60.01778. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 54.96074/60.09526. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 54.76766/60.06358. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 54.97620/60.12796. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 54.96211/60.18879. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 54.67160/60.10300. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 54.75153/60.20743. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 54.77459/60.13692. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 54.62285/60.10735. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 54.64746/60.20705. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 54.70334/60.18885. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 54.55097/60.20324. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 54.74988/60.06949. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 54.52568/60.11966. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: -0.04592498424680944\n",
      "Epoch 0, Loss(train/val) 70.17234/70.62577. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.97207/70.33075. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.67494/70.04037. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.44767/69.75275. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.22495/69.45662. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.91364/69.15961. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.66824/68.85656. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.44124/68.55383. Took 0.34 sec\n",
      "Epoch 8, Loss(train/val) 68.05641/68.24677. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.80204/67.92903. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.48389/67.60207. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.20952/67.26412. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.93135/66.89263. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.57514/66.51533. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.32800/66.17494. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.03474/65.85770. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.70292/65.52972. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.57979/65.18605. Took 0.34 sec\n",
      "Epoch 18, Loss(train/val) 65.34004/64.84769. Took 0.34 sec\n",
      "Epoch 19, Loss(train/val) 64.98981/64.52236. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 64.84449/64.18861. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.58146/63.85251. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.37851/63.53342. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.13526/63.24384. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.96284/62.96386. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.71408/62.71167. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.64424/62.46730. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.59571/62.24687. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.29229/62.04834. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.22968/61.86618. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 63.06788/61.69775. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.94614/61.54947. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.81793/61.41945. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.86378/61.31816. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.75218/61.24202. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.59639/61.21091. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.55139/61.19309. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.43669/61.18195. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.43248/61.17406. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 62.24476/61.16727. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 62.21240/61.16619. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.09554/61.16734. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.26979/61.17069. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.14190/61.17080. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.16575/61.17081. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.18926/61.16940. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.07487/61.16636. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.98960/61.16602. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.00508/61.16675. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.98544/61.16797. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.91339/61.16820. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.89003/61.16764. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.88738/61.16806. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.79968/61.17198. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.79545/61.17387. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.84378/61.17551. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.68524/61.17853. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.59281/61.18237. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.63915/61.18673. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.57052/61.18898. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.70145/61.19447. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.65878/61.20221. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 61.62119/61.20367. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.64367/61.20592. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.54609/61.20822. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.50037/61.21338. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.68571/61.22090. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.46043/61.22787. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.49773/61.23774. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.43556/61.24710. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.51725/61.25555. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 61.43199/61.26288. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.45254/61.27083. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 61.37453/61.28028. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.50955/61.29298. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 61.51188/61.31092. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 61.19620/61.32462. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 61.22479/61.34236. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.33594/61.36163. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.20966/61.37582. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 61.07899/61.38423. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.17694/61.38662. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 61.20760/61.39015. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 61.14050/61.38686. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 61.06391/61.38685. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.97628/61.38258. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.09307/61.37640. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.03384/61.38956. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 61.01727/61.39764. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.97954/61.40860. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.83391/61.38275. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.88860/61.37427. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.96151/61.42149. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.81413/61.44611. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.69545/61.44600. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 60.75211/61.50113. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.64952/61.51455. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 60.70954/61.46224. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.74082/61.47574. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 60.74281/61.44572. Took 0.32 sec\n",
      "ACC: 0.609375, MCC: 0.11874746116338349\n",
      "Epoch 0, Loss(train/val) 70.98629/71.08096. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.60800/70.81875. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.16196/70.54472. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.78001/70.24749. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.30004/69.91737. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.79503/69.54671. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.27388/69.12295. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.67674/68.62907. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.08628/68.04365. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.32908/67.33384. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.59043/66.44385. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 64.59668/65.37233. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 63.62662/64.22831. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 62.60140/63.26918. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 61.65700/62.62476. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 60.84118/62.24178. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 60.18894/61.97673. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 59.58632/61.82250. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 59.14676/61.68849. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 58.69372/61.58560. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 58.24564/61.49533. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 58.10509/61.40890. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 57.61847/61.32524. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 57.46560/61.25003. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 57.37700/61.18044. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 57.27234/61.12100. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 57.26526/61.06635. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 57.01235/61.02938. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 56.91491/60.98037. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 56.62841/60.92894. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 56.66261/60.87925. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 56.56385/60.84129. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 56.57688/60.81448. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 56.57014/60.79168. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 56.43418/60.76561. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 56.49642/60.73335. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 56.38704/60.71586. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 56.42652/60.69330. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 56.46410/60.67176. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 56.56637/60.65242. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 56.34959/60.64388. Took 0.34 sec\n",
      "Epoch 41, Loss(train/val) 56.18747/60.63023. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 56.36105/60.61480. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 56.30192/60.58666. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 56.10482/60.58171. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 56.14964/60.56914. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 56.21442/60.54787. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 56.05625/60.54242. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 56.11945/60.51622. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 55.96728/60.49692. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 56.07107/60.50230. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 55.99986/60.47456. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 55.92841/60.45118. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 56.04243/60.45535. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 55.89275/60.44014. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 55.97758/60.43000. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 55.75975/60.41400. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 55.77583/60.39830. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 55.70946/60.37735. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 55.80762/60.36159. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 55.83547/60.33148. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 55.77836/60.33209. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 55.70576/60.31912. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 55.73699/60.29623. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 55.72040/60.27813. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 55.72037/60.27184. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 55.77193/60.26743. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 55.59546/60.22985. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 55.71234/60.21129. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 55.47117/60.20674. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 55.44366/60.19704. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 55.61923/60.18214. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 55.45144/60.15194. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 55.40711/60.14082. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 55.46006/60.12505. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 55.45022/60.10572. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 55.39733/60.10069. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 55.36735/60.09705. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 55.46788/60.08255. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 55.32401/60.06882. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 55.48275/60.05560. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 55.36478/60.03997. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 55.39262/60.01939. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 55.40032/60.00240. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 55.38971/59.97528. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.28415/59.95649. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 55.22723/59.94786. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 55.27062/59.92576. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 55.32316/59.91045. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.28408/59.90244. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 55.35337/59.89273. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 55.13875/59.88222. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 55.29982/59.87428. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.04211/59.86363. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.10222/59.85327. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.28158/59.84072. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.24794/59.83322. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.24465/59.82212. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.05452/59.81632. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.06763/59.79038. Took 0.32 sec\n",
      "ACC: 0.5, MCC: -0.05790766725522051\n",
      "Epoch 0, Loss(train/val) 70.89483/70.78152. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.62689/70.64802. Took 0.34 sec\n",
      "Epoch 2, Loss(train/val) 70.41103/70.50752. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.15341/70.36174. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.91227/70.20146. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.65889/70.03327. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.37103/69.85550. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.17149/69.65627. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.84157/69.44606. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.63977/69.22063. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.41473/68.97847. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.06705/68.70775. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.77143/68.40544. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.40229/68.06598. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.12402/67.68229. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.81577/67.26920. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.43097/66.85738. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.08611/66.49298. Took 0.34 sec\n",
      "Epoch 18, Loss(train/val) 65.65918/66.16759. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 65.22471/65.89984. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 64.92337/65.67722. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.46927/65.48280. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.36795/65.33688. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.09641/65.23839. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.72872/65.15825. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.63259/65.09395. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.47436/65.03416. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.26330/64.99265. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.14917/64.94943. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 63.10842/64.91926. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.90035/64.90126. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.84447/64.88064. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.79426/64.85184. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.63218/64.82933. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.49227/64.79623. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.43999/64.75979. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.49458/64.72861. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.28628/64.70817. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.26797/64.67789. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.16071/64.63934. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.16272/64.59768. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.97521/64.56496. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.88100/64.53237. Took 0.34 sec\n",
      "Epoch 43, Loss(train/val) 61.78725/64.49545. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.60029/64.45578. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.84402/64.42703. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.71278/64.39177. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.73749/64.34697. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.55312/64.30591. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.43687/64.24794. Took 0.34 sec\n",
      "Epoch 50, Loss(train/val) 61.35766/64.22245. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.42321/64.17837. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.35590/64.18025. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.19347/64.12464. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.26554/64.09816. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.06001/64.00778. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.95988/63.98905. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.87446/63.94063. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.72757/63.83704. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.81759/63.75860. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.66546/63.86647. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.54697/63.82673. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.57030/63.71738. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.37873/63.68634. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.26586/63.62459. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.31789/63.61378. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.28244/63.59169. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.26123/63.55288. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.11344/63.51123. Took 0.34 sec\n",
      "Epoch 69, Loss(train/val) 60.06359/63.43193. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.96510/63.44077. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.75739/63.35463. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.82540/63.34954. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.67822/63.32613. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.67591/63.31445. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.29612/63.22326. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 59.41736/63.15384. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.22755/63.13379. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.18246/63.05053. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.21644/62.96313. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.12995/62.87539. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.93227/62.79617. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.81419/62.75630. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.77641/62.68820. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.72583/62.58209. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.58533/62.54889. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.48923/62.44805. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.37698/62.39846. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.31534/62.35499. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.13683/62.39376. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.17767/62.32388. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.03172/62.30309. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.14428/62.18618. Took 0.34 sec\n",
      "Epoch 93, Loss(train/val) 57.95361/61.99096. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.81714/61.95710. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.73496/61.82565. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.52772/61.78266. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.52093/61.61971. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.44316/61.51658. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.31006/61.46733. Took 0.33 sec\n",
      "ACC: 0.609375, MCC: 0.22618098660385072\n",
      "Epoch 0, Loss(train/val) 70.59995/70.75688. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.41621/70.54825. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.28089/70.34106. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.08992/70.12678. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.91341/69.90434. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.68283/69.66779. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.44714/69.41927. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.23615/69.16691. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.03305/68.90704. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.68405/68.63726. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.47525/68.35509. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.19292/68.05367. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.86931/67.73032. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.73059/67.38172. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.38311/67.00913. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 67.12880/66.60554. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.87310/66.16167. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.53114/65.70065. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.34554/65.24399. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.99287/64.75414. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.70858/64.23625. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.36830/63.70912. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.99758/63.17108. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.64647/62.61449. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.35581/62.03747. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.89720/61.47856. Took 0.34 sec\n",
      "Epoch 26, Loss(train/val) 63.38681/60.91050. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.88903/60.38346. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.78380/59.88437. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.46095/59.39860. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.24800/58.91029. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 61.86262/58.39293. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.60639/57.92939. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.39068/57.52158. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.23108/57.11348. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.96082/56.75981. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 60.64301/56.35546. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.42663/55.97546. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.21057/55.67855. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.95036/55.33606. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.71681/55.13293. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.54215/54.89989. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.21356/54.72203. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.06895/54.50760. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.92818/54.35987. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 58.79897/54.18657. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.55064/54.02217. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.51326/53.91053. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.23871/53.81308. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.23059/53.66441. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.98353/53.59149. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 57.84762/53.50494. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.89187/53.47287. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.80211/53.35129. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 57.64121/53.29480. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.37278/53.22497. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 57.55526/53.09869. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.33597/53.05938. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.15075/52.99960. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.17640/52.89726. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 57.10130/52.86738. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 56.98959/52.79758. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 56.97526/52.65120. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 57.06516/52.72749. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.84525/52.63120. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 56.52927/52.54192. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 56.69419/52.51923. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 56.65306/52.45874. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 56.49242/52.43153. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 56.30561/52.38901. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.41270/52.23884. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 56.42153/52.34490. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.19144/52.30894. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 56.20140/52.25492. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.12562/52.18327. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.02026/52.07882. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.15454/52.13713. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 55.95746/52.07795. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 55.87901/51.94664. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 55.76519/51.92952. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 55.85609/51.87857. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 55.69667/51.85836. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 55.67262/51.79161. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 55.90388/51.78892. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 55.68550/51.73802. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.57531/51.85171. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 55.50058/51.77230. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 55.44441/51.69788. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 55.38314/51.61404. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 55.58785/51.52296. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.35357/51.43909. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 55.71319/51.44739. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.41463/51.59804. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 55.09598/51.38419. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.26851/51.36274. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.19540/51.29819. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.18437/51.33126. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.19678/51.26785. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.00622/51.23651. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.01384/51.15219. Took 0.32 sec\n",
      "ACC: 0.421875, MCC: -0.1624591083221647\n",
      "Epoch 0, Loss(train/val) 70.88275/70.20037. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.48153/69.87045. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.08938/69.51244. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.75361/69.12370. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.31703/68.68326. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.88863/68.18722. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.39178/67.63879. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.78021/67.03799. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.18003/66.39722. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.46133/65.74047. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 65.70775/65.08489. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 64.95836/64.43832. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 64.15035/63.80733. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 63.28528/63.18046. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 62.23858/62.53880. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 61.21529/61.86878. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 60.12105/61.20423. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 59.27428/60.60130. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 58.36625/60.05070. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 57.55085/59.63369. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 57.01738/59.34043. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 56.53379/59.08282. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 55.80686/58.83543. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 55.46117/58.61015. Took 0.34 sec\n",
      "Epoch 24, Loss(train/val) 55.19710/58.42754. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 54.67418/58.33974. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 54.56814/58.24951. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 54.20494/58.16780. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 54.17530/58.09515. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 54.22867/58.01113. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 54.03209/57.92942. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 53.92993/57.85645. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 53.81071/57.78017. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 53.68884/57.70730. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 53.64972/57.65058. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 53.28778/57.59135. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 53.50748/57.53501. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 53.41560/57.47990. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 53.43277/57.41861. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 53.43571/57.36505. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 53.19561/57.31429. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 53.24063/57.27018. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 53.00827/57.22748. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 52.96421/57.18543. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 53.08879/57.14356. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 52.99014/57.10229. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 53.07347/57.06088. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 52.82058/57.02074. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 52.91215/56.98484. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 52.78080/56.94020. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 52.79099/56.89389. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 52.59377/56.85983. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 52.75135/56.82208. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 52.58471/56.78364. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 52.49281/56.74546. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 52.55991/56.71154. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 52.60834/56.68754. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 52.46174/56.66086. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 52.37195/56.63721. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 52.35275/56.59595. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 52.30574/56.57132. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 52.31511/56.57373. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 52.29537/56.58255. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 52.30279/56.58864. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 52.04326/56.58283. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 52.24551/56.56364. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 51.97475/56.55291. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 52.05225/56.54815. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 52.02405/56.51900. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 52.14161/56.53120. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 52.15591/56.52360. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 51.79389/56.54005. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 51.98849/56.53639. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 51.88289/56.63551. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 51.72523/56.61852. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 51.64982/56.63144. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 51.68138/56.59673. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 51.66463/56.71412. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 51.61146/56.76249. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 51.51959/56.78750. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 51.47452/56.72701. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 51.55135/56.80975. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 51.28734/56.74884. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 51.40647/56.77795. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 51.20910/56.84103. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 51.27709/56.60556. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 51.08919/56.62400. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 51.33851/56.82276. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 51.02375/56.58377. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 51.05138/56.55132. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 51.25543/56.66842. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 51.05613/56.53226. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 50.85782/56.45528. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 50.82579/56.59325. Took 0.34 sec\n",
      "Epoch 94, Loss(train/val) 50.89303/56.25922. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 50.58942/56.30893. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 50.73212/56.29943. Took 0.34 sec\n",
      "Epoch 97, Loss(train/val) 50.42341/56.36328. Took 0.34 sec\n",
      "Epoch 98, Loss(train/val) 50.68336/56.42257. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 50.54592/56.44344. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: 0.05902513184886853\n",
      "Epoch 0, Loss(train/val) 71.00009/71.05769. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.85001/70.90977. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.63099/70.75970. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.46128/70.60284. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.28609/70.44111. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.10677/70.26784. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.91660/70.07951. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.71366/69.86996. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.52466/69.64322. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.24216/69.38704. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.03256/69.09498. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.70833/68.76364. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.35141/68.41196. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.03811/68.06857. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.77825/67.79421. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 67.50992/67.55170. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.21934/67.33043. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.97071/67.12047. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.85112/66.93378. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.57055/66.76523. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.31845/66.61366. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 66.17431/66.45279. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 65.92912/66.28623. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 65.76421/66.10619. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.57135/65.92606. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.52751/65.73254. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 65.33085/65.51706. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.23632/65.28864. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.92768/65.04842. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.74838/64.80888. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.55965/64.56574. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.43928/64.30688. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.42054/64.07649. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 64.06841/63.79989. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.11987/63.51655. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.79005/63.29554. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.66740/63.03308. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.54275/62.78618. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.29404/62.55635. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.17910/62.31598. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.09701/62.15872. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.92112/62.00471. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.79750/61.84985. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.78752/61.71794. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.63105/61.58992. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.54199/61.48088. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.48980/61.35830. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.21445/61.24487. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 62.23958/61.19263. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.18197/61.12264. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.13312/61.01178. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.91019/60.92146. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.97711/60.83925. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.67761/60.72402. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.73868/60.65139. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.59371/60.57491. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.50969/60.52494. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.37211/60.51997. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.39849/60.49909. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.37333/60.49039. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.27734/60.48646. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.23704/60.52386. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.00012/60.54661. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.08007/60.63274. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.85362/60.69323. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.87410/60.64774. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.40949/60.58413. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.61206/60.51968. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.42739/60.64147. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.49524/60.73039. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.09142/60.89219. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.19258/61.01799. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 60.19414/61.13914. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 60.12859/61.36304. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.79290/61.44453. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.76144/61.54975. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.63613/61.44059. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.60510/61.42846. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.69157/61.56642. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.35894/61.37049. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.41527/61.51511. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.19271/61.31449. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.31159/61.39402. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.12257/61.42749. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.03864/61.35150. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.02869/61.47866. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.94542/61.60740. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.79478/61.60682. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.91888/61.56419. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.86945/61.29105. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.86521/61.53636. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.61905/61.56196. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.71673/61.59676. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 58.64469/61.70530. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.61168/61.33109. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.42093/61.65522. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.59842/61.51504. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.31336/61.54053. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.17677/61.47636. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 58.18025/61.40499. Took 0.32 sec\n",
      "ACC: 0.5, MCC: -0.12562244381357196\n",
      "Epoch 0, Loss(train/val) 70.71394/70.85185. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.52886/70.67323. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.32266/70.49279. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.11538/70.30446. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.88767/70.09887. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.64716/69.87181. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.37015/69.62086. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.07629/69.33932. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.76283/69.02020. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.35214/68.66161. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.87150/68.26020. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.46127/67.83212. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.13843/67.40667. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.71610/66.98200. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.32918/66.56339. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.92241/66.16751. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.59494/65.79221. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.20319/65.45188. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.98076/65.16583. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.46550/64.92723. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 64.38929/64.73538. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.08125/64.58396. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.85372/64.46824. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.64110/64.36707. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.39095/64.26558. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.19152/64.15747. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.00738/64.03569. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.71065/63.90622. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.63728/63.79164. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.28854/63.66088. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.17054/63.56449. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.94478/63.51006. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.83951/63.52869. Took 0.34 sec\n",
      "Epoch 33, Loss(train/val) 61.63153/63.53852. Took 0.34 sec\n",
      "Epoch 34, Loss(train/val) 61.52186/63.54003. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 61.55393/63.49608. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.33544/63.55643. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.12783/63.58236. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 61.07193/63.58529. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.97252/63.56272. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.80392/63.44784. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.80614/63.41485. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.83105/63.33753. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.67414/63.25050. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.48025/63.14973. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.24787/63.05543. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.16853/62.97170. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.00622/62.84157. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.05634/62.78395. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.07425/62.64128. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.75519/62.53016. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.72058/62.44691. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.57662/62.30549. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.58072/62.19878. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.49856/62.08434. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 59.43170/61.97429. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.34943/61.76037. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.23547/61.70501. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.08180/61.57433. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.09259/61.48439. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.06484/61.38004. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.03996/61.28519. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 58.78043/61.10369. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.81256/60.90424. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.86673/60.86381. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.65470/60.83882. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 58.70706/60.72696. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.55824/60.64450. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.50849/60.55542. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.47565/60.49468. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.40100/60.40634. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.42125/60.36119. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.30833/60.20796. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.25417/60.22044. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.17710/60.15598. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.93943/60.20733. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.94695/60.10184. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 58.00464/60.02880. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 57.94025/60.00180. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.82917/59.88243. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 57.88117/59.67833. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 57.61292/59.41493. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 57.43458/59.33621. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.50573/59.34138. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.38794/59.33611. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.27178/59.51100. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 57.16005/59.75766. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.09327/59.66535. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.16609/59.67206. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.09980/59.76254. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.90750/59.76020. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 57.08396/59.87528. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.78179/59.73108. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.81908/59.57277. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 56.46650/59.62231. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.38416/59.37506. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.27040/59.44888. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 56.41088/59.19963. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.16760/59.18763. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 56.01639/59.10929. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.15118578920369088\n",
      "Epoch 0, Loss(train/val) 70.13029/69.40109. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 69.94201/69.33962. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.77567/69.26997. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.61660/69.18678. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 69.37868/69.08437. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.20809/68.96910. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.96635/68.85141. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 68.72251/68.74130. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.44444/68.65414. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.14352/68.59606. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.86395/68.55365. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.50832/68.52369. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 67.34603/68.49335. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 67.04190/68.44961. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.83496/68.38252. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.54707/68.28998. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.32555/68.17891. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 66.00874/68.02368. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 65.68188/67.82173. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.47330/67.58028. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.14401/67.27704. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.87332/66.92348. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.57065/66.55426. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 64.29811/66.29305. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 64.14912/66.07245. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 63.81904/65.88211. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.70849/65.75253. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 63.51862/65.65498. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.49648/65.61462. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 63.28580/65.58057. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.16300/65.57141. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.09483/65.56110. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.00831/65.55318. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 62.81182/65.54055. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.88201/65.55471. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 62.71086/65.56078. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 62.59933/65.59086. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.51512/65.60962. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.45425/65.61940. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.32737/65.62418. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.28152/65.64342. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.15990/65.67889. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.10993/65.73505. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.01855/65.78259. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.99072/65.81225. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.88204/65.84696. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.82152/65.83755. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 61.61047/65.90952. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.53102/65.94233. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.62280/65.98717. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.46969/66.02357. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 61.41820/66.01202. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.41938/66.04455. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.25708/65.99196. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.11890/66.08884. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.17903/66.08625. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.02567/66.04246. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.99095/66.14857. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 60.99039/66.14407. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.87766/66.18705. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.90697/66.10006. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.72448/66.11736. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 60.73253/66.10283. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.67766/66.07815. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.67271/66.08018. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.58559/65.99506. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.49272/65.94461. Took 0.30 sec\n",
      "Epoch 67, Loss(train/val) 60.46090/65.91801. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 60.33094/65.93705. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.21628/65.84438. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.27439/65.80388. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.19075/65.90766. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.10161/65.84688. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.97739/65.73607. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 60.00845/65.73994. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.93800/65.74778. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 60.02983/65.67424. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.75805/65.54551. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 59.68041/65.55966. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 59.76483/65.80450. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 59.62249/65.70755. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 59.55291/65.50127. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.65599/65.43583. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.57908/65.90962. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.49063/65.48410. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.44169/65.55563. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.33650/66.17913. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.20959/65.43945. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 59.17827/65.62651. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.25716/65.82838. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.34910/65.56122. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.23350/65.65080. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.15086/65.72630. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.11966/65.60873. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.00551/65.84953. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.98840/65.56111. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 59.00097/65.81991. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.80688/65.80270. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 58.88605/65.60023. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 58.81457/65.65833. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.04319917848286286\n",
      "Epoch 0, Loss(train/val) 71.27725/70.71307. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 71.12130/70.70742. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 71.04610/70.70277. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.96499/70.70741. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.84370/70.72569. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 70.74715/70.76134. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.63621/70.81099. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.49481/70.86668. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.38128/70.90704. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 70.22387/70.90730. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 70.12891/70.87579. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.94263/70.82149. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 69.84753/70.75511. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.71206/70.67927. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 69.61000/70.59247. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.40777/70.50475. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 69.22843/70.41404. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.99054/70.33278. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 68.79179/70.25317. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.54696/70.17004. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 68.34697/70.08353. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 68.09549/70.00334. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.97828/69.92757. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 67.65873/69.84724. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 67.54845/69.76496. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 67.27934/69.67273. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 67.05474/69.57704. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 66.83368/69.47218. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.62216/69.35044. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 66.36495/69.21793. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 66.18017/69.07692. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.91099/68.91022. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 65.68791/68.72089. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.33620/68.51999. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 65.14305/68.33517. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.95881/68.18733. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.84466/68.08469. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.69830/67.99304. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.61553/67.92255. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 64.61869/67.87097. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.51952/67.84205. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.20557/67.82403. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.22309/67.81201. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.10865/67.80025. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 64.12925/67.77828. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 63.93261/67.76682. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 63.89155/67.77138. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.90973/67.76784. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.81457/67.77626. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.66415/67.78172. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.63894/67.76743. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.50046/67.79317. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 63.46966/67.84299. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.34489/67.88800. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.29005/67.91913. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.17391/67.98003. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 63.19380/68.01960. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 63.08669/68.07269. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.17078/68.14641. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 63.02032/68.20711. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.05894/68.23582. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 63.07817/68.26331. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.93176/68.28762. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 62.83024/68.32397. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.90775/68.35104. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 62.93919/68.37617. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.71109/68.42247. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.71563/68.45335. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 62.70415/68.48213. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.59845/68.49705. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.53104/68.51239. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.44895/68.53578. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.52539/68.54031. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.49903/68.53522. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.48825/68.55511. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 62.32519/68.53121. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.40824/68.55200. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 62.26932/68.53816. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.36085/68.54842. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 62.28651/68.53416. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 62.00998/68.54733. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.10113/68.49725. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 62.15943/68.50896. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 62.08122/68.48943. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 62.01479/68.47293. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.18281/68.44508. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.84829/68.44420. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 62.05249/68.43648. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.96885/68.43201. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.87287/68.41441. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.90210/68.41510. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.97958/68.40030. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.90288/68.40015. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 61.71833/68.40448. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.73641/68.40303. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 61.86105/68.40403. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 61.68744/68.40343. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 61.74894/68.41213. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.58144/68.41841. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.60505/68.42477. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.049929648757959806\n",
      "Epoch 0, Loss(train/val) 70.24265/68.45527. Took 0.95 sec\n",
      "Epoch 1, Loss(train/val) 69.99551/68.20364. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.82061/67.93361. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.53541/67.65198. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.37365/67.36309. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.12558/67.05994. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 68.94930/66.75740. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 68.67621/66.45897. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.46116/66.17083. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.28263/65.89130. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 67.99388/65.62453. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.72572/65.36040. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.50978/65.10482. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 67.27719/64.84395. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.12627/64.57705. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 66.81918/64.30415. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 66.57473/64.04570. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 66.34333/63.78729. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.04595/63.55386. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 65.87877/63.37351. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.63083/63.21484. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.36360/63.07573. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 65.10724/62.95488. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.91773/62.84437. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 64.61487/62.74254. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.45639/62.64261. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.16445/62.54859. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.88452/62.45948. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.62039/62.37082. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.50243/62.27983. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.11798/62.18465. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.05339/62.08450. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 62.87867/61.97470. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 62.76929/61.86367. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.53548/61.76130. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.40763/61.66645. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.23220/61.58326. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.18445/61.51027. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.05204/61.44152. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.92519/61.39616. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.68079/61.36142. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 61.53310/61.31862. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 61.66458/61.28783. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.40793/61.25477. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.47520/61.21465. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.37939/61.18917. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 61.27277/61.18010. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.20730/61.18339. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.04535/61.17128. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.04430/61.17304. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.88943/61.23086. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.74203/61.25719. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.85082/61.32296. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.80368/61.37267. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.66525/61.39082. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 60.56111/61.37996. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.47762/61.47092. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.43834/61.42402. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.37132/61.42329. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.37843/61.40326. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.31286/61.38356. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.30003/61.42880. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.27242/61.37597. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.28203/61.35641. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 60.16266/61.44493. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.01001/61.33337. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.19688/61.53000. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.17616/61.51770. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.97891/61.34302. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.85242/61.48364. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.98889/61.49224. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 59.94757/61.47487. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.70887/61.59177. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.89711/61.62452. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 59.91148/61.74007. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.59304/61.65697. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.56394/61.79761. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.58104/61.71037. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.57385/61.87814. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 59.58135/61.73066. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 59.47401/61.90445. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 59.36760/61.71827. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 59.34368/61.98478. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.45732/61.78052. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 59.33264/61.92476. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.18765/61.78801. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.30538/61.82678. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.23887/61.91476. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.27126/61.99531. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 59.17311/61.87403. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.22751/61.87166. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 58.91083/61.84638. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.08952/62.01788. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.96538/61.77026. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.89385/61.81108. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 58.92800/61.75171. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 59.04205/61.85518. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.89760/61.73439. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.83023/62.04474. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.88016/61.75103. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.021098286729420077\n",
      "Epoch 0, Loss(train/val) 70.82170/69.75539. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.60046/69.58089. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.33992/69.40248. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.06724/69.21899. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.84516/69.02478. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.60347/68.82216. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.40667/68.61331. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.15590/68.39834. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.87472/68.17039. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.57066/67.93008. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.25477/67.68574. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 67.81381/67.44803. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.54672/67.23700. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.27416/67.04906. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.88832/66.87108. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 66.66780/66.69725. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.38100/66.52792. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.05906/66.35714. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.89733/66.18715. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 65.75128/66.02816. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 65.51389/65.88400. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.35904/65.73245. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.15585/65.58199. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.93620/65.43156. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.68121/65.27873. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.54497/65.12596. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 64.47941/64.97592. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.20565/64.83030. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.01610/64.69080. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.85897/64.55683. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.76450/64.43293. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.62394/64.31699. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.57176/64.19987. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.39829/64.08983. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.28349/63.98327. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 63.19369/63.87271. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.09057/63.76918. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.95608/63.67714. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.99404/63.58813. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 62.74684/63.51194. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.73051/63.44729. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.68612/63.39746. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 62.51901/63.34757. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.50141/63.32384. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 62.50663/63.28456. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.43307/63.21980. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 62.24804/63.15728. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.07842/63.12899. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 62.10408/63.09849. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.96428/63.05323. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 62.05335/63.02263. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.98981/63.01621. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.02971/62.96638. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.81142/62.95858. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.83958/62.95667. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 61.64564/62.94551. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.70393/62.96244. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.78772/62.89672. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.56380/62.91895. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.51015/62.92644. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 61.55007/62.97145. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.48061/62.98770. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.40246/63.04323. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.33543/63.03522. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.19594/63.10588. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 61.29292/63.10240. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.34859/63.11337. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.17560/63.21190. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.13515/63.23888. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 61.14003/63.28111. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.96854/63.29045. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 61.04409/63.36105. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.84177/63.36309. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.96763/63.37617. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 60.87590/63.44261. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.76293/63.52741. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.66391/63.56229. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.72297/63.60865. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 60.64038/63.68339. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.57014/63.71481. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 60.52036/63.77634. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.37131/63.88879. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.38207/63.89414. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.41970/63.91272. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 60.22812/63.96329. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.19796/64.00050. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.06272/64.00625. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.01043/64.04441. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.03393/64.05885. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 60.02018/64.13626. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 59.76872/64.14133. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 59.78416/64.13094. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 59.82134/64.19608. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.75609/64.20341. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 59.68407/64.22153. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.79282/64.22586. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 59.63603/64.26016. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 59.52731/64.24316. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 59.82645/64.23528. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.59406/64.27329. Took 0.31 sec\n",
      "ACC: 0.484375, MCC: -0.011958266722236254\n",
      "Epoch 0, Loss(train/val) 70.39888/70.72519. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.20360/70.59947. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.02696/70.47666. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.85870/70.35233. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.69116/70.22349. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.50316/70.08566. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.29886/69.93170. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.07307/69.75807. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.91997/69.55783. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.72070/69.33602. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.47593/69.09930. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.21841/68.85037. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.94978/68.59700. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.62972/68.33610. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.36136/68.05987. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.03362/67.76070. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.63244/67.43418. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 66.27487/67.08246. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 65.94126/66.71149. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.59879/66.38358. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.27185/66.06600. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 64.88614/65.74293. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.72548/65.45248. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.49106/65.20766. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.22678/64.99254. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.95586/64.81363. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.79871/64.69400. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.71884/64.64826. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.66924/64.60236. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 63.47474/64.60764. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 63.20696/64.58086. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.24827/64.60861. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 63.09605/64.67387. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.89903/64.79932. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.81911/64.84843. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.72112/65.06609. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.79168/65.12653. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.65895/65.00341. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.58484/65.26375. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.37446/65.22128. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 62.35277/65.38054. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.47927/65.38971. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.23054/65.43549. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.14570/65.49992. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.11529/65.30916. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.11778/65.45253. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.93616/65.06254. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.96619/65.37540. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.84799/65.17387. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 61.87624/65.24975. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 61.72265/65.17616. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.80590/65.32784. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.83694/65.21073. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.69185/65.29741. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 61.81762/65.38890. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.55363/65.34708. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.58772/65.31134. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.64759/65.36962. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 61.50211/65.37718. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.44136/65.41420. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.34582/65.40997. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.47837/65.52607. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.47957/65.47153. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.31285/65.52753. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.32745/65.42781. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.26366/65.49519. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.26041/65.42538. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.22786/65.46825. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.12935/65.39873. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.16834/65.49316. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.99406/65.34927. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.92363/65.56563. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.92761/65.52422. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 60.83481/65.61520. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.78520/65.48213. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.84906/65.63073. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.86255/65.57236. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.82877/65.61456. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.74703/65.63179. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 60.77890/65.64378. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 60.74181/65.52820. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.61445/65.59985. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 60.76262/65.53461. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.67438/65.58386. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.57589/65.54809. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.67422/65.66425. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.51012/65.41261. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 60.54244/65.62802. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.38454/65.79102. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.50424/65.95373. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.36417/65.37057. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.42675/65.93505. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.36311/65.36171. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.31684/65.80186. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.37279/65.51224. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 60.31337/65.62399. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.22406/65.66518. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.23628/65.65029. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.06472/65.79550. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.98972/65.74224. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.06859245370246428\n",
      "Epoch 0, Loss(train/val) 69.91793/72.21959. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 69.75869/72.28121. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 69.55627/72.33819. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.39285/72.39359. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 69.14334/72.45065. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.02097/72.50208. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 68.83501/72.54723. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.62865/72.58421. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.40610/72.62025. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.31270/72.64376. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.03573/72.66208. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.79168/72.67325. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.59806/72.67535. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.42946/72.66286. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.20328/72.63036. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.86710/72.58007. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.67880/72.51295. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.36816/72.43836. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.02504/72.36481. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.78301/72.28564. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.39241/72.20299. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.35990/72.12873. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.12785/72.05181. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.82409/71.97321. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.77994/71.89918. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.59054/71.82688. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.47834/71.74587. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.29404/71.65731. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.37779/71.56808. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.09751/71.49119. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.98895/71.40174. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.95271/71.33203. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.97455/71.24846. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.83705/71.17741. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.79137/71.09537. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 63.75590/71.01205. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 63.58613/70.93524. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.64703/70.86288. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 63.57444/70.80906. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 63.46343/70.73212. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.46025/70.65785. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.46385/70.59074. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.19927/70.51479. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 63.23203/70.44475. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 63.22784/70.36285. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 63.07128/70.29977. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.94236/70.26305. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.92611/70.24607. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.73853/70.22660. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.73559/70.20431. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.70026/70.18466. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.68501/70.17951. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.55751/70.15575. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.50521/70.15244. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.45291/70.15583. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 62.44019/70.14700. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.26869/70.13908. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.27442/70.14150. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.18310/70.12940. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.04632/70.12548. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 62.14349/70.11956. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.07469/70.10691. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.06530/70.08089. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.22534/70.06747. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.04368/70.04613. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 62.03545/70.02507. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 61.94227/70.02709. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 61.72716/70.02165. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.70486/70.00379. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.81768/69.98311. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.76097/69.95173. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 61.89336/69.91096. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.69047/69.85600. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.70341/69.79923. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.58961/69.74693. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.51331/69.69360. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 61.47357/69.62979. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 61.37445/69.51997. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.38092/69.41257. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.38803/69.33928. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.21614/69.25073. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.17714/69.17551. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.12139/69.10355. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.97827/69.04807. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.90327/69.02205. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.87276/68.99410. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.70425/68.95329. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.80991/68.92027. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.73585/68.89767. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.58652/68.87077. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.56789/68.87103. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.58016/68.85324. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 60.58712/68.84377. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.54704/68.83451. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.37772/68.81032. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.39753/68.80049. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.32330/68.79833. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.28808/68.76839. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.12173/68.75906. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 60.29856/68.72935. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.12498768867296815\n",
      "Epoch 0, Loss(train/val) 70.29416/71.07006. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.02745/70.89629. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.80575/70.72017. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.58338/70.54225. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.27730/70.36909. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.00851/70.20148. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.71192/70.03705. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.40088/69.88401. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.12549/69.73392. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 67.86812/69.58942. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.65557/69.44997. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 67.44638/69.32139. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.16768/69.18992. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.00474/69.05608. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.77438/68.92521. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.57369/68.80297. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 66.48700/68.68243. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.36860/68.55580. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.11529/68.42172. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.99673/68.29087. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 65.75326/68.15651. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.67632/68.02769. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.50139/67.90791. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 65.46921/67.77544. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.21289/67.64075. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 65.04397/67.51601. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.98174/67.39298. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.89283/67.28371. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.78495/67.15765. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.57405/67.04052. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.58531/66.92030. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.34292/66.79702. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.31458/66.66641. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 64.23626/66.55971. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 64.15432/66.46001. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 63.96185/66.35388. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 63.90877/66.26019. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.85186/66.16933. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.84930/66.08274. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.64755/66.01744. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.50717/65.92872. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 63.38529/65.82676. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 63.22021/65.72996. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 63.11394/65.62598. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.00268/65.47108. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 62.84064/65.33865. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 62.87419/65.18104. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 62.66812/65.03198. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.52218/64.89086. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.27643/64.70541. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.35829/64.60422. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.08507/64.52361. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.05156/64.41017. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.91960/64.34839. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.85104/64.35445. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.70813/64.32883. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.57976/64.28736. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.44163/64.30688. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.23013/64.22147. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.26949/64.19685. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.27524/64.14387. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 61.14083/64.09769. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 61.15937/64.11486. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.89923/64.11501. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.84316/64.05604. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.88388/64.03017. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 60.77775/64.03246. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.71272/64.04727. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 60.53131/64.00775. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.52021/64.02638. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.35890/64.06018. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 60.26465/64.09666. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.27608/64.16180. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.23758/64.18068. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 60.13616/64.26169. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.09586/64.24091. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.10885/64.33560. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 60.08521/64.34343. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.92403/64.41748. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.94017/64.44306. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.95756/64.51479. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.78036/64.41181. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.66171/64.55203. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 59.64604/64.35999. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.60184/64.54806. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.53569/64.30792. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.56372/64.62543. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.41061/64.30612. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.34793/64.37286. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.33573/64.30187. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.31338/64.28366. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.31064/64.30795. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.27392/64.26929. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.19662/64.20903. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.16498/64.21698. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.00077/64.16823. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.97192/64.13374. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 59.00446/64.13904. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.96929/64.11765. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.93846/64.09154. Took 0.31 sec\n",
      "ACC: 0.5, MCC: 0.021109792565893827\n",
      "Epoch 0, Loss(train/val) 71.06949/70.53427. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.83858/70.35947. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.66838/70.18758. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.42526/70.01375. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.25630/69.83439. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.12544/69.65796. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.92909/69.48569. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.76212/69.31461. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.53168/69.13115. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.32285/68.93681. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.14982/68.73004. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.84903/68.51162. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.62222/68.28764. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.35227/68.05733. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.98914/67.82185. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.75510/67.59010. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.39369/67.36794. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 67.06497/67.15797. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.64639/66.92952. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 66.22480/66.68243. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 65.83040/66.39996. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.33096/66.10372. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.77989/65.82162. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.49675/65.57401. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.05787/65.36436. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.67246/65.19385. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.48734/65.05572. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.46024/64.93044. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.35695/64.80856. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.17194/64.67316. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 63.19017/64.54741. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 63.03068/64.50739. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.85759/64.47991. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.87315/64.42884. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.61734/64.36684. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.56687/64.31427. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.50607/64.25713. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.34199/64.19191. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.20117/64.12270. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.26251/64.08293. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 62.11853/64.07307. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.01777/64.00459. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 62.01249/63.95637. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.88083/63.92899. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.60704/63.91511. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.51193/63.91058. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.59747/63.90930. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.64408/63.84933. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 61.40913/63.79799. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 61.36485/63.80600. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.10834/63.81376. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 60.97980/63.78537. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.05384/63.75756. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 60.93167/63.71227. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.87277/63.71960. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.96076/63.74089. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.74158/63.77624. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.48312/63.69582. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 60.47561/63.70583. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.51122/63.61934. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.34523/63.61332. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.28440/63.59558. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.29822/63.61884. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.32775/63.59687. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.07994/63.60462. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.07456/63.55688. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.95305/63.52623. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.98994/63.49573. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.90703/63.50812. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.85791/63.47472. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.84094/63.44608. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.80326/63.51343. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.74331/63.40968. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.76399/63.40087. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 59.51598/63.39788. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.52488/63.46529. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.47799/63.37746. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.53133/63.31474. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 59.47323/63.28191. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.24708/63.26882. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 59.29664/63.27467. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 59.17839/63.31326. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.26239/63.29876. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.16636/63.25028. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.06573/63.26282. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.13097/63.26630. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 59.24387/63.29730. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 59.12302/63.36618. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.93413/63.31168. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.89109/63.23340. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.88558/63.26385. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.93077/63.22987. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.86144/63.25207. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 58.55983/63.22765. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.60823/63.25367. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.70268/63.30407. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.66941/63.25315. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.33436/63.15416. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.43059/63.11974. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 58.27994/63.16641. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.06052275326688024\n",
      "Epoch 0, Loss(train/val) 71.09067/70.91736. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.94313/70.74157. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.77482/70.56994. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.65339/70.40753. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.48097/70.25204. Took 0.30 sec\n",
      "Epoch 5, Loss(train/val) 70.36539/70.11481. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 70.17705/69.98553. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.00841/69.86258. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 69.86411/69.74386. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.66520/69.62557. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.48122/69.50679. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.29877/69.38911. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 69.09990/69.27838. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.88196/69.17367. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.70216/69.07723. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.45414/68.98199. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.36699/68.89566. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.13547/68.81996. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 67.96034/68.75108. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 67.82721/68.68932. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 67.64420/68.63367. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.47897/68.57787. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.27616/68.52429. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.07233/68.46535. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.96522/68.40005. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.86042/68.32246. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.66382/68.22201. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.48387/68.09528. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.23722/67.94489. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.05929/67.77296. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.91748/67.59273. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.79900/67.42491. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 65.64180/67.27837. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.39357/67.14016. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.25507/67.00723. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 65.24970/66.88310. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.96412/66.75988. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 64.99892/66.65876. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.80911/66.56868. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 64.65767/66.48851. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.55204/66.42378. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 64.50948/66.37011. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.28822/66.32832. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.17957/66.29990. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.01619/66.28507. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 63.95994/66.29714. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.84547/66.30248. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.77387/66.31349. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.82405/66.31171. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.59788/66.30303. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 63.68903/66.29152. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.47646/66.28529. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.37757/66.27345. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.13019/66.25696. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.27282/66.23000. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.26932/66.19227. Took 0.34 sec\n",
      "Epoch 56, Loss(train/val) 63.17335/66.15883. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 63.10930/66.12547. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 63.08242/66.09097. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.09538/66.04958. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.05220/66.01891. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.87094/65.98373. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 62.98002/65.94783. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.87319/65.90737. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.63078/65.86500. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.65086/65.81802. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.59627/65.76812. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.58693/65.70620. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 62.63043/65.65951. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 62.40275/65.61425. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.34205/65.54572. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.36979/65.48890. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.42135/65.43145. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 62.21500/65.37259. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 62.13084/65.31278. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.19657/65.24391. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.88819/65.18202. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.07558/65.13250. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.99762/65.08258. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.83222/65.02197. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.87484/64.96968. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.94552/64.91019. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.62109/64.86069. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.85252/64.82077. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.63938/64.78281. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.78123/64.72806. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.78607/64.68423. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.48236/64.64487. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.33644/64.59975. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.26629/64.56339. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.31715/64.54728. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.32945/64.51770. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.24121/64.47528. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 61.18160/64.43786. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.95607/64.40302. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 61.30555/64.35661. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.06911/64.32102. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 61.06423/64.28036. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 60.94268/64.26487. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.89280/64.25240. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.046127024215707656\n",
      "Epoch 0, Loss(train/val) 70.26902/70.13228. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.14223/69.90328. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.03234/69.69997. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.88322/69.51399. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.76448/69.34307. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.63466/69.18413. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.51793/69.02951. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.33390/68.87134. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.25736/68.71487. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 69.06281/68.53809. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.89955/68.34728. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.66787/68.13931. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.48795/67.90909. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.26488/67.67452. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.99743/67.43890. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 67.79351/67.22599. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 67.51394/67.03626. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.29650/66.86553. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 67.13534/66.71501. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.87427/66.57973. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.72650/66.45333. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.46968/66.33091. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.26757/66.21449. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.12775/66.10753. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.04968/66.00079. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 65.83976/65.89616. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.67228/65.79445. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.50617/65.69420. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.27389/65.60106. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.33322/65.51280. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.19732/65.43185. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.10306/65.35583. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.95849/65.28483. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 64.87346/65.21813. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 64.73195/65.14722. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 64.56529/65.07308. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 64.53472/64.99702. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 64.58966/64.91544. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.55200/64.82922. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.34626/64.73853. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.40491/64.64631. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.22692/64.56277. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 64.30853/64.46593. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.25373/64.38275. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 64.22785/64.31791. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.09607/64.24279. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.07112/64.16143. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.96827/64.06824. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.99454/63.99731. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.82083/63.92833. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 63.98997/63.83410. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.81910/63.74915. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.66652/63.68222. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 63.72689/63.58548. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.63717/63.50466. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.70568/63.38879. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.56513/63.26596. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.47568/63.16516. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.44437/63.04174. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.38128/62.94981. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.23174/62.87233. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 63.26210/62.79735. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.24644/62.70430. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 63.16994/62.64585. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.15078/62.65695. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.92910/62.62935. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.94839/62.57428. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 63.06430/62.53303. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.89939/62.51097. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.82677/62.48042. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.68597/62.48991. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.63733/62.55540. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.57842/62.55656. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.47003/62.56202. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.63714/62.60256. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 62.48076/62.60766. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.39135/62.74541. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.34465/62.75871. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 62.47885/62.77383. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.27287/62.70941. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 62.18777/62.99043. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 62.20853/62.90321. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 62.15904/62.99143. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.98763/62.91150. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.03687/62.97040. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.98667/62.90962. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.89415/62.95841. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.95469/62.96604. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.64631/63.01398. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.75461/62.96338. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 61.65750/62.88924. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.71400/62.87882. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.49877/62.84085. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.69998/62.91205. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.56493/62.97929. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 61.63096/63.06223. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.53054/63.07638. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.35510/63.11421. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.49444/63.07613. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.31477/63.02416. Took 0.33 sec\n",
      "ACC: 0.5, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) 71.14583/72.42535. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.78473/72.30704. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.33590/72.19725. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 69.99794/72.09197. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.54355/71.99765. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.14940/71.90780. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.64694/71.83241. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.25508/71.77468. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.79671/71.73412. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.26083/71.71658. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.83798/71.70118. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.52712/71.68109. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.06777/71.64497. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.69459/71.58885. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.37704/71.52071. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.05122/71.42725. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.83044/71.32244. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.43407/71.19753. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 64.11423/71.05076. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.94988/70.88227. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.67849/70.69338. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.30782/70.48388. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 62.90267/70.23831. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.62023/69.95392. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 62.20029/69.62600. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 61.77410/69.25788. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.39255/68.88482. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.99778/68.51890. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.57962/68.17443. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.12739/67.85041. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.74685/67.51649. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 59.31222/67.16734. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.04990/66.83516. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 58.67208/66.50417. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.54442/66.20852. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 58.30785/65.92592. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 57.94394/65.64619. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 57.94761/65.37608. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 57.68720/65.15308. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 57.56983/64.94204. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 57.35202/64.77766. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 57.32262/64.58523. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 57.27148/64.40958. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 56.91332/64.26753. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 57.00736/64.11444. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 56.68970/63.96629. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 56.65123/63.83739. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 56.74760/63.74825. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 56.53637/63.63637. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 56.36142/63.56391. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 56.41181/63.47970. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 56.25582/63.39856. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 56.09348/63.36999. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 56.19437/63.29757. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 55.87293/63.23913. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 55.88870/63.21293. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 55.67367/63.17955. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 55.57028/63.14585. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 55.56963/63.08815. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 55.44349/63.05047. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 55.18078/62.96572. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 55.32765/62.92335. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 55.39926/62.86061. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 55.10044/62.83088. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 55.10366/62.80766. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 54.98513/62.76156. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 54.89690/62.71808. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 54.93453/62.68000. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 54.78848/62.66021. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 54.71530/62.57245. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 54.80730/62.56897. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 54.66341/62.49844. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 54.60115/62.52444. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 54.65477/62.44703. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 54.43500/62.44942. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 54.42442/62.38039. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 54.30922/62.38739. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 54.31687/62.31947. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 54.31593/62.36206. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 54.30030/62.23325. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 54.13902/62.34745. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 54.18603/62.31517. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 54.24863/62.39413. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 54.12290/62.36401. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 53.98264/62.36913. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 53.97553/62.32209. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 53.89833/62.39833. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 53.84828/62.40113. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 53.83641/62.29539. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 53.63099/62.36988. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 53.77401/62.22350. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 53.71149/62.27431. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 53.54735/62.22138. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 53.79724/62.25027. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 53.60869/62.22531. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 53.57664/62.11426. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 53.58773/62.06612. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 53.34442/62.08313. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 53.26590/62.05997. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 53.40984/62.07302. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.12977983786586622\n",
      "Epoch 0, Loss(train/val) 70.32794/69.41679. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.10310/69.41448. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.92367/69.40549. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.77004/69.40144. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.56462/69.37222. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.33218/69.30598. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.15682/69.20375. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.92789/69.08414. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.58323/68.91716. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.35935/68.68948. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.98994/68.40340. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.67163/68.07784. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.29670/67.72994. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.03371/67.36371. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.56979/66.98024. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.21490/66.69055. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.81832/66.39786. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.59611/66.08832. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.38537/65.79648. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.10381/65.53135. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.81852/65.29091. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.73216/65.09827. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.52515/64.94555. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.30656/64.83145. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 64.20476/64.79241. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 63.96082/64.79980. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.95211/64.77071. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.75892/64.69952. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.71986/64.66227. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.69094/64.73693. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.66182/64.73204. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 63.51886/64.73584. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.43596/64.73008. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.28498/64.72727. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.25406/64.81335. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.20122/64.86237. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.22093/64.88374. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.10751/64.87253. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 63.12945/64.92622. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.99495/65.00238. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.95875/65.09253. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.85451/65.15247. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.85797/65.17699. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.67662/65.22447. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.64818/65.29920. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.61568/65.32281. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.66354/65.24777. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.61457/65.39552. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.55644/65.53440. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.57105/65.59444. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.41372/65.58616. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.29223/65.58402. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.25767/65.64110. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.32217/65.67025. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.17673/65.61925. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.00607/65.72250. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 62.08004/65.80867. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.94556/65.91436. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.80816/65.97636. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.84163/66.06718. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.66391/66.01684. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 61.45786/66.00300. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.40444/66.14240. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.34851/66.15028. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.25747/66.06175. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.21178/66.18107. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.33401/66.15679. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.09806/66.18327. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.31041/66.06225. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.10560/66.11857. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.19057/65.82144. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.77385/66.14560. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.88618/65.81732. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.85883/65.98997. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.72325/65.92189. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.81978/66.02943. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.82645/65.60718. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.67998/65.86160. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 60.66910/65.77296. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.44191/65.71537. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.41463/65.73070. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 60.46606/65.76891. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.37713/65.65233. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.36664/65.56969. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.42712/65.42669. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.24288/66.00569. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.38586/65.42033. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.17081/65.63059. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.28573/65.84177. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.12895/65.52913. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 60.05117/65.59621. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.97421/65.51233. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.99868/65.42838. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.63684/65.37391. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.72301/65.30338. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.69337/65.23432. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.58486/65.24304. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.68097/65.21629. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 59.59778/65.17947. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.50009/65.15665. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.16974982846110506\n",
      "Epoch 0, Loss(train/val) 69.99099/70.71338. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 69.82441/70.47717. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.60235/70.22694. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.46389/69.95598. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.26153/69.66102. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.04779/69.32675. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.77949/68.94807. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.58120/68.50990. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.22756/68.00993. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.86541/67.44675. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.51420/66.85690. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.99876/66.27577. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.62785/65.73400. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 66.20557/65.24550. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.81460/64.81871. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.44853/64.44179. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.14183/64.10256. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.76175/63.79962. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.37905/63.53104. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.06735/63.27974. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.98506/63.05518. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.69192/62.85359. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.43573/62.70362. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.20323/62.57128. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 63.02731/62.46449. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.83753/62.37003. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.72657/62.28229. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.60085/62.18714. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.41148/62.09561. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.44939/62.01388. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.23849/61.92527. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 62.32644/61.79131. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.98402/61.66817. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.03196/61.49044. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.94972/61.34485. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.85157/61.18645. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.72991/61.00844. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.55231/60.79834. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.43671/60.66389. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.32920/60.51751. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.23078/60.42963. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.11863/60.14027. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.82941/59.98980. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.75985/59.99950. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.61321/59.90495. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.47305/59.80809. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.29724/59.81898. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 60.34407/59.59426. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.07604/59.49806. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.14017/59.28315. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.94647/59.27907. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.92133/59.17019. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.81510/58.81861. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.71811/58.73114. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.53512/58.79482. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.62520/58.51188. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 59.37732/58.68286. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.36487/58.23510. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.35017/58.23878. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.36792/57.99372. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.10336/58.04843. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.16907/57.86652. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.01717/57.89593. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.16339/57.85938. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.96678/57.83548. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 58.94913/57.58852. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.04422/57.82361. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.91256/57.68814. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.61547/57.73356. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.60292/57.65738. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.51769/57.52952. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.50724/57.49384. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.60344/57.50339. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.47124/57.24088. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 58.29656/57.20594. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.27999/57.21376. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.37090/57.25765. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 58.17373/57.22538. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.08927/57.08198. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.09211/57.14485. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.13520/56.81816. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.90822/56.99009. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 57.75961/57.00167. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.78055/56.98555. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.80625/57.13105. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 57.74707/57.33115. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.63453/57.05697. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.60606/56.77044. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.56089/56.59448. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.44763/57.10184. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.27277/57.35434. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.28597/57.87259. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.40223/58.33355. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.34812/58.58593. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.33867/58.48146. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 57.46314/58.27645. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.23846/57.75830. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.24218/57.85189. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.17650/58.12255. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.04086/58.54745. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.1088776457161647\n",
      "Epoch 0, Loss(train/val) 71.91796/71.74415. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.65311/71.49068. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 71.37428/71.23346. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 71.10586/70.96460. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.83429/70.68645. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.59667/70.39735. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 70.32093/70.10174. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.01343/69.79645. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.66910/69.47526. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.30493/69.13707. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.99643/68.77514. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.55023/68.38817. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.20560/67.97457. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.72991/67.53126. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.18195/67.06866. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.67542/66.60081. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.23085/66.14880. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.61161/65.72085. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.22182/65.32516. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.65001/64.95738. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 64.35733/64.62372. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.96993/64.32724. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.57648/64.06174. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.26926/63.82420. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.85589/63.60078. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.65354/63.38621. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 62.28684/63.18254. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 61.95418/62.99064. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 61.72933/62.79823. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.52393/62.61311. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.24858/62.42936. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.98100/62.29571. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.64426/62.17255. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.40752/62.04258. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.12607/61.89571. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.88633/61.72357. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.70339/61.54877. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.48664/61.40062. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.36109/61.27515. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.98416/61.15867. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 58.93285/61.04449. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 58.69441/60.94499. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.51038/60.84782. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.35496/60.75512. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 58.23587/60.66325. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.02751/60.57813. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 57.86805/60.49371. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.92375/60.41879. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 57.77410/60.34973. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 57.68434/60.27752. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.70757/60.19855. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.55003/60.12877. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 57.62938/60.06106. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.39192/59.97924. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.45056/59.90310. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.52242/59.84086. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 57.05982/59.77088. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.32991/59.70611. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.14099/59.63950. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.06953/59.53905. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.11927/59.46459. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.10540/59.38828. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.09705/59.31073. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 56.91017/59.21626. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 56.94436/59.11963. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.73734/59.03122. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 56.71381/58.95559. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 56.77416/58.86207. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 56.62474/58.75623. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 56.62728/58.67688. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.56741/58.58372. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.47169/58.49935. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.48087/58.40040. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 56.38429/58.27102. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.39836/58.16646. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.33546/58.05994. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.27712/57.97234. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.16263/57.86008. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.01580/57.73597. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.02260/57.60658. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 55.96349/57.48012. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 55.95717/57.36464. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 55.91974/57.23994. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 55.70216/57.15203. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 55.89137/57.02908. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.56623/56.90597. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 55.70183/56.78884. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 55.42071/56.65801. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.42852/56.55188. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 55.26708/56.37766. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.12511/56.21337. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 55.03832/56.09078. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.10205/55.97614. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 54.80566/55.83290. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 54.80373/55.72056. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 54.74494/55.61682. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 54.43920/55.46189. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 54.29801/55.41278. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 54.19302/55.28521. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 54.34676/55.22453. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.11834526708278773\n",
      "Epoch 0, Loss(train/val) 70.63170/71.58397. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.50321/71.34969. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.35542/71.10566. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.20591/70.85005. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.98905/70.57822. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.87186/70.28899. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.61613/70.00192. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.40749/69.71943. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.23192/69.42886. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.02344/69.13509. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.83251/68.84553. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.60772/68.55216. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.39670/68.24226. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.07073/67.90623. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.89242/67.55334. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.63502/67.18407. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 67.39156/66.79481. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.18762/66.37598. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.87491/65.93428. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.56932/65.46014. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.21730/64.95870. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.90293/64.43771. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.46821/63.94185. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.17871/63.46256. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.99121/63.01302. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.67595/62.61018. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.43685/62.26214. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 64.19576/61.96945. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.12610/61.76519. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.93425/61.58266. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.71545/61.42979. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.58360/61.28549. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.61625/61.17167. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.53101/61.05504. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.25608/60.97221. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.31600/60.89144. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.18245/60.82094. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.10313/60.77843. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 62.84200/60.73124. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.02494/60.69504. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.66840/60.66826. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.77344/60.64157. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.83402/60.63519. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.69204/60.61559. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.55574/60.60512. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 62.49227/60.58043. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.45341/60.55278. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.47384/60.52544. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.38474/60.48959. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.36362/60.48861. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.40387/60.48566. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.18671/60.46560. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 62.27071/60.45424. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.08572/60.43217. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.07320/60.43390. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.03251/60.41550. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.96767/60.36803. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 61.90048/60.39416. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.01683/60.39972. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.02021/60.37128. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.90608/60.34524. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 62.00449/60.32654. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.83701/60.30310. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 61.79459/60.33807. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.53438/60.26242. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 61.68659/60.25729. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 61.52739/60.19416. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.64169/60.17773. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.48590/60.19699. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.51207/60.13599. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.37351/60.08767. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.43214/60.06905. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.32703/60.04703. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.17874/59.96746. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.07466/59.92440. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.24312/59.93526. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.27625/59.89239. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.08225/59.83015. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.13878/59.81139. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.08918/59.78750. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 61.00927/59.77483. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.10599/59.74805. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.08304/59.71772. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.94634/59.66554. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.13236/59.64222. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 60.80927/59.62453. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.90749/59.62957. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.81955/59.59561. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.68099/59.57884. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.85251/59.62025. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.64892/59.67303. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.64377/59.59534. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.59450/59.57572. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.72710/59.59722. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.72204/59.50163. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.67812/59.60422. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.56548/59.57775. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.49969/59.50630. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.31879/59.59508. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 60.39670/59.52406. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) 70.39026/70.80198. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.11434/70.58711. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.88386/70.37579. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.57540/70.15802. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.30564/69.93563. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.95744/69.70306. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.65334/69.46484. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 68.27219/69.22153. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.96533/68.96863. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.65913/68.69550. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.16675/68.38964. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.80320/68.03835. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.30096/67.62742. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.76394/67.15347. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.20362/66.62585. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.74679/66.04869. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.26603/65.43960. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.66253/64.79664. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.11471/64.11086. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.60531/63.38606. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 61.99326/62.63033. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 61.52499/61.87112. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 61.09880/61.21301. Took 0.34 sec\n",
      "Epoch 23, Loss(train/val) 60.56876/60.58820. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 60.23986/60.03114. Took 0.34 sec\n",
      "Epoch 25, Loss(train/val) 60.04830/59.57985. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 59.69059/59.22044. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 59.45934/58.93063. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 59.34585/58.71120. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.12872/58.55764. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.19175/58.44645. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.19218/58.34787. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 58.98034/58.29189. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.00720/58.25668. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 58.87160/58.24478. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 58.69456/58.23857. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 58.70338/58.23725. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.70789/58.23903. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.64840/58.23524. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.58331/58.23292. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 58.61393/58.23975. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 58.57662/58.23236. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.55758/58.20976. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.53502/58.20405. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.44345/58.20779. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.32720/58.20599. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 58.19876/58.20108. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.36434/58.20193. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 58.27514/58.21268. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.07342/58.22008. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.08817/58.21408. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.00733/58.20589. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.16771/58.20662. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 57.92370/58.21086. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.99446/58.20887. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 57.90490/58.20829. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.84707/58.21199. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 57.72233/58.22484. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.91378/58.22912. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 57.73550/58.24974. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.78774/58.24610. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.68160/58.23655. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.34310/58.23327. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.56904/58.23812. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 57.51133/58.28700. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.43444/58.31340. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.15441/58.35170. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.15047/58.40388. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 57.20087/58.42550. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.10854/58.38223. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.91677/58.39013. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 56.92185/58.35716. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.82381/58.26025. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.66653/58.24480. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 56.67298/58.14256. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.64768/58.08050. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.62346/58.04156. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.34667/57.99147. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.36289/57.95321. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.11013/57.90799. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 56.20904/57.91733. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.18583/57.86709. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.16850/57.85537. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.12958/57.83651. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.28859/57.80871. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.90764/57.79566. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.06591/57.79087. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 55.98772/57.80717. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.89013/57.79305. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.96164/57.75708. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.75642/57.77821. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 55.84234/57.79708. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.80220/57.79652. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.82118/57.78347. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.90895/57.78781. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.85905/57.81238. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.72914/57.76131. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.62937/57.77770. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.68091/57.81165. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.71698/57.75172. Took 0.33 sec\n",
      "ACC: 0.34375, MCC: -0.2889738156210036\n",
      "Epoch 0, Loss(train/val) 70.15275/70.28047. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.71595/69.96191. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.30661/69.63308. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 68.83280/69.28112. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.35366/68.89574. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 67.78937/68.46741. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.06666/67.98002. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 66.22969/67.40819. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 65.37400/66.75260. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 64.41206/65.99697. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 63.43247/65.20230. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 62.53051/64.36439. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 61.75118/63.45323. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 61.06196/62.48990. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 60.39675/61.43990. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 59.69544/60.22990. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 59.14940/58.99382. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 58.41600/57.69136. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 57.61584/56.71524. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 56.91423/56.17094. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 56.64601/55.90086. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 56.20017/55.72589. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 56.16207/55.58739. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 56.01036/55.47987. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 55.96242/55.39720. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 55.88990/55.32395. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 55.81959/55.25838. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 55.73043/55.20327. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 55.63163/55.15459. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 55.31865/55.11644. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 55.38673/55.07814. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 55.33939/55.04132. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 55.33935/55.00413. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 55.27756/54.97113. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 55.22021/54.94110. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 55.24859/54.91171. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 55.23609/54.87787. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 54.94887/54.84653. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 55.05182/54.84191. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 54.87517/54.84145. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 54.90658/54.83471. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 55.06281/54.86639. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 54.85313/54.91214. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 54.72868/54.92426. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 54.67249/54.97430. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 54.53094/55.03500. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 54.54717/55.09286. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 54.49505/55.14812. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 54.50483/55.19233. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 54.39629/55.22707. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 54.39348/55.30387. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 54.25007/55.33434. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 54.23684/55.37068. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 54.26950/55.35027. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 54.06898/55.39919. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 54.17178/55.43319. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 54.16790/55.45557. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 54.10991/55.48310. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 54.02103/55.49094. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 53.99991/55.51870. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 54.09628/55.56823. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 53.90124/55.58333. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 53.97899/55.55972. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 53.87715/55.54481. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 53.80276/55.52795. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 53.69864/55.54290. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 53.71457/55.56867. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 53.68969/55.56688. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 53.62418/55.59084. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 53.61373/55.61177. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 53.57801/55.58246. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 53.54309/55.56199. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 53.54098/55.53714. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 53.70476/55.54418. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 53.38511/55.55232. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 53.46489/55.54433. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 53.35769/55.57824. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 53.46857/55.59871. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 53.36974/55.58083. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 53.30547/55.57278. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 53.36754/55.60619. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 53.37288/55.60464. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 53.33011/55.61731. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 53.24339/55.63697. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 53.18838/55.70343. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 53.17458/55.70502. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 53.17050/55.67566. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 53.15045/55.67524. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 53.08657/55.73662. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 53.11608/55.74529. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 52.83837/55.78174. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 52.81639/55.78632. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 52.84083/55.76544. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 52.82674/55.76495. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 52.82791/55.80923. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 53.00517/55.85425. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 52.76511/55.84863. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 52.79786/55.83998. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 52.77593/55.84955. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 52.62969/55.85752. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.011958266722236254\n",
      "Epoch 0, Loss(train/val) 69.69568/70.83702. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.46030/70.76643. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.28861/70.68282. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.03259/70.59902. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.77620/70.49767. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.54542/70.38231. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.19234/70.24321. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.03590/70.07867. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.58427/69.89153. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.23085/69.66279. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.96272/69.38850. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.55743/69.06804. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.01021/68.72252. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.69315/68.35484. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.05267/67.98032. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.70173/67.62149. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.19264/67.27859. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.92084/66.95765. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 63.34782/66.64484. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.13166/66.35436. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.83051/66.06301. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.57262/65.76840. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.33117/65.48272. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.04678/65.20782. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.01935/64.95745. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.79550/64.76802. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 61.35806/64.59480. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.19623/64.45566. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.03849/64.36616. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.05823/64.30764. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.00875/64.26578. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.83074/64.24564. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.70177/64.23612. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.76717/64.23492. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.61219/64.23940. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.59921/64.24811. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.56524/64.25853. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.29404/64.26060. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.39142/64.25150. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.25816/64.25869. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.00440/64.24809. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.15743/64.25298. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 59.98738/64.27309. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.93153/64.28493. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.87580/64.29294. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.94082/64.31108. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 59.79731/64.32301. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.82356/64.32326. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.76860/64.33627. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 59.67305/64.33307. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.68595/64.30691. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.61456/64.28854. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.68512/64.29063. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.62991/64.28614. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.46168/64.28680. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.43669/64.26173. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.34919/64.23595. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.19801/64.24744. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.27283/64.26498. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.22090/64.22215. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.16275/64.22084. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.22499/64.23652. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 59.13996/64.23452. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.94456/64.24345. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.98613/64.24884. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.01791/64.24596. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.11444/64.26549. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.94444/64.24921. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.01860/64.25591. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.86231/64.27589. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.85555/64.27563. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.82771/64.25788. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.70740/64.27730. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.62636/64.25436. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 58.52072/64.23969. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.66259/64.29778. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.42014/64.30376. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 58.33564/64.33899. Took 0.34 sec\n",
      "Epoch 78, Loss(train/val) 58.20027/64.27363. Took 0.34 sec\n",
      "Epoch 79, Loss(train/val) 58.43520/64.32365. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.25731/64.40695. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.21098/64.41876. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.10340/64.40179. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.00746/64.48173. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.09629/64.53766. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.04407/64.50137. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.05894/64.50367. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.80147/64.54771. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 57.97106/64.56173. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.90260/64.57327. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 57.77162/64.61529. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.65428/64.68144. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.90836/64.70139. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.81351/64.77743. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.89343/64.73637. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 57.63018/64.86435. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.60882/64.88734. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.62693/65.02055. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.60510/65.06017. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.46187/65.15537. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.09202163616785992\n",
      "Epoch 0, Loss(train/val) 70.26516/71.17310. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.96762/71.01878. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.69831/70.84795. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.44629/70.66125. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.17291/70.46204. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.93646/70.25345. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.58631/70.03593. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.23832/69.81047. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.98430/69.58370. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.57215/69.36014. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 67.19920/69.13467. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.79216/68.90285. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.43390/68.66859. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.98119/68.43484. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.47397/68.20077. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.06557/67.96225. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.67220/67.71584. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.25384/67.47200. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.69574/67.22663. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.21293/66.98580. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.92494/66.74960. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 62.45017/66.52409. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 62.17834/66.31589. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.03187/66.12285. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 61.59747/65.92988. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.42201/65.74894. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 61.04675/65.59095. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.99429/65.44232. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.81219/65.30692. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.51722/65.17398. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.55669/65.05997. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 60.32605/64.94396. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.12252/64.83486. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.98980/64.74419. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.70827/64.66667. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.54656/64.61787. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.30623/64.57880. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.38462/64.56278. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 59.10264/64.54852. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.09630/64.51528. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 59.06733/64.49053. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.85482/64.47903. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 58.82039/64.46978. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.79818/64.46086. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 58.69859/64.45218. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.44829/64.44400. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.47377/64.43557. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.38545/64.42321. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.36105/64.39952. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.23771/64.38908. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.17242/64.37971. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 58.26275/64.35390. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.05700/64.33020. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.27233/64.33521. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.04611/64.32206. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.93237/64.31105. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.79826/64.28740. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.83476/64.26854. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.89549/64.22593. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.65279/64.20045. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 57.65957/64.20839. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.60157/64.19273. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.63219/64.16022. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 57.47592/64.13655. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.53269/64.10262. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.25034/64.06721. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.29232/64.01749. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.51491/63.96914. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.36939/63.93375. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.30943/63.89241. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.17237/63.83374. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 56.99384/63.78440. Took 0.34 sec\n",
      "Epoch 72, Loss(train/val) 57.17740/63.74088. Took 0.34 sec\n",
      "Epoch 73, Loss(train/val) 57.03756/63.67919. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.98140/63.64067. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.02159/63.60389. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.83730/63.54354. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.77035/63.50948. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.67048/63.49030. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.54804/63.44657. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.72939/63.40376. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.67231/63.32862. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.62425/63.31291. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.76843/63.29553. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.49529/63.23056. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.64537/63.17776. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.49065/63.17542. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.58677/63.11108. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.42575/63.08192. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 56.37583/63.04458. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.44945/62.97977. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.39517/62.93959. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.98012/62.89333. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.15973/62.83743. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.02430/62.76537. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.16204/62.73601. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.17018/62.70399. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.89527/62.59594. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 56.10629/62.60051. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.89801/62.55976. Took 0.33 sec\n",
      "ACC: 0.5625, MCC: 0.1259881576697424\n",
      "Epoch 0, Loss(train/val) 70.76843/71.20652. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.62865/71.05581. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.44777/70.90280. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.29753/70.74723. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.15938/70.58990. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.98670/70.43647. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.82420/70.28810. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.65810/70.14353. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.51488/70.00507. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.37248/69.87151. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.19119/69.74154. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.04020/69.61292. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.87979/69.48532. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 68.67210/69.35990. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.50271/69.22986. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.39681/69.10835. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.19368/69.00076. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.97233/68.89397. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.88872/68.79601. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 67.66035/68.70889. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 67.58784/68.61553. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.45537/68.52074. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.25443/68.42852. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.11291/68.32973. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.98473/68.21753. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 66.72578/68.09382. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.62336/67.95908. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 66.45839/67.81090. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.28399/67.65343. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.08135/67.46903. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 65.95294/67.27382. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 65.75398/67.07899. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.54219/66.88913. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 65.51299/66.68388. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 65.21833/66.47735. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 64.96799/66.26103. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.76233/66.02920. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 64.40400/65.75053. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.17637/65.40736. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.97055/64.99487. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.68219/64.52722. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.19487/64.03566. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.89644/63.52958. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.52651/63.06243. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.26199/62.68126. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.12661/62.39772. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.02416/62.16893. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.65425/61.98896. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.63545/61.86881. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.52668/61.78529. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.29741/61.73308. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.18517/61.71240. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.09602/61.69381. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.96791/61.66470. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.95079/61.62251. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.78600/61.58543. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.84807/61.62014. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.70348/61.62353. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.60759/61.80146. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.74250/61.72625. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.59197/61.57131. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.60076/61.56370. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.43722/61.53144. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.31360/61.50405. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.36622/61.53806. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.10874/61.49578. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.19836/61.41916. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.11629/61.30406. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.28073/61.14933. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.18585/61.24455. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.20130/61.36992. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.98012/61.38474. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.92920/61.36356. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 59.98561/61.22792. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.09216/61.30073. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.86816/61.27718. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.76261/61.15401. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.85488/61.13087. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 59.81304/61.17493. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.84202/61.10532. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 59.87790/61.16724. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 59.72764/61.20021. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.80058/61.20924. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.80837/61.26316. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.59805/61.27212. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.71217/61.13674. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.61605/61.11568. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.50327/61.17506. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 59.65543/61.12450. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 59.56067/61.26091. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.47647/61.19801. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.32628/61.19717. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.28377/61.22190. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 59.22471/61.27244. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.20795/61.20006. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.14445/61.24238. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.13564/61.21501. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.16437/61.34412. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.12079/61.24694. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.20291/61.36679. Took 0.31 sec\n",
      "ACC: 0.46875, MCC: -0.11891767800211263\n",
      "Epoch 0, Loss(train/val) 70.48173/68.68910. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.21493/68.43240. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.97775/68.15364. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 69.75502/67.86143. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.52557/67.55373. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.27683/67.23822. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.96534/66.92278. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 68.71422/66.62054. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.41032/66.31133. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.05489/65.97402. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 67.60460/65.60564. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.12678/65.19902. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.69573/64.75806. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.14206/64.28399. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.56653/63.78196. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 65.09729/63.26654. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.62130/62.74484. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.15465/62.21426. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.71432/61.68530. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 63.32989/61.18465. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.07646/60.78716. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 62.58297/60.45147. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.46006/60.17587. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 62.30409/59.97949. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 62.15754/59.83032. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.02982/59.69789. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 61.91410/59.58484. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.99167/59.48663. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.70021/59.39785. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.61412/59.31495. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.67092/59.24651. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.61011/59.18210. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.44026/59.12273. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.38842/59.07571. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.44662/59.02829. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.20594/58.97680. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.21828/58.91802. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.03553/58.86660. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 61.20211/58.82938. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.94770/58.78860. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.90999/58.75192. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 60.91988/58.71809. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.93406/58.66962. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 60.83892/58.62757. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.75496/58.58282. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 60.76181/58.53428. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.57444/58.48030. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 60.66465/58.43930. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 60.55730/58.39157. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.47499/58.33829. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 60.51253/58.29746. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.41155/58.23519. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 60.35973/58.18976. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.35312/58.13086. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.18215/58.07975. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.22021/58.04825. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.12365/58.00335. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.18055/57.96753. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 59.94627/57.92043. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 59.91016/57.87180. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.87360/57.83065. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 59.97551/57.77901. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.89453/57.73866. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.67319/57.71189. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.69913/57.69995. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 59.63217/57.66287. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 59.71503/57.63761. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.54900/57.61827. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.50915/57.57928. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 59.47666/57.52169. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.19950/57.49265. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 59.34288/57.47750. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.44304/57.44947. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 59.20092/57.40994. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 59.30547/57.36572. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.08376/57.35085. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.25343/57.33098. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.11944/57.27625. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 59.10140/57.22759. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.87492/57.19841. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.97873/57.19242. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 59.04536/57.16384. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.05595/57.13539. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 58.99279/57.06747. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.72897/57.03474. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.80077/57.00157. Took 0.34 sec\n",
      "Epoch 86, Loss(train/val) 58.73280/56.95882. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.61993/56.92605. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.67194/56.88352. Took 0.35 sec\n",
      "Epoch 89, Loss(train/val) 58.66024/56.86179. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.47526/56.83566. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.53130/56.80251. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.47782/56.76406. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.36605/56.76910. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.46109/56.73046. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 58.41193/56.66919. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.25171/56.63530. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.20878/56.63554. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 58.36029/56.61369. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.24646/56.55899. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) 70.79141/69.94464. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.60532/69.81037. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.49401/69.68439. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.36785/69.55522. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.24573/69.42268. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.10102/69.28096. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.96669/69.12324. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.80956/68.95057. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.66877/68.75922. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.50493/68.54627. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.33844/68.30052. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.16247/68.01900. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.90447/67.70173. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.68573/67.33702. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 68.41609/66.91061. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.15887/66.44939. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.89739/65.99509. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.51756/65.52160. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.19243/65.07874. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.98740/64.67506. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.68100/64.33334. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.44263/64.04839. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.26789/63.83299. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.98979/63.66317. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.94705/63.52494. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.80459/63.41008. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.68201/63.31604. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.44137/63.23854. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 65.38063/63.18436. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.36057/63.13643. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.06737/63.10081. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.05514/63.07714. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.95757/63.05157. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 64.94517/63.01935. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.70123/62.98834. Took 0.34 sec\n",
      "Epoch 35, Loss(train/val) 64.63003/62.95450. Took 0.34 sec\n",
      "Epoch 36, Loss(train/val) 64.56828/62.92504. Took 0.34 sec\n",
      "Epoch 37, Loss(train/val) 64.51244/62.89341. Took 0.34 sec\n",
      "Epoch 38, Loss(train/val) 64.50477/62.86405. Took 0.34 sec\n",
      "Epoch 39, Loss(train/val) 64.22166/62.83538. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 64.18369/62.80838. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.14100/62.77756. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 64.08039/62.74292. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 63.92025/62.70000. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 63.84617/62.66016. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 63.62986/62.61241. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.58680/62.55417. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.52006/62.47852. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 63.32864/62.41084. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.23760/62.35213. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.19773/62.33523. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.09264/62.34507. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 62.95821/62.35872. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 62.97578/62.54741. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.82992/62.43780. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.83362/62.69611. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 62.59819/62.75553. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.60587/63.10413. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.55113/63.03532. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.50961/63.44624. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 62.50659/63.30803. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 62.41241/63.62646. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.36435/63.48656. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 62.23602/63.74611. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.11744/63.84887. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.12166/63.83112. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.02516/64.09082. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.92790/63.96390. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.83012/64.51232. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 61.82927/64.06951. Took 0.30 sec\n",
      "Epoch 70, Loss(train/val) 61.69076/64.70153. Took 0.30 sec\n",
      "Epoch 71, Loss(train/val) 61.73272/64.21815. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 61.62286/64.81725. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 61.64110/64.05893. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.59402/64.89847. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 61.51335/64.56577. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.38904/65.18420. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 61.29934/64.80129. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.24304/65.13573. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.32529/64.94762. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 61.23595/65.20969. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.06262/64.86470. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 61.01417/65.24246. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.03459/65.12435. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 60.79159/65.02779. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.87186/64.90668. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.84444/65.07283. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 60.82268/64.91180. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.77463/64.76067. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.63951/65.10172. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.59106/64.89051. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.48580/64.81371. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 60.47948/64.94025. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.46370/64.93990. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.37675/64.82086. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 60.40896/64.82369. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.44641/64.90382. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 60.16059/64.78564. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.22007/64.85553. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 60.07389/64.64838. Took 0.33 sec\n",
      "ACC: 0.59375, MCC: 0.20321305705762227\n",
      "Epoch 0, Loss(train/val) 70.70570/69.79646. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.53135/69.65049. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.35425/69.51412. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.15367/69.37617. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.95863/69.22633. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.78514/69.07854. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.58651/68.92254. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.33482/68.75758. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.16514/68.58572. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.89387/68.40800. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.72581/68.21945. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.51471/68.02695. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.24138/67.82299. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 67.97600/67.61565. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.78855/67.40022. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 67.60442/67.17903. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.32396/66.94804. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.09566/66.70804. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.84029/66.45840. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 66.67714/66.20625. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 66.42446/65.94587. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.05830/65.67238. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.88441/65.40646. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.67403/65.15176. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.39519/64.91537. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.12872/64.71853. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.91407/64.54865. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.59183/64.39446. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.31971/64.25559. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 64.24264/64.14178. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.99649/64.06469. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.95604/63.99224. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.79639/63.92193. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 63.74161/63.85523. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.66049/63.80765. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.33201/63.76839. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.39859/63.72920. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.29899/63.68991. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 63.27691/63.65233. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.14944/63.61260. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.17962/63.58281. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 63.10327/63.55822. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 63.11618/63.53561. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.80262/63.52692. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.00177/63.51426. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 62.75264/63.50552. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.86802/63.52452. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.69487/63.49524. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 62.61708/63.46316. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.66660/63.43430. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.55093/63.39845. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.55272/63.39766. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.54701/63.36962. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.32455/63.34004. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 62.29012/63.25494. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.39558/63.22485. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 62.35110/63.26900. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.31333/63.22890. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.34176/63.16767. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.20057/63.18356. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.21893/63.18135. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.04005/63.19349. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 62.08520/63.25599. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.99673/63.19869. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 61.83127/63.17404. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.92253/63.20550. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.76005/63.23534. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 61.85757/63.22342. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 61.68527/63.24639. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.66905/63.28736. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 61.62357/63.25678. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.56120/63.27500. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.50657/63.28605. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 61.52345/63.27210. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 61.48378/63.32178. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.40151/63.34935. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 61.40290/63.37862. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.39349/63.42406. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.12218/63.44245. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.31743/63.40661. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.19096/63.48151. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.89014/63.42551. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.02483/63.54921. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.88377/63.49042. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.82800/63.55563. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.72729/63.67657. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.72903/63.69355. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.66910/63.66279. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.60587/63.70643. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.53741/63.76681. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.45155/63.84637. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 60.42171/63.85652. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.26636/63.80978. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.33283/63.82396. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.27510/63.84245. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.17565/63.92552. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.13249/63.89025. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.05737/63.84310. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.98100/63.83953. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.12654/63.90133. Took 0.31 sec\n",
      "ACC: 0.609375, MCC: 0.21489596171766712\n",
      "Epoch 0, Loss(train/val) 70.45494/71.35316. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.28683/71.22002. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.20732/71.09657. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.07434/70.97549. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 69.93705/70.85799. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.84379/70.74302. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.72640/70.63000. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.58075/70.51204. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.42215/70.39309. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 69.31037/70.27229. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.12449/70.14928. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.09270/70.01418. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 68.87998/69.87578. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.69789/69.73344. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.54360/69.58580. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.33907/69.42603. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 68.18236/69.25965. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.98994/69.09541. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 67.82318/68.92521. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 67.65519/68.74797. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 67.39661/68.56634. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 67.18256/68.37961. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.95805/68.18271. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.87940/67.97402. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 66.52765/67.75505. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 66.25062/67.52120. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.11322/67.28464. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 65.82071/67.03466. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 65.60766/66.79026. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.31465/66.54513. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 65.20726/66.28939. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.94088/66.05190. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.78379/65.83410. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.50029/65.63829. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 64.45008/65.43971. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.31790/65.27287. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.06319/65.10269. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 63.93602/64.94420. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.94891/64.79620. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.60976/64.64619. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 63.56159/64.50070. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.53345/64.37852. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 63.27972/64.27612. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.10991/64.15291. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.04278/64.00703. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.97854/63.87693. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 62.88171/63.75805. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.64395/63.61722. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.55575/63.48759. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 62.48385/63.35987. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 62.41589/63.23563. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.46475/63.13493. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.12780/63.03023. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 62.18782/62.90371. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 62.16495/62.78210. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.02682/62.68098. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 62.16577/62.58085. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.99320/62.47021. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 61.92105/62.32941. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 61.79872/62.20577. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 61.71504/62.09609. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.71281/61.98589. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.60297/61.91109. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.70026/61.80670. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.56383/61.72671. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 61.46603/61.65209. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.48943/61.55918. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.28561/61.47897. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 61.39242/61.41965. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.35920/61.37026. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.29997/61.31120. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.12517/61.25800. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.06151/61.20641. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.08478/61.15785. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.96864/61.10989. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 61.13191/61.05259. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.99298/60.98584. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.11826/60.96740. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.92259/60.93467. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.03297/60.90121. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.64314/60.86324. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 60.84448/60.81235. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.85410/60.76012. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 60.68855/60.72779. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.65683/60.69513. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 60.74161/60.66224. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.60997/60.63083. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.53859/60.59676. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.61077/60.56409. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 60.60485/60.52989. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.49598/60.49997. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.57374/60.47910. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.56447/60.44485. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.57602/60.40969. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.53838/60.38768. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 60.44711/60.37457. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.42717/60.39013. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 60.41703/60.36997. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.25605/60.32349. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.16860/60.31194. Took 0.31 sec\n",
      "ACC: 0.40625, MCC: -0.19364916731037085\n",
      "Epoch 0, Loss(train/val) 70.77514/71.66964. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.52685/71.48922. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.35157/71.30293. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.16181/71.10555. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 69.95196/70.90188. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.77027/70.69315. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.56949/70.48039. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.36266/70.26965. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.11492/70.07629. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.95795/69.87724. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.72929/69.70518. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.61104/69.54436. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.36914/69.39062. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.18189/69.23894. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 67.92186/69.09378. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.74839/68.95980. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.53859/68.83187. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.37820/68.70261. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 67.25973/68.57476. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.91645/68.43976. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 66.73164/68.29881. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.56699/68.14754. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.44299/67.96853. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 66.18543/67.77729. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.98120/67.57962. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 65.80090/67.38120. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.65811/67.16856. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 65.49111/66.93218. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 65.35803/66.69555. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.23807/66.46397. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.03718/66.23547. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.83652/66.02552. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 64.76590/65.82670. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 64.56566/65.61146. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.49091/65.42806. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.31906/65.25840. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.23236/65.06011. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 64.08953/64.88631. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.02664/64.76805. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 63.62845/64.61781. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.49428/64.47417. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.27518/64.36997. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.08091/64.29863. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.00769/64.25397. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.82651/64.23640. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 62.79166/64.24644. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.61712/64.29150. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.51695/64.31607. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.40073/64.35087. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 62.36522/64.39592. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.33573/64.42921. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 62.06881/64.45215. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 62.12166/64.49638. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.07523/64.50922. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.91026/64.50732. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 61.69262/64.51299. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 61.63773/64.51962. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.60662/64.51650. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.50276/64.50182. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.64495/64.48285. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.30984/64.45099. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 61.29443/64.40979. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 61.15885/64.37394. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.10750/64.33437. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.04530/64.28936. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 61.13784/64.24927. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 60.97072/64.22372. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 60.85721/64.20419. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 60.85929/64.14934. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.80624/64.10123. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.61223/64.07248. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.62232/64.03702. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.61560/63.98503. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.55928/63.96020. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.44600/63.90128. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.25827/63.87217. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 60.22629/63.84536. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.22741/63.78526. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.01390/63.76757. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.99726/63.72968. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.01208/63.69922. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.97884/63.65042. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.95013/63.61502. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 59.82502/63.57725. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.80510/63.53732. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.81885/63.46317. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.58103/63.37372. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.61679/63.35467. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.47010/63.22234. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.28681/63.15655. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.36314/63.09189. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.28600/63.02647. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.34734/62.96827. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.18037/62.96180. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.12517/62.85780. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.03215/62.97200. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.06443/62.85700. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.92047/62.87593. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.77559/62.81286. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 58.78732/62.80716. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.10981749844451165\n",
      "Epoch 0, Loss(train/val) 70.52726/71.29259. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.36096/71.16856. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.09408/71.04464. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.79682/70.90653. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.59636/70.75207. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.44405/70.57170. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.10215/70.35936. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.85060/70.10060. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.53044/69.82712. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.22305/69.55368. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.83465/69.29616. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.55540/69.07683. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.26243/68.90895. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 67.06646/68.78931. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.65146/68.70602. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.45302/68.65515. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.18380/68.61432. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.85031/68.58044. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.72852/68.54774. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.44041/68.52430. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 65.25965/68.50719. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.08112/68.49881. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.10562/68.49709. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.82606/68.49119. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.71703/68.48964. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.48032/68.48985. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.42427/68.50516. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.31527/68.52228. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.19697/68.55311. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.07952/68.58086. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.08362/68.59692. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.05004/68.61248. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 63.83247/68.62855. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 63.78614/68.63484. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.75422/68.64069. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.82622/68.63708. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.65296/68.62967. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.57022/68.62120. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.38388/68.60841. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.37399/68.59878. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.34873/68.58925. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.16289/68.58296. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.11670/68.57628. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.09477/68.57273. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.97572/68.57303. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 62.94652/68.58516. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.85814/68.61037. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.79158/68.63684. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.75414/68.66943. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.64947/68.70813. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.62511/68.75228. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.53235/68.79437. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.46006/68.82983. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.19280/68.86868. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.20321/68.89230. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.32949/68.90688. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 62.01500/68.92032. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.07219/68.91702. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 62.09224/68.90939. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.87482/68.89722. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 61.79632/68.88860. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.82352/68.87370. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.75375/68.85587. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 61.62447/68.83482. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.47539/68.80527. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.61965/68.79575. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.42385/68.76925. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.45934/68.73959. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 61.24873/68.69623. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.25051/68.67046. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 61.04641/68.63107. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 61.09863/68.60358. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.81165/68.54927. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.91988/68.48582. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.72915/68.44827. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 60.85999/68.40876. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.68777/68.34759. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.58942/68.31001. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.53484/68.26215. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.50872/68.21037. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 60.54666/68.16018. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.35579/68.12415. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.37638/68.06107. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.33839/68.00795. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.46129/67.95287. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.20206/67.92087. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.25382/67.86599. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 60.14143/67.80497. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.09051/67.75077. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 59.97479/67.68633. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.95654/67.62184. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.91162/67.56800. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.79140/67.52885. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.85513/67.47301. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.70107/67.45214. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.67461/67.41311. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.43617/67.35381. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.54228/67.31973. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 59.51321/67.27408. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.36805/67.24508. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.06950480468569159\n",
      "Epoch 0, Loss(train/val) 70.17791/69.90200. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 69.85602/69.75818. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.53409/69.59672. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.16511/69.41627. Took 0.34 sec\n",
      "Epoch 4, Loss(train/val) 68.86188/69.22036. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.46708/69.02181. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.08491/68.80938. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 67.67578/68.61359. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.17973/68.43984. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.75171/68.28308. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.34082/68.11798. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.92607/67.92609. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 65.45703/67.66537. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 64.83962/67.32658. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.53067/66.91461. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.05267/66.50079. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.58708/66.14676. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 63.36599/65.82469. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.00629/65.52969. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.69310/65.27657. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.58114/65.04729. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.42123/64.87157. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 62.26196/64.72118. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 62.01902/64.57472. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.70459/64.43269. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 61.41217/64.32584. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.26276/64.23897. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 60.95438/64.16751. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.90137/64.09973. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 60.70209/64.03549. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.63359/63.96905. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.60197/63.92407. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.46863/63.86448. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.31546/63.82656. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.24088/63.77645. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.10396/63.73246. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.05828/63.69447. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.01881/63.61273. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.10412/63.58228. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 59.86573/63.50944. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.84904/63.47895. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 59.68540/63.40599. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.76903/63.37275. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.64048/63.24002. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.49770/63.24662. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.51461/63.18769. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.34846/63.18771. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 59.41775/63.11165. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.24241/63.08117. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 59.28175/63.03950. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.25669/62.98365. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.95923/62.89965. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.17061/62.82659. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.10270/62.76808. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.92310/62.68166. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.01279/62.60513. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.85056/62.52623. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.79242/62.44444. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 58.71616/62.37146. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.64507/62.38415. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 58.68321/62.22690. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.48357/62.22979. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.50593/62.26987. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.52899/62.18955. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.42874/62.07869. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 58.34594/62.01701. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.30718/62.07673. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.34476/62.03585. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.17305/62.01156. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.23335/61.92743. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 58.21921/61.74834. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.10437/61.76171. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 57.92594/61.85993. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.99212/61.85235. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.00042/61.83618. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 57.93021/61.63593. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.90466/61.52556. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 57.84020/61.61666. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.68553/61.57220. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.75896/61.58176. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.62521/61.51298. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.54508/61.43248. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.59149/61.45939. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.70249/61.42530. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 57.51828/61.38734. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.58201/61.45357. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 57.47554/61.42016. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.39200/61.40228. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 57.37272/61.35183. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.34079/61.32323. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.40158/61.28203. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.26181/61.33760. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.15995/61.39817. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.19455/61.37277. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.02660/61.34527. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.00060/61.27860. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 56.99823/61.25922. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 56.89397/61.31365. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.01329/61.51915. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.13813/61.59483. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.07953140787214905\n",
      "Epoch 0, Loss(train/val) 70.51464/71.66370. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.37063/71.59901. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.22039/71.53323. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.05884/71.46339. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.88234/71.38517. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.69589/71.29469. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.44044/71.18611. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.24693/71.05218. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.98808/70.89899. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.77580/70.72755. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 68.46470/70.54491. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.18712/70.37107. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 67.97986/70.20367. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.73783/70.04246. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 67.53720/69.88758. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.25964/69.73549. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.98866/69.58026. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 66.88350/69.41541. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.65306/69.24010. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 66.33858/69.04596. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 66.22064/68.83646. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.97831/68.61564. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 65.83403/68.39201. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.58167/68.17583. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.37747/67.96484. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.31610/67.77636. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 65.23360/67.61231. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 65.14033/67.45705. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 65.05929/67.32049. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.95661/67.20358. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.85998/67.09020. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.73573/66.98363. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.56647/66.89280. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.51725/66.79714. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.42143/66.70377. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.36999/66.63813. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 64.31359/66.57841. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 64.12068/66.52339. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 63.98659/66.45491. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 63.76685/66.39880. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.61720/66.34675. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 63.59438/66.29584. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.47910/66.26001. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 63.22658/66.17775. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 63.22895/66.10407. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.21922/66.04318. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 63.03795/65.91620. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.04984/65.85978. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.94758/65.66190. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 62.81108/65.69888. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.79224/65.61697. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 62.49946/65.92245. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.58901/65.48651. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 62.55552/65.65150. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 62.43357/65.93623. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.56472/65.60820. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.37321/65.64632. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.30672/65.97964. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 62.16875/65.94137. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.19078/65.69943. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.07726/65.62096. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.03348/65.60133. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 61.88564/65.48569. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 61.76119/65.65410. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.74797/65.43658. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.62356/65.43330. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.66483/65.58321. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 61.53795/65.53104. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.50995/65.96793. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.44097/65.70277. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 61.38789/65.79274. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.24013/65.56996. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.26513/66.18646. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.11027/65.57454. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.04837/65.82088. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.10933/65.79376. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.94105/66.69846. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 61.00507/65.86085. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.88158/66.84575. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.82081/66.56075. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 60.65632/66.39607. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 60.75509/66.28883. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 60.58621/66.41074. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.63456/66.60486. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 60.63580/65.97248. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.46654/65.91783. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.42220/66.62751. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.54503/66.95105. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.47468/66.68253. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 60.23923/66.00968. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.28528/66.82984. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.24448/66.97914. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.38354/66.73896. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 60.23250/66.38882. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.18532/67.08571. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.40323/66.48282. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.97576/67.34003. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.12890/67.00609. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.90365/67.03161. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.86491/67.11924. Took 0.32 sec\n",
      "ACC: 0.5, MCC: -0.0009775171065493646\n",
      "Epoch 0, Loss(train/val) 70.55051/70.70443. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.34451/70.59082. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.10130/70.48900. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.82850/70.40263. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.58953/70.31858. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.30919/70.23563. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.11627/70.15299. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.80531/70.06638. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.53609/69.97179. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.19631/69.86985. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 67.99796/69.76511. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.71705/69.66201. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 67.38184/69.55565. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.10960/69.45238. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.93583/69.34910. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.63022/69.24786. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 66.39028/69.15277. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 66.09402/69.05807. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.98269/68.96181. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.66056/68.86041. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 65.42926/68.75437. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.17736/68.62936. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.78559/68.49607. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.58310/68.34718. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 64.39962/68.18837. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 64.18038/68.02853. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.82817/67.87167. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.59329/67.73433. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.37004/67.63850. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.27768/67.55133. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 63.00137/67.49115. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.76423/67.43558. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 62.88361/67.39258. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.59002/67.36546. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.53568/67.32531. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.47843/67.30156. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.36812/67.29149. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.41330/67.28969. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.19134/67.30305. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.20565/67.30117. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.03171/67.28416. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.95939/67.27350. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.01924/67.25944. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.00068/67.24137. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.85965/67.21759. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.80265/67.20552. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.60389/67.22207. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.63801/67.22540. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.52879/67.20808. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 61.50379/67.22133. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.48672/67.21860. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.39252/67.22834. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.17450/67.23349. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 61.15157/67.21917. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.97836/67.23020. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.21650/67.21322. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.12299/67.21016. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.02155/67.21069. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.79971/67.20828. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.93829/67.21069. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 60.85494/67.22530. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.56848/67.25143. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.87933/67.22488. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.78992/67.25926. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.68371/67.26212. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 60.59011/67.25159. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.54522/67.28722. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.43895/67.26016. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.38943/67.29383. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.32422/67.26973. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.19081/67.29243. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.30635/67.21368. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.37131/67.21268. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 60.36657/67.25207. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.12524/67.26854. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 60.01486/67.26398. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.08161/67.27979. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.01298/67.30192. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 60.16121/67.32658. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.82707/67.31665. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.95053/67.33569. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.06632/67.32877. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.90220/67.33265. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.17487/67.30609. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.85528/67.34114. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 59.75572/67.32984. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.78356/67.36136. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 59.82708/67.34075. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 59.42785/67.36501. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.60971/67.37385. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 59.57940/67.37256. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 59.44753/67.39549. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.59868/67.38625. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.37412/67.36777. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 59.41038/67.40973. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.42215/67.40311. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 59.31515/67.41386. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.33317/67.43130. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.22054/67.43884. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.15282/67.41138. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.014274868079616495\n",
      "Epoch 0, Loss(train/val) 71.38456/71.01509. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.15580/70.83247. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.95287/70.64832. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.70912/70.45777. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.49880/70.25755. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.21396/70.03585. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.94461/69.78282. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 69.68376/69.51494. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 69.40547/69.24567. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.07808/68.98135. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.91684/68.72913. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.55987/68.49844. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.28929/68.29929. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.03575/68.12215. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.74169/67.97116. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 67.51220/67.84428. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.30174/67.73904. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.92592/67.66117. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.76459/67.60902. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.49416/67.58327. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.23014/67.57283. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.94291/67.55067. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 65.54536/67.51681. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.37367/67.44467. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.03356/67.32751. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 64.75815/67.17614. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.57516/67.01420. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.38470/66.84175. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.08328/66.69191. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.95807/66.55046. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 63.76843/66.39126. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.60884/66.25082. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.48330/66.08881. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.17511/65.90871. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 63.04437/65.74135. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.96155/65.59855. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.75304/65.49498. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.67791/65.33805. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.42567/65.17858. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 62.35291/65.06710. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 62.36631/64.97047. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.22789/64.91051. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.05954/64.89072. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.95464/64.88436. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 61.89372/64.86462. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.64379/64.85670. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.71881/64.88338. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.52106/64.89191. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.38753/64.95313. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 61.35105/64.99940. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.26311/65.00211. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.11887/65.04771. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.03167/65.04694. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.01582/65.02837. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.90958/65.00652. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.69247/64.95023. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 60.61937/64.88342. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.62407/64.80972. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.45124/64.75549. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.25469/64.72908. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 60.26891/64.70715. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.13213/64.70509. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.94183/64.67086. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.85947/64.67758. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.81625/64.68331. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.82558/64.66343. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.65675/64.66347. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.70810/64.64198. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.52500/64.63313. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.45555/64.64341. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.28014/64.62257. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 59.30323/64.62083. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.28551/64.61565. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.24515/64.58189. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.20893/64.54858. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.02220/64.56920. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 59.08876/64.55771. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 59.11371/64.57558. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 58.97117/64.56927. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.82482/64.55692. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 58.87526/64.58499. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.69342/64.58446. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.66336/64.58956. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.78286/64.60201. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.72708/64.61293. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 58.51565/64.62301. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.56869/64.62720. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 58.66320/64.67577. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 58.49160/64.66898. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.44359/64.68163. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 58.31384/64.68401. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.47783/64.69460. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 58.24358/64.69126. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.11512/64.72278. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.29531/64.74432. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 58.22999/64.75925. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.02187/64.77547. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 58.10264/64.77573. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.04286/64.79050. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.12967/64.78568. Took 0.31 sec\n",
      "ACC: 0.515625, MCC: 0.02421797398482414\n",
      "Epoch 0, Loss(train/val) 70.45920/69.59003. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.23873/69.42896. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.99376/69.25311. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.75212/69.05417. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.52167/68.83001. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.24844/68.56784. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.94960/68.25844. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.65258/67.88816. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.27775/67.44686. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.86705/66.93091. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.36477/66.31187. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.84853/65.58634. Took 0.34 sec\n",
      "Epoch 12, Loss(train/val) 66.19818/64.77472. Took 0.34 sec\n",
      "Epoch 13, Loss(train/val) 65.61552/63.90502. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.05446/63.05501. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.43826/62.29232. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.83864/61.63453. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.40269/61.11137. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.04877/60.70681. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.84300/60.40622. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.82202/60.18956. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 62.39266/60.01371. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.23536/59.86269. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.17315/59.72012. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.14540/59.59085. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.05131/59.46777. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 61.75529/59.34995. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.82170/59.23485. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.68257/59.11932. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 61.60927/59.00359. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.52346/58.88429. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 61.43276/58.75515. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 61.34687/58.62734. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.23935/58.51194. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.11180/58.40430. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 61.15786/58.31081. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.96407/58.23243. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.01372/58.16255. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.06638/58.08976. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 60.86845/58.03530. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.86283/57.98977. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.87099/57.96090. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.83835/57.92246. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.73764/57.89548. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.63642/57.85136. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.49448/57.83614. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.39690/57.78556. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.33879/57.73880. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.35068/57.69833. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.32564/57.66915. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.33479/57.63476. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.38666/57.61398. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.31009/57.57757. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.04235/57.54440. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 60.01123/57.49492. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.12264/57.48115. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.97909/57.42385. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.03096/57.40170. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.71703/57.33540. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.88331/57.33471. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.77988/57.27335. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 59.93885/57.18921. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.82823/57.16779. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 59.73784/57.14789. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.62058/57.12969. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.55609/57.09298. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.49975/57.06631. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.56612/57.01642. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.40442/57.00609. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.44775/56.93503. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.38758/56.98758. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.47264/56.98687. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.30019/56.88132. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.06420/56.82032. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.17763/56.79174. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.18792/56.76010. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.13915/56.75552. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.11563/56.70474. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.05357/56.69973. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.11133/56.65602. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.91327/56.61687. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.67145/56.60754. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.74079/56.56000. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.58740/56.57688. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.86541/56.50288. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.80917/56.64167. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.86472/56.46032. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.47490/56.48741. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.60213/56.39958. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.39709/56.51354. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.22259/56.44449. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.22794/56.57122. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.24141/56.44495. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.95614/56.66562. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.80903/56.51715. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.77649/56.40081. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.63709/56.40247. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.66857/56.52390. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.27306/56.54745. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.46774/56.36295. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.021098286729420077\n",
      "Epoch 0, Loss(train/val) 70.91644/71.81770. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.64345/71.67146. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.41948/71.51714. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.16433/71.35423. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.94853/71.17721. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.69554/70.98904. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.47477/70.77173. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.18941/70.52479. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.85247/70.24649. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.52545/69.91178. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.11872/69.49217. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.67744/68.95122. Took 0.34 sec\n",
      "Epoch 12, Loss(train/val) 67.16382/68.25629. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.47597/67.38287. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.81738/66.32511. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.99316/65.16830. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.18887/64.01866. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.48145/63.07834. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.91071/62.38000. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.54767/61.77928. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.06180/61.25895. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 61.78945/60.81860. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.56673/60.50464. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.36254/60.27950. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.14430/60.08109. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.01523/59.91055. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.02190/59.74821. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 60.83304/59.59911. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.73699/59.47141. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.72923/59.36557. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.64341/59.26399. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 60.53661/59.17920. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.54963/59.10273. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.43205/59.03845. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.19382/58.94950. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.28164/58.86047. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 60.07986/58.75601. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.07996/58.62593. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 59.97186/58.49947. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.92891/58.38055. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 59.78761/58.27234. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.68938/58.17091. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.58869/58.01948. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.47554/57.89598. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.30567/57.71915. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 59.30223/57.57804. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 59.30973/57.44187. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 59.24840/57.33739. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.02485/57.28367. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.94681/57.22224. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 58.91146/57.15639. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.65215/57.07694. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 58.71007/57.02814. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.71216/56.97840. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.61926/56.91175. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 58.46307/56.90462. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.36508/56.87239. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.43989/56.83578. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.29378/56.83262. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.23830/56.76676. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.16768/56.72332. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.12077/56.73242. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.03607/56.69574. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.88274/56.66755. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.96413/56.62185. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.84439/56.62145. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.73170/56.59933. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.67799/56.62540. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.67174/56.52359. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.46640/56.56369. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 57.39688/56.49709. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.33662/56.44830. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.18501/56.42738. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.23169/56.39397. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.32221/56.36624. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 56.93217/56.32856. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 56.96140/56.29475. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.03161/56.32060. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.88412/56.24097. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 56.81266/56.19556. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.76239/56.19943. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.67282/56.18299. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.75623/56.14476. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.64034/56.20884. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.60399/56.24842. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.51599/56.21051. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.39014/56.16601. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.37056/56.16629. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 56.39465/56.19624. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.22911/56.22283. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.25878/56.16819. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.27656/56.22678. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 56.22120/56.19052. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.23487/56.22270. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.16990/56.21591. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.95081/56.23096. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.91102/56.24056. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.98880/56.27001. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.89317/56.28518. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 55.79949/56.34969. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.24309042315524473\n",
      "Epoch 0, Loss(train/val) 69.00644/68.13805. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 68.55993/67.67812. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 68.18039/67.17667. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 67.75462/66.62083. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 67.23190/65.98898. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 66.67093/65.24942. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 66.00580/64.38678. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 65.22880/63.42325. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 64.39881/62.42314. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 63.70693/61.45059. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 63.22054/60.52605. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 62.56597/59.64592. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 61.97476/58.80467. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 61.39221/57.97385. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 60.94552/57.14420. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 60.23399/56.32846. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 59.79557/55.53164. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 59.14969/54.79228. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 58.63642/54.14559. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 58.18426/53.58091. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 57.82210/53.10421. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 57.48298/52.70881. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 57.21580/52.37697. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 57.07058/52.10573. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 56.72533/51.87395. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 56.64397/51.66106. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 56.59106/51.46672. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 56.40918/51.30360. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 55.98596/51.14635. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 56.09455/50.99229. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 55.89984/50.84838. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 55.84898/50.71907. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 55.66846/50.59017. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 55.53759/50.46798. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 55.41612/50.35441. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 55.41134/50.24115. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 55.29055/50.13391. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 54.99893/50.03292. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 55.20089/49.93339. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 54.99395/49.83816. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 54.83357/49.74577. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 54.85348/49.65517. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 54.71107/49.55455. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 54.65567/49.45139. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 54.44519/49.35573. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 54.44449/49.26039. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 54.39359/49.16641. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 54.41903/49.07764. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 54.31124/48.98754. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 54.21730/48.92194. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 54.06704/48.83545. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 54.03802/48.78057. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 54.03232/48.69214. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 53.87332/48.60036. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 53.85948/48.56541. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 53.83357/48.53600. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 53.95126/48.39833. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 53.67120/48.36584. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 53.88419/48.31868. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 53.81213/48.24583. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 53.70692/48.23495. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 53.50001/48.14096. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 53.60885/48.08163. Took 0.35 sec\n",
      "Epoch 63, Loss(train/val) 53.44022/48.09819. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 53.43618/48.03204. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 53.22987/47.94396. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 53.24004/47.98002. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 53.35297/47.89850. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 53.32469/47.86160. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 53.15091/47.81361. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 53.06310/47.78712. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 53.18609/47.80509. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 53.19874/47.71940. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 53.13542/47.69328. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 53.06735/47.64736. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 52.97729/47.60365. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 52.91192/47.60303. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 53.02084/47.52964. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 52.95025/47.47784. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 52.76170/47.44303. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 52.66146/47.39798. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 52.71107/47.39215. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 52.70580/47.32197. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 52.68572/47.24112. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 52.55136/47.23735. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 52.32742/47.18124. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 52.49553/47.11673. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 52.47686/47.06720. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 52.45833/47.03099. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 52.42936/47.01152. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 52.16210/46.97507. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 52.14205/46.90281. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 52.21559/46.84243. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 52.13249/46.83392. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 52.03439/46.88677. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 52.03821/46.89180. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 51.95256/46.72259. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 51.93452/46.65189. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 52.01451/46.62769. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 51.92233/46.69906. Took 0.32 sec\n",
      "ACC: 0.640625, MCC: 0.21345300090639918\n",
      "Epoch 0, Loss(train/val) 69.84177/69.77898. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.50464/69.56641. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.14536/69.33054. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 68.69357/69.05461. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.30182/68.74142. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 67.82866/68.39460. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.22636/68.02599. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 66.79487/67.66431. Took 0.34 sec\n",
      "Epoch 8, Loss(train/val) 66.21472/67.32227. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 65.62484/67.01464. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 65.12540/66.73776. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 64.64426/66.49001. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 64.22939/66.28965. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 63.93144/66.10985. Took 0.34 sec\n",
      "Epoch 14, Loss(train/val) 63.44317/65.93297. Took 0.34 sec\n",
      "Epoch 15, Loss(train/val) 63.22158/65.73434. Took 0.34 sec\n",
      "Epoch 16, Loss(train/val) 62.95517/65.52422. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.83723/65.28310. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 62.49385/65.02008. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.32358/64.75893. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.11629/64.52080. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 61.97155/64.29208. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.83082/64.05968. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.59246/63.84918. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.57160/63.67115. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.35740/63.52301. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.23679/63.38573. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.04225/63.26385. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.16177/63.16580. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.81688/63.08261. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 60.73243/62.98123. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.71023/62.88298. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.53340/62.82785. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.32073/62.75733. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.11193/62.70589. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.30270/62.67162. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.19951/62.60282. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 59.98124/62.55959. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.91651/62.52675. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.79712/62.50382. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.63457/62.48484. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.65592/62.44970. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 59.56470/62.42808. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.30378/62.39777. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.47674/62.36467. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.38723/62.34641. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.24709/62.32872. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 59.12963/62.31200. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.08217/62.28793. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.98771/62.25082. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.85531/62.20488. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 58.76650/62.16487. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 58.95278/62.12423. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.83454/62.07187. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.58838/62.01434. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.58169/61.92568. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 58.48038/61.86899. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.39944/61.75548. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.28950/61.65174. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.06127/61.56184. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 58.09565/61.47519. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.00136/61.35930. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.81832/61.26001. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 57.76305/61.20031. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.73122/61.15591. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.51107/61.05227. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.39304/61.07108. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.29109/61.01699. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 57.23410/61.02250. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.12143/60.95510. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.10525/60.89750. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.98317/60.88955. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 56.96947/60.83438. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.91824/60.79297. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.92012/60.73814. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.70348/60.75043. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.61334/60.64297. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.58375/60.62833. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.52846/60.54527. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.56168/60.57997. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.38289/60.49748. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.32551/60.47361. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.14168/60.44258. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.07267/60.38609. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 55.95319/60.45399. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.82632/60.32561. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 55.65939/60.32011. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 55.62376/60.18730. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.42200/60.10954. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 55.39898/60.04828. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.21911/59.90007. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 55.29231/59.90596. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.09762/59.76600. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.07154/59.80280. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 54.84249/59.52317. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 54.62560/59.62981. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 54.56787/59.41360. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 54.64870/59.42496. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 54.32565/59.39676. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 54.36939/59.62766. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.09812140249614061\n",
      "Epoch 0, Loss(train/val) 70.82155/70.94678. Took 0.35 sec\n",
      "Epoch 1, Loss(train/val) 70.67254/70.88654. Took 0.34 sec\n",
      "Epoch 2, Loss(train/val) 70.51397/70.82172. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.30338/70.75565. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.12164/70.69145. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.92877/70.62737. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.68413/70.56681. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.38172/70.51363. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.04506/70.44514. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.70956/70.34851. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.39568/70.24071. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.91061/70.11581. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.62562/69.97549. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.26764/69.81123. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.96303/69.61485. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.43347/69.38891. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.16223/69.13383. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.79703/68.82697. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.50286/68.48072. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.31141/68.18704. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.06428/67.92091. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.80030/67.67165. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.83391/67.45936. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.44480/67.30269. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.48120/67.16223. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.16210/67.03831. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.09724/66.94841. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 64.02644/66.90733. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.91572/66.87567. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.86805/66.85859. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.83960/66.85698. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.70493/66.86076. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.77865/66.87109. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.69306/66.88580. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.52498/66.91566. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.37631/66.94634. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.39795/66.95766. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.37566/66.96925. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.28318/67.01031. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 63.22775/67.02548. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.15972/67.02818. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.99706/67.05389. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.95451/67.05339. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.97140/67.05254. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.81715/67.06524. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.75956/67.03048. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.70973/67.06049. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.51729/67.07399. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 62.45580/67.05658. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 62.45949/67.00333. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.35815/67.04356. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.20746/67.10397. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.05420/67.06580. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.22871/67.07507. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.05998/67.02299. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.98511/67.03220. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.74500/67.09499. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.92426/67.06097. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.83263/67.06149. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.65169/67.05804. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.33594/66.97012. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.37752/66.94827. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.18214/67.01542. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.36208/66.97314. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.05220/66.99630. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.90345/67.32122. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.12126/67.49586. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.68145/67.58264. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.78259/67.83516. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.66013/67.95641. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.53182/68.24759. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.35013/68.31622. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.43192/68.46229. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.35537/68.73328. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.14712/68.84886. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.01553/68.96974. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.11591/68.93994. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.19064/69.34860. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.86300/69.39976. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.79517/69.36827. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.81335/69.34206. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.69043/69.44349. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.74702/69.51196. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.44436/69.67907. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.39772/69.58542. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.45006/69.66610. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.26697/69.72939. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.28107/69.72269. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.28654/69.80444. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.21999/69.80037. Took 0.34 sec\n",
      "Epoch 90, Loss(train/val) 59.09704/69.78914. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.06105/69.85258. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.06778/69.91855. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 59.05247/69.90628. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.00292/69.95298. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.74014/69.99630. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.02347/69.99564. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.75216/69.95479. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 58.71464/69.92831. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 58.55485/69.94873. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.07052955496249108\n",
      "Epoch 0, Loss(train/val) 70.69562/70.99563. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.50064/70.74673. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.21975/70.47900. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.02228/70.17064. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.72435/69.80123. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.37402/69.34077. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.98782/68.74796. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.45263/67.97472. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.77485/66.96616. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.96430/65.72714. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 65.96863/64.31847. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 64.90350/62.94490. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 64.02660/61.84269. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 63.29051/60.93781. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 62.65889/60.20520. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 62.41532/59.61723. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 62.01757/59.16993. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 61.67017/58.78675. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 61.51633/58.43924. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 61.27194/58.11958. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 61.03925/57.84221. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 60.86679/57.60240. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 60.66135/57.38146. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 60.53335/57.08972. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 60.39802/56.86480. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 60.06382/56.70130. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 59.99157/56.56720. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 59.82827/56.47779. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 59.81241/56.39273. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.51277/56.28249. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 59.41836/56.13734. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 59.36866/56.10588. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.19186/55.98188. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.11353/55.88017. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.12057/55.85598. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.13106/55.76133. Took 0.34 sec\n",
      "Epoch 36, Loss(train/val) 58.77082/55.72699. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.68931/55.71619. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 58.73030/55.64967. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.64681/55.62043. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.77042/55.61575. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 58.65219/55.53109. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.29747/55.48593. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 58.37831/55.38012. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.37081/55.39260. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.35491/55.32991. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.25116/55.32067. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.17389/55.27964. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 58.15660/55.21991. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.05375/55.12969. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 58.08116/55.18721. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 57.90744/55.07958. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.80704/54.99143. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 57.67611/55.03622. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.65799/54.91183. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.51238/54.94284. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 57.58794/54.84135. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 57.64047/54.80464. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.52763/54.88364. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 57.47938/54.71097. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 57.47840/54.83897. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.34221/54.72292. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 57.30488/54.64460. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.21454/54.69990. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.16092/54.62169. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.20015/54.58478. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.18760/54.53541. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 56.99818/54.56202. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.06787/54.55254. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.20681/54.50323. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 56.99956/54.60472. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 56.91671/54.51217. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 56.99362/54.47443. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.73325/54.46655. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 56.70598/54.52210. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.72142/54.47144. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.78627/54.47841. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.78422/54.51127. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.71175/54.47530. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 56.70759/54.39022. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.45264/54.57206. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.43966/54.49065. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.48402/54.45148. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.60306/54.39614. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.37126/54.51784. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.46321/54.49268. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.49971/54.47552. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.36863/54.58432. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.35440/54.50047. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 56.17032/54.50916. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.20228/54.42678. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.22191/54.46849. Took 0.34 sec\n",
      "Epoch 92, Loss(train/val) 56.08953/54.44763. Took 0.34 sec\n",
      "Epoch 93, Loss(train/val) 56.12300/54.40971. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 56.00890/54.53849. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.88243/54.53712. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.87568/54.45412. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.94825/54.42468. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.87910/54.51886. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.83291/54.48767. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: -0.04645240022848054\n",
      "Epoch 0, Loss(train/val) 69.17168/69.25203. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 68.72366/68.89585. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 68.25067/68.52934. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 67.76727/68.14909. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 67.27638/67.75020. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 66.78674/67.33534. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 66.19567/66.90915. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 65.64981/66.46076. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 64.96446/65.98086. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 64.36479/65.46129. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 63.68876/64.89689. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 63.00137/64.30991. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 62.38312/63.70711. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 61.71711/63.12000. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 61.05844/62.54858. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 60.46281/62.01130. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 59.76712/61.50473. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 59.23725/61.07613. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 58.92781/60.77988. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 58.59910/60.56594. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 58.46340/60.39604. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 58.06682/60.23435. Took 0.34 sec\n",
      "Epoch 22, Loss(train/val) 58.07055/60.07874. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 57.78086/59.93880. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 57.59626/59.80676. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 57.39742/59.68193. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 57.45661/59.57133. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 57.21789/59.46749. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 57.28222/59.37290. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 56.99958/59.28714. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 57.08881/59.20881. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 56.79103/59.12330. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 56.89610/59.04773. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 56.76080/58.97750. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 56.66158/58.89087. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 56.52576/58.83672. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 56.36870/58.71889. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 56.48411/58.66815. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 56.24430/58.51552. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 56.09800/58.51204. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 56.06467/58.40430. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 56.00021/58.41325. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 55.98100/58.32984. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 55.67913/58.37939. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 55.77217/58.26945. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 55.66379/58.31919. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 55.59728/58.21791. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 55.56661/58.27284. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 55.40841/58.13173. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 55.23212/58.14762. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 55.30487/58.11996. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 55.23872/58.10212. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 55.07190/58.05839. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 55.08033/58.06512. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 55.04019/57.96807. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 55.24063/57.97963. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 54.83758/57.98314. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 55.01698/57.93084. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 54.89261/57.87347. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 54.80744/57.82965. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 54.73530/57.81602. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 54.89822/57.85624. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 54.67546/57.73298. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 54.70981/57.71339. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 54.65005/57.71524. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 54.53211/57.75412. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 54.57551/57.59188. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 54.24056/57.53108. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 54.19751/57.55511. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 54.38792/57.59496. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 54.18180/57.52388. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 54.15086/57.52650. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 54.14233/57.29752. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 53.99553/57.50719. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 53.69942/57.30956. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 53.90213/57.36023. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 53.87042/57.32085. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 53.57813/57.11242. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 53.55197/57.29702. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 53.63406/57.21981. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 53.55082/57.27774. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 53.46321/57.23241. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 53.36095/57.02005. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 53.19471/56.98567. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 53.18460/57.06488. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 53.38459/56.94492. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 53.00915/56.94494. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 53.16387/56.98147. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 53.14297/56.84510. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 52.88467/56.79067. Took 0.34 sec\n",
      "Epoch 90, Loss(train/val) 52.92443/56.78988. Took 0.34 sec\n",
      "Epoch 91, Loss(train/val) 52.91862/56.71955. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 52.88173/56.79063. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 52.74861/56.66877. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 52.86769/56.57784. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 52.75217/56.60175. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 52.65915/56.76814. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 52.63484/56.78475. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 52.76202/56.62423. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 52.45662/56.53954. Took 0.33 sec\n",
      "ACC: 0.5, MCC: 0.013900245738365579\n",
      "Epoch 0, Loss(train/val) 70.53384/70.38105. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.24164/70.11144. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.03319/69.84149. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.69718/69.56535. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.39214/69.25588. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.01823/68.90836. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.61543/68.52231. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.16038/68.11018. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.74639/67.69777. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.33193/67.30350. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.75391/66.93903. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.37876/66.61637. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.97835/66.32770. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.72905/66.08159. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.20700/65.86659. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.05735/65.67240. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.80179/65.48640. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.55078/65.30154. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.24083/65.10099. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.98772/64.88538. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.70140/64.65633. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.54923/64.42500. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.30566/64.19247. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.14402/63.96191. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.05991/63.72709. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.78572/63.49937. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.45597/63.29929. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.39879/63.11796. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.32787/62.95436. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.17788/62.81584. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.01605/62.68799. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.06628/62.57927. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.02554/62.48603. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.87423/62.39852. Took 0.34 sec\n",
      "Epoch 34, Loss(train/val) 61.63267/62.32072. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.74508/62.23591. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.63950/62.15815. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 61.52168/62.09658. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.56957/62.04223. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 61.48634/61.98449. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.13332/61.93064. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.21795/61.88819. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 61.14926/61.85760. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.15926/61.82112. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.00765/61.78335. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.90819/61.75473. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.97283/61.74650. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.97765/61.74344. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.83592/61.73958. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.57728/61.77603. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.67614/61.82220. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.93691/61.86068. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.76522/61.92380. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.56884/61.99366. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.72145/62.02068. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.46876/62.05362. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.51163/62.10295. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.49991/62.12416. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.43088/62.18091. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.35048/62.22307. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.48406/62.26038. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.35043/62.33800. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.33852/62.40863. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.31783/62.41933. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.30256/62.36235. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.22999/62.36018. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.20001/62.40182. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.19144/62.45436. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.18141/62.52390. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.25348/62.56283. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.16749/62.58398. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.13322/62.60115. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.00876/62.62946. Took 0.34 sec\n",
      "Epoch 73, Loss(train/val) 59.98259/62.66703. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.06903/62.70491. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.01047/62.75692. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.84374/62.79522. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.84602/62.82003. Took 0.34 sec\n",
      "Epoch 78, Loss(train/val) 59.90815/62.81890. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.76527/62.82793. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.70410/62.86281. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.90620/62.85169. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.77794/62.85627. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.08325/62.90680. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.66545/62.95832. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.63900/63.00047. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.72992/63.05357. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.76895/63.06221. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 59.55097/63.08178. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.66606/63.11271. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.65088/63.13255. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.50635/63.14706. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.61227/63.16329. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.56158/63.17127. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.47734/63.21815. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.54077/63.26041. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.39654/63.31945. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 59.46402/63.37836. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.35228/63.43533. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.50130/63.43270. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) 71.30292/70.79317. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.99450/70.41673. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.71674/70.03474. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.41501/69.62996. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.09094/69.19514. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.79505/68.72456. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.35796/68.20084. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.99060/67.62901. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.52496/67.01295. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.94626/66.34539. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.27395/65.63740. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.43473/64.90913. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.60138/64.16768. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 64.74152/63.40840. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 63.76939/62.68377. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 62.85751/61.96659. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 61.88173/61.21953. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 61.33910/60.52339. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 60.80788/60.05042. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 60.55855/59.70976. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 60.31981/59.45670. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 60.14082/59.26485. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 60.03266/59.10896. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 59.92307/58.99349. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 59.74599/58.88993. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 59.56461/58.81377. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 59.51530/58.74438. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 59.45824/58.67845. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 59.46129/58.61519. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.09376/58.54886. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 59.01609/58.48030. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 58.94959/58.42037. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 58.79096/58.36665. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 58.78370/58.31252. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.62708/58.26589. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 58.57595/58.22026. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.53737/58.19047. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 58.45396/58.20775. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.31553/58.21719. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.17472/58.21391. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.18599/58.23996. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.01707/58.24050. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 58.05045/58.23455. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.01368/58.27433. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 57.86218/58.29155. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.68220/58.26846. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 57.62186/58.31704. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 57.54593/58.41026. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.68903/58.50562. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.52933/58.41675. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.34707/58.36915. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.30687/58.38720. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.38499/58.31917. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.35021/58.28047. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 57.23434/58.30874. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.18161/58.33039. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.11188/58.30737. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.01907/58.33251. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 56.99249/58.33585. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 57.05601/58.34367. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 56.88168/58.30246. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 56.83522/58.24487. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 56.87023/58.33007. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 56.76171/58.35367. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.75817/58.14724. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.72687/58.12363. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 56.59993/58.07688. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 56.59740/58.00497. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 56.56232/58.16859. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 56.63218/58.34162. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.28334/57.99168. Took 0.34 sec\n",
      "Epoch 71, Loss(train/val) 56.42124/57.94891. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.46372/57.96521. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.19696/58.12534. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 56.16483/57.96046. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.15948/58.18232. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 56.24074/58.30124. Took 0.34 sec\n",
      "Epoch 77, Loss(train/val) 56.18364/58.11825. Took 0.34 sec\n",
      "Epoch 78, Loss(train/val) 56.23961/58.20963. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.04718/58.10632. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 56.03878/58.26304. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.11734/58.25616. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 55.92731/58.05075. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 55.93869/58.06306. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 55.78779/58.13681. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 55.85645/58.01502. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 55.78988/58.05141. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 55.72413/58.11903. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 55.76509/58.18885. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.76048/58.17767. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.76908/58.24199. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.74196/58.02329. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.59932/58.02324. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 55.65406/58.14367. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.55099/58.24158. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.53371/58.20961. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.55107/58.25535. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.45204/58.52485. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 55.44322/58.27308. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.52024/58.27732. Took 0.33 sec\n",
      "ACC: 0.578125, MCC: 0.1455213750217998\n",
      "Epoch 0, Loss(train/val) 70.09041/70.21045. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.82820/69.92647. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.53905/69.62309. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.21265/69.27229. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.85310/68.87704. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.44639/68.43333. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.03863/67.94595. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.62317/67.43218. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.02351/66.89182. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.45131/66.33790. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.87516/65.78207. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.35273/65.22959. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 64.71549/64.69125. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 64.02535/64.16833. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 63.66497/63.66384. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 62.91861/63.18185. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 62.59551/62.74635. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.43589/62.37380. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 62.13808/62.02729. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 61.98269/61.67982. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 61.74098/61.33538. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 61.39567/61.03408. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.35408/60.77790. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 60.97468/60.56083. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.85856/60.37869. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 60.80964/60.23113. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.63484/60.09880. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.52672/59.98387. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 60.60706/59.87844. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.40344/59.78291. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 60.40288/59.70084. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 60.23076/59.61737. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.06917/59.54259. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.05432/59.47075. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.88792/59.40117. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.85475/59.33470. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.81503/59.27125. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 59.68712/59.21247. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 59.65535/59.15960. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.55948/59.10739. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 59.58150/59.05490. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.38238/59.00689. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 59.35544/58.95279. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.22956/58.89802. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.08993/58.84328. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 59.20165/58.82707. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.02921/58.78672. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.93708/58.77526. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.75772/58.76436. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.58416/58.74086. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.79283/58.71772. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.74795/58.73256. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 58.54630/58.64123. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.64213/58.61516. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 58.45051/58.62107. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.63713/58.50073. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 58.35435/58.55616. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.40589/58.46081. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.49937/58.46132. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.53534/58.41595. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.12042/58.39644. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.13838/58.33550. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.15151/58.32706. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.14016/58.29068. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 58.06783/58.29782. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.15758/58.26264. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 57.91829/58.23961. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.08259/58.21600. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.96875/58.19927. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.89119/58.15873. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.82937/58.15214. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.86843/58.12594. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.74324/58.10826. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.90860/58.10579. Took 0.34 sec\n",
      "Epoch 74, Loss(train/val) 57.82559/58.05387. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.82547/58.04905. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 57.72043/58.02901. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 57.76482/58.01062. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.61780/57.97872. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 57.67433/57.96060. Took 0.34 sec\n",
      "Epoch 80, Loss(train/val) 57.59608/57.96044. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 57.54399/57.94073. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 57.56113/57.92017. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.52529/57.89722. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.59488/57.88533. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.53523/57.86518. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.43603/57.84274. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.44717/57.81923. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.32724/57.79943. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 57.24287/57.77560. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.45223/57.76742. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 57.35666/57.72722. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.32803/57.72152. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.39150/57.70805. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.28472/57.69355. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 57.09923/57.67046. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.25064/57.64896. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.11300/57.63775. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.31330/57.64991. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.05641/57.63731. Took 0.32 sec\n",
      "ACC: 0.5, MCC: -0.009163235455864739\n",
      "Epoch 0, Loss(train/val) 70.40790/70.69353. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.17619/70.51043. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.87545/70.33329. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.60330/70.15004. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.37644/69.97533. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.16239/69.80660. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.92886/69.64100. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.64234/69.46772. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.26554/69.28844. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.02577/69.09629. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.61709/68.89126. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.30842/68.64851. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.86490/68.35099. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.39567/67.98177. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.86821/67.52969. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.12902/67.03755. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.44666/66.56181. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.85989/66.18678. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.56879/65.89259. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.08534/65.67992. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 62.99621/65.50124. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.68722/65.34792. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.47351/65.21152. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.18326/65.06994. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.06756/64.94876. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.92727/64.82797. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.90709/64.70113. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.66885/64.56690. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.48856/64.43170. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.41706/64.30318. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.23478/64.17121. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 61.15891/64.03801. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.15247/63.89203. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.03846/63.76698. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.98063/63.63197. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.82720/63.50541. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.93027/63.39810. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.74487/63.29087. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.74059/63.19146. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.63044/63.11441. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.33837/63.07121. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.38096/63.00228. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.34146/62.95785. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.40814/62.96320. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.29135/62.93173. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.19839/62.86335. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.00131/62.77670. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.02960/62.70420. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.98708/62.71099. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.81848/62.67187. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.91212/62.64863. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.63692/62.56793. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.72208/62.50867. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.61664/62.49972. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.49465/62.42551. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.54261/62.37199. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.34437/62.34781. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.32580/62.25336. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.17304/62.13978. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.15476/62.11972. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.20673/62.05329. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.11484/62.07840. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.05337/61.95103. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 59.17212/61.87566. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.94093/61.81575. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.76108/61.71016. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.81248/61.66837. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.48948/61.61266. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.51460/61.63566. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.52356/61.51003. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 58.41406/61.48178. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.26931/61.55070. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.31532/61.42755. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.26149/61.39919. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.01372/61.35778. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.07824/61.20844. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.15989/61.20372. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.04891/61.22186. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.70124/61.20852. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.78307/61.04128. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.68585/61.02990. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.70989/60.85618. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.61449/61.08721. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.61502/60.69764. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.60329/61.12546. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.36669/60.62873. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.58246/61.13404. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.34778/60.63552. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.45376/61.07751. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.24863/60.55617. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.14089/60.93283. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 57.22738/60.50151. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.14517/60.93177. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.02678/60.44220. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.99785/60.89159. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.98588/60.39545. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.96229/60.75554. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 56.91851/60.34071. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.04957/60.63167. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 56.65103/60.29416. Took 0.32 sec\n",
      "ACC: 0.421875, MCC: -0.1624591083221647\n",
      "Epoch 0, Loss(train/val) 70.93097/71.04853. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.69127/70.91599. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.45730/70.77916. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.21895/70.62606. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.99188/70.45419. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.75086/70.27113. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.50792/70.07069. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.22327/69.85440. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.98031/69.62753. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.75100/69.38304. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.48388/69.12897. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.22133/68.86334. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.99352/68.59637. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.77810/68.33648. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.60139/68.07953. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.29843/67.81572. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.13875/67.54379. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.87691/67.28273. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.50083/67.01981. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.17290/66.81176. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.91574/66.61507. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.65637/66.44456. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.45898/66.32030. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.16641/66.25075. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.00576/66.19631. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.83999/66.16933. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.63475/66.16679. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.47551/66.18384. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.26972/66.27856. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.19848/66.45753. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 64.12387/66.75805. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.00939/66.92913. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.83390/66.97266. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.76006/67.00789. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.56977/67.03778. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.57435/67.02547. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.50127/67.04610. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.41006/66.99441. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.20081/66.90576. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.23061/66.97314. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.93925/66.92065. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.85446/66.86423. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.87773/66.86306. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.83208/66.84566. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.70078/66.81334. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.73968/66.84714. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.37177/66.81587. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.44023/66.77663. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.37492/66.77606. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 62.32024/66.68917. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.25581/66.61121. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.74407/66.51674. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.94394/66.45579. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.12201/66.45609. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.84277/66.39291. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.87027/66.30639. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.62779/66.31142. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.56657/66.18114. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.53817/66.27165. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.50139/66.19950. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.39999/66.14064. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.36343/66.06161. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.25841/66.07971. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.25700/65.98174. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.16834/65.99145. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.97094/65.91606. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.11933/65.87096. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.12492/65.91737. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.87204/65.78550. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.87206/65.86411. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.75472/65.71498. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.90217/65.77827. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.77992/65.75538. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.83128/65.74718. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.67945/65.68307. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.56436/65.70301. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.59996/65.69557. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.39855/65.66734. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 60.70837/65.64452. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.73501/65.53903. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.76933/65.59915. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.44028/65.62083. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 60.48557/65.58367. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.34762/65.69593. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.30878/65.56755. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.17386/65.56544. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.33657/65.56114. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 60.25187/65.55492. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 60.23848/65.55790. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.23509/65.53777. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.17714/65.45895. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.14656/65.52503. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.99968/65.41038. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.03086/65.50876. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 60.26924/65.39646. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.31018/65.59095. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.15537/65.27471. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.03893/65.67410. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.16048/65.40811. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.95960/65.61536. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.11142851539596063\n",
      "Epoch 0, Loss(train/val) 70.39520/71.35069. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.17390/71.21442. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.86665/71.07877. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.67671/70.93735. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 69.40031/70.78081. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.16909/70.60127. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.89410/70.40604. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.56205/70.18832. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.29964/69.93849. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.96923/69.65492. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.72989/69.34383. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.34010/68.99084. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.97812/68.60385. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.73683/68.19652. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.26571/67.75713. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.89046/67.27403. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.77564/66.76601. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.26737/66.23372. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.04211/65.70788. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.68697/65.20718. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.36833/64.74480. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.20421/64.33316. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.02301/63.95789. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.69478/63.62284. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.68429/63.33882. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.20676/63.08462. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.25003/62.87636. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.17772/62.70227. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.91252/62.55427. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.93181/62.44863. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.96750/62.37101. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.92264/62.29934. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.91821/62.25771. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.80652/62.22631. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.54935/62.20739. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.59270/62.20790. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.61699/62.21211. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.41628/62.21890. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.43730/62.26183. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.37272/62.26778. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.27098/62.22719. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.31500/62.21635. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.22015/62.23330. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.18304/62.20869. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.17112/62.16507. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.95981/62.15668. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.01897/62.12915. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.10573/62.09827. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.99201/62.08018. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.79110/62.07062. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.69210/62.05084. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.90037/62.03234. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.83401/62.01527. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.63384/61.99923. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.70260/61.99134. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 61.62626/61.96897. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.68876/61.95527. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.75081/61.93442. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.63196/61.91313. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.44265/61.88937. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.52963/61.88055. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.26774/61.85579. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.57560/61.83173. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.29094/61.82499. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.31311/61.76949. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.23310/61.75409. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.42618/61.69592. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.24872/61.66695. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.21708/61.63042. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.16806/61.58932. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.16861/61.53706. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 61.02972/61.49147. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 61.05138/61.48253. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.04926/61.43777. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.21078/61.41039. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.89140/61.34174. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 61.10677/61.31950. Took 0.34 sec\n",
      "Epoch 77, Loss(train/val) 61.12405/61.28147. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.10680/61.27151. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.03789/61.24223. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.89261/61.19781. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.95476/61.21330. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 61.00943/61.18662. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 60.83380/61.24168. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 61.04773/61.20245. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.58120/61.19791. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.82701/61.17577. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 60.58471/61.13654. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.76794/61.16413. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 60.62204/61.21582. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.43470/61.16523. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.71548/61.22288. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.48599/61.23187. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.55107/61.17054. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 60.53290/61.23066. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.57463/61.07396. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.32947/61.15919. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.54519/61.10163. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.46403/61.19227. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.23933/61.10131. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: -0.0063072969384049705\n",
      "Epoch 0, Loss(train/val) 70.57210/70.76690. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.39545/70.60588. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.21238/70.43393. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.01398/70.24618. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.85270/70.04382. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.60112/69.83095. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.44885/69.60587. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.13590/69.36758. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.06097/69.13774. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.80456/68.91946. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.60712/68.70327. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.44572/68.49472. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.19191/68.29211. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.97300/68.08719. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.73377/67.87765. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.58563/67.66508. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.31753/67.45080. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.10704/67.23111. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.65802/67.00954. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.36854/66.78218. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 66.18010/66.55368. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.86899/66.33503. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.50343/66.11829. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.20418/65.89001. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.98135/65.67310. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.73270/65.46573. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.51491/65.27380. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.12605/65.09488. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.90974/64.93433. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.56596/64.78864. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 63.30999/64.64378. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.21943/64.49660. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.91248/64.34975. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.85023/64.18210. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.61791/63.98921. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.48135/63.74522. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.51310/63.44285. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.23756/63.13346. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.24783/62.85584. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.07341/62.66907. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.11163/62.47748. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.02554/62.29878. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.99223/62.17488. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.78763/62.08016. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.73130/61.95109. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.71467/61.84858. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.71985/61.73709. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.70410/61.71797. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.57808/61.73710. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.49553/61.72585. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.49156/61.72284. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.29772/61.68596. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.10190/61.69714. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.47134/61.70119. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.16930/61.75421. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.88904/61.74787. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.99457/61.79214. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.95421/61.79296. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.97696/61.84819. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.95869/61.93857. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.91265/61.92965. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.95402/61.91599. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.85161/61.89861. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.65869/61.94019. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.78863/61.92786. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.75133/61.95927. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.57132/61.85570. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.58026/61.81162. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.39702/61.86546. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.44863/61.86267. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.38592/61.93691. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.40161/61.84330. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.22454/61.88367. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.30934/61.75592. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.22116/61.70366. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.21504/61.69394. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.11397/61.71258. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.17198/61.75699. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 60.06551/61.64951. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.11627/61.65136. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.99318/61.54608. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.92304/61.55717. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.88062/61.70084. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.86882/61.28075. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.99053/62.26925. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.89009/61.48368. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.56709/62.07170. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.69076/61.96362. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.77285/61.77367. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 59.61584/61.37695. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.57803/62.31689. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.46909/61.70205. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.67402/61.19168. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 59.48263/62.27724. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.49586/61.73034. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.49974/61.65666. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.47706/61.85725. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.35974/61.35053. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.29609/61.87634. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.40316/61.30773. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.12800929106264186\n",
      "Epoch 0, Loss(train/val) 71.46920/71.93420. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 71.08681/71.70744. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.72105/71.49957. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.34722/71.30155. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.95142/71.08930. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.45472/70.85767. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.93124/70.59025. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.31244/70.26721. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.64078/69.88408. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.04690/69.44202. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.36971/68.92379. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 65.79531/68.30644. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.20076/67.61137. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 64.54264/66.87553. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.00553/66.15413. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 63.51482/65.48402. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.05389/64.86514. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.59005/64.29530. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 62.34053/63.77597. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 61.86180/63.28978. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 61.55258/62.87128. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.18975/62.49135. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 60.97552/62.15409. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 60.71919/61.85325. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.52975/61.58635. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 60.42232/61.33791. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.30021/61.10593. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 60.12140/60.89959. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.00241/60.69825. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.82010/60.50203. Took 0.34 sec\n",
      "Epoch 30, Loss(train/val) 59.60898/60.31546. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.50325/60.15327. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 59.21609/60.03415. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 58.92888/60.03637. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 58.65634/59.80995. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 58.50337/59.59818. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.32936/59.35101. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 58.12277/59.22430. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 57.84025/58.94634. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 57.58373/58.77821. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 57.40387/58.61543. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 57.15917/58.40968. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 57.10991/58.26629. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 56.96961/58.16055. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 56.82522/58.04433. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 56.42421/57.81929. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 56.38054/57.73112. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 56.29023/57.64022. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 56.42164/57.56544. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 56.11031/57.50161. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 55.94095/57.40965. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 55.82254/57.37663. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 55.72282/57.32425. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 55.70041/57.28777. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 55.57210/57.24182. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 55.62981/57.15484. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 55.28791/57.07224. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 55.26438/57.02504. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 55.33374/57.02887. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 55.23195/57.06594. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 55.02586/56.99885. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 54.97934/56.88081. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 55.11468/56.85461. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 55.01544/56.91818. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 54.83990/56.94340. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 54.84822/56.98185. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 54.61018/56.92818. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 54.80574/56.96638. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 54.85865/56.76397. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 54.69864/56.70684. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 54.45025/56.77730. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 54.43191/56.84980. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 54.45930/56.83415. Took 0.34 sec\n",
      "Epoch 73, Loss(train/val) 54.40661/56.74680. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 54.29573/56.65248. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 54.34294/56.73793. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 54.18941/56.80592. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 54.33371/56.63918. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 54.20290/56.65281. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 54.19068/56.73962. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 54.15689/56.71198. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 54.37238/56.50798. Took 0.34 sec\n",
      "Epoch 82, Loss(train/val) 54.09976/56.62298. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 53.98432/56.59166. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 53.86284/56.73727. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 53.84626/56.83622. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 53.73651/56.74702. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 53.68455/56.75897. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 53.68727/56.73610. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 53.58751/56.76393. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 53.40087/56.74999. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 53.56781/56.75070. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 53.52768/56.74326. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 53.54662/56.69364. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 53.44561/56.70596. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 53.51602/56.59370. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 53.75428/56.46619. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 53.52852/56.68133. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 53.29937/56.74630. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 53.70996/56.51311. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: 0.026948402781814772\n",
      "Epoch 0, Loss(train/val) 71.15680/71.15634. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.93774/70.98820. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.69536/70.80683. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.43592/70.60599. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.22722/70.37934. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.92346/70.12636. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.66624/69.85307. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.35426/69.57163. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.08397/69.27753. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.80544/68.96557. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.41554/68.63357. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.07489/68.27473. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.65557/67.88416. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.24333/67.46605. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.77896/67.02489. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.28215/66.56124. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.86144/66.07452. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.35526/65.57032. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.85495/65.05267. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.42098/64.44633. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.94226/63.69532. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.45377/62.96643. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.02649/62.32322. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.63936/61.75441. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.33635/61.18731. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.98346/60.73775. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 61.74517/60.40458. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.49207/60.14832. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.34203/59.97179. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.08939/59.85281. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.95988/59.71463. Took 0.34 sec\n",
      "Epoch 31, Loss(train/val) 60.88613/59.59288. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.71942/59.48578. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.64455/59.37326. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.40609/59.28077. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.34260/59.19372. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 60.23725/59.11549. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.13676/59.06633. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.23309/59.03092. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.10936/58.99497. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.03528/58.96253. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.93522/58.89828. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.75249/58.94699. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.83306/58.94261. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.83543/58.84558. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 59.79280/58.89702. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 59.59285/58.95473. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.68314/58.90591. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.39096/58.93439. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.64451/58.90285. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.51026/58.92232. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.44316/58.93326. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.37875/58.90786. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.47505/58.83765. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.33162/58.77196. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 59.36831/58.79252. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.34556/58.79561. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.28985/58.79165. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.21538/58.76138. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 59.20662/58.74475. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.30355/58.75924. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.39060/58.77222. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 58.99192/58.77190. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.00224/58.75412. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.05037/58.72530. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 59.01950/58.69176. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.11109/58.65527. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.92824/58.64829. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.95595/58.64681. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.85617/58.63778. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.08143/58.67390. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.90760/58.67801. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.72501/58.67461. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.87283/58.63340. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 58.77860/58.60298. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.80089/58.58540. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.80124/58.61414. Took 0.35 sec\n",
      "Epoch 77, Loss(train/val) 58.68663/58.62897. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.72882/58.59731. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.97674/58.60611. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.60233/58.57432. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.52644/58.58370. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.67273/58.54650. Took 0.34 sec\n",
      "Epoch 83, Loss(train/val) 58.52341/58.57405. Took 0.34 sec\n",
      "Epoch 84, Loss(train/val) 58.61640/58.61517. Took 0.34 sec\n",
      "Epoch 85, Loss(train/val) 58.54089/58.57828. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.54821/58.59604. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.41992/58.57814. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.44298/58.59209. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.46906/58.52298. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.45901/58.53148. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.50926/58.59246. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.35029/58.55129. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.26980/58.62043. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.32170/58.58294. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.28512/58.53548. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.34105/58.58966. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.23618/58.51802. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.43192/58.45267. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 58.05400/58.41560. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.05979133361118127\n",
      "Epoch 0, Loss(train/val) 69.15824/68.97409. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 68.91720/68.77796. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 68.68248/68.55994. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 68.38218/68.31633. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.14290/68.03561. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 67.80637/67.70508. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 67.49572/67.32766. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.08322/66.88798. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 66.62200/66.39412. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 66.07348/65.86352. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.63682/65.32642. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 65.16541/64.81098. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 64.63457/64.33238. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 64.16612/63.88935. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 63.74285/63.49767. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.48217/63.16114. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.11772/62.86097. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.93118/62.59874. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 62.70137/62.37351. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.45770/62.18488. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.38226/62.01186. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 62.12873/61.85962. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.98021/61.72059. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 61.86474/61.59812. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.81687/61.49397. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 61.72386/61.39972. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.35084/61.32011. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.50366/61.21484. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.23193/61.12627. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.25754/61.05926. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 61.11477/60.96606. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.10733/60.98799. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.05480/61.02882. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.94578/60.91386. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.03496/60.85872. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.98017/60.77301. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.83008/60.74966. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.75606/60.76454. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.72195/60.86502. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.74215/60.80065. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.64197/60.60542. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.85485/60.54454. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.49981/60.49236. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.62518/60.43636. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.67018/60.44215. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.29541/60.35594. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.37881/60.32578. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.29320/60.26771. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.43546/60.10188. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.38679/60.13287. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.67653/60.16359. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.33748/60.00142. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.43264/59.95131. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.34494/59.96643. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.30459/59.83370. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.35030/59.75511. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.05793/59.71485. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.25286/59.69073. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.28707/59.61515. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.27575/59.58204. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.07104/59.50685. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.19382/59.45014. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.06547/59.37968. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.03620/59.32413. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.97729/59.27550. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.01680/59.24336. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.06832/59.18976. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.83438/59.15276. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.03657/59.09338. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 59.97079/59.05136. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.83740/59.11626. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.88477/58.98624. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.94033/58.97826. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.64696/59.00762. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.94062/58.94572. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.48792/58.97864. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.56318/58.98536. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.50963/58.94131. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.65104/58.99022. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.46507/59.00687. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.44842/58.96953. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.30923/59.03972. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.49346/58.99072. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.33412/58.97039. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.23340/59.01949. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.37665/58.96906. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.10409/59.00378. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.30365/58.95921. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.25141/59.01914. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 59.19377/58.85318. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.19441/59.06986. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.31553/58.96992. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.16424/59.00398. Took 0.34 sec\n",
      "Epoch 93, Loss(train/val) 58.97779/58.97746. Took 0.34 sec\n",
      "Epoch 94, Loss(train/val) 59.10515/59.04632. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.20752/59.06980. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.10575/58.96807. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.81020/59.13050. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.89404/59.12473. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.96472/59.07334. Took 0.33 sec\n",
      "ACC: 0.359375, MCC: -0.21826836858277812\n",
      "Epoch 0, Loss(train/val) 70.65279/70.75765. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.49341/70.64759. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.32915/70.54070. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.15113/70.43676. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.93209/70.33537. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.69824/70.22482. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.52179/70.10748. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.23637/69.97669. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.02594/69.83517. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.75937/69.66501. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.44251/69.48084. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.17577/69.27770. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.91137/69.05941. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.40911/68.80756. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.17436/68.51590. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.80015/68.18282. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.46316/67.81989. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.10676/67.43322. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.60734/67.03098. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.31066/66.61614. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.07752/66.21409. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.60339/65.81583. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.19273/65.43372. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.77100/65.05978. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.70644/64.71774. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.45932/64.41746. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.10070/64.14603. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.80497/63.90760. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.58617/63.72485. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.54599/63.58245. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.31734/63.47171. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.18292/63.37469. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.09927/63.28450. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.10068/63.19863. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.89668/63.13348. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 61.98535/63.07862. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.82783/63.02549. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.77902/62.97697. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 61.57025/62.92582. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.68519/62.87553. Took 0.34 sec\n",
      "Epoch 40, Loss(train/val) 61.57965/62.81713. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.39693/62.75159. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.29139/62.69302. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.11326/62.62962. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.06137/62.55128. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.01595/62.45711. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.99777/62.35202. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.98056/62.22525. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.76189/62.08281. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.56007/61.94334. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 60.43254/61.83163. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.30921/61.69921. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.33878/61.56310. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.96267/61.42858. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.93848/61.28543. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.01819/61.15725. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.67812/61.00735. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.57699/60.90009. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.46905/60.78981. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.56474/60.64171. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.53497/60.54697. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.32206/60.42719. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 59.27208/60.35992. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.16398/60.21993. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.07772/60.09526. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.71413/60.00436. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.75191/59.90013. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.81746/59.79563. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.63924/59.66268. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.63014/59.59127. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.38000/59.45476. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.39532/59.37661. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.35235/59.25114. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.25506/59.16125. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 58.10991/59.03954. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.11509/58.97933. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.80729/58.84425. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 57.83999/58.76752. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 57.65206/58.65890. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.88989/58.55742. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 57.62698/58.44330. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.51158/58.33469. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 57.54044/58.23089. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.25382/58.12759. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.28663/58.02889. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.38946/57.93785. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 57.03300/57.83924. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.97564/57.72330. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 57.16938/57.61869. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.02447/57.54546. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.90394/57.42930. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.72019/57.33051. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.70554/57.28544. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.72627/57.15331. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.67755/57.12803. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.50845/57.05161. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.66331/57.00409. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 56.40578/56.94923. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.36076/56.87486. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.02787/56.83047. Took 0.33 sec\n",
      "ACC: 0.4375, MCC: -0.10881399260327249\n",
      "Epoch 0, Loss(train/val) 69.96262/69.04801. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.70934/68.85848. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.47996/68.65605. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.17668/68.43784. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.89665/68.19772. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.51218/67.93117. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.22008/67.63773. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.84590/67.32734. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.31077/66.99468. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 66.84890/66.64338. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.39912/66.29105. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.93448/65.94523. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 65.42257/65.60757. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.02743/65.28153. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 64.74722/64.97421. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.30764/64.68825. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.97098/64.47524. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.78140/64.29614. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.66235/64.15408. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.47016/64.02798. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.28819/63.91226. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.07977/63.81160. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 62.92376/63.72717. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 62.73157/63.65278. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.61910/63.58030. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.41374/63.51923. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.54594/63.47645. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.34109/63.43162. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.25251/63.38845. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.04381/63.35731. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.05463/63.32563. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 61.85353/63.27667. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.60407/63.21223. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.48636/63.13123. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.38738/63.06195. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.40574/63.00980. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.21947/62.92450. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 61.21270/62.85733. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 61.19707/62.81839. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.90839/62.74864. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.89656/62.71503. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 60.63180/62.68451. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.75062/62.63699. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.58841/62.58707. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.36467/62.54753. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.26390/62.56119. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.28639/62.55746. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.16928/62.52265. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.02184/62.45275. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.91809/62.42094. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.63793/62.38155. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.65235/62.36126. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.54326/62.35188. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.43508/62.29447. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.28145/62.27056. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 59.21407/62.25438. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.15037/62.20943. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.92033/62.21517. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 58.78242/62.18466. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.65767/62.11603. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 58.51653/62.12545. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.64285/62.11208. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 58.31991/62.13065. Took 0.34 sec\n",
      "Epoch 63, Loss(train/val) 58.43506/62.15628. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.27142/62.20372. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.13756/62.20891. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 58.30425/62.23218. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.01884/62.27083. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 57.88188/62.28942. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.88954/62.32473. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.68258/62.28941. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.68799/62.33568. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.66662/62.34274. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 57.67205/62.32360. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.61793/62.38427. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.45747/62.36759. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 57.26733/62.37252. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 57.31669/62.42936. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 57.24669/62.43861. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.35041/62.47006. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 57.23252/62.46174. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.22468/62.41468. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.13541/62.40865. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.93715/62.44182. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.96650/62.43137. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.94557/62.41712. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.71468/62.42970. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 56.83436/62.40580. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 56.66712/62.40116. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.43541/62.34824. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.65891/62.35722. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.39449/62.37354. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 56.37323/62.32751. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.36864/62.37200. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.18677/62.36398. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.23608/62.27323. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.10604/62.30334. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 56.03743/62.23285. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 56.24650/62.21614. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.98137/62.21855. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.019557778346917184\n",
      "Epoch 0, Loss(train/val) 69.98663/68.12662. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.70638/67.86526. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.44660/67.57267. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.17434/67.24699. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 68.82914/66.87016. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.43362/66.45599. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.07955/66.01466. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.55713/65.55271. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.99477/65.09785. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 66.30569/64.65874. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 65.80004/64.26557. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 65.01019/63.89955. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 64.27512/63.54215. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 63.57512/63.18575. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 63.01103/62.86116. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 62.36297/62.55721. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 61.85398/62.26358. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 61.40377/61.98634. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 61.21450/61.73457. Took 0.34 sec\n",
      "Epoch 19, Loss(train/val) 60.86386/61.50473. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 60.68332/61.25859. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 60.53582/61.00254. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 60.33351/60.76876. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 60.03013/60.56933. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 59.94948/60.38418. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 59.82239/60.22275. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 59.89748/60.15104. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 59.76663/60.06186. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 59.72840/59.96499. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 59.77478/59.88361. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.33874/59.80667. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 59.33641/59.74643. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.50417/59.69423. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 59.44275/59.64457. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.25877/59.57734. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 59.26338/59.52649. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.06005/59.47001. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.12412/59.40448. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 59.13735/59.34774. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.15395/59.29956. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 59.10410/59.25549. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 59.08224/59.21857. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.01256/59.18264. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 58.89884/59.11696. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.90532/59.07787. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 58.88903/59.02722. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 58.90037/58.98560. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.81470/58.95457. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 58.87614/58.89528. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.79514/58.83818. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 58.84853/58.81393. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.79317/58.80295. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 58.74943/58.79379. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 58.60963/58.78733. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 58.66094/58.78166. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 58.50069/58.76268. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 58.46326/58.74745. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.76961/58.72189. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 58.41426/58.72844. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.68458/58.72344. Took 0.34 sec\n",
      "Epoch 60, Loss(train/val) 58.58760/58.70921. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.40196/58.68655. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 58.49724/58.67359. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.49489/58.65310. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.37748/58.63323. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.53351/58.61061. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.34256/58.61586. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.38309/58.61332. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 58.36551/58.60860. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.33113/58.60794. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 58.44664/58.60126. Took 0.34 sec\n",
      "Epoch 71, Loss(train/val) 58.27536/58.60078. Took 0.34 sec\n",
      "Epoch 72, Loss(train/val) 58.27160/58.58955. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.18308/58.59013. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.90836/58.68109. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 58.11981/58.63998. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 57.90976/58.68499. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 58.01022/58.76480. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.02351/58.93458. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 57.89272/58.84069. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 57.78715/59.22575. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.96746/59.02917. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 57.86276/59.39579. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.66027/59.34281. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.57869/59.53368. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.64681/59.51845. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 57.59322/59.72963. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.66004/59.54990. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 57.42505/59.86365. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 57.47105/59.61645. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.42614/59.95213. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 57.54337/59.77514. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 57.34621/59.96166. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.34104/59.94449. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.52988/60.07352. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.30420/60.00902. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.53775/60.18821. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.16020/59.79376. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.39176/60.07986. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.18017/59.83872. Took 0.33 sec\n",
      "ACC: 0.65625, MCC: 0.1002139840590231\n",
      "Epoch 0, Loss(train/val) 70.35671/70.07605. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.16426/69.98938. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.97698/69.89748. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.72171/69.79797. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.51731/69.68421. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.27049/69.54941. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 68.99011/69.38995. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.74654/69.20634. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.47165/68.99066. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.10629/68.74448. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.83886/68.47873. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.50515/68.20693. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.26227/67.95161. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.98602/67.71522. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.74936/67.49937. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.54189/67.29070. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.35503/67.08516. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 66.26886/66.88551. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.90382/66.68679. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.73065/66.48027. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.50537/66.28310. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 65.31986/66.08937. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.04978/65.91254. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.80867/65.72024. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.47643/65.48683. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.19145/65.28671. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.10238/65.10307. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.72685/64.94746. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.56901/64.70699. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.49833/64.58819. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.26528/64.31872. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 62.98151/64.14182. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.87109/63.94905. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.60436/63.75534. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.43850/63.56322. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.26818/63.42443. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.21275/63.25058. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.01136/63.06006. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.90053/62.89236. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.56598/62.72175. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.58841/62.54732. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.41544/62.39283. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 61.27532/62.25883. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.24538/62.07719. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.10847/61.99508. Took 0.34 sec\n",
      "Epoch 45, Loss(train/val) 60.95965/61.91959. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.87376/61.88396. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.68873/61.82905. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.60312/61.76595. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 60.57908/61.75268. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.41805/61.66159. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.26680/61.69630. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.20048/61.66550. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.08099/61.68739. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.20945/61.62799. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.88076/61.63750. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.73915/61.59303. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.68951/61.59793. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.80758/61.64556. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.67505/61.60983. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.50505/61.58110. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.61546/61.58947. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.51018/61.59169. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.42447/61.53215. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.26251/61.58529. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.20328/61.63442. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.10135/61.62926. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.15649/61.58826. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.18056/61.52308. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.22127/61.54815. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.05329/61.45175. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.92437/61.55385. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.03211/61.49732. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.82035/61.48801. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.91159/61.52198. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.80519/61.48026. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.65468/61.49904. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.76117/61.47528. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.63938/61.45796. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.64257/61.45833. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.52436/61.47382. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 58.31663/61.38598. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 58.25989/61.37036. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.31849/61.35646. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.25414/61.36524. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.16041/61.31347. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.16979/61.21746. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.12975/61.29985. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 58.13900/61.32338. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 57.87552/61.37551. Took 0.30 sec\n",
      "Epoch 90, Loss(train/val) 58.06586/61.38749. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.85731/61.35035. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.76940/61.40189. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.64263/61.36296. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.66063/61.32627. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 57.63922/61.30802. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 57.67533/61.28230. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.49099/61.26434. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.54867/61.28230. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 57.55518/61.42423. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.048507125007266595\n",
      "Epoch 0, Loss(train/val) 71.25638/72.20440. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.00625/71.98255. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.74088/71.77038. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.47633/71.56399. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.14011/71.36540. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.85127/71.16036. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.58351/70.93549. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.26973/70.69009. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.92624/70.42077. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.63318/70.12944. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.29548/69.82393. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.96485/69.52405. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.59479/69.23112. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.31935/68.94391. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.98091/68.65460. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.71792/68.35716. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.34626/68.05629. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.12760/67.75973. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.75478/67.48279. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.50780/67.23566. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.31211/67.02530. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.11098/66.83917. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.80275/66.67077. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.70439/66.51237. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.54772/66.36307. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.57797/66.22345. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.37955/66.08839. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.18900/65.96905. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.99512/65.85426. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.07507/65.74661. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.00908/65.64340. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.91385/65.54515. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.88751/65.44711. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 63.73789/65.34624. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.68322/65.24582. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.56494/65.14522. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.42824/65.03861. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.50409/64.92709. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 63.33440/64.81027. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.39582/64.67836. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.16733/64.52509. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.13478/64.35213. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.81970/64.15330. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 62.92119/63.92933. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.64618/63.69930. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.49020/63.50308. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.41010/63.34671. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.26375/63.22712. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.08898/63.13274. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.05911/63.05562. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.01781/62.99340. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.03680/62.93565. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.06149/62.88952. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.91774/62.84740. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.82554/62.80112. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.81568/62.75891. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.86040/62.72423. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.72572/62.68680. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.88443/62.65722. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.70655/62.61401. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.61062/62.56838. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.68256/62.53349. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 61.54398/62.47744. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.40141/62.42604. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.35493/62.34768. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.26767/62.24068. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.18350/62.05486. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.09747/61.81152. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.93871/61.62228. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.90571/61.50967. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 60.79659/61.40957. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.75208/61.32416. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.72045/61.26293. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.65331/61.24331. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.63551/61.22577. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.72116/61.19479. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.56755/61.17897. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.45824/61.14186. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.49802/61.10150. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.46606/61.08704. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.30488/61.08563. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.28741/61.06359. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.34778/61.06820. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 60.10416/61.05057. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 60.25063/61.06281. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 60.27981/61.05577. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.21882/60.91750. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.04123/60.96191. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.15183/60.94035. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.16034/61.04927. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.09578/60.80080. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.85709/60.96900. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.94117/60.70306. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 59.99630/61.03194. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 59.96991/60.62960. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.99872/60.81147. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 59.82642/60.66241. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.86941/60.77892. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.90196/60.55931. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.73824/60.72836. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.0416070055112537\n",
      "Epoch 0, Loss(train/val) 70.64221/69.71460. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.49304/69.64447. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.34192/69.57130. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.19786/69.48582. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.02675/69.39340. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.81247/69.28440. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.62680/69.16257. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.37841/69.02576. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.13632/68.87469. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.90050/68.70824. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.63688/68.53004. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.30082/68.34352. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.10456/68.15719. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.79843/67.98190. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.47055/67.81767. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.08714/67.65592. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.74104/67.48853. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.32582/67.27953. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.03996/67.01794. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 65.68886/66.69778. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.39824/66.36578. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.15245/66.04413. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.74125/65.73120. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.54633/65.47837. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.98050/65.27087. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.02157/65.08992. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 63.82412/64.94220. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.66286/64.80499. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 63.48276/64.67648. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.45797/64.56361. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 63.19374/64.45051. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 63.11638/64.34789. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 62.93403/64.25712. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.84755/64.16440. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.76990/64.08403. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.57923/64.00991. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.68220/63.94228. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.71224/63.86305. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.52751/63.79913. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.41577/63.73902. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.37441/63.67102. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.39495/63.62469. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.29534/63.57407. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.23483/63.51794. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 62.27283/63.46461. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.24059/63.42990. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.13500/63.37543. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.07339/63.31998. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.00058/63.26797. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.07754/63.23243. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.00561/63.18230. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.00345/63.14022. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.85777/63.12547. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.87114/63.10025. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.87602/63.05045. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.90243/62.99837. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.75321/62.93940. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 61.70988/62.90500. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.91704/62.86445. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 61.82153/62.80077. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.68792/62.73743. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.72296/62.68264. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 61.54007/62.64001. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.86522/62.59430. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.67413/62.55104. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.76190/62.50287. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.46977/62.47511. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.40629/62.45108. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.62811/62.43773. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.58116/62.40819. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.37194/62.36341. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.53349/62.33601. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.43235/62.26744. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 61.70051/62.21610. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 61.43167/62.18072. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 61.49724/62.14637. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.28449/62.11581. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.35164/62.10076. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.30976/62.08849. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.42007/62.06015. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.20735/62.01785. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.24976/61.97653. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.16077/61.93093. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.24828/61.88914. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.22899/61.86032. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 61.22403/61.81234. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.23586/61.78837. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.14964/61.76227. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.07004/61.72909. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.07330/61.69283. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.05512/61.67045. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.06658/61.65671. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.03703/61.62516. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.07247/61.59658. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.92473/61.57017. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.04373/61.56329. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.88775/61.55163. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.04951/61.52482. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.73414/61.48978. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.89049/61.45749. Took 0.32 sec\n",
      "ACC: 0.390625, MCC: -0.21943699408049175\n",
      "Epoch 0, Loss(train/val) 70.65342/70.22504. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.54538/70.13641. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.38756/70.05999. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.27305/69.99170. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 70.15106/69.93006. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.97226/69.86775. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.85946/69.80119. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.66611/69.72503. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.52413/69.64098. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 69.33157/69.55077. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.14424/69.44711. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.92397/69.33940. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.69779/69.22339. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.52242/69.09223. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 68.42803/68.96002. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.18226/68.85626. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.08716/68.74552. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.93969/68.61974. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.85500/68.49621. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.58465/68.36755. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 67.48556/68.24004. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.35665/68.11340. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.32664/67.98662. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.15228/67.86413. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 67.05971/67.74131. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 67.10255/67.63627. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.81365/67.51713. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.89412/67.39901. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.72209/67.28247. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.82885/67.17002. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.58278/67.06696. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 66.58142/66.96626. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 66.51919/66.85636. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 66.50540/66.76470. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 66.49745/66.69348. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 66.38141/66.62145. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 66.37293/66.54702. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 66.18546/66.47701. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 66.13966/66.40195. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 66.09563/66.31538. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 66.05796/66.24014. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 65.99307/66.16468. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 65.90779/66.10985. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 65.81292/66.04762. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 65.81496/65.97639. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 65.78527/65.92674. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 65.66605/65.88541. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 65.75021/65.84838. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 65.69085/65.82526. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 65.69414/65.78365. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 65.55765/65.75858. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 65.48186/65.74260. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 65.52143/65.73015. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 65.35051/65.70358. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 65.29388/65.64819. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 65.42644/65.59461. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 65.21799/65.56345. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 65.08594/65.49149. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 65.12315/65.47919. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 65.08431/65.42036. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 64.89630/65.34977. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 64.92249/65.33199. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 64.90528/65.30153. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 64.92865/65.25877. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 64.79074/65.23129. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 64.87073/65.16645. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 64.61530/65.17088. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 64.69673/65.08982. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 64.52227/65.11054. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 64.54143/65.09179. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 64.52055/64.99648. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 64.35027/65.01910. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 64.41082/64.91624. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 64.26611/64.89739. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 64.11330/64.95401. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 64.04184/64.82874. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 63.97618/64.81917. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 63.96641/64.72252. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 63.86438/64.84900. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 63.88545/64.64584. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 63.65100/64.83879. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 63.66330/64.54604. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 63.71640/64.85493. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 63.73795/64.59372. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 63.59316/64.66708. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 63.43510/64.71529. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 63.57976/64.60999. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 63.45218/64.57548. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 63.50688/64.83695. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 63.37186/64.76083. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 63.19485/64.67568. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 63.08046/64.77139. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 63.27729/64.76834. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 62.97079/64.78340. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 62.94061/64.54101. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 62.94754/64.66666. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 62.90060/64.56902. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 62.66633/64.49476. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 62.70744/64.37738. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 62.86451/64.28200. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: 0.018122009407318746\n",
      "Epoch 0, Loss(train/val) 70.77815/71.43708. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.58606/71.30500. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.48028/71.18130. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.36973/71.06485. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.22847/70.94662. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.08930/70.83070. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.91663/70.72308. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.75000/70.61950. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.60808/70.51383. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.51690/70.41525. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.33518/70.31055. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.20438/70.21030. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.98931/70.10419. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.83932/69.99830. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.64655/69.87658. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 68.45839/69.73640. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 68.28354/69.58324. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.09853/69.40636. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.83595/69.20055. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.66488/68.96222. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 67.45894/68.69100. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.18096/68.39626. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.99386/68.06991. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.81522/67.70526. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.53465/67.29349. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.41894/66.83998. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.17095/66.36245. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.07687/65.84624. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.99920/65.33216. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.78864/64.82768. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.58300/64.35372. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.57145/63.93581. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.44946/63.53450. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.44431/63.18968. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.38488/62.92410. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.18458/62.68679. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.04199/62.49413. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.85427/62.36827. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.83257/62.28471. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 64.83766/62.23912. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.56219/62.16237. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.66181/62.09622. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.60691/62.03819. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 64.51195/61.98265. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.38666/61.99229. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.30750/61.94823. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.30243/61.89569. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 64.25593/61.83710. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.11558/61.83180. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.00442/61.84325. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.93416/61.83809. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 63.95098/61.82974. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.91017/61.86549. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.82734/61.88206. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.75048/61.93139. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 63.75908/61.90068. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 63.61113/61.89100. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 63.55216/61.85991. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.53971/61.85680. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 63.49539/61.82421. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.40023/61.81686. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 63.48536/61.86449. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 63.35408/61.89529. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.35615/61.92377. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.24938/61.87903. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.11112/61.84678. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 63.24457/61.84735. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 63.06664/61.85099. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.92796/61.83212. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 62.86034/61.85093. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 63.00331/61.82865. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.90750/61.82167. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.85917/61.79352. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 62.84983/61.72313. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 62.62977/61.83049. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.58667/61.85395. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.48546/61.82343. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 62.48348/61.84756. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.46608/61.81433. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.41509/61.87441. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.49439/61.84480. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 62.38473/61.84322. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 62.19815/61.85973. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 62.20946/61.86151. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 62.17861/61.91243. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 62.16841/61.85714. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.07564/61.90459. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.96219/61.93570. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 62.08640/61.92583. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 62.06178/61.97559. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.76033/62.08141. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.90321/62.07665. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.78883/62.11891. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.85496/62.06631. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.84782/62.08061. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.65862/62.21401. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 61.75032/62.36150. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.72970/62.33941. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.67738/62.35412. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.64838/62.42430. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.019557778346917184\n",
      "Epoch 0, Loss(train/val) 71.01362/73.72577. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.71629/73.35144. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.47425/72.96953. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.19312/72.59118. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.91902/72.22253. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.63088/71.83678. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.33511/71.44041. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.00330/71.03151. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.60448/70.61006. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.22101/70.16943. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.81858/69.72542. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.31333/69.27124. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.81718/68.78797. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 66.38318/68.29077. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.83964/67.77935. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.30707/67.25463. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.84792/66.74525. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.37258/66.27390. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.12616/65.86940. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.64010/65.49860. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.30506/65.19395. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 63.05690/64.93860. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.78057/64.71969. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.48043/64.53829. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.49184/64.37871. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 62.14481/64.21989. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.91374/64.08263. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 61.87368/63.95361. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.55826/63.89970. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.67267/63.85365. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.48288/63.81610. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.42653/63.76182. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 61.15898/63.70274. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.14860/63.64843. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.07975/63.59082. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 61.00347/63.54150. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.87843/63.50481. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.76392/63.44477. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.69842/63.39550. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.57096/63.34531. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.60543/63.33034. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.51126/63.31729. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.28002/63.27487. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.40081/63.25101. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.12157/63.26073. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.24623/63.23286. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.08458/63.19089. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.09294/63.17613. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.04467/63.14596. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.99418/63.12363. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.96577/63.08788. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.90087/63.08041. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.91080/63.06906. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.83019/63.09369. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.85082/63.06723. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 59.64912/63.08101. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.73306/63.05053. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.46109/63.04334. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.66268/63.01200. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.40672/63.03600. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.36842/62.98742. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.42219/62.97910. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 59.38506/62.94962. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 59.36346/62.88120. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.39325/62.89348. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.23254/62.83734. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 59.27319/62.81752. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.19706/62.79936. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.08419/62.78964. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 59.05189/62.77050. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.07154/62.75902. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.03616/62.75423. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.01392/62.73003. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.13036/62.72883. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.04032/62.73475. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.76903/62.71753. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.83901/62.70400. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.70080/62.69978. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.73855/62.66064. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.69534/62.64914. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.68371/62.63277. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.67725/62.62728. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 58.71313/62.63051. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.58854/62.62943. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.64035/62.64953. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.67252/62.64675. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.59994/62.67390. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.68212/62.69993. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.42443/62.68268. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.58932/62.67180. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.34782/62.71934. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.41740/62.75590. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 58.35166/62.80049. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.28714/62.82794. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.16577/62.84139. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.25704/62.83594. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 58.14914/62.88684. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.16649/62.92183. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.25294/62.97893. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.25792/63.02050. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.018801111554573632\n",
      "Epoch 0, Loss(train/val) 70.43632/70.01199. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.33701/69.88338. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.16583/69.74875. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.99516/69.59985. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.84000/69.44083. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.68262/69.26364. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.46802/69.06088. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.24437/68.83308. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.00193/68.57264. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.67729/68.27166. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.37944/67.92561. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.04553/67.53543. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.64089/67.09009. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.26876/66.58476. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.91296/66.01838. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.46435/65.41186. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.02765/64.77398. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.68110/64.14901. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.31031/63.58437. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.05104/63.09348. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.87607/62.69654. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.63453/62.40795. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.50970/62.18011. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.32272/62.00904. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.27982/61.87980. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.12155/61.78242. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.05002/61.69830. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.90669/61.62275. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.86734/61.55406. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.84214/61.49403. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.64224/61.43734. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.59414/61.37653. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.51665/61.31868. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.35776/61.24520. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.23569/61.16815. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.32190/61.10056. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.10746/61.02948. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.03873/60.96650. Took 0.34 sec\n",
      "Epoch 38, Loss(train/val) 63.04272/60.89933. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.88625/60.82624. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.80008/60.75789. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.53556/60.68486. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.46848/60.62914. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.47121/60.55448. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.21727/60.50604. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.11685/60.44036. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.04635/60.37842. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.83873/60.32550. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.74334/60.26188. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.77899/60.21252. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.73710/60.13084. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.48146/60.07472. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.42521/60.02929. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.21632/59.93506. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.32610/59.89446. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.09798/59.84264. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.16669/59.78111. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 60.90857/59.80806. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.87330/59.72618. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.85921/59.64622. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.76759/59.64515. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.74503/59.55369. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.66030/59.52916. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.62830/59.52117. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.54252/59.46382. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.35557/59.43692. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.41547/59.39060. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.32049/59.31263. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 60.30201/59.27777. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.22873/59.23257. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.10041/59.18725. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.15214/59.16704. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.06556/59.11335. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.05167/59.08119. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.90314/59.03302. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.91842/58.99721. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 59.84098/58.95590. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.76507/58.91562. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 59.95029/58.88166. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.78760/58.85387. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.89644/58.83342. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 59.65743/58.81124. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.58620/58.77879. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.70735/58.75866. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 59.61533/58.73498. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 59.58550/58.70366. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 59.49636/58.67532. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 59.52988/58.64602. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.51576/58.62079. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 59.38220/58.58291. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.38980/58.55725. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.45121/58.52576. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.41150/58.51081. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.29241/58.48783. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.25078/58.46630. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 59.30313/58.45514. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.22715/58.43148. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.17148/58.40858. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.27516/58.38925. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.12048/58.37380. Took 0.31 sec\n",
      "ACC: 0.40625, MCC: -0.08973031700969425\n",
      "Epoch 0, Loss(train/val) 71.04602/71.11459. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.86115/71.04192. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.64995/70.96516. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.45988/70.89016. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.28505/70.82313. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.04970/70.76308. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.90083/70.70962. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.61891/70.66058. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.39754/70.62980. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.17375/70.60594. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 69.00601/70.60802. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.72824/70.64105. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.48273/70.69815. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.25110/70.76659. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.92372/70.82178. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.64704/70.86475. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.42792/70.88083. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 67.23066/70.85666. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.01283/70.80910. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.78804/70.74814. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.78101/70.68124. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.45354/70.60983. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.52743/70.53026. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 66.27451/70.44917. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.22067/70.37965. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.98284/70.30387. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 66.04059/70.23083. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.90919/70.16417. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.94977/70.10149. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.82042/70.04211. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.70501/69.98425. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 65.58640/69.92646. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.43687/69.86836. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 65.35500/69.83083. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.29110/69.79564. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.11393/69.75240. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 65.07206/69.71162. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.98118/69.67398. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.88500/69.64080. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.67590/69.60529. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 64.70427/69.55338. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 64.45699/69.49193. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.43442/69.45025. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.22541/69.41210. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.14103/69.37931. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.15530/69.33927. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.97184/69.25656. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.75651/69.18389. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.71268/69.15543. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 63.70961/69.13500. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.56494/69.09640. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 63.36098/69.04095. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.32198/69.04214. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 63.36788/69.02783. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.13938/68.97659. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.99392/69.02786. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 62.90414/68.98357. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.88644/68.89739. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.67936/68.90371. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.61501/68.86531. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.54921/68.71235. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.33817/68.67184. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 62.35768/68.64507. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.41501/68.49160. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.36723/68.36835. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.37618/68.47946. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.31745/68.30119. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.13984/68.36829. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 61.99095/68.33823. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 62.02543/68.28748. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.02333/68.25763. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 61.76725/68.25690. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.77846/68.31332. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 61.82625/68.29408. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.75731/68.42889. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.77696/68.15531. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.60895/68.38715. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 61.47496/68.16105. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.62500/68.44783. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 61.51471/68.17279. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 61.50861/68.49550. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.59713/67.87387. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 61.41690/68.54053. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.43186/67.99633. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.35253/68.41405. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.20696/67.68092. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.32411/68.22720. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.25460/67.76199. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.27410/68.16702. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.19973/67.69565. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.23882/67.92298. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.14527/67.68476. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 60.91716/68.00215. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.90655/67.89949. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 61.00488/68.06491. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.83791/67.87959. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.83195/68.04126. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.84934/67.71032. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.81117/67.97055. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 60.67043/67.61374. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.15694120514358612\n",
      "Epoch 0, Loss(train/val) 71.26808/70.92036. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.09318/70.93468. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.88492/70.93437. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.69473/70.91918. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.53154/70.88526. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.28215/70.83987. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.07731/70.78227. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.89196/70.71446. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.64584/70.64188. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.40015/70.56561. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 69.16593/70.48680. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.90202/70.40874. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.65759/70.33582. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.39971/70.26675. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.19764/70.20067. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.94369/70.14280. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.75521/70.09319. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.48994/70.05542. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.30236/70.01902. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 67.04310/69.98791. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.80962/69.97592. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.58255/69.97444. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 66.40918/69.98711. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 65.99458/70.01134. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.80091/70.04036. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.69269/70.07345. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.45359/70.09172. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 65.13100/70.11065. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 64.95673/70.13567. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.72353/70.16363. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.50160/70.19879. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.20576/70.23383. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.12263/70.25707. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.79990/70.27494. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 63.58440/70.26279. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.35728/70.22350. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.18227/70.15661. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 63.12590/70.09013. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.92219/70.01927. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.77342/69.96665. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.62497/69.91154. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.58911/69.86093. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.53862/69.79239. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 62.42088/69.73550. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.45573/69.68896. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.19604/69.64670. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.19004/69.61799. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.13856/69.59396. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.03335/69.58238. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.93155/69.57607. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 62.19668/69.57055. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.85850/69.57147. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.84236/69.56248. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.08259/69.58614. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.63270/69.60336. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.74511/69.60948. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.69810/69.60350. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.57410/69.59938. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.62295/69.61101. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.51103/69.65788. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.55847/69.65840. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.40689/69.65261. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 61.39353/69.70370. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.35392/69.70015. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.30455/69.71343. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.22608/69.73547. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.21580/69.75716. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.86497/69.77570. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.09734/69.81064. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.91831/69.88828. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.90006/69.87994. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 60.72057/69.90025. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.54060/70.00833. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.74769/70.06073. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.75477/70.12698. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.60093/70.15791. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.57340/70.17368. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.39743/70.23212. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.50531/70.40644. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.61848/70.43219. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.57141/70.53478. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.36387/70.52284. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 60.36770/70.60599. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 60.18986/70.69776. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 60.16646/70.69163. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 60.20610/70.70166. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.29088/70.83142. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.25589/70.90604. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.19588/70.94510. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.15911/71.00944. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.01832/71.04564. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.03279/71.07681. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.10685/71.09901. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.98220/71.16385. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.92184/71.24188. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 60.09424/71.23211. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.01094/71.23776. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.92776/71.31123. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 60.04241/71.34989. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.86300/71.38802. Took 0.32 sec\n",
      "ACC: 0.609375, MCC: 0.1643989873053573\n",
      "Epoch 0, Loss(train/val) 70.68461/70.65614. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.53374/70.46597. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.40588/70.26630. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.29870/70.04903. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.11336/69.81721. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.97013/69.57388. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.79558/69.31742. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.62903/69.04700. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.44884/68.75812. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 69.20957/68.45289. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.95145/68.12165. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.79254/67.77679. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.47228/67.41275. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.28706/67.02612. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.92604/66.61679. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.62374/66.17974. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.23760/65.72597. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.84779/65.26513. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.45803/64.82407. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.03002/64.42842. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.66994/64.09534. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.32130/63.81347. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.04097/63.58190. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.76883/63.37466. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 64.49912/63.18349. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.21504/63.00963. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.17686/62.82303. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.91685/62.64741. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.83778/62.51237. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.40773/62.37386. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 63.30045/62.26720. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.19848/62.20488. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.01217/62.13181. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.81522/62.01927. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.68834/61.93606. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.50896/61.76971. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 62.29163/61.62293. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.20628/61.52995. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.09921/61.41513. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.97825/61.31549. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.75804/61.15639. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.67023/61.01218. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.48630/60.86476. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.53293/60.79592. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.25957/60.70117. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.27078/60.53939. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.04279/60.38861. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.11540/60.31989. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.79031/60.18887. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.58157/60.02824. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 60.55422/59.91518. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.41625/59.89931. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.32803/59.68042. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.18035/59.65060. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.94131/59.50459. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.01984/59.38784. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.87993/59.34957. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.82981/59.40459. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.79183/59.29139. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.58743/59.30192. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.40250/59.28210. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.26005/59.37144. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.99854/59.58261. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.96989/59.36177. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.86955/59.62313. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.60107/59.63437. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.39347/59.73583. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.45700/59.98617. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 58.21995/59.37326. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.03378/59.19107. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.82113/58.96804. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.91976/59.18046. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.55757/58.89299. Took 0.34 sec\n",
      "Epoch 73, Loss(train/val) 57.57406/58.28649. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.55900/58.55113. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.15622/58.15257. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.19743/57.97272. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.16632/58.14666. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.93429/58.55222. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.92106/57.76830. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.69206/57.96831. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.78389/57.98229. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.86731/57.45118. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.61959/57.83553. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.59207/57.80496. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.43995/57.30289. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.48415/57.84394. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.40082/57.62895. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 56.32218/57.34863. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 56.22573/57.67598. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.06755/57.87455. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 55.90924/57.27693. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.95788/57.44427. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.01020/57.29675. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.81556/57.29160. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.52877/57.66716. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.91817/57.22759. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 55.63090/57.43630. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.54136/57.51841. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.41252/57.40340. Took 0.31 sec\n",
      "ACC: 0.53125, MCC: 0.29935920183150355\n",
      "Epoch 0, Loss(train/val) 70.35057/69.84583. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.04013/69.57214. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.81290/69.29908. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.48184/69.02477. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.16818/68.74639. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.89603/68.45710. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.61443/68.15093. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.25251/67.83073. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.88246/67.49016. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.59264/67.12926. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.18175/66.73914. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.83053/66.33012. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 66.38035/65.91212. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.91069/65.49926. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.46956/65.10429. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 65.07153/64.73084. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.70296/64.38279. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.60886/64.05790. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.19420/63.74084. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.01618/63.43408. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.71917/63.12617. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.58573/62.82536. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 63.35643/62.52398. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.05384/62.20968. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.87941/61.89876. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.71655/61.58495. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.49274/61.25431. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.13482/60.93663. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.02779/60.66452. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.86495/60.38459. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.50709/60.09197. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.32789/59.80517. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.96250/59.50787. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.63625/59.19812. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.34032/58.87952. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.92265/58.56565. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.64161/58.32183. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.19238/58.16272. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 58.93211/58.03441. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 58.79482/57.94383. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.49461/57.89985. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.55192/57.85333. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 58.41556/57.82384. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.41516/57.79902. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.20226/57.79034. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 58.00791/57.78026. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 58.01649/57.78316. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.08047/57.79664. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.05473/57.77472. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 57.81517/57.78875. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.87076/57.81308. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.83533/57.84052. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.72415/57.82718. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.67561/57.82747. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 57.65341/57.84286. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 57.63325/57.85566. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.51150/57.88474. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 57.41937/57.88637. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.53144/57.89832. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 57.45814/57.91856. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 57.42825/57.94817. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.36927/57.98471. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.26627/57.99270. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.38647/57.98319. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.19753/57.98721. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.14143/57.96114. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.11465/57.97136. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.05274/57.99970. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.15058/57.99249. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.15240/57.97932. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.14788/57.96428. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.13319/57.92435. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 57.05016/57.91849. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 56.91872/57.91180. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.11830/57.89750. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.93908/57.89057. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.85561/57.86835. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.04639/57.82759. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 56.83190/57.79351. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.83832/57.75689. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 56.87425/57.72562. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.79159/57.73626. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.71998/57.74077. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.68689/57.73196. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.62571/57.69877. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.53545/57.64419. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.58013/57.60387. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.56598/57.58493. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 56.51009/57.56254. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 56.56027/57.52013. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.24549/57.49521. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.52414/57.48502. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.26601/57.49287. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.16653/57.51334. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.04710/57.48882. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 56.05611/57.46521. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.16373/57.44394. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 56.07661/57.43334. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.00363/57.41110. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.03756/57.38223. Took 0.33 sec\n",
      "ACC: 0.59375, MCC: 0.14547859349066158\n",
      "Epoch 0, Loss(train/val) 70.88013/69.80602. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.76346/69.81616. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.63751/69.82321. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.55143/69.82706. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.44205/69.83558. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.31581/69.84258. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.24575/69.84647. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.05738/69.85602. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.88989/69.86328. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.78268/69.87667. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.63116/69.88398. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.44639/69.87277. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.28861/69.84917. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.09551/69.82480. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.91454/69.80308. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 68.62341/69.75393. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 68.49171/69.66028. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.21232/69.53625. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.11843/69.37935. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.75734/69.21445. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.59582/69.01709. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.46043/68.83669. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.31366/68.59024. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.14013/68.33331. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 67.00067/68.09658. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.76956/67.95037. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.63506/67.84412. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.54997/67.77398. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.17235/67.73441. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 66.37255/67.70148. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 66.15279/67.66109. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 66.09386/67.62179. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 66.06293/67.58842. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 66.01574/67.55653. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.85720/67.53209. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.75259/67.51023. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.73183/67.48972. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.57923/67.44106. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 65.63273/67.38341. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 65.53138/67.34109. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 65.45958/67.31670. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 65.48203/67.28889. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 65.34146/67.27790. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 65.29758/67.23400. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 65.18897/67.19682. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 65.04692/67.18095. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.98876/67.14157. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 64.79553/67.10524. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 64.73649/67.08717. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.73485/67.06572. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 64.74660/67.11719. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 64.43930/67.07201. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 64.39632/67.07475. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 64.26714/67.09180. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 64.20906/67.07024. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.99015/66.96439. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.97020/66.99099. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.79757/66.98222. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.90062/67.00786. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.75875/67.11013. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.65387/67.19841. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 63.53483/67.25330. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.50326/67.25346. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.31039/67.20138. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 63.18729/67.18254. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.02360/67.14009. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 63.19246/67.18899. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.87961/67.13297. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.91868/67.20903. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.64886/67.28820. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 62.83628/67.29621. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.55703/67.30313. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 62.52027/67.22067. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 62.50980/67.20477. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 62.51115/67.13593. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.29217/67.10117. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.22746/67.02593. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.06611/67.03050. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 62.11206/66.99509. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 62.12271/67.03709. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 61.92792/67.04194. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.83374/67.01926. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.64566/66.98573. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.74719/67.06230. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 61.72750/67.16393. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 61.63564/67.17687. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.57678/67.18102. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 61.70551/67.27429. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 61.38808/67.20712. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 61.54599/67.31991. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 61.29354/67.20612. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 61.28923/67.41085. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.27167/67.15118. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.15971/67.41726. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 60.94432/67.11677. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.15572/67.39178. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.01594/67.09058. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.93101/67.38401. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.87813/67.11642. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.85831/67.31537. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.16721934418092857\n",
      "Epoch 0, Loss(train/val) 70.60933/70.64469. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.35247/70.24504. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.11716/69.80515. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.83960/69.33434. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.53432/68.82104. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.22375/68.26293. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.86628/67.65189. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.56777/66.97380. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.22905/66.26196. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.84116/65.55400. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.51486/64.89866. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.07319/64.31281. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.85175/63.81334. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.49999/63.44638. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.23036/63.14659. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.12335/62.90036. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 65.70032/62.68830. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.67302/62.50675. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.51295/62.34121. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 65.37698/62.19129. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.09118/62.04511. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.03585/61.92891. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.97502/61.81622. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.73367/61.70248. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.56735/61.59397. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.33476/61.49223. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.38107/61.39502. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 64.19396/61.31373. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.17255/61.25091. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.79601/61.19346. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.74524/61.13905. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.63500/61.08970. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.59286/61.04516. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.51374/61.00278. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.23403/60.95834. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.11337/60.91228. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.00158/60.85345. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 62.75732/60.77703. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.75839/60.67522. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.50946/60.56358. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.29272/60.44507. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.26555/60.33129. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.04468/60.23483. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.87072/60.14993. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.91700/60.06899. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.87555/59.99335. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.65897/59.91862. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.48880/59.84386. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.37493/59.77539. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.56843/59.70240. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.28098/59.61869. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.08577/59.60954. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 61.07632/59.59063. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.13204/59.50885. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.88895/59.58797. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.91924/59.53631. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.81566/59.67841. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.69658/59.55676. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.42133/59.56222. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 60.61151/59.73318. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 60.41413/59.53596. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.32376/59.65248. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.31611/59.74140. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.10736/59.65274. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.31454/59.66845. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.12334/59.66102. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.93090/59.75832. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 59.87575/59.58713. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.88078/59.70350. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.84625/59.62532. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.96396/59.65947. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.86559/59.51439. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.49971/59.49023. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.57131/59.54339. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.64491/59.48559. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 59.36371/59.54309. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.43174/59.47816. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.40306/59.57245. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 59.32257/59.54762. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.31622/59.57855. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.28351/59.57017. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 59.16575/59.67765. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.07062/59.55317. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 59.12751/59.55720. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.03462/59.66452. Took 0.34 sec\n",
      "Epoch 85, Loss(train/val) 58.98900/59.56395. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.93493/59.63949. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.90441/59.64867. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.91861/59.57376. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.79625/59.63219. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.96653/59.55564. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.79137/59.64152. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.76443/59.61061. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 58.63237/59.65658. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.67393/59.62554. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.51055/59.62942. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.64919/59.54601. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.60318/59.59212. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.61042/59.61784. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 58.50745/59.57397. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.01659128610703117\n",
      "Epoch 0, Loss(train/val) 71.25149/71.18987. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.98408/70.94188. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.81417/70.69106. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.54267/70.42915. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.33041/70.14580. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.06733/69.82880. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.74758/69.45856. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.37928/69.01391. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.02801/68.47984. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.55652/67.86652. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.99293/67.16739. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 67.34543/66.42644. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.68236/65.75862. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.20660/65.24044. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.56076/64.74210. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.99561/64.25916. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.46133/63.80495. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.06887/63.41385. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.51487/63.06946. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.34684/62.79115. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.96465/62.55392. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.71556/62.34432. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.41246/62.15855. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.35952/61.98492. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.99648/61.81133. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 61.86646/61.63610. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.56120/61.46601. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 61.64926/61.29482. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.28633/61.12407. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.29617/60.95779. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.22819/60.79090. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 61.17133/60.62998. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.95973/60.47276. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.84298/60.34019. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.73409/60.21944. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.60359/60.10936. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.64731/60.01682. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.43926/59.93804. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.36098/59.86606. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.37817/59.80471. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.15078/59.75451. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.08826/59.70866. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.17082/59.68386. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.17971/59.66266. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.05679/59.64745. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 59.78263/59.63191. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.63204/59.62105. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.88148/59.61379. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.75905/59.60983. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.64240/59.61237. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.65278/59.62305. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.64051/59.62766. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.43837/59.63081. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.39389/59.63504. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.33319/59.65017. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 59.31860/59.65767. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.28310/59.66648. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.22956/59.68222. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.11830/59.68217. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 59.16712/59.68107. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.16368/59.68146. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.33372/59.67207. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.09368/59.67570. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.89359/59.68269. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.01179/59.66994. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.90599/59.65696. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 58.96120/59.65776. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.85033/59.66492. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.89972/59.66824. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.75518/59.67381. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.87450/59.68635. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.67164/59.69161. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.64780/59.67080. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.63257/59.66081. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 58.53384/59.64542. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.49023/59.63792. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 58.48277/59.63046. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 58.49936/59.64075. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.46318/59.65507. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.32357/59.64458. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.46720/59.63123. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.30935/59.67414. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.41985/59.66994. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.24888/59.66263. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.19111/59.71796. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 58.09136/59.73449. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.14860/59.72586. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.13268/59.75086. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.17473/59.72895. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.02150/59.72398. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.94928/59.76689. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 57.92799/59.75002. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.99154/59.77122. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.85512/59.74069. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.84715/59.82162. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.80016/59.72432. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.85441/59.86230. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.72421/59.72569. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.66694/59.91510. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.75745/59.71617. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.1455213750217998\n",
      "Epoch 0, Loss(train/val) 70.99507/70.55605. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.80907/70.47272. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.63176/70.38939. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.42901/70.30205. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.24491/70.21248. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.04387/70.11594. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.87914/70.00950. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.70648/69.89522. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.51426/69.76730. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.34557/69.62724. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.15474/69.47293. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.93155/69.30219. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.59566/69.10363. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.48360/68.88299. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 68.17244/68.64455. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.94973/68.39415. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 67.64833/68.14103. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.45788/67.88646. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.23328/67.62553. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.92673/67.36040. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 66.54959/67.07047. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 66.31879/66.75770. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 65.88755/66.40532. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.55612/66.01297. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.02702/65.56547. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.58681/65.02947. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.25520/64.40760. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.68005/63.70606. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.28964/62.97138. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.85026/62.28956. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.63563/61.69180. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.19983/61.21578. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.06164/60.88586. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.95901/60.66232. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.75381/60.45642. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.67392/60.30170. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.49295/60.14479. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.31224/60.00321. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.45993/59.88355. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 61.23423/59.77383. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.18092/59.64992. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.96595/59.57143. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.98906/59.49662. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.81715/59.43493. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 60.73537/59.35708. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.77426/59.29788. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.54827/59.25130. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.41858/59.19367. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.33817/59.15079. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.23621/59.11171. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.26522/59.11863. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.06963/59.08058. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.90202/59.07086. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.04722/59.09026. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.80106/59.08852. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.74279/59.07725. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.79924/59.11020. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.66902/59.19691. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.65019/59.27436. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.41765/59.30418. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.50206/59.37588. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.35270/59.50898. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.24823/59.57651. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 59.00192/59.68638. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.02988/59.75551. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 59.08605/59.78385. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.00486/59.86839. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.89959/59.92223. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.89598/59.94001. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.84855/59.99079. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.65891/60.03443. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.80532/60.07274. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 58.53012/60.20417. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.54914/60.23014. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.36585/60.29880. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.23541/60.27596. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.16119/60.40012. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.12326/60.36782. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.00432/60.46195. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.08996/60.45409. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.00145/60.45775. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.92354/60.47066. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.76201/60.52522. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 57.69906/60.56370. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.63652/60.74412. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.58713/60.58088. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.53414/60.76219. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.43470/60.60212. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.46059/60.81301. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.29779/60.51892. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.61785/60.80628. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.30378/60.44124. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.32025/60.64068. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.22483/60.50343. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.20339/60.60737. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.08613/60.60189. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.08448/60.54456. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.06061/60.55073. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 56.96715/60.53813. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.88598/60.55764. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.011444873404026341\n",
      "Epoch 0, Loss(train/val) 70.50082/71.24518. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.17357/71.16222. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.82639/71.06904. Took 0.34 sec\n",
      "Epoch 3, Loss(train/val) 69.50769/70.97152. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.12340/70.87377. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.79704/70.77217. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.40302/70.67081. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.04240/70.57292. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.56628/70.48409. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.11312/70.40327. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 66.66732/70.32631. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.28528/70.24541. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.83438/70.16006. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.48225/70.06852. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.10198/69.96368. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.87279/69.84688. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 64.54154/69.70779. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.27585/69.54792. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.03544/69.36629. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.93163/69.16137. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.63799/68.94138. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.54999/68.72247. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.37984/68.51826. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.09273/68.30603. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.91820/68.09000. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.86762/67.87808. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.67615/67.64745. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.37243/67.39882. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.36975/67.14361. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.16315/66.92523. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.23182/66.75680. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.08180/66.60645. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.03010/66.46960. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.86901/66.36964. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.93949/66.28358. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.84876/66.22912. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.74199/66.18581. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.74638/66.13458. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 61.68452/66.06470. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.54030/66.03708. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.59045/66.01619. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.60817/65.99934. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.44897/65.98492. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.69479/65.95599. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.51821/65.92673. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.54997/65.89722. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.39585/65.88102. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.48318/65.86730. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.30959/65.86941. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.36282/65.86128. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.25480/65.86349. Took 0.34 sec\n",
      "Epoch 51, Loss(train/val) 61.27344/65.86859. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.17942/65.87498. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.21338/65.84942. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.00611/65.82533. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.10228/65.81775. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.15830/65.82299. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.09193/65.82253. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.09594/65.80309. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.03455/65.78289. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.97337/65.76537. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.05646/65.73649. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.91021/65.73222. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.84424/65.72934. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.90930/65.69411. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.97114/65.67245. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.83757/65.67294. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.76161/65.66644. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 60.72821/65.61718. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.73669/65.58224. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.77446/65.56271. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.82435/65.51739. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.68581/65.47903. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.51892/65.45448. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.64091/65.44922. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.54988/65.46221. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.57050/65.46150. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.63205/65.43032. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.50130/65.42222. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.38401/65.42181. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.44333/65.42059. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.48088/65.39100. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.29838/65.36420. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.41940/65.30772. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.29630/65.26089. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.30721/65.35630. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 60.41788/65.28579. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.33305/65.32714. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.26580/65.38483. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 60.18572/65.30638. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.19147/65.35704. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.20571/65.33953. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.16734/65.36407. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.12196/65.31537. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 60.12236/65.31662. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.06354/65.33037. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.02921/65.28645. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.07873/65.32216. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.05152/65.34696. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.99863/65.29948. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: -0.07265392195447241\n",
      "Epoch 0, Loss(train/val) 70.68989/70.30819. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.42662/70.06354. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.10922/69.80901. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.80867/69.54476. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.48163/69.26095. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.18627/68.95482. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.88553/68.62872. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.48724/68.26902. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.06509/67.85448. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.65672/67.39465. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.19447/66.87546. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.61560/66.28803. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.07174/65.62573. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 65.42296/64.88647. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 64.79799/64.06976. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.15443/63.19182. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.33674/62.25338. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 62.63725/61.31014. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 62.21798/60.45083. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 61.70309/59.69364. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 61.26350/59.07663. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 61.17299/58.63468. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 60.89609/58.28696. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 60.70108/58.01019. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 60.64690/57.76534. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 60.50314/57.54060. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 60.37634/57.33492. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 60.20619/57.15191. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.26042/56.99396. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.12955/56.84508. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 60.08899/56.71507. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.94923/56.59652. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 59.63416/56.49321. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 59.87447/56.39997. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 59.63955/56.31530. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.72105/56.24097. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.48997/56.16926. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.56307/56.10482. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.51530/56.04418. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 59.56539/55.98817. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.48857/55.93657. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.40865/55.88861. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.40879/55.84532. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.48078/55.80587. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.38222/55.76942. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.31345/55.73428. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 59.11976/55.70295. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.20534/55.67506. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.17412/55.64714. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 59.34045/55.62153. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.16290/55.59786. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.10006/55.57174. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.16467/55.54990. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.06406/55.53950. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.04034/55.53233. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.96321/55.52630. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.98265/55.52092. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.03816/55.52077. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.02009/55.52601. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.86829/55.53114. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.11265/55.54655. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.96210/55.56910. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 58.86217/55.59575. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.93103/55.63531. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.09169/55.68973. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.75569/55.74786. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.77277/55.82340. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.78704/55.92024. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.92088/56.01332. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.72226/56.12118. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.73319/56.22520. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.62831/56.30024. Took 0.34 sec\n",
      "Epoch 72, Loss(train/val) 58.59948/56.39115. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.66031/56.49356. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.48794/56.58113. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 58.64721/56.65880. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.53076/56.74218. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 58.51873/56.84503. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.59874/56.88712. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.60266/56.91035. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.44030/56.95730. Took 0.34 sec\n",
      "Epoch 81, Loss(train/val) 58.58095/57.01439. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.54244/57.07965. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.40751/57.09355. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.21215/57.10415. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.18292/57.13301. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.14833/57.19007. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.16516/57.23997. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.40645/57.28960. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.30578/57.34157. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.22844/57.38543. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.21012/57.39154. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.24313/57.43850. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.97471/57.47902. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.02170/57.49986. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.22008/57.54284. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.24339/57.59395. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.09576/57.60300. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 58.12354/57.68681. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.02223/57.78810. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.14400244857369446\n",
      "Epoch 0, Loss(train/val) 70.25242/70.84731. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.96424/70.56803. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.66593/70.26389. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.31330/69.92023. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.95154/69.52381. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.44881/69.06435. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.98916/68.52144. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.37302/67.88115. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.63229/67.11317. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 65.67239/66.19117. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 64.65519/65.11040. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 63.70309/63.97218. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 62.57705/62.90266. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 61.80007/62.01756. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 61.20949/61.39236. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 60.66561/60.93565. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 60.42316/60.56063. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 60.04068/60.24580. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 59.79422/59.97559. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 59.76115/59.74714. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 59.49727/59.53827. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 59.30157/59.35378. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 59.31317/59.18090. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 59.20321/59.01796. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 59.06996/58.86482. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 58.71857/58.72113. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 58.80362/58.59223. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 58.53021/58.47297. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 58.72041/58.36007. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 58.59135/58.25568. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 58.49800/58.15844. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 58.32134/58.07236. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 58.51419/57.98841. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 58.48305/57.91293. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 58.38674/57.83781. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 58.36209/57.76381. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.35585/57.69205. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.29246/57.62268. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.23673/57.55795. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 58.00338/57.49624. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 57.84276/57.43990. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.24604/57.38495. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 58.16244/57.33306. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.11389/57.28449. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 58.10595/57.23727. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.86198/57.18746. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.17485/57.13820. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 57.91424/57.08408. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.99334/57.03670. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.94882/56.99070. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.90967/56.94570. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.95004/56.90056. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 57.64508/56.84887. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.87561/56.81136. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 57.87013/56.77565. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.82210/56.72911. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.75594/56.68196. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 57.80270/56.63322. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.58964/56.58164. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.91467/56.53116. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.82975/56.47179. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.67893/56.40177. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.68181/56.34518. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.62646/56.28469. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.79479/56.23042. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.65003/56.17431. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.65127/56.11713. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 57.36238/56.06428. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.54428/56.01437. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.50867/55.97053. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.56911/55.93150. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.44205/55.88844. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.29659/55.84192. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.46629/55.80404. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.39827/55.78295. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.50514/55.75623. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.41450/55.72000. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 57.40698/55.68472. Took 0.34 sec\n",
      "Epoch 78, Loss(train/val) 57.50749/55.64886. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.29519/55.61628. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.42138/55.59102. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.32605/55.56751. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.58213/55.55223. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 57.16687/55.54307. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 57.47527/55.53666. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.27191/55.52694. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 57.14159/55.50578. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.08741/55.50236. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.02274/55.49636. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.42613/55.49775. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.13650/55.48869. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 57.24025/55.49641. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.92580/55.50713. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.93313/55.48873. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.02416/55.45306. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.94534/55.45147. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 56.79513/55.45364. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.08998/55.43325. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.89582/55.43690. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.74048/55.40663. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.05514348094667237\n",
      "Epoch 0, Loss(train/val) 70.93472/70.94378. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.63493/70.85072. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.45395/70.76687. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.18062/70.69296. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.85453/70.62533. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.54145/70.54906. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.24920/70.45236. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.86289/70.34161. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.63603/70.22300. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.24247/70.09255. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.93252/69.95780. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.60460/69.81507. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.34018/69.65868. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.07679/69.49154. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.75180/69.31224. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.54787/69.12502. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.33534/68.91708. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.11147/68.68364. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.68517/68.42471. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.50441/68.11829. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.36557/67.76767. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.99271/67.37611. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.59285/66.94733. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.39138/66.51057. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 64.20103/66.06487. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.90237/65.60703. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.71831/65.15235. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.44808/64.75996. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.28547/64.42209. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 63.14444/64.13079. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.79453/63.91129. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.81064/63.74480. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.50180/63.59370. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.29530/63.46372. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.20470/63.37631. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.85928/63.31669. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.99257/63.27120. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.82417/63.23137. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 61.69519/63.21203. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 61.62870/63.20223. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.65508/63.18467. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.39659/63.14565. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.36362/63.09904. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.40193/63.07571. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.18424/63.05092. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.16948/63.00273. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.10105/62.97400. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.06587/62.95462. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.96095/62.92741. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.00179/62.89106. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.10798/62.86085. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.95550/62.83619. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.97047/62.79933. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.91256/62.75454. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 60.78921/62.71093. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.95661/62.66410. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.62616/62.63694. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.52281/62.57976. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.39439/62.49711. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.64820/62.39102. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.60978/62.30964. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.34012/62.22384. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.49563/62.13657. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.38704/62.05108. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.23033/62.00458. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 60.34922/61.95919. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.18185/61.90859. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.06390/61.85566. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.05469/61.82573. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.17733/61.78519. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.17004/61.76479. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.08703/61.75315. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.79074/61.74917. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 59.97077/61.67677. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.87428/61.63380. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.90742/61.63308. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.88836/61.63604. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.72984/61.61544. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.70267/61.59876. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.65321/61.62661. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.76247/61.63364. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.62685/61.62614. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.59328/61.58521. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.50496/61.55872. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.45917/61.54402. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 59.33767/61.49950. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.50808/61.54656. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.47593/61.57248. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.37335/61.55400. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.41136/61.57636. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 59.33755/61.60316. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.33848/61.61041. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.30559/61.55445. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.36791/61.53645. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.08452/61.58931. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.14163/61.59900. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 59.12253/61.61367. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.23134/61.54901. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.10047/61.54806. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.95125/61.57949. Took 0.33 sec\n",
      "ACC: 0.578125, MCC: 0.12565352717793946\n",
      "Epoch 0, Loss(train/val) 69.92251/70.22694. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.69335/70.00408. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.43066/69.76310. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.21412/69.50400. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.90108/69.21783. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.54395/68.89085. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.16184/68.52441. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.77257/68.11133. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.25119/67.62241. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.71912/67.05714. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.09181/66.39537. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.37351/65.64597. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 64.68439/64.95924. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 63.93803/64.41223. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 63.57110/63.95669. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.09573/63.59075. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 62.75817/63.32951. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 62.59044/63.12559. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.30799/62.98863. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.17486/62.88551. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.13533/62.80833. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.11837/62.73153. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 61.93609/62.66608. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.72399/62.60823. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.50082/62.55547. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 61.51167/62.50544. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.42814/62.44917. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.45828/62.40933. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.33017/62.36681. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.19147/62.32471. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 61.18244/62.28034. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.03257/62.23741. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.08701/62.19220. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.89631/62.14601. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.65806/62.11093. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.82954/62.07434. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.71824/62.03519. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.59275/61.99441. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.46884/61.96646. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 60.53052/61.93781. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 60.35543/61.88814. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.44660/61.84941. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.28434/61.81675. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.36141/61.75476. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.27108/61.69897. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.24787/61.67835. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.06630/61.65080. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.99289/61.61992. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.98596/61.55147. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.89968/61.51870. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.75182/61.51526. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.76094/61.48528. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.97327/61.45825. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.65270/61.42181. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.76818/61.38408. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.65110/61.38153. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.45157/61.35138. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.61820/61.28895. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.52486/61.31263. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.45892/61.26477. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.43949/61.20533. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 59.38547/61.15205. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.38068/61.12799. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 59.22908/61.12144. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.29901/61.10364. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.07763/61.09266. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 58.97841/61.09752. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.96144/61.12948. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.86536/61.19134. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.00692/61.11671. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.01871/61.05657. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 58.95090/60.97361. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.75816/60.93975. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.72461/60.96778. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 58.80527/60.93683. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 58.80789/60.90524. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 58.53926/60.89597. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.85401/60.90612. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.66185/60.89602. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.63792/60.90456. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.57499/60.89415. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.57612/60.95604. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.51436/60.89246. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.46464/60.78110. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.61573/60.68227. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.52102/60.76466. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.31317/60.69817. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.46794/60.62502. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.51364/60.57671. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.40037/60.52367. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.28849/60.57637. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 58.20964/60.59625. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.30905/60.58013. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.35506/60.46962. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.12239/60.49285. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.12631/60.45211. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.11065/60.33462. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.21353/60.30799. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 58.04457/60.33537. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.18760/60.30290. Took 0.33 sec\n",
      "ACC: 0.453125, MCC: -0.04982728791224399\n",
      "Epoch 0, Loss(train/val) 70.97247/71.53172. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.83681/71.53093. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.72738/71.53104. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.59699/71.52998. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.47197/71.53047. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.35952/71.52645. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 70.22755/71.51283. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 70.13147/71.50087. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 70.00218/71.48665. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 69.93207/71.46526. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.82991/71.43202. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.64714/71.38675. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.53981/71.33105. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.39467/71.25464. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 69.26437/71.16098. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.12421/71.05254. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 68.93204/70.91299. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 68.79618/70.75082. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.59044/70.57766. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.38556/70.37645. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 68.20941/70.14796. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.90693/69.88483. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.80804/69.60558. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.52764/69.33857. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 67.31563/69.05804. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 67.05809/68.73589. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.90719/68.44730. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 66.62836/68.13647. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.57969/67.81877. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.17758/67.52556. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.23424/67.19953. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 65.94561/66.88773. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 65.73284/66.60562. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.61670/66.32111. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 65.64140/66.04158. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 65.36650/65.79198. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.25845/65.56679. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 65.16547/65.35814. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.98938/65.18121. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.89631/65.05845. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 64.89829/64.89093. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.90624/64.81883. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.55955/64.72826. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.53593/64.64739. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 64.48603/64.58793. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 64.51019/64.54131. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.36030/64.49805. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 64.30977/64.46841. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.21266/64.42509. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.08474/64.36596. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 64.02627/64.38808. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.95436/64.30772. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.92242/64.33495. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 63.86196/64.27540. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.71599/64.27273. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.70455/64.27490. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 63.71256/64.24842. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 63.50574/64.22115. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.57348/64.18208. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.39190/64.23388. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.28512/64.16513. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 63.28246/64.20811. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 63.11262/64.20105. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.27685/64.06717. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 63.12987/64.20444. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.10907/63.97215. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 63.06102/63.94889. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.91612/64.22207. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 62.95864/64.11716. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.75036/64.03702. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.73222/64.18407. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.62454/64.22852. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.51751/64.22598. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 62.51497/64.15273. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.49886/64.19601. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.39270/64.12479. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 62.42575/64.23508. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.41735/64.05360. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 62.30905/63.94273. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 62.39237/64.08043. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 62.11874/64.37021. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.09483/64.31023. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 62.09104/64.32387. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.96976/64.33517. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.03749/64.34296. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.91557/64.07582. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.85788/63.99301. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.72760/64.01798. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.63709/64.14413. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 61.74138/64.23019. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 61.58985/64.35118. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.51880/64.45717. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.45989/64.27338. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 61.37539/64.43062. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.41906/64.53773. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.23668/64.44420. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 61.15329/64.57463. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 61.21112/64.61016. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 60.92451/64.64507. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.92000/64.59908. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.004186446382769878\n",
      "Epoch 0, Loss(train/val) 71.12183/70.73830. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.81572/70.49128. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.57095/70.24298. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.28348/69.99638. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.01903/69.75113. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.72293/69.50607. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.48627/69.26258. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 69.16213/69.02008. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.94752/68.77064. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.69123/68.51969. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.37070/68.26279. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.07487/68.00037. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.80863/67.72368. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 67.43546/67.42914. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.18295/67.11184. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 66.88387/66.77643. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.52462/66.41065. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.20026/66.03067. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.82471/65.62045. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.48493/65.18082. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.11967/64.75182. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 64.71488/64.34864. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.35714/63.88529. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.78187/63.33457. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.24566/62.73553. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.68030/62.16800. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 62.28083/61.60596. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 61.92873/61.09540. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 61.76425/60.66909. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 61.49079/60.33347. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.20133/60.05749. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.27768/59.83215. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.03378/59.64089. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 60.92274/59.46011. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 60.84566/59.28880. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.85744/59.10950. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 60.67722/58.93732. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.71053/58.77325. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.52169/58.63588. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 60.48243/58.48576. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.36086/58.34661. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 60.46771/58.23535. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 60.29729/58.09512. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.39233/57.95222. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.18118/57.83438. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 60.17854/57.72035. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 60.02374/57.61850. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 60.02848/57.52894. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 60.03952/57.44227. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.02332/57.37317. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.84446/57.29651. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.81381/57.22395. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 59.86694/57.16042. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.86928/57.10531. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 59.81461/57.06973. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 59.66744/57.04984. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.48142/57.01785. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.55176/56.95780. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.55404/56.94835. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 59.32941/56.92180. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.38330/56.92717. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.41147/56.89322. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 59.42665/56.88550. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.34406/56.89146. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.22055/56.89049. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 59.13360/56.90130. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 59.14386/56.91008. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 59.00042/56.94845. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 58.99171/57.01946. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 59.13435/57.05644. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 58.93688/57.09850. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.00209/57.16363. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.79228/57.20824. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.78799/57.22974. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 59.02502/57.30454. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.71420/57.32323. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.74560/57.33247. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.83489/57.55475. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.60812/57.32164. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.53146/57.41764. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 58.57271/57.31425. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 58.53530/57.50771. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 58.42737/57.28916. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.43286/57.34219. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.19579/57.29512. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 58.36173/57.44083. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.44795/57.43356. Took 0.30 sec\n",
      "Epoch 87, Loss(train/val) 58.28583/57.41111. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 58.12600/57.46503. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 58.22535/57.62381. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 57.96022/57.41945. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.09067/57.89279. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.12388/57.32323. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.84661/57.70379. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.79056/57.85040. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.93561/57.21750. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.87055/57.48172. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.84153/57.42558. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 57.89984/57.45294. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 57.60098/57.44088. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.099230849433283\n",
      "Epoch 0, Loss(train/val) 70.94084/71.46349. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.62367/71.02705. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.41043/70.61200. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.20907/70.20815. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 69.95965/69.81633. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.70465/69.41686. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.45708/69.00374. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.18053/68.57423. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.86774/68.13310. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.54022/67.69440. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 68.20269/67.25664. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.91497/66.82054. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.59521/66.36982. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 67.22454/65.88602. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.88582/65.35188. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 66.57697/64.75117. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 66.10036/64.07790. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.69723/63.38220. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.20055/62.72322. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 64.83024/62.11041. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.27284/61.55116. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 63.85344/61.10255. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 63.57001/60.77736. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.12101/60.50091. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.94839/60.28830. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 62.73533/60.13391. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.57664/60.01012. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.39931/59.87402. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.39758/59.75057. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 62.20039/59.63345. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 62.13138/59.54082. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.03796/59.49770. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 62.07972/59.43895. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.97501/59.41052. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 61.93762/59.35241. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 61.83430/59.27377. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.69353/59.21743. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.83401/59.15816. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.58265/59.09581. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 61.51023/59.04427. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.51623/58.99938. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.51904/58.95848. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.24580/58.91823. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 61.42058/58.90060. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 61.34339/58.88160. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 61.43967/58.81246. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.20999/58.75336. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.31101/58.68454. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 61.10830/58.64701. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.12779/58.61022. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 61.08620/58.54570. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.86705/58.49180. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.01042/58.44946. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 60.99147/58.38351. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.89142/58.35831. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.90845/58.32931. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.88421/58.28962. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.81465/58.27239. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.66799/58.25378. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.76968/58.21726. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.68559/58.16978. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.78823/58.11396. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.69194/58.07936. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.68884/58.03374. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 60.69444/58.00974. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.69061/57.98664. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.46832/57.95064. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 60.43967/57.88694. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 60.41838/57.86731. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.45502/57.90005. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.38441/57.85100. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.36082/57.81290. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.40968/57.76632. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.33915/57.76577. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 60.52616/57.77296. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.24706/57.75306. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.25699/57.70966. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.28357/57.67147. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.25109/57.66546. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.21324/57.64936. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.33813/57.66285. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.19632/57.65259. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 60.06349/57.69800. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.98630/57.63146. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.06931/57.62590. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 59.97713/57.59596. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.02277/57.59373. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.06492/57.62328. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.99931/57.66754. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.12689/57.66598. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 59.91301/57.62194. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.90772/57.68287. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.90658/57.67729. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.90494/57.70491. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.94555/57.71571. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 59.63623/57.74927. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.78397/57.76025. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.68906/57.73748. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 59.84731/57.70234. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.66973/57.72448. Took 0.32 sec\n",
      "ACC: 0.640625, MCC: 0.16060893826870834\n",
      "Epoch 0, Loss(train/val) 70.74221/70.10547. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.58137/70.03054. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.42913/69.95262. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 70.29878/69.87389. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.13766/69.79344. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.96596/69.71185. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.87358/69.62900. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 69.65998/69.54471. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.49196/69.45367. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.36112/69.35693. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.20518/69.25891. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.05553/69.15659. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 68.80314/69.04697. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.73168/68.93430. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.52885/68.82006. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 68.36196/68.69852. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.21764/68.57684. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 68.01284/68.45122. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 67.87838/68.32314. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.70165/68.19435. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.51194/68.06728. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.39833/67.94603. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.19113/67.82661. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.07832/67.71387. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.89820/67.60365. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.84048/67.49455. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 66.75791/67.38249. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.50638/67.26855. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.37902/67.13910. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.22653/66.99165. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.05092/66.82283. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 65.76889/66.62905. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 65.70453/66.41811. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.47048/66.18946. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 65.34530/65.95933. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.13486/65.73941. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 64.96986/65.53896. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 64.73719/65.36546. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 64.65429/65.21904. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.58626/65.10207. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.47071/65.00616. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.34796/64.92330. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.28232/64.85190. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.14694/64.79753. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.14980/64.74649. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.89643/64.70472. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.95087/64.66337. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.88636/64.62440. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.76805/64.58852. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.66388/64.55616. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 63.66407/64.52745. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.77189/64.50027. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 63.70593/64.47000. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 63.53766/64.44324. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.45110/64.41698. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.40869/64.39751. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.26498/64.37864. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 63.34548/64.35954. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.28788/64.33942. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.29804/64.31992. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 63.13629/64.30294. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 63.24029/64.28611. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.99091/64.27297. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 62.98758/64.25753. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.90785/64.23760. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 63.12417/64.22150. Took 0.34 sec\n",
      "Epoch 66, Loss(train/val) 62.95076/64.20486. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.88894/64.18766. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.83919/64.17020. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.85858/64.15403. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.81404/64.13864. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.84805/64.12437. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 62.62235/64.11189. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.80978/64.09637. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 62.64275/64.08268. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 62.73082/64.06597. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.65716/64.05271. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 62.56373/64.04253. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.52613/64.02970. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.55540/64.01539. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 62.45132/64.00371. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.55566/63.98809. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 62.53052/63.97407. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 62.35369/63.96696. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.38695/63.95304. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.33712/63.93684. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.15404/63.92006. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 62.21981/63.90736. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 62.24412/63.89621. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 62.30103/63.88169. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 62.28796/63.87080. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 62.08911/63.86051. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 62.12575/63.84827. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 62.19410/63.83623. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 62.12952/63.82378. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 62.17980/63.81460. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.99280/63.79975. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.90805/63.78572. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.90456/63.76793. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.77088/63.75812. Took 0.32 sec\n",
      "ACC: 0.421875, MCC: -0.14859644825447751\n",
      "Epoch 0, Loss(train/val) 70.69658/70.79998. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.47688/70.62515. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.22625/70.44716. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.97710/70.26838. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.73096/70.08470. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.46954/69.90446. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.19161/69.72674. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 68.86328/69.54114. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.52324/69.35348. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.13563/69.15173. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 67.73729/68.92354. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 67.31169/68.65549. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.88181/68.33643. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 66.36272/67.97389. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.87710/67.58392. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 65.50252/67.16355. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.18910/66.70422. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.65162/66.19730. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.31978/65.68155. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.13960/65.16831. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.73662/64.71778. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.32869/64.32839. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.10724/63.97912. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 62.96600/63.67506. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.62670/63.41233. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.51598/63.18772. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.44571/62.98398. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.25035/62.80155. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.17979/62.62484. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 61.98554/62.45631. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.79828/62.29491. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.57697/62.12383. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.55283/61.93314. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.47013/61.80548. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 61.28766/61.71405. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.23757/61.61079. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 61.13679/61.53050. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 61.08744/61.46704. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.91651/61.40044. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.86257/61.35042. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.72653/61.30467. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.66766/61.25360. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.49973/61.21159. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.43693/61.19578. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.36741/61.18121. Took 0.30 sec\n",
      "Epoch 45, Loss(train/val) 60.22263/61.14855. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 60.12016/61.10924. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.04293/61.06440. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.90293/61.02253. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.85978/60.97434. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 59.72276/60.91376. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.74354/60.84387. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.62212/60.88258. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.38505/60.79287. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.24542/60.89231. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.22066/60.75474. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.12305/60.70900. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 59.03612/60.68240. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.95706/60.64280. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.93182/60.67007. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.89036/60.51940. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.85379/60.54648. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 58.59099/60.51545. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.60728/60.64117. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 58.43029/60.28158. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.45845/60.38922. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 58.32201/60.22595. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.31972/60.30562. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.05371/60.15769. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.22483/60.25910. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.00566/60.08426. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.90544/59.98902. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 57.80156/60.03805. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.88324/60.05844. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.77762/59.97225. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.70614/59.86861. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.65375/59.87337. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 57.54162/59.83221. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.57355/59.84479. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 57.52273/59.83930. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 57.39936/59.63616. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.25760/59.78767. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.36226/59.50143. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.36236/59.46126. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 57.06170/59.33860. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.08021/59.28025. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.19641/59.08182. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.03953/58.90974. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.05391/58.93069. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.00523/59.45379. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.07674/59.01859. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 57.01420/59.38981. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.86672/59.19884. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 56.99141/59.02754. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 56.76254/59.11674. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 56.72179/58.82346. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.76798/58.83355. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 56.58736/58.75512. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.60997/58.91391. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.52722/59.02755. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.009163235455864739\n",
      "Epoch 0, Loss(train/val) 70.95966/70.46846. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.77274/70.33047. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.63259/70.19016. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.42961/70.04253. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.26841/69.88085. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.03163/69.70142. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.88036/69.50275. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.64813/69.29087. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.46403/69.06691. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.26967/68.83962. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.04764/68.59858. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.85340/68.35611. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.48021/68.10510. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.29050/67.86108. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.91825/67.61134. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.62518/67.36433. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 67.22752/67.10320. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.84560/66.83266. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.60715/66.54649. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.20192/66.23089. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.77910/65.87300. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.39470/65.47029. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.88288/65.02207. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.45111/64.53223. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.97286/64.02076. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 63.67376/63.51883. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.27262/63.03982. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.01284/62.60657. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.78069/62.22913. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.49661/61.89271. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.53369/61.59443. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.10291/61.30268. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.00499/61.04593. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.82552/60.82551. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.89231/60.64615. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.65384/60.49835. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.60204/60.37065. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.46898/60.24976. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.29149/60.14244. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.48739/60.06031. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.30969/59.96640. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.36649/59.88533. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 61.40716/59.83242. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.21392/59.76161. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.07633/59.70186. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.09226/59.66601. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.07585/59.66570. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.99477/59.61057. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.86681/59.56086. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.77629/59.51287. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 60.71909/59.47922. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.66600/59.47134. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 60.78642/59.43375. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.76457/59.41019. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.80448/59.40656. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 60.71900/59.38266. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.44669/59.36960. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.41357/59.36301. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.50011/59.35730. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.31117/59.35227. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.45095/59.33784. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.33075/59.34520. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.21039/59.32864. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.43100/59.31918. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.15091/59.32988. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.24119/59.33197. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.27058/59.34763. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.19162/59.34045. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 59.99608/59.34622. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.11488/59.36045. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.00936/59.36254. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.92067/59.35779. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.06378/59.35847. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.80490/59.35677. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.88802/59.34657. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.83865/59.34417. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.74235/59.33756. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.61157/59.33315. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.72677/59.32587. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.68180/59.32513. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.48611/59.31693. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.43158/59.31649. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.47863/59.33926. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.50869/59.29422. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.49354/59.34061. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 59.12282/59.37082. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.63553/59.39253. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 59.33443/59.38084. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.36529/59.39141. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 59.08436/59.36853. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 59.15634/59.34856. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 59.37630/59.34659. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.20004/59.37056. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.23564/59.36506. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.19373/59.32117. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.17249/59.34807. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.18969/59.37164. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.13229/59.34892. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.81335/59.30557. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.19277/59.32836. Took 0.33 sec\n",
      "ACC: 0.5, MCC: -0.05013806979968223\n",
      "Epoch 0, Loss(train/val) 71.08433/70.85152. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.92057/70.74496. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.80728/70.64172. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.68334/70.54047. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.52871/70.44170. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.40167/70.34917. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 70.26546/70.25877. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 70.13887/70.16790. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.98821/70.08041. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.86661/69.99072. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.71096/69.90095. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 69.60072/69.81590. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.49503/69.73277. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.34975/69.65128. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.15082/69.56783. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.07425/69.48351. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 68.89648/69.40154. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.73945/69.32179. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.56423/69.25031. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.42259/69.16907. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 68.19068/69.08692. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 68.11140/68.99929. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.81270/68.90808. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 67.66902/68.81020. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 67.46042/68.69801. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 67.29023/68.57121. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 67.08717/68.44123. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.88660/68.30144. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.61648/68.14112. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.35839/67.97126. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 66.17406/67.77420. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 65.87211/67.53862. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 65.58498/67.24600. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.31315/66.89135. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.96963/66.45954. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.76929/66.02234. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.46658/65.64767. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.24390/65.35253. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.94520/65.13790. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.83731/64.95073. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.67758/64.78013. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.49755/64.63035. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.45592/64.49238. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.26253/64.36742. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.11611/64.22855. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 63.02182/64.08788. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.89864/63.94278. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.71482/63.83520. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.61542/63.64738. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.62444/63.48954. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.29089/63.35249. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.06888/63.16733. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.15451/62.98895. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.90470/62.78292. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.73218/62.54401. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.60039/62.31979. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 61.33854/62.12955. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.22892/62.02904. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.01197/61.85783. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.93677/61.69474. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 60.84813/61.56627. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.74436/61.53359. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.44092/61.35822. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.29495/61.24857. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.21418/61.18324. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.02234/61.11826. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.01134/61.02715. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.79790/60.95273. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.74908/60.93005. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 59.68110/60.83039. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.46372/60.84206. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.38592/60.81669. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.30552/60.77140. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.37735/60.70827. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.22645/60.70383. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.22874/60.77520. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.97649/60.69317. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 58.86139/60.65813. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.92786/60.57758. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.15165/60.47685. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.07299/60.72174. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.70849/60.52081. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.54057/60.70034. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.70427/60.45076. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.78182/60.55266. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 58.77041/60.64224. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.51829/60.37372. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.29511/60.33328. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.39928/60.57784. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.51189/60.44753. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.21561/60.39574. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.24598/60.43036. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.31305/60.41281. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 58.08351/60.37680. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.97769/60.23112. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.01318/60.63380. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 57.93565/60.40886. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.96755/60.56296. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 57.83242/60.46381. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.93010/60.50223. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.05464091115261005\n",
      "Epoch 0, Loss(train/val) 70.74837/70.65915. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.53797/70.43140. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.28058/70.21867. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.05749/70.01787. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.78101/69.82341. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.52133/69.62610. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.21148/69.42538. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 68.90250/69.21953. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.59301/69.00734. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.19879/68.78613. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.82762/68.55350. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.49415/68.30790. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.17457/68.05457. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.79884/67.78655. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.48988/67.49572. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.18199/67.17789. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 65.91147/66.81973. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.53811/66.43161. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.31277/66.01733. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.01382/65.54256. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 64.62693/65.01022. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.30882/64.40703. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 63.89780/63.72594. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.70213/62.97278. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.14841/62.16052. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.81017/61.48021. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.25168/60.88812. Took 0.34 sec\n",
      "Epoch 27, Loss(train/val) 62.05437/60.35721. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.49495/59.86439. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 61.45786/59.41625. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.13080/59.02407. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 60.88944/58.68949. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.56850/58.43793. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.45940/58.25206. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.44445/58.09134. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.27932/57.97294. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.26050/57.87865. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.23720/57.79997. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.06297/57.72878. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.03784/57.67033. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.92649/57.61803. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.01201/57.57425. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.92121/57.54058. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 59.81284/57.50658. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.67645/57.47796. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.65298/57.45174. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.73802/57.42696. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.71734/57.40158. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.48888/57.38338. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 59.45719/57.36483. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.49225/57.35457. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.31915/57.35011. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.35259/57.34522. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 59.29220/57.34698. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.17262/57.36753. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.19091/57.38572. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.13070/57.42911. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.95544/57.43270. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.90633/57.43798. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.84815/57.45603. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.74335/57.47820. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.75193/57.51479. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 58.69369/57.59754. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.66436/57.55363. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.72873/57.56461. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 58.38993/57.65131. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.45394/57.52523. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.46138/57.63154. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.49732/57.64728. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.43452/57.85083. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.34025/57.80129. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.07759/57.78339. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.09569/57.84973. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.06906/58.02211. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.26310/57.93675. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.13020/57.89101. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.05694/58.00493. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 57.87837/57.98609. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.10193/58.09580. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.93187/58.16732. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.86614/58.14282. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.93566/58.34712. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.94157/58.25213. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.84825/58.35962. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 57.87135/58.37578. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.80351/58.31719. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.60865/58.39057. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 57.63020/58.33732. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.67484/58.35437. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.63327/58.43177. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 57.56530/58.72168. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.52704/58.54163. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.76764/58.60740. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.58070/58.68230. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.46391/58.62135. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 57.51360/58.76396. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.46363/58.77510. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.37188/58.80633. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.44051/58.80526. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.35569/58.76013. Took 0.32 sec\n",
      "ACC: 0.375, MCC: -0.2633392678518175\n",
      "Epoch 0, Loss(train/val) 70.32653/70.28103. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.17440/70.23852. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.03009/70.19114. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.84928/70.13635. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.67779/70.07008. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.51584/69.99811. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.26942/69.91916. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.12436/69.83379. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.90793/69.73886. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.66820/69.62778. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.36183/69.49876. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.21249/69.37041. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.79942/69.23190. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.53948/69.09019. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.28284/68.94770. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 66.96702/68.81390. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.51482/68.69092. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.10602/68.58547. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 65.86527/68.50532. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.48277/68.44053. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.29006/68.38326. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.14557/68.32724. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.74074/68.26888. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.64552/68.20292. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 64.49264/68.12670. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.45251/68.04259. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.26927/67.94901. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.12177/67.83884. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.82964/67.73421. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.89997/67.63125. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.75641/67.52798. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.68194/67.43258. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.61394/67.33603. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.66720/67.24346. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.44107/67.14857. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.31370/67.05817. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.25959/66.96851. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.23764/66.89017. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.17705/66.75779. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.11163/66.66564. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.94688/66.62485. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 63.01758/66.56934. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.06756/66.49871. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.96628/66.42117. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 63.07244/66.35875. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.98306/66.32053. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.87151/66.24789. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.94950/66.21852. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.93421/66.15434. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.78775/66.09809. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.79002/66.02453. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.74110/65.94221. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.57946/65.86668. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.68764/65.85118. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.59347/65.82091. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 62.60154/65.80048. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.42482/65.81168. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 62.59419/65.77090. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 62.46713/65.73546. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.56809/65.73656. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 62.46805/65.77536. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.42548/65.75788. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.20260/65.74760. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.40317/65.77144. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.15206/65.75115. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.06661/65.73139. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.93486/65.75066. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.08992/65.74171. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.98961/65.69962. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.04460/65.71678. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.91167/65.73818. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.90372/65.71149. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.96427/65.77919. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.73235/65.74552. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.60582/65.81490. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.57786/65.81429. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 61.57746/65.80093. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.60686/65.73818. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.33865/65.75812. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 61.38577/65.81026. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 61.19844/65.80722. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.29523/65.78558. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 61.13167/65.72948. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.09662/65.73152. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.14393/65.70444. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.04105/65.71371. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 61.02321/65.73882. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.98081/65.69594. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.98953/65.66404. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.82986/65.71375. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.85018/65.73829. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.71883/65.73785. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 60.69864/65.75172. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.71677/65.68502. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.69956/65.60133. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.66510/65.67626. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.51636/65.58910. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 60.68296/65.73057. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 60.77903/65.63227. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.39924/65.52695. Took 0.32 sec\n",
      "ACC: 0.578125, MCC: 0.14859644825447751\n",
      "Epoch 0, Loss(train/val) 70.88505/70.02283. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.61757/69.88138. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.33940/69.73445. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.07583/69.58258. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.86663/69.43336. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.65600/69.28533. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.43479/69.13828. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.20484/68.98737. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.97749/68.84013. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.70689/68.70004. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.54006/68.56779. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.35982/68.44141. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.10390/68.31778. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.91303/68.20408. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.64614/68.09563. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 67.50886/67.98522. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 67.26334/67.87566. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 67.05971/67.77325. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.01834/67.67036. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.75775/67.56388. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.43155/67.44852. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 66.24950/67.32521. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.03939/67.20143. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 65.73779/67.08143. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.45541/66.96709. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.34460/66.86581. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.98379/66.78173. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 64.68012/66.70930. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 64.56789/66.65006. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 64.15410/66.59573. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.92816/66.53651. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.72735/66.47534. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.50915/66.41599. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.33107/66.34743. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.02977/66.27936. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.80665/66.22242. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.55780/66.17142. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.37438/66.14600. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 62.26167/66.14217. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.89009/66.13042. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 61.80435/66.12115. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.64890/66.11682. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.68514/66.10612. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.59083/66.08364. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.38393/66.05914. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.23746/66.03569. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.17279/66.01359. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.00067/65.98454. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.83656/65.96049. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.65564/65.92986. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.74478/65.89387. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.66375/65.85696. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.38470/65.82819. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.36995/65.78203. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.28058/65.70454. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.17088/65.65342. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.04957/65.59620. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.92536/65.52637. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.88624/65.45240. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.89597/65.37363. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.68227/65.31857. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.57338/65.24921. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 59.57180/65.18147. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 59.47251/65.14052. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.51578/65.09595. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.34962/65.05149. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.32275/65.00525. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.26751/64.95451. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.27994/64.88041. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.13522/64.84013. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 59.00817/64.79531. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.08909/64.74536. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.01370/64.70948. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 58.94996/64.67625. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.97191/64.64970. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.86824/64.63152. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.88940/64.60847. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.64778/64.56265. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 58.67852/64.53316. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.60518/64.50677. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.64916/64.49665. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.53166/64.47442. Took 0.34 sec\n",
      "Epoch 82, Loss(train/val) 58.44002/64.47086. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.40217/64.46590. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.36698/64.43626. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.25809/64.39905. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.22042/64.40137. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.18911/64.39859. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.18935/64.37158. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 58.21762/64.41572. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.06336/64.39585. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.02179/64.47849. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.98040/64.43758. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 57.92020/64.52132. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.90203/64.38425. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.85479/64.49496. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.80850/64.37270. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.81871/64.66238. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.67180/64.39250. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.81734/64.69583. Took 0.32 sec\n",
      "ACC: 0.421875, MCC: -0.04115547222147856\n",
      "Epoch 0, Loss(train/val) 69.75255/69.83376. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.49326/69.77261. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.21027/69.71011. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 68.96771/69.64331. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 68.66382/69.56098. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.32322/69.46287. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.94318/69.34960. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.50451/69.21765. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.12505/69.06169. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.62826/68.87499. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 66.15384/68.66542. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 65.76173/68.43411. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.21592/68.17766. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 64.83111/67.89909. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.48565/67.59631. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 64.06742/67.25690. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.66904/66.89147. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.45776/66.49151. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 63.16841/66.05042. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.89626/65.58868. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.53669/65.08437. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.11194/64.52654. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 61.68953/63.95588. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.25127/63.53232. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.88665/63.23498. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 60.57266/63.02633. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.48030/62.91886. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 60.25639/62.88030. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 59.87493/62.86063. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 59.90828/62.86716. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.94971/62.87318. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.85352/62.88827. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 59.64154/62.90451. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 59.65372/62.91129. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.52339/62.91010. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.44967/62.91764. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 59.38357/62.93398. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 59.29758/62.96074. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.11436/62.98308. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.18101/63.01113. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.21551/63.03894. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 59.15750/63.07076. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.09524/63.09876. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.02718/63.13494. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.86953/63.15392. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.78960/63.18783. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.77911/63.20824. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.79832/63.23841. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 58.76214/63.24866. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.69571/63.26166. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.69981/63.26723. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 58.68910/63.27276. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 58.56745/63.28229. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 58.38058/63.29479. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.52139/63.30641. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.46242/63.31764. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.29388/63.32216. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.50892/63.33146. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.27773/63.35048. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.31011/63.33189. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.37123/63.32655. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.36237/63.34360. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.25208/63.35512. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 58.22659/63.35521. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.08800/63.34802. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 58.13758/63.34197. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.99477/63.35367. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.96391/63.36973. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.06441/63.35716. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.14775/63.34023. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.95467/63.33106. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.83259/63.33414. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.96533/63.34157. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.01336/63.32991. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.81778/63.33254. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.91200/63.33432. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.79726/63.32512. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.79035/63.33779. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.81115/63.33118. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 57.70873/63.33333. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.68916/63.33701. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 57.72518/63.34037. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 57.58760/63.33592. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.62012/63.34239. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.65937/63.34363. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 57.64166/63.36136. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.55280/63.38171. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.52421/63.41376. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 57.51615/63.40910. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.57619/63.43367. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.45937/63.45612. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.53804/63.45123. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.42612/63.43988. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.32116/63.41927. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.32196/63.40058. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.29300/63.43705. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.38020/63.41516. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.13865/63.47619. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.00194/63.43197. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.12214/63.42313. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.08222643447147887\n",
      "Epoch 0, Loss(train/val) 70.98183/72.63960. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.72753/72.54726. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.54055/72.45314. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.40258/72.35897. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.22543/72.26837. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.99099/72.18140. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.87253/72.10373. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.68272/72.03352. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.51587/71.97465. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.34540/71.92210. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.17316/71.87762. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.04398/71.84239. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.82162/71.81796. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.65549/71.80293. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 68.43188/71.79785. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.27412/71.79043. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.00799/71.78935. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 67.89678/71.78340. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 67.66797/71.77667. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 67.43861/71.76244. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.25463/71.73069. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 67.02592/71.68454. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.72002/71.60914. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 66.53586/71.49477. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 66.29682/71.33485. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.98201/71.13063. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.80223/70.88891. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.47464/70.65183. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.23040/70.44287. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.95666/70.26234. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.71021/70.11112. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 64.56192/69.98898. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 64.40131/69.89436. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.15797/69.80715. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 64.03599/69.71855. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.83690/69.62504. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.64685/69.50325. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.58780/69.36295. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 63.33605/69.20203. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 63.43843/69.02922. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.17054/68.85287. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 62.88349/68.74831. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.87342/68.68616. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.80693/68.63913. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.69228/68.61786. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.57006/68.58900. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.45695/68.56450. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.35278/68.53894. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.31980/68.49942. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.19040/68.44897. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.17750/68.41382. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.94352/68.35985. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.92548/68.32252. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.71141/68.27686. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 61.66053/68.22143. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.59970/68.14230. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.63362/68.03860. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.59083/67.95001. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.39752/67.86946. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 61.33762/67.78439. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.22769/67.77359. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.14976/67.79401. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.96785/67.71419. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.92760/67.71277. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 60.88265/67.60668. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.80116/67.44117. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.61729/67.37764. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.53879/67.42887. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.44343/67.34724. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.28036/67.33076. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.23096/67.28510. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.22309/67.24899. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.15155/67.24696. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 60.10358/67.25340. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.09260/67.17110. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.81933/67.11888. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 59.91909/67.10255. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.67360/67.09267. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.57652/67.06995. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.59915/67.08344. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.73380/67.10474. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 59.71024/67.08824. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 59.50781/67.08408. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.34605/67.08079. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.46044/67.09517. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.29628/67.09683. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.23188/67.12689. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.28265/67.09875. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.30865/67.13405. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.34350/67.13879. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.29174/67.15090. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.17562/67.09608. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.18071/67.11864. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.02891/67.03477. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 59.13267/67.11099. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.06279/67.08339. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.12322/67.08989. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.81911/66.99181. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 58.98328/67.10964. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.98741/66.96959. Took 0.33 sec\n",
      "ACC: 0.578125, MCC: 0.17485381766873062\n",
      "Epoch 0, Loss(train/val) 70.69900/70.63131. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.36302/70.50659. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.12601/70.37915. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.83973/70.24126. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.46192/70.10722. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.25938/69.96870. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.00509/69.82143. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.71135/69.65490. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.44694/69.45676. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.18267/69.22713. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.96782/68.98743. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.57806/68.76162. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.41910/68.53268. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.09067/68.31144. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.79732/68.07545. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 66.55540/67.82939. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.28053/67.57658. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.11320/67.30925. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.86750/67.00711. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.63303/66.66776. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.28005/66.28741. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.07205/65.90597. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.73231/65.38784. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.35857/64.76119. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.84508/64.15993. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.56734/63.73150. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.99636/63.35309. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.74795/63.04130. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.37354/62.80815. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.21612/62.63704. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 61.93292/62.54251. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 61.69602/62.51665. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.70742/62.50528. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.62418/62.49081. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.52933/62.49553. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.40116/62.51998. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.34104/62.53960. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.36751/62.56651. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 61.24373/62.59454. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 61.28113/62.62892. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.10635/62.65834. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.11069/62.68269. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.13337/62.69641. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 61.02779/62.71666. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 61.12675/62.72715. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.14044/62.74070. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.06990/62.72744. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 60.83859/62.75096. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.89696/62.77594. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 61.01713/62.76924. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 60.98550/62.73055. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.82199/62.73688. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.83393/62.78469. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.83328/62.83557. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.55629/62.88470. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 60.68101/62.88379. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.67763/62.86699. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.63281/62.88181. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 60.58359/62.91278. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.49970/62.97121. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.55357/63.06046. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.36255/63.10392. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.39396/63.12677. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.54139/63.15216. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.36693/63.19070. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.44924/63.23278. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.24520/63.27406. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.30667/63.32340. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 60.30367/63.39874. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.29205/63.46224. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.45151/63.48611. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 60.29307/63.54977. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.28186/63.60307. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.14438/63.64040. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.13487/63.64185. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.09407/63.64214. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.02148/63.70395. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.01496/63.74760. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.84166/63.81730. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.77666/63.85504. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.77087/63.86035. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.73229/63.92351. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 59.65101/63.94625. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.70975/63.92763. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 59.60991/63.94994. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.53343/64.02398. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.43403/63.96703. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 59.44243/64.02661. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.38322/64.11063. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 59.30352/64.12344. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.36929/64.16955. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 59.16678/63.91225. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 59.28589/63.91421. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.23716/63.95470. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.14421/63.98582. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.30871/64.10286. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.12759/64.10442. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.07714/64.20068. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.89533/63.93136. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 59.17857/63.89767. Took 0.32 sec\n",
      "ACC: 0.484375, MCC: 0.026100007954032563\n",
      "Epoch 0, Loss(train/val) 70.64537/71.17506. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.51382/71.05102. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.41328/70.92810. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.29216/70.80354. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 70.15660/70.68340. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 70.06702/70.56495. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.97211/70.44761. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 69.81893/70.33077. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.71987/70.21018. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.61770/70.08278. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 69.45321/69.94985. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.34248/69.80693. Took 0.30 sec\n",
      "Epoch 12, Loss(train/val) 69.17365/69.65823. Took 0.30 sec\n",
      "Epoch 13, Loss(train/val) 69.09805/69.50954. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 69.00388/69.35569. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.85238/69.19912. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 68.73487/69.02353. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.54387/68.84235. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 68.34239/68.64951. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.28468/68.43508. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 68.09185/68.19820. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 67.84484/67.94612. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.76928/67.69753. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 67.51070/67.44344. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 67.25545/67.17532. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.99725/66.89674. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 66.74871/66.59821. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 66.55938/66.29854. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.25073/65.99050. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 65.96687/65.69040. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.78126/65.39241. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 65.59565/65.09535. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 65.32466/64.80865. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.25476/64.53738. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.99497/64.26601. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.90316/64.01327. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 64.72773/63.79213. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 64.65115/63.57244. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.55029/63.40657. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.40234/63.29883. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.37749/63.21685. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.19694/63.12999. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 64.09715/63.05628. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.92090/63.00354. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.80088/62.98903. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 63.83400/62.96088. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.59988/62.93322. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 63.61790/62.89044. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 63.52122/62.88010. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.36893/62.86764. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 63.34493/62.83319. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.31287/62.79807. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.26210/62.77697. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.09926/62.76554. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.89978/62.75211. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 62.98382/62.73347. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 62.96463/62.72757. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.81588/62.69573. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.73317/62.68990. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.64284/62.67967. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 62.69186/62.67303. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 62.52106/62.69643. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.48904/62.68042. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.52775/62.70504. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 62.44496/62.68281. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.23259/62.64799. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.29261/62.60445. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.22073/62.59358. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.00312/62.60666. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 62.07717/62.61974. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.94712/62.52345. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.93709/62.45403. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 61.79630/62.47246. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.69551/62.42027. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.71122/62.40701. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 61.94957/62.38396. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 61.71510/62.40183. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 61.67494/62.32562. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.55619/62.24545. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 61.56768/62.15517. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 61.44581/62.16552. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.57855/62.15094. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 61.43336/62.10712. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 61.45661/62.07440. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.26263/61.97564. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.19695/61.95199. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 61.27639/61.93769. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.18644/61.82963. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 61.16303/61.89917. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 61.10266/61.83346. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 61.02365/61.88529. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.97103/61.74463. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 61.07776/61.74201. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.94578/61.68255. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 60.94016/61.58887. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.96913/61.63472. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.79976/61.59595. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.83989/61.53942. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.73943/61.48040. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 60.72984/61.48522. Took 0.32 sec\n",
      "ACC: 0.59375, MCC: 0.19941818058542932\n",
      "Epoch 0, Loss(train/val) 70.22572/70.24436. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 69.99169/69.98991. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.74494/69.71582. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.39786/69.41671. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 69.12340/69.10338. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.76191/68.77774. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.47841/68.44370. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.13432/68.10283. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.82339/67.75420. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.46180/67.39689. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.13889/67.03133. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.70136/66.64088. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.36930/66.23539. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.90537/65.82304. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.56011/65.45358. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.19853/65.15922. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.84434/64.91681. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.65534/64.70547. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.39428/64.50662. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.05666/64.32467. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 63.99306/64.15080. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.72469/63.97350. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.57231/63.78072. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.29450/63.56588. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.04553/63.32133. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.84613/63.03133. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.68416/62.68219. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.33116/62.27709. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.15012/61.83973. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.78170/61.41338. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.51555/61.04141. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.13986/60.71024. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 60.81794/60.41027. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 60.46130/60.10962. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 60.02771/59.82380. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.86529/59.58075. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 59.65599/59.39094. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.51472/59.23605. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 59.46562/59.09964. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.40436/58.96663. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.40829/58.84652. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.20359/58.73623. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.11144/58.62299. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.06058/58.51282. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.92447/58.40677. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.96010/58.29581. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.79994/58.19581. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 58.69378/58.09058. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 58.73524/57.99423. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 58.72778/57.91626. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 58.62325/57.82068. Took 0.34 sec\n",
      "Epoch 51, Loss(train/val) 58.45030/57.74623. Took 0.34 sec\n",
      "Epoch 52, Loss(train/val) 58.48902/57.67349. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 58.38521/57.56511. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 58.42124/57.49992. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 58.26923/57.42389. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 58.22045/57.35645. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.11390/57.24582. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 57.99365/57.21129. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.93960/57.12215. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 57.94387/57.06107. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 57.81098/57.05749. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.63929/56.99715. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.71872/56.93844. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.65048/56.88956. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.51266/56.84126. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.36091/56.77189. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.47593/56.70796. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.31898/56.62119. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 57.27065/56.58810. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.29078/56.54908. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.21898/56.49853. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.09818/56.43822. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.04592/56.41785. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.03816/56.34013. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.04813/56.33562. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 56.87775/56.28824. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.74822/56.26304. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 56.86416/56.24839. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.83707/56.20214. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.73451/56.15454. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 56.66451/56.14174. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 56.70185/56.12114. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.63855/56.09636. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 56.52652/56.02370. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.45618/55.98712. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.49566/55.97673. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.43110/55.95996. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 56.28352/55.88082. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 56.30582/55.92958. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.30165/55.85454. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.22905/55.91919. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.22476/55.89252. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.12628/55.93032. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.11648/55.85798. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 56.11224/55.90197. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.00690/55.94930. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.93548/55.89675. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.09099/55.87629. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.87410/55.94690. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: 0.04645240022848054\n",
      "Epoch 0, Loss(train/val) 70.85678/71.77921. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.64066/71.68088. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.46756/71.58247. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.23727/71.48434. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.00109/71.39043. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.82140/71.29040. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.60900/71.18383. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.33733/71.07419. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.10863/70.96169. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.83580/70.85185. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.60284/70.73988. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 68.26430/70.63451. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.95042/70.53516. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.58673/70.44629. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.30445/70.36718. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.98210/70.29486. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.54936/70.22662. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.27989/70.15481. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.92280/70.07412. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.66069/69.97365. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 65.31284/69.85771. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.05064/69.71761. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.78391/69.55869. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.51674/69.38364. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 64.29865/69.18858. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.99965/68.97195. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.89899/68.74676. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.46964/68.50963. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.20504/68.24889. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.99285/67.95895. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 62.75890/67.64908. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.59925/67.32346. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.34033/66.99442. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 61.93728/66.64934. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 61.69359/66.28481. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 61.34261/65.90938. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.21983/65.53986. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.90624/65.17393. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.62777/64.81140. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.33309/64.44746. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.27910/64.14242. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.24569/63.88512. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.11834/63.64842. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.15377/63.46267. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.08202/63.30993. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.88671/63.18073. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.92635/63.07741. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 59.72080/62.99603. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.65205/62.93213. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.72442/62.87616. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.70519/62.83103. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 59.61150/62.79741. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.39185/62.76841. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.36829/62.73947. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.38882/62.71477. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 59.37710/62.69348. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.37177/62.67700. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.31638/62.65867. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.29613/62.64061. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.30960/62.62821. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.16605/62.62428. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.08460/62.61704. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.20430/62.61445. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.32409/62.60958. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.99576/62.60079. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.93770/62.58168. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.85323/62.56779. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 58.96303/62.55388. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.90160/62.56266. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.92699/62.55723. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.90488/62.54148. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.92507/62.52026. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 58.75243/62.52145. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.80920/62.53317. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.73987/62.54033. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.70107/62.53771. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.54582/62.53020. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 58.61961/62.52641. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.50618/62.52591. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.31958/62.52834. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.42286/62.53269. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.51823/62.52179. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.42420/62.51615. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.30129/62.50247. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.27225/62.54361. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.14702/62.56800. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.17903/62.57691. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.37014/62.59758. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.99789/62.63942. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.05605/62.67109. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.95889/62.70458. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.04144/62.73553. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.76440/62.71035. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.68246/62.65562. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.61558/62.62879. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.67766/62.52640. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.65719/62.49437. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 57.46857/62.44329. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.51416/62.41780. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.31515/62.37931. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.099230849433283\n",
      "Epoch 0, Loss(train/val) 70.33348/71.85458. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.09530/71.72777. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.87741/71.60638. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.67486/71.48966. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.40617/71.37907. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.18719/71.26701. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.98009/71.15331. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.74755/71.04039. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.42329/70.92326. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.07857/70.79940. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.79678/70.66026. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.40442/70.51817. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.15291/70.36678. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 66.78665/70.20980. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.27274/70.03403. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.93774/69.84344. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.56925/69.64613. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.24418/69.45158. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.81711/69.24498. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.51244/69.03341. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.25354/68.84873. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.06997/68.67015. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.78224/68.46964. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 63.67551/68.24525. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.37067/67.98866. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.22889/67.71532. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.06064/67.44222. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.87239/67.20328. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 62.51005/66.98643. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.36137/66.80420. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.35809/66.66388. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.17015/66.52312. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.13658/66.38795. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.89027/66.27348. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.97962/66.19482. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 61.76763/66.14150. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.61769/66.09989. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.38439/66.04069. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.37516/65.97843. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.38946/65.89547. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 61.16376/65.79574. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.17985/65.71684. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.95048/65.62025. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 60.94194/65.51402. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.86935/65.44479. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.89935/65.35930. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.95087/65.24145. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 60.67770/65.16573. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.68397/65.05185. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.62135/64.94193. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.69469/64.84555. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.48440/64.79626. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.49710/64.66818. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.24625/64.60161. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.26576/64.57752. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.25075/64.50284. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.21823/64.49525. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 60.13411/64.42509. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.01253/64.35166. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.10204/64.25905. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.04000/64.26652. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.08272/64.26347. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.87424/64.28085. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.77773/64.16312. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.76631/64.21074. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 59.69980/64.19246. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 59.50440/64.15958. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.58952/64.12640. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.51169/64.16637. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.53262/64.17618. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.27295/64.17412. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.46285/64.19061. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.41322/64.13361. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.33055/64.17938. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.26635/64.15607. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.21670/64.19288. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 59.11422/64.15802. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.27779/64.17500. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.10984/64.12019. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.01537/64.15424. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 59.09514/64.14291. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.06240/64.12737. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.98519/64.06261. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.97577/64.08193. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.86510/64.04430. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.82684/64.06357. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.59011/64.16410. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.57597/64.09917. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.56231/64.09940. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.57338/63.97112. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.57975/64.08669. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.55261/63.96739. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.54130/64.01859. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.39340/64.03362. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 58.32425/63.97219. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.45579/63.96861. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 58.46372/64.00809. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 58.30159/63.93253. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.28408/63.99824. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.22071/64.11510. Took 0.32 sec\n",
      "ACC: 0.640625, MCC: 0.2875509247045426\n",
      "Epoch 0, Loss(train/val) 70.42996/71.60762. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.27926/71.50871. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.19421/71.41026. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.07112/71.31632. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.94412/71.23507. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.85761/71.15611. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.71450/71.07140. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.60448/70.98368. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.42451/70.89762. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.26141/70.81681. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.08931/70.72734. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.94078/70.61878. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.70158/70.50169. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.49644/70.37326. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.20813/70.23024. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 67.91507/70.07806. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.70310/69.92408. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.40328/69.77115. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.17000/69.62055. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.85657/69.46719. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 66.69135/69.30437. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.47634/69.14334. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 66.32954/68.97945. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.04666/68.81548. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.00125/68.64779. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 65.66192/68.46738. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.64466/68.29469. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.52167/68.12269. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 65.35043/67.95263. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 65.17434/67.78221. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 65.07567/67.62288. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.96963/67.48402. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.84651/67.32724. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 64.63757/67.16236. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.47465/67.01086. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.39228/66.86401. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.29595/66.74285. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 64.25921/66.58250. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 64.09501/66.49557. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.88587/66.36703. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.98285/66.28473. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.93663/66.22002. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.94315/66.12537. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.74285/66.06060. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 63.77468/66.01970. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.63390/65.96461. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.62791/65.89785. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 63.64076/65.88947. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.45321/65.79401. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.52801/65.79472. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.42094/65.71847. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.33888/65.68032. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 63.53685/65.67489. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.29359/65.54757. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.39695/65.57201. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.39102/65.56329. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.31951/65.54880. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 63.29050/65.53251. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.21858/65.48047. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.10793/65.49611. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 63.22962/65.40853. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 63.19204/65.47840. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 63.00433/65.38139. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 63.03867/65.33869. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.68482/65.31356. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.99418/65.29204. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.90251/65.25910. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.88403/65.20175. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.98631/65.14146. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.89451/65.16509. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.61889/65.10722. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.94702/65.07805. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.73078/65.00168. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 62.71878/65.06757. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.56330/64.94182. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.62670/65.04771. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.65957/64.95557. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.79207/64.96901. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 62.54513/64.84294. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.44691/64.94420. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.55164/64.76608. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.50180/64.84366. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 62.32232/64.65255. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 62.40280/64.80359. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.37445/64.57895. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.18500/64.57128. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 62.11652/64.48317. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.99522/64.49886. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 62.01588/64.32447. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 61.99800/64.33942. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.72393/64.23415. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.86743/64.24174. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 61.75774/64.22919. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.80685/64.22071. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.51222/64.09718. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.47250/64.19833. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.57957/64.05589. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.51538/64.01925. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.40602/63.97279. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.21792/64.16422. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.03202563076101743\n",
      "Epoch 0, Loss(train/val) 70.82727/71.37057. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.69883/71.29218. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.57442/71.21362. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.47076/71.12846. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.37760/71.04320. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.29608/70.96212. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.14551/70.88596. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.07921/70.81647. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.96002/70.75372. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.87517/70.69357. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.81312/70.63554. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.68256/70.58095. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 69.53902/70.53249. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 69.44086/70.48370. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.36284/70.43970. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 69.21432/70.39831. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 69.16429/70.35859. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 68.99207/70.31600. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 68.87858/70.27408. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 68.76936/70.23872. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 68.66871/70.20361. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 68.58464/70.16463. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 68.37614/70.12656. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 68.25980/70.08655. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 68.11283/70.04441. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 67.96589/69.99899. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 67.91497/69.94401. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 67.72786/69.89311. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 67.59988/69.83860. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 67.43502/69.77966. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 67.27745/69.71527. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 67.13613/69.64596. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 67.07886/69.57191. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 66.90214/69.49348. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 66.73209/69.41164. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 66.66396/69.32063. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 66.46298/69.23196. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 66.47045/69.13521. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 66.22449/69.01290. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 66.01609/68.88930. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 65.81091/68.75922. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 65.82174/68.64038. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 65.62078/68.50327. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 65.35024/68.37210. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 65.41921/68.24245. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 65.33614/68.12449. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 65.05327/67.97836. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 64.90599/67.83192. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.84432/67.68862. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 64.65904/67.54063. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 64.68299/67.41167. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 64.33311/67.26608. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 64.38971/67.09680. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 64.07132/66.92027. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.95685/66.69987. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 64.01915/66.46475. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 63.67151/66.20028. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.39437/65.95711. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 63.35236/65.74152. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 63.20111/65.54286. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.86079/65.42646. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.90782/65.38646. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.83984/65.32532. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 62.57270/65.24711. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.35855/65.18982. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.39613/65.06996. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 62.18251/65.00266. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.23406/64.90273. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.15674/64.85363. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.95669/64.84847. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.10260/64.83589. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 61.79963/64.80588. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.81454/64.75828. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.71672/64.73856. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.72926/64.70496. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.68793/64.70367. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.70492/64.70436. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.66596/64.69231. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.40436/64.69054. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 61.43913/64.69402. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.37369/64.71404. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.22329/64.68694. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 61.42672/64.70370. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.11875/64.70144. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.20157/64.73137. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 61.16892/64.71478. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.17573/64.68056. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.07557/64.71419. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.16790/64.69630. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 60.93417/64.71317. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 61.01325/64.70570. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.09862/64.68286. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 60.84364/64.73602. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 60.74584/64.70037. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.83831/64.69215. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 61.05130/64.73287. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.80366/64.67849. Took 0.34 sec\n",
      "Epoch 97, Loss(train/val) 60.67030/64.77003. Took 0.34 sec\n",
      "Epoch 98, Loss(train/val) 60.68186/64.72348. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 60.72333/64.74374. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.019772733298509516\n",
      "Epoch 0, Loss(train/val) 72.47344/72.34972. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 72.07195/71.81673. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.67987/71.29643. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 71.21748/70.80427. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.90808/70.34952. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 70.45660/69.93031. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.12702/69.54604. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.72811/69.18352. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.40672/68.85086. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.98485/68.54206. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.66029/68.25670. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.35851/67.99323. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.96852/67.73696. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 67.51749/67.48098. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.29666/67.22619. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.96288/66.95621. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.65055/66.67214. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.30843/66.37056. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 65.83344/66.06888. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 65.56883/65.79034. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 65.40508/65.53941. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.08790/65.30707. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 64.80035/65.10439. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 64.49532/64.92222. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 64.36371/64.75589. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.23236/64.60416. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.05643/64.46575. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.80476/64.34267. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.73845/64.23172. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.51987/64.12573. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.45613/64.02398. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.34019/63.92699. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.16772/63.82548. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.03316/63.72568. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.90011/63.61983. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.80128/63.51230. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.73234/63.39973. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.47643/63.28004. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.55903/63.17498. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.32064/63.06770. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.29450/62.94001. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.05107/62.79279. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.09263/62.64902. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.03038/62.49156. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.77383/62.32742. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 61.55406/62.16076. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.39937/61.99837. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.23785/61.82993. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.16632/61.65349. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.82689/61.45515. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.53445/61.26012. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.50836/61.10237. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.16273/60.99614. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.24390/60.93895. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.89816/60.91547. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 59.96331/60.91518. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.81082/60.92606. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.75741/60.94005. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 59.63359/60.96157. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 59.44060/60.95673. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.47114/60.93327. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.36868/60.95731. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.28094/60.90407. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.14603/60.85098. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.03841/60.80272. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 58.93114/60.68587. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 58.80414/60.62487. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.91264/60.56624. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.70837/60.50733. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.72325/60.46165. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.63074/60.43269. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.66728/60.40733. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.49022/60.41447. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.41909/60.42423. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.46924/60.40409. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 58.23020/60.30617. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 58.19109/60.22927. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.10912/60.16389. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.12099/60.11817. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.13160/60.04824. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.14819/59.99361. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.10741/59.91825. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 57.98879/59.86868. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 57.99066/59.82217. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.93481/59.77104. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 57.91219/59.73103. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 57.79920/59.68673. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.88730/59.62979. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.73512/59.61678. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.81123/59.61360. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.74536/59.55102. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.67006/59.51315. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.73113/59.50475. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.64460/59.49634. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.64577/59.45237. Took 0.34 sec\n",
      "Epoch 95, Loss(train/val) 57.76669/59.44736. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.85913/59.43128. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.47939/59.38455. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 57.49353/59.35844. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.61298/59.36343. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: 0.007040915115573488\n",
      "Epoch 0, Loss(train/val) 71.02054/70.73358. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.72611/70.56614. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.53355/70.39814. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.30395/70.23840. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.06164/70.08272. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.88699/69.93048. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.64525/69.77324. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.43875/69.61132. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 69.20787/69.44415. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.95783/69.26170. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.71584/69.06969. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.43063/68.86241. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 68.18133/68.64185. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.84823/68.40462. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.49978/68.15817. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.12329/67.95602. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.65885/67.77415. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.22815/67.58550. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.71008/67.36793. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.11047/67.10265. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.49050/66.78447. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.96541/66.43909. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.41098/66.10255. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.89285/65.77847. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.59411/65.47929. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 62.17800/65.20203. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.00326/64.93967. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.69084/64.69604. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 61.45678/64.49274. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.45472/64.34179. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 61.20853/64.21059. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.17098/64.08232. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.05760/63.96983. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.83644/63.86670. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.85463/63.76148. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 60.74812/63.65337. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 60.67673/63.53719. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.52667/63.42433. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.45592/63.29486. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.32622/63.18742. Took 0.31 sec\n",
      "Epoch 40, Loss(train/val) 60.35849/63.10437. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.23583/63.03388. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.14790/62.95256. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.23797/62.89955. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 59.99124/62.83703. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.02049/62.78776. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 59.92985/62.72439. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.76025/62.69420. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.76984/62.62435. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.67806/62.58136. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.60197/62.51813. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 59.68102/62.47058. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 59.40895/62.39950. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.51561/62.36298. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.47336/62.29971. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.46726/62.22834. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 59.25671/62.17110. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.27832/62.12505. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 59.21154/62.09121. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.08291/62.02084. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.92093/61.95380. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.98181/61.93299. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.89346/61.90946. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.95227/61.83838. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.74046/61.78969. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.73181/61.78474. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 58.58592/61.74588. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 58.60900/61.70703. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.63845/61.70667. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 58.61622/61.66064. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.33922/61.60498. Took 0.31 sec\n",
      "Epoch 71, Loss(train/val) 58.44185/61.58250. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.29821/61.53270. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 58.36843/61.49533. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 58.29096/61.50969. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.22871/61.45728. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 58.07758/61.46230. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.32583/61.45260. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.06962/61.43570. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.25946/61.38374. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.98971/61.36401. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.05041/61.37502. Took 0.30 sec\n",
      "Epoch 82, Loss(train/val) 58.01391/61.31036. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.98013/61.28942. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.80645/61.21271. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 57.99943/61.31802. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.84890/61.27933. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.03483/61.25337. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.84329/61.16811. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.64707/61.22074. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.68536/61.14461. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.78455/61.15348. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 57.57677/61.05594. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.61688/61.19974. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.67857/61.06852. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.26336/61.21273. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.37070/61.20837. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.39512/61.20925. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.39554/61.09959. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.33343/61.21895. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.10259783520851541\n",
      "Epoch 0, Loss(train/val) 71.54911/70.69154. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.31200/70.57034. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 71.08925/70.44905. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.90624/70.32858. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.68556/70.21142. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.50302/70.09573. Took 0.30 sec\n",
      "Epoch 6, Loss(train/val) 70.26790/69.97634. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.00883/69.84475. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.79125/69.69621. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.59027/69.52389. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.33819/69.32165. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.10991/69.09828. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 68.92479/68.84952. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 68.62073/68.56744. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.34144/68.24210. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.07641/67.88021. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 67.74055/67.46419. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.37633/67.00268. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.93562/66.50649. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 66.56444/65.98885. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.13732/65.48610. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 65.56337/65.00967. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.25577/64.57209. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.83703/64.17075. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 64.54557/63.86103. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.22539/63.62796. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.93747/63.43109. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 63.72946/63.26490. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.53106/63.14050. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 63.01649/63.01258. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.92102/62.89103. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.75373/62.76364. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.20290/62.64473. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 61.96917/62.54920. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.73184/62.45150. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 61.60472/62.35888. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.31514/62.27344. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.33553/62.19024. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.21119/62.11748. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.02734/62.05321. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.95309/62.00061. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.93308/61.95352. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.85933/61.90786. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 60.96065/61.85479. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.71277/61.80684. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.68635/61.76576. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 60.67086/61.72251. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 60.67850/61.67961. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 60.52363/61.63416. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.54612/61.59592. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 60.46419/61.55321. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 60.33923/61.51352. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 60.41673/61.48340. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 60.45990/61.44376. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.43255/61.40247. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.32121/61.36583. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.21661/61.33214. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.34957/61.28672. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.29471/61.23596. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 60.08831/61.18038. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 60.32096/61.12368. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.16426/61.05595. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 59.97914/60.98472. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 59.97514/60.92099. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 60.07487/60.82937. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 60.10709/60.76651. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.93853/60.76382. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.71520/60.74268. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.87726/60.69699. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 59.81759/60.62935. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.77600/60.62666. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.73053/60.57280. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 59.76194/60.49335. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 59.72757/60.49580. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.54670/60.45520. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.61185/60.38367. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 59.69635/60.37132. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.47789/60.28683. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.53589/60.28395. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 59.47353/60.16501. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 59.37366/60.22723. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.59830/60.03886. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.54679/60.13738. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.20855/59.99142. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 59.50860/59.99021. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.35819/59.95302. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 59.26901/59.87043. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 59.25833/59.90495. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.17997/59.81392. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 59.30500/59.84198. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.22232/59.70543. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.20615/59.77775. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 59.10583/59.62211. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.23475/59.70853. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.12320/59.59620. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.14806/59.58954. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.10162/59.49108. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.03243/59.53532. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 58.83777/59.42603. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 59.03636/59.51991. Took 0.32 sec\n",
      "ACC: 0.5625, MCC: 0.14462158210542375\n",
      "Epoch 0, Loss(train/val) 71.18681/70.21155. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 71.01675/70.08152. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.83551/69.95398. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.63097/69.82502. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.45568/69.69390. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 70.29023/69.56107. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 70.13374/69.42825. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.96302/69.29593. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 69.78395/69.16105. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.59788/69.02879. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 69.39586/68.90279. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 69.15735/68.78198. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 68.99151/68.65657. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 68.78027/68.53420. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.54053/68.40218. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 68.30699/68.26695. Took 0.31 sec\n",
      "Epoch 16, Loss(train/val) 68.05093/68.12416. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.84707/67.96541. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 67.57523/67.77990. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 67.34662/67.58852. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 67.10090/67.37450. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 66.88035/67.12930. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.69127/66.86809. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.46255/66.59232. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.22822/66.32618. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 66.10117/66.06932. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.84880/65.81135. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 65.62072/65.56655. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.34772/65.33858. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.30949/65.13224. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.18409/64.92467. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 64.89298/64.71094. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 64.75775/64.52008. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.71019/64.38362. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.31458/64.24745. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.23191/64.17934. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.11267/64.07768. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.91773/63.99281. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 63.90841/63.89191. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.84516/63.81005. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.64133/63.76978. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 63.72533/63.73066. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.60178/63.74256. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.63170/63.69451. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 63.31592/63.67047. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.38421/63.62134. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.48385/63.57198. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.21545/63.52618. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.30109/63.48639. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 63.35759/63.43392. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 63.21978/63.39997. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.11432/63.36584. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 63.03736/63.32540. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.92507/63.29031. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.01066/63.25968. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 62.91821/63.22692. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 62.76843/63.18134. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 62.76628/63.15577. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.77473/63.12643. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.78226/63.09161. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 62.57707/63.06163. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.62402/63.02770. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.54732/62.99865. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 62.54907/62.97895. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.48620/62.94354. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.51283/62.92720. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.48300/62.89186. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.34616/62.87087. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.44680/62.82910. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.33933/62.82000. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.51172/62.78804. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.21216/62.78460. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.21857/62.75178. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.25698/62.73826. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.11291/62.70643. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 62.10296/62.69025. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 62.11172/62.66387. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.09838/62.64844. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.09531/62.61605. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.99901/62.60064. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.88677/62.56290. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.97796/62.56036. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 61.91899/62.53158. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.96502/62.52354. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.88376/62.50294. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.72475/62.49691. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 61.81136/62.46874. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 61.66574/62.45587. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 61.55761/62.43307. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.64144/62.42775. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.65679/62.41024. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.62133/62.40239. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 61.59313/62.38177. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.49425/62.34979. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.48734/62.32202. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.26077/62.30907. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.43162/62.28818. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.39990/62.27631. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.22257/62.27867. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.32403/62.25311. Took 0.31 sec\n",
      "ACC: 0.53125, MCC: -0.0010820172848339962\n",
      "Epoch 0, Loss(train/val) 69.58482/69.28722. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.37097/69.13072. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.20812/68.96848. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.02280/68.79886. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.74680/68.62144. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 68.51773/68.42831. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.29629/68.21902. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.98273/68.00219. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.78879/67.76633. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.42694/67.51074. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.10583/67.24518. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 66.83050/66.96912. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.54387/66.69230. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.13053/66.41171. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.74979/66.14076. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.61467/65.87799. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.27191/65.61906. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.92215/65.36459. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.78449/65.12602. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 64.42697/64.90303. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.22937/64.68712. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.18180/64.48621. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 63.89498/64.29959. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.72752/64.13680. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.44390/63.97919. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.33494/63.82115. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.19925/63.66728. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.10972/63.51474. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 62.99965/63.36759. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.74933/63.21523. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.51779/63.06927. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.40624/62.93387. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.36883/62.79754. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.08811/62.65802. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.09562/62.52344. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.73332/62.38100. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.70237/62.24211. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.61320/62.10365. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.41874/61.99171. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.28006/61.86633. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.21453/61.74955. Took 0.31 sec\n",
      "Epoch 41, Loss(train/val) 61.03140/61.64833. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.91389/61.54769. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.62626/61.43932. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.67823/61.36129. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 60.19451/61.30920. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.29522/61.24868. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.29451/61.17592. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.37334/61.05885. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 60.10422/61.02570. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.90687/61.02383. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.84791/60.90307. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.76253/60.73769. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.84744/60.63464. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.43381/60.56861. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 59.30565/60.33456. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.23793/60.15252. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.07594/60.03590. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.92464/59.82701. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.65829/59.86578. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.67714/59.46908. Took 0.31 sec\n",
      "Epoch 61, Loss(train/val) 58.47489/59.42420. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.40896/59.27900. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 58.31090/59.17094. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 58.29762/58.93398. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.32124/58.77429. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.22519/58.66878. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.80909/58.40857. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 57.88821/58.22931. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.71464/58.04771. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.79333/58.04789. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 57.60048/57.88689. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.50551/57.60825. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.37405/57.58953. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 57.27849/57.42724. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 57.13943/57.29350. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.15208/57.21055. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.23113/57.16499. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.06845/57.07843. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 56.96138/57.01863. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.91525/56.88489. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.89145/56.81375. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 56.54973/56.77926. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.65573/56.58839. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 56.73231/56.62931. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.59235/56.66336. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.59347/56.62363. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.57370/56.63855. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 56.35183/56.33752. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.27831/56.63204. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.24314/56.37726. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.32891/56.45187. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 56.15529/56.35663. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 56.06355/56.54200. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.04053/56.38021. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.95819/56.29808. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.99741/56.39153. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.93337/56.31345. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.94859/56.07127. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.86679/56.11894. Took 0.31 sec\n",
      "ACC: 0.46875, MCC: -0.12529113460674984\n",
      "Epoch 0, Loss(train/val) 70.81165/70.71688. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.50491/70.50499. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.28949/70.28160. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.99998/70.04701. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.73898/69.79048. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.46709/69.52008. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.23617/69.23988. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.87007/68.94899. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.55363/68.64419. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.19214/68.33345. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.92549/68.04266. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.57735/67.77549. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.13748/67.53745. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.97091/67.33149. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.48460/67.14947. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.28815/66.98768. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 66.11093/66.85233. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.82518/66.72501. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.64829/66.59933. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.25017/66.49483. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.14510/66.39730. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.92151/66.30203. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.69270/66.21158. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.57654/66.12094. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 64.45120/66.03017. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.27327/65.93277. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.02524/65.83087. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.83024/65.72384. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 63.57878/65.61372. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.34315/65.50475. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.03265/65.40505. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.98125/65.30923. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.88277/65.22240. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.86463/65.13857. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.70361/65.07175. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.52737/65.00490. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.35739/64.95403. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.36711/64.90720. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 62.15876/64.85948. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.22340/64.81086. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.00133/64.76287. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.85022/64.71885. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.93800/64.67409. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.87334/64.62971. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.93732/64.57618. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.74364/64.52699. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.80688/64.48299. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.72542/64.44402. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.54554/64.40316. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 61.59366/64.35974. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.61038/64.32713. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.59825/64.29152. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.39161/64.25648. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.62045/64.22806. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.43458/64.20121. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.18155/64.17566. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 61.29346/64.14871. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.39172/64.12025. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.29796/64.09674. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.38488/64.07150. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.10861/64.04489. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.17373/64.01987. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.14496/63.99540. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.13784/63.97647. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.22652/63.95736. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.37320/63.94344. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.16232/63.93142. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.96179/63.90955. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.92812/63.87929. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.96588/63.86301. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 60.93847/63.84570. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.90693/63.82948. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.82200/63.80287. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 60.99532/63.78502. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.84760/63.76711. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.76109/63.75431. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.75742/63.73104. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.80330/63.70735. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 60.60537/63.68567. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 60.74188/63.67469. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.54925/63.64909. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.70458/63.62826. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.45370/63.60910. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.56903/63.58981. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 60.50229/63.57777. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.37790/63.56034. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.30128/63.54622. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.45542/63.51553. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.23081/63.48771. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.19661/63.47942. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.11005/63.47527. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.06683/63.44833. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.14647/63.42017. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 60.00582/63.40632. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.90978/63.39386. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.87110/63.37745. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.88489/63.37176. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.63284/63.36600. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.63655/63.36082. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.53797/63.35012. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.1636319382479181\n",
      "Epoch 0, Loss(train/val) 70.10798/68.54747. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.91201/68.46472. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.77813/68.37649. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.59400/68.28069. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.52750/68.17821. Took 0.31 sec\n",
      "Epoch 5, Loss(train/val) 69.33187/68.06390. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.19815/67.93480. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.03139/67.79611. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.80056/67.64258. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.67683/67.47798. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.52638/67.30124. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.28825/67.11937. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.13525/66.92604. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.93819/66.73228. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.73983/66.54364. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.55943/66.36008. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.27227/66.16520. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 67.06818/65.98472. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.83221/65.81040. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.60301/65.64726. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.36235/65.49946. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.08790/65.36098. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 65.87186/65.23372. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.71807/65.10297. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.39853/64.96471. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.14900/64.80695. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.78527/64.63287. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 64.55431/64.47366. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 64.45864/64.31304. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 64.13987/64.16122. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.90860/64.10573. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 63.99822/64.13773. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.53103/64.20521. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 63.54858/64.23300. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.28547/64.30545. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.20469/64.37978. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.97284/64.49159. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.80258/64.50285. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.67087/64.59912. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.60079/64.63306. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.57876/64.66807. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.42477/64.68735. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.32304/64.70972. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.39960/64.72759. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.19500/64.71726. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.21238/64.74771. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.97007/64.76226. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.03478/64.76241. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.04921/64.75955. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.02945/64.80386. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.76457/64.80697. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 61.90231/64.80695. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.84823/64.80412. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.57048/64.76990. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.64025/64.78719. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.63797/64.80539. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.67073/64.84049. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.37425/64.85939. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.37261/64.86678. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.24607/64.85324. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.26656/64.85735. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.36945/64.88400. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 61.26456/64.90990. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.20681/64.93156. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.26147/64.92724. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 61.11865/64.90906. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.03168/64.90879. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 61.12705/64.94469. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 61.06443/64.95887. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.08976/64.96249. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.02571/64.93037. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.86919/64.93666. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.79071/64.96655. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.89819/64.94678. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.61701/64.95018. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.72477/64.94770. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.71023/64.93400. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.64867/64.92297. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.58761/64.93436. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.66210/64.94833. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 60.57286/64.95206. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.48702/64.95976. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 60.30101/64.93327. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.47469/64.93670. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.21426/64.92890. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.42659/64.94170. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.33389/64.94421. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 60.24727/64.92673. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 55.96813/51.71790. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 56.00066/51.69865. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 56.04791/51.66135. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 56.07249/51.61407. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 55.98112/51.54732. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 55.94556/51.52421. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 55.79729/51.46014. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 55.93480/51.35459. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 55.83141/51.29643. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.79665/51.23284. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 55.65894/51.20983. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 55.51502/51.22662. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.84323/51.13889. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.59816/51.06560. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.49717/51.02276. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.46097/50.96839. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.62343/50.93484. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.47968/50.86724. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.33649/50.78579. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.60894/50.73434. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.41333/50.63245. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.30853/50.57808. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.43841/50.49285. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.25613/50.38524. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.12498768867296815\n",
      "Epoch 0, Loss(train/val) 70.37281/69.18584. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.94652/68.59748. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.51162/67.99482. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.00695/67.37374. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.58088/66.72640. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.07218/66.05505. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.54495/65.36195. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.00430/64.64281. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 66.42060/63.89281. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 65.86399/63.10143. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 65.24688/62.28641. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 64.73611/61.45249. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 64.06667/60.61549. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 63.44025/59.78566. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 63.04819/58.99158. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 62.59798/58.25599. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 62.15281/57.58040. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 61.78253/56.97674. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 61.35940/56.40564. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 61.08642/55.88316. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 60.76141/55.42094. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 60.60698/55.03652. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 60.26335/54.72417. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 60.18151/54.45838. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 59.88704/54.22752. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 59.63430/54.02584. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 59.61116/53.85651. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 59.56607/53.71994. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 59.27685/53.57779. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.20507/53.46871. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 59.25188/53.39572. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.05688/53.31782. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 58.96585/53.18414. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 58.81786/53.08858. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 58.74906/53.03630. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 58.83235/52.98943. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.60507/52.92763. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 58.66900/52.89066. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 58.54515/52.84188. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 58.47866/52.77815. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.34585/52.76667. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 58.26972/52.73810. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 58.42735/52.68319. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.15009/52.63239. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.20957/52.62509. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 58.10605/52.63983. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 58.04196/52.70362. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 57.85666/52.86708. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 57.78406/53.07484. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 57.67208/53.07226. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 57.62852/53.24206. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 57.60359/52.94553. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.55233/53.45404. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.40890/53.01393. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.25355/53.65949. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 57.44740/53.14083. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.19867/53.64958. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.20661/53.29998. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.03053/53.68240. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 57.10106/53.38047. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 57.22383/53.62075. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.11014/53.30384. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 57.01588/53.67416. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 56.94112/53.25508. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.97430/53.59187. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.90704/53.43223. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 56.83894/53.43519. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 56.69153/53.24689. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 56.80688/53.60075. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 56.79795/52.95819. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.71154/53.86962. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 56.85339/53.02811. Took 0.34 sec\n",
      "Epoch 72, Loss(train/val) 56.56880/53.54589. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.72744/53.01222. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 56.51342/53.79880. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.62906/53.34750. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.49407/53.01698. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.38381/53.44451. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 56.51358/53.12022. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.35774/53.48849. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 56.32930/52.62132. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.46855/53.74613. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.26368/53.06183. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 56.35904/53.23608. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 55.89073/53.06315. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 56.16704/53.16535. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 56.21073/53.06518. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.21017/52.70191. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.99013/53.68728. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 56.14446/52.69084. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 56.05541/53.65178. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 56.20692/52.56433. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 55.99046/53.66861. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 56.15296/52.90405. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.69037/53.57231. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 55.88524/52.68140. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 55.76487/53.70134. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.97358/52.63041. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.87439/53.76588. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.71664/53.00384. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: 0.051799406700962544\n",
      "Epoch 0, Loss(train/val) 70.72386/70.38139. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.50129/70.34894. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.31900/70.31163. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.09384/70.27307. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.90797/70.23072. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.73097/70.17763. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.49775/70.11736. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.23719/70.04645. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.00958/69.96301. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.71855/69.85927. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.43332/69.74352. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.05611/69.62560. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.67498/69.50641. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.09775/69.37857. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 66.64426/69.21709. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.26811/69.00703. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.73276/68.73985. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.15164/68.43308. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.83271/68.08170. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.55317/67.69803. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.17510/67.31423. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.83979/66.93587. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.79536/66.58795. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.51415/66.29399. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.38652/66.05865. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.11479/65.81535. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.10127/65.64380. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.91321/65.51633. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.85774/65.38554. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 62.76155/65.28503. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.71117/65.21750. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.61344/65.19375. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.37209/65.17519. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.40536/65.09480. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.36494/65.06383. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.24306/65.06695. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.00698/65.05044. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.20542/65.04005. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.05884/65.04027. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.04986/65.02254. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.97894/64.96228. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.88575/64.93351. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.88400/64.92075. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.70237/64.90474. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.63540/64.88596. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.67193/64.91957. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.58401/64.95403. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 61.56813/64.94571. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.37986/64.96274. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.34642/64.99136. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.30938/64.97170. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.26020/64.95285. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.23208/64.98786. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.16712/65.00079. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.25194/64.94574. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.07636/64.96173. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.23796/64.98716. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.11076/64.93973. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.03155/64.90241. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.00926/64.90776. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.94641/64.88563. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.76220/64.86752. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.92504/64.81355. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.96647/64.86108. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.72200/64.89529. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.59312/64.89648. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 60.55429/64.83947. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.62088/64.85840. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.63523/64.86924. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.71409/64.88298. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.37695/64.89650. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.58664/64.86990. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 60.51302/64.87579. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.43491/64.87676. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.28938/64.92379. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 60.24915/64.92163. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.14921/64.97018. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.10656/64.99411. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 60.27028/64.97109. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.94636/65.01736. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.05946/65.00527. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.03770/65.03043. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.95543/65.01849. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.08041/65.07227. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.00540/65.13242. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 59.81787/65.08482. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 59.88002/65.14582. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.92734/65.10622. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.98662/65.21179. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 59.87436/65.21375. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.88174/65.20924. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.75418/65.24754. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.77486/65.28757. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.74634/65.33083. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.67105/65.36164. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.62952/65.32970. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.79034/65.37039. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.64544/65.39887. Took 0.34 sec\n",
      "Epoch 98, Loss(train/val) 59.53103/65.42672. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.60312/65.42448. Took 0.32 sec\n",
      "ACC: 0.609375, MCC: 0.1886680513554908\n",
      "Epoch 0, Loss(train/val) 71.22170/71.79333. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.95880/71.73073. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.75595/71.67062. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.51254/71.61203. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.26723/71.55298. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.01264/71.49133. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.69210/71.42062. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.37265/71.34634. Took 0.34 sec\n",
      "Epoch 8, Loss(train/val) 69.02509/71.27145. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.67959/71.19681. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.38958/71.12501. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.16446/71.05872. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.89007/70.98949. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.62625/70.92519. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 67.43050/70.86449. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 67.13499/70.80382. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 67.01167/70.74683. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.79883/70.69930. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.73082/70.66135. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.53991/70.62844. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.37873/70.59540. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 66.21232/70.56737. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.04104/70.53057. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.02255/70.49599. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.93481/70.46233. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.65771/70.43649. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 65.58039/70.39244. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 65.57785/70.34935. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.40288/70.31801. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 65.20859/70.28000. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.15683/70.24194. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.13626/70.20017. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 65.00105/70.14968. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.91570/70.10379. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.85926/70.04556. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 64.67407/69.98602. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.63811/69.92536. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 64.47581/69.87910. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 64.43618/69.82807. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.36804/69.76727. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 64.18814/69.71890. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 64.04601/69.65694. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.08513/69.58524. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 63.95653/69.50659. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 64.01299/69.42294. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.70798/69.32666. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 63.70709/69.23390. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.68333/69.13955. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.56598/69.01333. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 63.36355/68.89553. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.24622/68.75750. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 63.25914/68.59840. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 63.15646/68.42730. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.96428/68.27405. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 62.89371/68.10716. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 62.78414/67.99895. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.71621/67.89369. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 62.53795/67.78520. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 62.47436/67.69672. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.42675/67.60987. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 62.44208/67.50705. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.20228/67.40698. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.23118/67.30051. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 62.09621/67.23940. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.90656/67.17559. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.02014/67.11839. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.87900/67.01809. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.84250/66.87368. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 61.74146/66.78954. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.69072/66.75751. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.71934/66.68984. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.50701/66.63436. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.46884/66.51014. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.45802/66.48875. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.53495/66.44447. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 61.33173/66.37929. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.26552/66.32620. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 61.27077/66.26329. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.35934/66.17638. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.16573/66.04729. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 61.22271/66.00823. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.24891/66.03028. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.97866/65.93833. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.00878/65.81622. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.75339/65.77892. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 60.94434/65.84914. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.90525/65.72711. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.76658/65.71609. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 60.86614/65.66608. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.78435/65.74091. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.62540/65.55071. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.65020/65.58298. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.62144/65.48722. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.40269/65.32616. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.45205/65.32831. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.39502/65.22192. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 60.45490/65.33794. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.29276/65.24824. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.39311/65.20612. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 60.15578/65.22657. Took 0.32 sec\n",
      "ACC: 0.421875, MCC: -0.0759934587645922\n",
      "Epoch 0, Loss(train/val) 70.99191/69.63802. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.48031/69.17456. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.08846/68.69074. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.58148/68.17706. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.03996/67.61794. Took 0.34 sec\n",
      "Epoch 5, Loss(train/val) 68.56914/66.99480. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 67.92944/66.29588. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.29134/65.50102. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 66.60031/64.60071. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 65.67777/63.57113. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 64.66794/62.43379. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 63.50427/61.26324. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 62.31834/60.12004. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 61.44134/59.17306. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 60.59644/58.26946. Took 0.34 sec\n",
      "Epoch 15, Loss(train/val) 60.07501/57.46233. Took 0.34 sec\n",
      "Epoch 16, Loss(train/val) 59.31292/56.70115. Took 0.34 sec\n",
      "Epoch 17, Loss(train/val) 58.87644/55.97178. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 58.41000/55.28383. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 57.97526/54.63301. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 57.44200/54.02118. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 56.97650/53.44938. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 56.55191/52.93876. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 56.34608/52.53307. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 56.02049/52.19025. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 55.87767/51.90845. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 55.71240/51.66767. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 55.51753/51.47116. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 55.51520/51.30294. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 55.23436/51.15742. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 55.25560/51.04304. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 55.11141/50.94590. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 54.94802/50.87782. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 54.89196/50.81758. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 54.81979/50.75667. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 54.83520/50.70628. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 54.36616/50.64481. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 54.56995/50.58829. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 54.48008/50.53715. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 54.31873/50.47022. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 54.25919/50.39893. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 54.35761/50.31631. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 54.16000/50.22283. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 53.99151/50.12432. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 54.14382/50.02938. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 53.90337/49.92606. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 53.87068/49.86116. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 53.55464/49.77647. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 53.64190/49.68912. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 53.64076/49.58816. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 53.48625/49.49688. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 53.47867/49.46582. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 53.23064/49.37535. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 53.14304/49.28514. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 52.98345/49.22559. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 53.04270/49.16742. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 52.87277/49.13992. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 52.92850/49.05676. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 52.66272/48.94497. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 52.74820/48.89299. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 52.76094/48.86830. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 52.49072/48.80838. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 52.58281/48.78053. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 52.54131/48.80753. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 52.31955/48.73599. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 52.32184/48.66894. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 52.16367/48.66736. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 52.20959/48.65860. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 52.14198/48.61644. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 52.12635/48.57176. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 51.98323/48.62488. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 52.02621/48.63900. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 51.98028/48.57541. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 51.83433/48.51671. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 51.72923/48.64737. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 51.76995/48.60453. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 51.58453/48.56684. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 51.77497/48.56726. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 51.72696/48.60022. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 51.47079/48.59577. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 51.63283/48.60499. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 51.73053/48.58510. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 51.40480/48.58141. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 51.48728/48.60981. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 51.49226/48.71286. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 51.40554/48.64697. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 51.23065/48.60919. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 51.44173/48.61678. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 51.45195/48.66588. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 51.19008/48.73063. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 51.24564/48.65646. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 51.20419/48.61274. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 51.34079/48.67378. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 51.12357/48.73523. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 51.04372/48.72920. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 51.13814/48.66806. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 51.11200/48.68335. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 51.16920/48.75690. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 51.16857/48.78508. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 50.98220/48.72436. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.09341218537003596\n",
      "Epoch 0, Loss(train/val) 70.33745/70.20654. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.09735/70.10773. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 69.83677/70.00738. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.58408/69.90396. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.34001/69.79900. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.05933/69.68719. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.70688/69.56467. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.49868/69.43040. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 68.10470/69.28405. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.77627/69.13603. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.38287/68.98837. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.96115/68.83224. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.57053/68.67166. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.13120/68.49715. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.79861/68.29959. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.36240/68.08564. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.02918/67.85490. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.61020/67.61681. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.43507/67.38493. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.15674/67.16682. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.78071/66.96772. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.60503/66.82050. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.64818/66.69921. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.32855/66.60710. Took 0.34 sec\n",
      "Epoch 24, Loss(train/val) 63.11985/66.52640. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.15575/66.46026. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.86736/66.39601. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.59784/66.35066. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.51559/66.32957. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.45129/66.30952. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.32586/66.28117. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.13001/66.25156. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.05256/66.20360. Took 0.34 sec\n",
      "Epoch 33, Loss(train/val) 61.88097/66.15862. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.89096/66.09885. Took 0.34 sec\n",
      "Epoch 35, Loss(train/val) 61.77184/66.03018. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.57200/65.95573. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.43474/65.89624. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 61.32388/65.82637. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 61.56009/65.74602. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.24240/65.66233. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 61.10222/65.56833. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.06463/65.48972. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.03634/65.41206. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.80908/65.31480. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 60.75428/65.22640. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.76992/65.14868. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 60.66749/65.05208. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.67363/64.95726. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.49966/64.85524. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.58391/64.76357. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 60.41229/64.67400. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.32197/64.55458. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.31977/64.46655. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 60.26290/64.37744. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.15462/64.31042. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.03288/64.23254. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.01433/64.12514. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.91897/64.02993. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.67884/63.91533. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.88725/63.82396. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 59.65242/63.73746. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.60990/63.68885. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 59.65118/63.59892. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 59.50306/63.56308. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.48852/63.49632. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.43117/63.47861. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 59.39579/63.41471. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.16556/63.38721. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 59.36284/63.36423. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.33581/63.36855. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.26189/63.30004. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.04912/63.24615. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.92965/63.20427. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.08869/63.20403. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.91290/63.18864. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.92093/63.12095. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.93131/63.13624. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.78902/63.12347. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.67075/63.07246. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.70928/63.04473. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.66696/63.00210. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.67834/62.96359. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.58696/62.93403. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.62111/62.82824. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.36419/62.85803. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 58.50113/62.76176. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 58.39853/62.76897. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.38010/62.75532. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 58.22041/62.69455. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.32785/62.55416. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.28655/62.61174. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 58.03084/62.53492. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.14591/62.57658. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.12598/62.49919. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 58.20255/62.52674. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 58.23749/62.41379. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 58.13693/62.39008. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.92492/62.44242. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.08101/62.41029. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.03419927840283847\n",
      "Epoch 0, Loss(train/val) 70.65705/70.85469. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.46506/70.66342. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.29443/70.47891. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.11794/70.29619. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.94534/70.10550. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.69615/69.90762. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.51064/69.69854. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.29696/69.47499. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.01438/69.22862. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.71494/68.96042. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 68.46807/68.66712. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 68.06734/68.34999. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 67.68725/68.00205. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.35922/67.63435. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.93474/67.24347. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.68388/66.83192. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.31427/66.38996. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 65.93049/65.90607. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.59390/65.36436. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.21860/64.75354. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.88284/64.10769. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.42047/63.43169. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.00107/62.70770. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.74329/61.99034. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.15519/61.31480. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.03161/60.72579. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.66547/60.24364. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.53411/59.83762. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.08642/59.47838. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.92952/59.18971. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.63460/58.95032. Took 0.35 sec\n",
      "Epoch 31, Loss(train/val) 61.66183/58.73819. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.37208/58.54999. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.10199/58.38755. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.01415/58.24918. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 60.81361/58.11123. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.76389/58.02860. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 60.58887/57.96684. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.51399/57.91240. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.26856/57.85838. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 60.13203/57.81083. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.15958/57.78636. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 59.97034/57.74212. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.70273/57.68992. Took 0.34 sec\n",
      "Epoch 44, Loss(train/val) 59.65717/57.65014. Took 0.34 sec\n",
      "Epoch 45, Loss(train/val) 59.62587/57.60802. Took 0.34 sec\n",
      "Epoch 46, Loss(train/val) 59.50219/57.59412. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.33075/57.57376. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.20707/57.55446. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 58.98668/57.55170. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.06859/57.53823. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 58.88916/57.50399. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 58.64083/57.48429. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.65809/57.41322. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 58.62782/57.40693. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.33283/57.33746. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.40984/57.30014. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 58.26494/57.25797. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.22910/57.21244. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.12329/57.19791. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 58.07162/57.13297. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.05106/57.13248. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 57.94716/57.00761. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.84231/57.01501. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.98301/56.87749. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 57.75982/56.96751. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.70381/56.83273. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.60977/56.85613. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 57.57959/56.77346. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.34582/56.75586. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 57.44478/56.69130. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.37853/56.65805. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 57.47788/56.60264. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 57.34825/56.51768. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.42365/56.45642. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 57.10785/56.41195. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 57.03537/56.37857. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 57.15233/56.38457. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.09110/56.28446. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 56.91348/56.28048. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 56.80020/56.22018. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 56.96676/56.20074. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.83513/56.17915. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 56.77893/56.05688. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.87843/56.00426. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 56.57077/55.99440. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 56.43089/55.91758. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 56.51289/55.81176. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 56.54731/55.78453. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 56.42834/55.71809. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 56.35882/55.64870. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 56.55565/55.58177. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 56.50777/55.59975. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 56.34178/55.59561. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 56.37855/55.51646. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 56.35009/55.50634. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 56.30407/55.47947. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 56.13838/55.45369. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.22722/55.42517. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 56.16052/55.38808. Took 0.32 sec\n",
      "ACC: 0.53125, MCC: -0.02450715406979359\n",
      "Epoch 0, Loss(train/val) 70.61964/70.66301. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.37346/70.40993. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.15582/70.14128. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.88249/69.83061. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.58592/69.45435. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.25881/68.98787. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.87108/68.40252. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.39391/67.69730. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.88917/66.90641. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.24329/66.07449. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.66186/65.28127. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 65.96070/64.53802. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.39530/63.85984. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 64.80441/63.26020. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.17103/62.75274. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.76173/62.34596. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.44497/62.02664. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.03228/61.77060. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 62.71419/61.58519. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.41645/61.43587. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.13818/61.29925. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.94444/61.17600. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 61.77042/61.07730. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 61.39144/60.97564. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.26173/60.87123. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 60.99415/60.74781. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 60.84315/60.59602. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 60.67379/60.42176. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.33125/60.23928. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 60.12480/60.06464. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 59.76624/59.89381. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 59.59484/59.76527. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 59.47269/59.67574. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 59.32866/59.60585. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 59.21236/59.51449. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 59.08651/59.45175. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 59.13484/59.41129. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 59.00606/59.39409. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.77068/59.37233. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 58.73033/59.36202. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 58.54098/59.36816. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 58.58540/59.37290. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 58.68583/59.33626. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 58.33312/59.31273. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 58.50702/59.31276. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 58.27749/59.26784. Took 0.34 sec\n",
      "Epoch 46, Loss(train/val) 58.17010/59.23024. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 58.27827/59.20238. Took 0.34 sec\n",
      "Epoch 48, Loss(train/val) 57.98673/59.14837. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 58.05744/59.12264. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 58.00380/59.10480. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 57.79583/59.07663. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 57.73287/59.01830. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 57.75814/58.94785. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 57.56143/58.85925. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 57.51633/58.81850. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 57.52016/58.80613. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 57.40003/58.69664. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 57.45524/58.62428. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 57.32373/58.55321. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 57.20486/58.40665. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 57.07670/58.29867. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 57.10953/58.23951. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.04148/58.07059. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.74349/57.99896. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.85730/57.81075. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 56.66568/57.64628. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 56.62672/57.45818. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 56.77172/57.32819. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 56.70257/57.17247. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.67389/57.20447. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.54000/57.16366. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.30149/69.23148. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 68.00112/68.94810. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.53805/68.65351. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 67.13580/68.35550. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.75238/68.06734. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 66.28555/67.78062. Took 0.31 sec\n",
      "Epoch 11, Loss(train/val) 65.89154/67.50619. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.39333/67.22842. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.03127/66.94014. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 64.74312/66.64790. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.30045/66.36583. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.93028/66.07822. Took 0.31 sec\n",
      "Epoch 17, Loss(train/val) 63.54677/65.78690. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.20228/65.48988. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 62.82771/65.19788. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.59743/64.90999. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.37308/64.63691. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.14867/64.36964. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.74686/64.17471. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 61.78194/64.00006. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.63354/63.85979. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.49437/63.73778. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.29202/63.61658. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 61.11346/63.50309. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 61.35991/63.40297. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.11888/63.32867. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 61.03124/63.32824. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.94747/63.25428. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.80386/63.15100. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 60.99724/63.20781. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 60.85431/63.18420. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 60.82257/63.14621. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 60.73612/63.05217. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.63307/63.08138. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 60.67189/63.03911. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.60419/62.99254. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.38112/62.98493. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 60.42210/62.98561. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 60.33009/62.98317. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 60.41150/62.93833. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 60.40308/62.81700. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.14894/62.78572. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.22760/62.84078. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 60.25490/62.77305. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 60.12421/62.68955. Took 0.31 sec\n",
      "Epoch 50, Loss(train/val) 60.08661/62.74454. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 60.00697/62.71588. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 60.04249/62.72358. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 60.07358/62.68198. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.86329/62.63620. Took 0.31 sec\n",
      "Epoch 55, Loss(train/val) 59.77982/62.63782. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 59.70872/62.61340. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 59.69737/62.57224. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 59.72339/62.49628. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 59.65087/62.49326. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 59.61240/62.48219. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.66744/62.40312. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.55828/62.41473. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 59.46071/62.36646. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.37535/62.37062. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.23659/62.25419. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 59.34327/62.29855. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.25902/62.24767. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.16341/62.20692. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.22249/62.15849. Took 0.31 sec\n",
      "Epoch 70, Loss(train/val) 58.97287/62.14413. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.17447/62.09467. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.98034/62.05587. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 58.94224/62.03059. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.02087/61.98512. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 58.83611/61.86847. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.75636/61.86138. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.72752/61.81628. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 58.72958/61.75883. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 58.65261/61.67716. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 58.85256/61.56966. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 58.61028/61.52435. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 58.63674/61.38531. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.49119/61.28563. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 58.42939/61.16505. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 58.46992/61.10313. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.32930/60.99783. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 58.37293/60.89642. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.20781/60.84782. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.14198/60.70532. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 58.28562/60.80727. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 58.08001/60.78117. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.10584/60.76259. Took 0.31 sec\n",
      "Epoch 93, Loss(train/val) 57.95420/60.64865. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 58.01161/60.70544. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 57.89904/60.70093. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 57.83604/60.68486. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.96538/60.65835. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.90705/60.56522. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 57.70096/60.57277. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.0885319710087594\n",
      "Epoch 0, Loss(train/val) 70.83556/71.07953. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.51430/70.81286. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.26756/70.55011. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.99320/70.28976. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 69.80927/70.02725. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.47384/69.75958. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.26570/69.47960. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 68.99178/69.18495. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.70515/68.87811. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.50406/68.55996. Took 0.31 sec\n",
      "Epoch 10, Loss(train/val) 68.18401/68.22652. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.90239/67.87775. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 67.61187/67.52185. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 67.27982/67.15302. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.99863/66.78641. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.74965/66.42468. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.38907/66.06503. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.03790/65.71152. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 65.70002/65.37094. Took 0.31 sec\n",
      "Epoch 19, Loss(train/val) 65.48311/65.04583. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.15604/64.72670. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.98890/64.40880. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 64.58834/64.08801. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.45660/63.76413. Took 0.31 sec\n",
      "Epoch 24, Loss(train/val) 64.21164/63.42583. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.01132/63.07839. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.70723/62.70678. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 63.55525/62.34480. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 63.31834/61.99444. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.06147/61.63506. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.83322/61.28711. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.67995/60.91518. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.35222/60.54238. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 62.38442/60.14738. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.04819/59.77763. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.99271/59.46401. Took 0.31 sec\n",
      "Epoch 36, Loss(train/val) 61.67109/59.15705. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.71318/58.88504. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.43659/58.63561. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 61.30640/58.39814. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.21628/58.15736. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.00675/57.92701. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 60.83465/57.71305. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.68734/57.49964. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.69057/57.30543. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 60.38516/57.14186. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.43906/56.98439. Took 0.31 sec\n",
      "Epoch 47, Loss(train/val) 60.40022/56.83842. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 60.24488/56.72422. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 60.20513/56.63084. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.04618/56.54636. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 59.95564/56.52555. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 59.81974/56.47551. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 59.88182/56.44926. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.82032/56.48522. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 59.65921/56.49112. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 59.58695/56.51601. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 59.55936/56.51347. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 59.42431/56.53207. Took 0.31 sec\n",
      "Epoch 59, Loss(train/val) 59.53119/56.50872. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.33593/56.57218. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 59.43789/56.56942. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 59.30958/56.56586. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.31186/56.65891. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.26746/56.66929. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 59.31315/56.69908. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 59.30209/56.70905. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 59.19511/56.71308. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.18139/56.72812. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.10350/56.72706. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.12687/56.73332. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.06813/56.73850. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.05272/56.69652. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.13632/56.76689. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 58.98377/56.75087. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.92787/56.75098. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 58.74948/56.76842. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.97905/56.74198. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.81840/56.81422. Took 0.31 sec\n",
      "Epoch 79, Loss(train/val) 58.77032/56.76698. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.78434/56.81374. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.86109/56.78638. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.70192/56.76404. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 58.78620/56.74872. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.63895/56.64888. Took 0.31 sec\n",
      "Epoch 85, Loss(train/val) 58.64641/56.72005. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 58.56048/56.61443. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.57080/56.64928. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 58.34246/56.41091. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.28614/56.62000. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 58.26952/56.13150. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 58.35043/56.42104. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 58.36864/56.03855. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.15882/56.20495. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 58.04437/55.92649. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 57.97756/55.93789. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.86400/55.95689. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 57.82700/55.86678. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.83840/55.78837. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 57.86530/55.76416. Took 0.32 sec\n",
      "ACC: 0.625, MCC: 0.12371937255211683\n",
      "Epoch 0, Loss(train/val) 70.39352/68.93079. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.18454/68.80035. Took 0.31 sec\n",
      "Epoch 2, Loss(train/val) 70.02785/68.65536. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.79181/68.48251. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.58499/68.28903. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.41665/68.07740. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.17862/67.84212. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 68.90625/67.57990. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.59167/67.29073. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.31106/66.98275. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.95165/66.65593. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.71793/66.32197. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.30519/65.99635. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.01083/65.68930. Took 0.31 sec\n",
      "Epoch 14, Loss(train/val) 66.71124/65.38493. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.47003/65.11862. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.18015/64.90445. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.97911/64.71468. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 65.73335/64.53661. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.63016/64.36404. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 65.36967/64.18514. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.14726/63.99664. Took 0.31 sec\n",
      "Epoch 22, Loss(train/val) 65.00854/63.79878. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 64.75624/63.60553. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 64.65235/63.41298. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.42524/63.21629. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 64.28261/63.01736. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.27928/62.82727. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.07579/62.64433. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 63.94674/62.47028. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 63.87628/62.30696. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 63.59391/62.13385. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.66714/61.97174. Took 0.31 sec\n",
      "Epoch 33, Loss(train/val) 63.42369/61.83353. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.46764/61.71443. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.42642/61.61108. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.34352/61.51682. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.19645/61.43568. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.11855/61.36237. Took 0.31 sec\n",
      "Epoch 39, Loss(train/val) 63.24566/61.28600. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.04064/61.21973. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.03247/61.16394. Took 0.31 sec\n",
      "Epoch 42, Loss(train/val) 62.88315/61.11599. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 62.91018/61.08753. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 62.79824/61.05199. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.87102/61.01850. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.84427/60.98225. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.78602/60.95263. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.69561/60.94188. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 62.69762/60.91948. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.83518/60.87825. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.66008/60.85171. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 62.56108/60.84612. Took 0.31 sec\n",
      "Epoch 53, Loss(train/val) 62.67183/60.83331. Took 0.31 sec\n",
      "Epoch 54, Loss(train/val) 62.67928/60.80611. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.72213/60.79073. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.70128/60.76505. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 62.56457/60.73698. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 62.60428/60.72465. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.62635/60.70428. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.52797/60.68152. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.46962/60.67709. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.43109/60.66031. Took 0.31 sec\n",
      "Epoch 63, Loss(train/val) 62.38040/60.64988. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.39038/60.64487. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 62.36777/60.63671. Took 0.31 sec\n",
      "Epoch 66, Loss(train/val) 62.51423/60.62106. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 62.46578/60.60901. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.54862/60.60565. Took 0.31 sec\n",
      "Epoch 69, Loss(train/val) 62.39700/60.60965. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.45098/60.60919. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.36648/60.59155. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 62.44905/60.55907. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.24873/60.53326. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.28335/60.51978. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.23314/60.51695. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.33266/60.51021. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.22837/60.48281. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.19298/60.47998. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 62.09570/60.44444. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.22831/60.45305. Took 0.31 sec\n",
      "Epoch 81, Loss(train/val) 62.22956/60.43089. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 62.20456/60.38224. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 62.12685/60.35625. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.15556/60.32925. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.15793/60.31548. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 62.11782/60.30767. Took 0.31 sec\n",
      "Epoch 87, Loss(train/val) 62.08508/60.30168. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 62.10950/60.28302. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 61.97642/60.28627. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 61.99013/60.28437. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 62.04638/60.29694. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 62.12096/60.26156. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 62.08084/60.21343. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 62.01643/60.17014. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.96796/60.14802. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 61.95780/60.13149. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.83674/60.16357. Took 0.30 sec\n",
      "Epoch 98, Loss(train/val) 62.15154/60.13521. Took 0.30 sec\n",
      "Epoch 99, Loss(train/val) 61.94770/60.10834. Took 0.32 sec\n",
      "ACC: 0.40625, MCC: -0.19738550848793068\n",
      "Epoch 0, Loss(train/val) 70.36925/71.31863. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.09654/71.17413. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.86723/71.01225. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.58978/70.83055. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.27780/70.61816. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.89970/70.35860. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.52573/70.02549. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.05151/69.61760. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.56305/69.17090. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.04628/68.75823. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.50631/68.40900. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.15231/68.13036. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 65.74128/67.89892. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 65.43450/67.70058. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.04015/67.53465. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.76927/67.40700. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.65869/67.31588. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.52284/67.25732. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.31671/67.20604. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.25746/67.16222. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 64.20515/67.12186. Took 0.31 sec\n",
      "Epoch 21, Loss(train/val) 64.00661/67.08353. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.98127/67.04273. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.89018/67.00230. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.87045/66.96591. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.68154/66.92271. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.56264/66.88549. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.73388/66.85280. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.52390/66.82091. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.49491/66.78262. Took 0.31 sec\n",
      "Epoch 30, Loss(train/val) 63.36834/66.74036. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.34803/66.70579. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.32361/66.65819. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.17329/66.62000. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.31626/66.57661. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 62.99947/66.53593. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.03803/66.49922. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.07270/66.46754. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 62.90493/66.43547. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.96539/66.39160. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 62.99202/66.34793. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.89871/66.31538. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.96432/66.28342. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.81982/66.25385. Took 0.31 sec\n",
      "Epoch 44, Loss(train/val) 62.74847/66.21960. Took 0.31 sec\n",
      "Epoch 45, Loss(train/val) 62.61592/66.19057. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.78238/66.16346. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.74804/66.13504. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.64293/66.10096. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.53939/66.07655. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.66038/66.04115. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.49440/66.00417. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.44082/65.97459. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.48623/65.95814. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 62.37665/65.93474. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.39115/65.91925. Took 0.31 sec\n",
      "Epoch 56, Loss(train/val) 62.24575/65.91387. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.33754/65.90460. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 62.26526/65.90022. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.09602/65.89453. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.06760/65.88184. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.13934/65.89541. Took 0.31 sec\n",
      "Epoch 62, Loss(train/val) 61.94233/65.90693. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.01540/65.92412. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 61.93601/65.92679. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.83721/65.92921. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.91023/65.91941. Took 0.31 sec\n",
      "Epoch 67, Loss(train/val) 61.80906/65.89763. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.70019/65.85429. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.73951/65.89692. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.69933/65.80045. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.60928/65.89018. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.53593/65.76487. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.58460/65.76041. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.39157/65.77873. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.37173/65.73264. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 61.47023/65.70670. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.33428/65.63692. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 61.26405/65.69545. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.27922/65.66344. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.07930/65.64391. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.07526/65.64311. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.21497/65.62148. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 61.00565/65.64240. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.99652/65.64700. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.82363/65.55944. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.88446/65.68881. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.99020/65.53003. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.91788/65.63103. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.80999/65.56779. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.76143/65.55293. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.73677/65.58835. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.66847/65.58739. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.64772/65.50398. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.57638/65.49763. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.54861/65.53096. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.58072/65.54708. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.45178/65.53314. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.48161/65.46657. Took 0.31 sec\n",
      "Epoch 99, Loss(train/val) 60.56997/65.50356. Took 0.32 sec\n",
      "ACC: 0.40625, MCC: -0.10100707475121518\n",
      "Epoch 0, Loss(train/val) 71.10991/70.11044. Took 0.32 sec\n",
      "Epoch 1, Loss(train/val) 70.91811/70.05521. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.78124/69.99999. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.63816/69.93648. Took 0.34 sec\n",
      "Epoch 4, Loss(train/val) 70.47260/69.87492. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.30984/69.80557. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 70.12626/69.72686. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.01229/69.64206. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.81032/69.53663. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.60948/69.40862. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 69.49282/69.26297. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.26959/69.09267. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 69.04321/68.89563. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.81788/68.66146. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 68.52881/68.38362. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 68.17131/68.06857. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.93275/67.75613. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.59963/67.47623. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 67.29561/67.27080. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.00883/67.14378. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.82478/67.06174. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.59942/67.01932. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.34369/66.99879. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.19883/66.98032. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 66.13454/66.95837. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 65.98187/66.92985. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 65.83757/66.89973. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 65.62829/66.85342. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 65.58861/66.80009. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 65.48771/66.74364. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 65.17881/66.68974. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 65.21102/66.66002. Took 0.31 sec\n",
      "Epoch 32, Loss(train/val) 65.09160/66.65788. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.94633/66.69977. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 64.82908/66.79478. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 64.61231/66.92227. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.35367/67.01558. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 64.29708/67.08537. Took 0.31 sec\n",
      "Epoch 38, Loss(train/val) 64.16780/67.11764. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.15366/67.15049. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.95916/67.17883. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.83184/67.23239. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.92435/67.25757. Took 0.31 sec\n",
      "Epoch 43, Loss(train/val) 63.83721/67.28732. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.65548/67.31113. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.67570/67.34250. Took 0.31 sec\n",
      "Epoch 46, Loss(train/val) 63.61743/67.38321. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.60543/67.41065. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 63.53176/67.45918. Took 0.31 sec\n",
      "Epoch 49, Loss(train/val) 63.50795/67.50465. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.42378/67.52828. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.27216/67.57738. Took 0.31 sec\n",
      "Epoch 52, Loss(train/val) 63.33527/67.58801. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.36568/67.64921. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.25106/67.68685. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.09831/67.73188. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.19160/67.82112. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 63.03072/67.87502. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 63.02358/68.00648. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.97890/68.05016. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.96033/68.09360. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 62.77139/68.15205. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.67729/68.21220. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.66272/68.29642. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.64674/68.37423. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.70445/68.31062. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.52947/68.34306. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.39994/68.49486. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.41950/68.53858. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.28522/68.44377. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.31420/68.49818. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.12284/68.26969. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.15173/68.55110. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.94290/68.19128. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.07845/68.53502. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.80179/68.37662. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 62.00616/68.54286. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 61.83958/68.30171. Took 0.31 sec\n",
      "Epoch 78, Loss(train/val) 61.78254/69.11343. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.79396/68.79128. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.54313/68.38202. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.58770/69.03889. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.67722/68.88000. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.54666/68.88145. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.67772/68.62349. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 61.69695/68.72937. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.64643/68.86430. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.39294/68.79868. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 61.30013/68.96032. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 61.57017/68.80610. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.46934/68.68075. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 61.25667/69.27097. Took 0.31 sec\n",
      "Epoch 92, Loss(train/val) 61.49428/69.07256. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.23780/69.31629. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 61.31413/69.00755. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 61.16812/69.49831. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.29309/69.35493. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 61.12838/69.39342. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 61.13110/69.27703. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.03486/69.74060. Took 0.32 sec\n",
      "ACC: 0.4375, MCC: -0.17849364309852617\n",
      "Epoch 0, Loss(train/val) 70.88646/71.14240. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.56094/70.79934. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.27856/70.45002. Took 0.31 sec\n",
      "Epoch 3, Loss(train/val) 69.98293/70.08456. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.69049/69.69576. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.44786/69.29382. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.12221/68.86082. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.79136/68.39845. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.41649/67.88452. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 68.04788/67.31760. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.66327/66.70128. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.19274/66.02138. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.66876/65.30296. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.17471/64.55897. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.73857/63.79818. Took 0.31 sec\n",
      "Epoch 15, Loss(train/val) 65.24176/63.04613. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.68565/62.30095. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.24198/61.54833. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.81562/60.82951. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.51218/60.21280. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 63.12849/59.68467. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.91109/59.20860. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.57635/58.79790. Took 0.31 sec\n",
      "Epoch 23, Loss(train/val) 62.34568/58.43271. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.03729/58.11506. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 61.93215/57.84790. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 61.69902/57.60875. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.41013/57.40378. Took 0.31 sec\n",
      "Epoch 28, Loss(train/val) 61.18812/57.22601. Took 0.31 sec\n",
      "Epoch 29, Loss(train/val) 61.11933/57.07628. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.98266/56.95304. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.98237/56.83248. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 60.66711/56.74761. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 60.50150/56.68427. Took 0.31 sec\n",
      "Epoch 34, Loss(train/val) 60.31362/56.65087. Took 0.31 sec\n",
      "Epoch 35, Loss(train/val) 60.31656/56.64531. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.26261/56.60881. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.16639/56.50243. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 60.06884/56.43814. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 59.95500/56.31236. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 59.76579/56.29676. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.75954/56.18870. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 59.75757/56.12683. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 59.59952/56.08754. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 59.69037/56.10405. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 59.49300/56.05506. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.34399/56.10176. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.38496/55.97223. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.43388/56.18824. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.16981/55.97906. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.15458/56.04224. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.15827/56.02626. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.12405/55.86243. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.10276/55.90611. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.02268/55.98639. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.81491/55.77658. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.98158/55.99797. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 58.89778/55.72891. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.97616/55.91540. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.74975/55.76115. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 58.78966/55.76651. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.68920/55.63841. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.67254/55.76358. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.76797/55.70119. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.67112/55.80717. Took 0.31 sec\n",
      "Epoch 65, Loss(train/val) 58.46976/55.50842. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.67725/55.86469. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.56269/55.38993. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.55528/55.96463. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.46142/55.79853. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.49369/55.71431. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.53099/55.61612. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 58.53484/56.00632. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.31230/55.54180. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 58.38519/56.00074. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 58.29760/55.53014. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.36312/55.78091. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.13779/55.46045. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 58.21250/55.64557. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.14874/55.59607. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.28871/55.53632. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.27250/55.70094. Took 0.31 sec\n",
      "Epoch 82, Loss(train/val) 58.07340/55.55493. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.02704/55.88059. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.08599/55.57294. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.26992/55.97890. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.99324/55.41300. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 57.89675/55.76983. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 57.90796/55.84799. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 57.95317/55.62384. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.05156/55.81731. Took 0.31 sec\n",
      "Epoch 91, Loss(train/val) 57.86908/55.49356. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.83551/55.68428. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.77056/55.79683. Took 0.31 sec\n",
      "Epoch 94, Loss(train/val) 57.70187/55.59388. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.80601/55.72976. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 57.67540/55.56728. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 57.61733/55.48788. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.75555/55.66500. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.58926/55.50225. Took 0.31 sec\n",
      "ACC: 0.375, MCC: -0.2876281618169493\n",
      "Epoch 0, Loss(train/val) 70.32897/69.52482. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.01613/69.16136. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.81671/68.78267. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.58528/68.35819. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.33684/67.87410. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.95528/67.29122. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.52367/66.61720. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.13676/65.86842. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.60091/65.05754. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.01920/64.22105. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.52596/63.40570. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.08713/62.64671. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 65.49821/61.97557. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.09450/61.39699. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 64.60455/60.90924. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 64.18243/60.49318. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 63.73852/60.12700. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.30321/59.79671. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.03855/59.50093. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 62.67791/59.24796. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.42467/59.03683. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 62.13910/58.85933. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.09215/58.70319. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 61.64382/58.55912. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 61.55655/58.43966. Took 0.31 sec\n",
      "Epoch 25, Loss(train/val) 61.39617/58.33313. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 61.35296/58.21690. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 61.08344/58.10647. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 60.93143/58.01295. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 60.95490/57.92941. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 60.67821/57.84448. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 60.69891/57.75629. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 60.59437/57.68743. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 60.67991/57.63957. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 60.51188/57.59950. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 60.33624/57.54529. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 60.39022/57.48179. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 60.27624/57.43196. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 60.35381/57.39856. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 60.09939/57.34170. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.02978/57.30582. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 59.95791/57.25502. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 59.97797/57.19254. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 59.87279/57.13608. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.08913/57.08929. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 59.88444/57.02957. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.67573/56.96854. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.76756/56.91656. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 59.59555/56.87104. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 59.76323/56.82875. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.68403/56.76136. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 59.53662/56.70858. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 59.58915/56.64592. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 59.41280/56.57709. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 59.27985/56.52486. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 59.22613/56.45621. Took 0.34 sec\n",
      "Epoch 56, Loss(train/val) 59.18603/56.40484. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.00675/56.36062. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 59.13210/56.31319. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 59.35914/56.26136. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 59.14764/56.20813. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.96198/56.17899. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 59.10186/56.12411. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.98396/56.07934. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 58.96530/56.05959. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.88077/56.01135. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 58.89525/55.92566. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.84160/55.85724. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 58.62429/55.79470. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.64181/55.75338. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 58.72083/55.72755. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 58.60181/55.69272. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 58.71856/55.67199. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 58.47887/55.65663. Took 0.31 sec\n",
      "Epoch 74, Loss(train/val) 58.47827/55.64246. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 58.59374/55.61159. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 58.53743/55.56170. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 58.39159/55.51823. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 58.40738/55.49338. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 58.35017/55.45966. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.33266/55.48909. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 58.20123/55.46505. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 58.12206/55.43397. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.30211/55.40768. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 58.12035/55.36222. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 58.10126/55.33775. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.94932/55.34928. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.02671/55.33220. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.04933/55.30804. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.14676/55.29459. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 57.90505/55.31809. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 57.93710/55.35022. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.76814/55.30428. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.88498/55.33790. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.81336/55.29593. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.72392/55.34195. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.72901/55.27011. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.59796/55.35266. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 57.56006/55.23310. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 57.39338/55.32301. Took 0.32 sec\n",
      "ACC: 0.546875, MCC: 0.10259783520851541\n",
      "Epoch 0, Loss(train/val) 70.92157/70.80854. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.73332/70.75152. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.53191/70.69686. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.28943/70.63525. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.09755/70.57260. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.84629/70.51531. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.57084/70.46390. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.32229/70.42529. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.04340/70.40175. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.72627/70.39056. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.41241/70.39300. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.05756/70.40798. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.71459/70.43217. Took 0.31 sec\n",
      "Epoch 13, Loss(train/val) 67.27454/70.46523. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.93660/70.49094. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.60520/70.50430. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.34520/70.50062. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.13269/70.47269. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.91639/70.40408. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.71252/70.30946. Took 0.31 sec\n",
      "Epoch 20, Loss(train/val) 65.50442/70.20007. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 65.40730/70.06625. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.14103/69.91206. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.10870/69.74590. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 65.00215/69.55685. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.78296/64.37176. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.79231/64.41089. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.73491/64.34100. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.60818/64.36185. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.55142/64.28825. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.44577/64.27771. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.34942/64.27297. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.44513/64.30167. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.40688/64.28664. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 62.17031/64.25945. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.22496/64.16830. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.13002/64.22503. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.09788/64.25848. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.00966/64.31802. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.81139/64.14495. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.96051/64.28578. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.88531/64.20197. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.90885/64.18101. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.86279/64.09216. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.80962/64.20241. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.74390/64.04907. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.61518/64.07937. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.67447/64.07336. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.50250/63.99785. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.39923/64.01751. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.52107/64.04257. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.44418/63.98471. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.18773/63.95199. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.42727/63.90966. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.34801/63.86979. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.25462/63.79946. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.13150/63.85281. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 61.11335/63.76782. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.20558/63.81725. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.16672/63.76443. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 61.10685/63.80300. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 61.06576/63.78321. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.06557/63.71173. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 61.00215/63.78101. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.99906/63.74858. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.09050/63.72808. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.95657/63.72160. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.89775/63.70591. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.90210/63.69737. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.93726/63.70411. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.87902/63.65486. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.81736/63.68784. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.84191/63.68754. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.63444/63.69004. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.63984/63.68849. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.60430/63.71838. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.015019349877480085\n",
      "Epoch 0, Loss(train/val) 69.76517/70.28735. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.51668/70.03471. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.31299/69.77197. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.08834/69.49181. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.75860/69.18630. Took 0.34 sec\n",
      "Epoch 5, Loss(train/val) 68.43883/68.83654. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.12170/68.40575. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 67.61091/67.85662. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.05023/67.14423. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.39658/66.22366. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 65.65738/65.20794. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 64.84878/64.25417. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 64.41017/63.62373. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 64.06088/63.19073. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 63.91813/62.91637. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.85908/62.73881. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.56056/62.60844. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 63.64823/62.52680. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.50133/62.44323. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.52281/62.37743. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.25182/62.32597. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.32186/62.28082. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.20418/62.24397. Took 0.34 sec\n",
      "Epoch 23, Loss(train/val) 63.17399/62.21311. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.28011/62.17919. Took 0.34 sec\n",
      "Epoch 25, Loss(train/val) 63.17667/62.15477. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 63.10995/62.12477. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.01355/62.10174. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 63.07478/62.08127. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.92927/62.05373. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.00250/62.01018. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.90928/61.98524. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.82546/61.96075. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.79855/61.92139. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.80610/61.89177. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.56206/61.84285. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.70192/61.80578. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.67216/61.80177. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.54733/61.77477. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.52557/61.75176. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.37842/61.72663. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.33337/61.70853. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.33300/61.70350. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.13669/61.71229. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.10547/61.69483. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.07529/61.67802. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.18389/61.65937. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.99883/61.67734. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.76226/61.67058. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.88672/61.65432. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.88625/61.64209. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 61.90051/61.62839. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.80581/61.62635. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.57958/61.59656. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.59831/61.56655. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.55780/61.53999. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.57105/61.54985. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 61.60319/61.55535. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.24477/61.57212. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.40515/61.58932. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 61.30676/61.58132. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.27766/61.54710. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.50156/61.53145. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.39221/61.54166. Took 0.31 sec\n",
      "Epoch 64, Loss(train/val) 61.14448/61.54349. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.16472/61.56796. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.91310/61.62168. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 60.84992/61.66457. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.94604/61.68005. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 60.89892/61.79804. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.91186/61.91916. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 60.88529/61.94061. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.57584/61.98688. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 60.56398/62.12053. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.69317/62.33127. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.57600/62.44889. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.57327/62.50867. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.59416/62.54067. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.39261/62.52575. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.39507/62.50098. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.16468/62.43669. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.23456/62.43986. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.29495/62.32094. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.20518/62.31129. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.09538/62.29722. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.08872/62.24938. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.15980/62.29959. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.98303/62.22815. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.85290/62.19390. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.77224/62.24333. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 59.74717/62.27686. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 59.73055/62.26622. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.66475/62.22097. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.55814/62.18767. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 59.38735/62.18735. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.32844/62.07472. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.20427/62.10095. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 59.16179/62.12776. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 59.10409/61.96921. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 58.92972/61.95834. Took 0.33 sec\n",
      "ACC: 0.515625, MCC: 0.0022154222857491456\n",
      "Epoch 0, Loss(train/val) 70.45944/70.89043. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.26018/70.77121. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 70.05937/70.65394. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.82155/70.53543. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 69.57964/70.41058. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 69.29591/70.28166. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.09410/70.14182. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.75909/69.98344. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.49268/69.81461. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.27090/69.62982. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.94765/69.42795. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 67.55219/69.20875. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.09020/68.96567. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 66.76032/68.70290. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 66.26442/68.41605. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.74559/68.11114. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.30752/67.80128. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.89817/67.50674. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.42358/67.24344. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.04021/67.07854. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 63.79918/66.94132. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.56163/66.82197. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.32404/66.71753. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.20786/66.62316. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.05581/66.53815. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.85182/66.46161. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.66839/66.39157. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.68924/66.33047. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 62.58539/66.27496. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.51692/66.22690. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.31228/66.18576. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 62.36308/66.14847. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.22538/66.11949. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.16814/66.09687. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 62.02529/66.07365. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.09697/66.05343. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.07809/66.03922. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 62.07323/66.02498. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.87126/66.01015. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 61.96360/65.99404. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.65922/65.98058. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.91957/65.97174. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 61.67842/65.95135. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 61.66375/65.92878. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.66628/65.90162. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 61.65831/65.87377. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 61.39723/65.83416. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.55792/65.78243. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 61.56679/65.72782. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.33530/65.66615. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.41239/65.61363. Took 0.34 sec\n",
      "Epoch 51, Loss(train/val) 61.37943/65.57185. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.16554/65.52678. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 61.15997/65.48808. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 61.34493/65.44805. Took 0.34 sec\n",
      "Epoch 55, Loss(train/val) 61.12250/65.41039. Took 0.34 sec\n",
      "Epoch 56, Loss(train/val) 61.19719/65.37068. Took 0.34 sec\n",
      "Epoch 57, Loss(train/val) 61.22408/65.34288. Took 0.34 sec\n",
      "Epoch 58, Loss(train/val) 60.99281/65.31643. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.14773/65.28825. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.03865/65.25056. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.91579/65.20889. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.96848/65.18649. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.03951/65.16473. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.01570/65.13504. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 61.11637/65.10532. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.95634/65.07414. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.95419/65.05634. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 60.87887/65.03924. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.93227/65.02460. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 60.84240/65.01525. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 60.73582/65.00991. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.70848/64.99210. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.66076/64.96487. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 60.84389/64.94261. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.63750/64.92266. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.62032/64.91245. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.65370/64.90546. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 60.68073/64.89670. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.47790/64.87775. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.53049/64.86597. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.66268/64.88155. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.46949/64.89340. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.46827/64.88012. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.45060/64.86382. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.40833/64.84245. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.35991/64.82590. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 60.32902/64.82384. Took 0.31 sec\n",
      "Epoch 88, Loss(train/val) 60.27885/64.82703. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.21006/64.86732. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.12727/64.86173. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.10689/64.90185. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.26708/64.85426. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 60.15423/64.84084. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.10755/64.81079. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.93037/64.82108. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 59.91936/64.83619. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.01982/64.75093. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 59.95107/64.73834. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 59.88178/64.73695. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.14907119849998599\n",
      "Epoch 0, Loss(train/val) 71.58844/72.25632. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 71.35110/72.21790. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 71.14885/72.18335. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 71.04657/72.14960. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.82996/72.12170. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 70.69626/72.09591. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 70.53501/72.06095. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 70.38264/72.02814. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 70.24890/71.99055. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 70.08478/71.94656. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 69.90858/71.89464. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 69.74792/71.83872. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 69.50153/71.77840. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 69.30295/71.71346. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 69.10344/71.63837. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 68.88326/71.55256. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 68.60524/71.46877. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 68.41287/71.38190. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 68.10020/71.29317. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 67.90786/71.20570. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 67.62475/71.11891. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 67.38074/71.04375. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 67.22416/70.97641. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 66.98465/70.91340. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 66.94673/70.86292. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 66.65339/70.82085. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 66.67069/70.77819. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 66.37208/70.72724. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 66.29285/70.68368. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 66.27794/70.64506. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 66.15717/70.60790. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 65.97899/70.56232. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 65.96746/70.51340. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 65.79347/70.46686. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 65.75373/70.41012. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 65.58686/70.33833. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 65.52292/70.25175. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 65.43122/70.14613. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 65.25863/70.01915. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 65.23852/69.88966. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 65.03334/69.74136. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 64.92638/69.56528. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 64.78265/69.37722. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 64.60988/69.17374. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 64.47709/68.99358. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 64.26837/68.83581. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 64.28682/68.71766. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 64.22719/68.62150. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 64.05841/68.53835. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 63.88835/68.45943. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.83147/68.38435. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 63.74374/68.31562. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.70758/68.25110. Took 0.34 sec\n",
      "Epoch 53, Loss(train/val) 63.49731/68.18472. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.48464/68.15112. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 63.49593/68.11172. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 63.42066/68.04083. Took 0.34 sec\n",
      "Epoch 57, Loss(train/val) 63.25155/67.99421. Took 0.34 sec\n",
      "Epoch 58, Loss(train/val) 63.27798/67.93008. Took 0.34 sec\n",
      "Epoch 59, Loss(train/val) 63.13490/67.86519. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 63.08770/67.78813. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 63.05422/67.72401. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 63.08339/67.66322. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.97078/67.61641. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.87939/67.57953. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 62.93918/67.53958. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 63.01391/67.48656. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.84006/67.44528. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 62.80935/67.40279. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.78383/67.35079. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 62.73761/67.30585. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 62.60812/67.26054. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.64660/67.19630. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 62.63255/67.17137. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.56871/67.11577. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.54331/67.02518. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 62.55708/66.94630. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 62.55916/66.89592. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 62.39318/66.87009. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 62.47848/66.83455. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 62.32294/66.77172. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 62.34254/66.71796. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 62.37009/66.65026. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 62.14955/66.59463. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 62.10686/66.52122. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 62.32705/66.46755. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 62.09012/66.41751. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 62.00475/66.35360. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 61.97871/66.28374. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 61.92459/66.24060. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 61.85084/66.19516. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 61.90760/66.15501. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.86872/66.13558. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 61.88347/66.11078. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 61.69199/66.09471. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 61.83968/66.10506. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 61.61314/66.08146. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 61.70405/66.09285. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 61.69549/66.08968. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 61.62499/66.04964. Took 0.32 sec\n",
      "ACC: 0.453125, MCC: -0.047878341926898\n",
      "Epoch 0, Loss(train/val) 70.90550/70.91193. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.75657/70.80973. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.57899/70.70734. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.40385/70.60256. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.22236/70.48856. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 70.01016/70.36048. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 69.81280/70.22020. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.57114/70.05999. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.29520/69.87867. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 68.95877/69.66560. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.49729/69.41132. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.04241/69.10271. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.46545/68.72078. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 67.10645/68.26956. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.49312/67.76456. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 66.02989/67.23714. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 65.67210/66.72250. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.18667/66.25452. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 64.85490/65.86544. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 64.41739/65.55725. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 64.04981/65.36113. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.96149/65.26057. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 63.67284/65.21301. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 63.48136/65.20251. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.36078/65.21800. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 63.09799/65.23129. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.93342/65.24033. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 62.79910/65.23646. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.58859/65.22519. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.56793/65.20676. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 62.35540/65.18488. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.18978/65.15264. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.15442/65.12547. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.03583/65.09240. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 61.74564/65.08597. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.65880/65.05231. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.52425/65.00527. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.46836/64.95124. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.09649/64.92225. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.99570/64.87826. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.85701/64.85266. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.76366/64.79520. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.54542/64.74299. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.56211/64.68145. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.21427/64.64736. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.04272/64.58356. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 59.88407/64.52663. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 59.85166/64.46591. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.57534/64.37150. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.49611/64.29117. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 59.35390/64.23979. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.29577/64.18437. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.03000/64.08793. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 58.91534/64.00850. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 58.77652/63.94865. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 58.61628/63.86612. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 58.57187/63.85738. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 58.44900/63.82375. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 58.15428/63.75836. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 58.18184/63.68530. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 58.05298/63.62162. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 58.01542/63.62923. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 57.89258/63.62368. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 57.88907/63.61507. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 57.60100/63.55151. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 57.43303/63.56073. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 57.42283/63.51199. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 57.48856/63.47844. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 57.16147/63.46923. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 57.20963/63.43871. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.09162/63.38361. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.01836/63.35493. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 56.87253/63.35968. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 56.84361/63.31718. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 56.65305/63.29680. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 56.68881/63.29003. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 56.59058/63.28810. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 56.48867/63.23125. Took 0.33 sec\n",
      "Epoch 78, Loss(train/val) 56.35924/63.26249. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 56.38899/63.22831. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 56.18247/63.22914. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 56.13313/63.20603. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 56.17591/63.22644. Took 0.34 sec\n",
      "Epoch 83, Loss(train/val) 56.11963/63.19963. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 56.07499/63.22294. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 55.80291/63.20131. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 55.67631/63.19273. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 55.90387/63.17903. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 55.70343/63.18900. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.71906/63.13156. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 55.86397/63.17112. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.60900/63.18954. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.65892/63.16386. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 55.54639/63.17044. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 55.31196/63.18204. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 55.24340/63.13536. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 55.42977/63.22840. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 55.31313/63.19545. Took 0.34 sec\n",
      "Epoch 98, Loss(train/val) 55.31900/63.19663. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 55.26787/63.20346. Took 0.33 sec\n",
      "ACC: 0.484375, MCC: -0.07265392195447241\n",
      "Epoch 0, Loss(train/val) 69.71626/68.99242. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.56168/68.91117. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.31537/68.82254. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.07169/68.71604. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.81069/68.58996. Took 0.33 sec\n",
      "Epoch 5, Loss(train/val) 68.56844/68.45178. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.33934/68.29572. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.02069/68.12055. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 67.76364/67.93092. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 67.40392/67.71432. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.95901/67.48112. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 66.62353/67.21163. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 66.19211/66.91692. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.84808/66.60651. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 65.65699/66.32568. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.34261/66.04381. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.14285/65.76865. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.99175/65.49529. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 64.62378/65.25567. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 64.61648/65.04936. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 64.46931/64.87370. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 64.17324/64.73148. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.20252/64.59038. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 64.05614/64.46995. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.87767/64.35606. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.69013/64.25044. Took 0.31 sec\n",
      "Epoch 26, Loss(train/val) 63.69337/64.15282. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 63.75651/64.08362. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.73403/64.01797. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 63.47037/63.96799. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.42793/63.93299. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.31560/63.89368. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 63.27156/63.86740. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.32112/63.84592. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.22139/63.84064. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 63.07937/63.82845. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.08153/63.83976. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.94652/63.84866. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.97102/63.85233. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.78810/63.86117. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.88030/63.87183. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.77137/63.85532. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.74379/63.86007. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.66058/63.86854. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 62.75190/63.87284. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.58717/63.86523. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.58602/63.85164. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.65250/63.82016. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.44227/63.82537. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 62.37631/63.80745. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.22529/63.79023. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.18464/63.79490. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 62.24342/63.72436. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.18886/63.68410. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.15035/63.68647. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 62.09495/63.69969. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.83241/63.72271. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.89777/63.74830. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.81929/63.76152. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.84041/63.70135. Took 0.31 sec\n",
      "Epoch 60, Loss(train/val) 61.70261/63.68445. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.66258/63.72117. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.67148/63.71058. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.49764/63.69785. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.48405/63.70128. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.56909/63.73948. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 61.47634/63.79886. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.44767/63.81892. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.57603/63.82129. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.21669/63.82941. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.24996/63.88263. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.22538/63.88956. Took 0.34 sec\n",
      "Epoch 72, Loss(train/val) 61.23132/63.90412. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.07568/63.95421. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.03735/63.92393. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 61.17771/63.92908. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 61.08002/63.93451. Took 0.31 sec\n",
      "Epoch 77, Loss(train/val) 61.04225/63.95833. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.97334/64.02931. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.07312/63.97378. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.84401/63.98170. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.84124/63.99672. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.89964/64.05836. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.85847/64.06118. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 60.80937/64.00749. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.79331/63.95734. Took 0.33 sec\n",
      "Epoch 86, Loss(train/val) 60.72988/63.92931. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.55755/63.92239. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.48524/63.96140. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 60.56965/63.93501. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.70983/63.92445. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 60.55788/63.86025. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 60.48796/63.88507. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.30519/63.86520. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.39126/63.87240. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 60.52194/63.85402. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.42792/63.82135. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 60.27855/63.80228. Took 0.33 sec\n",
      "Epoch 98, Loss(train/val) 60.23356/63.82962. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.17911/63.84193. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: -0.012577870090366055\n",
      "Epoch 0, Loss(train/val) 70.68685/70.85581. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.53179/70.72786. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.33613/70.59573. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.17444/70.45486. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.00974/70.30936. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.82340/70.15440. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.61251/69.98788. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.46241/69.81037. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 69.21394/69.62328. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 69.12250/69.42419. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.92056/69.20343. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.59941/68.96081. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 68.40348/68.70145. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.08443/68.42301. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.87793/68.14530. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 67.66802/67.85852. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.40487/67.55571. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.14164/67.24146. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.87869/66.90388. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 66.49771/66.55029. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 66.23596/66.19612. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.77782/65.83953. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.52402/65.48535. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 65.23241/65.16450. Took 0.35 sec\n",
      "Epoch 24, Loss(train/val) 64.82905/64.86588. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 64.69512/64.60162. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.33024/64.37245. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.94489/64.17722. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.70615/64.01616. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.44063/63.88802. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 63.17364/63.76011. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.07742/63.63876. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 62.78890/63.52096. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.61713/63.39901. Took 0.34 sec\n",
      "Epoch 34, Loss(train/val) 62.72550/63.30001. Took 0.34 sec\n",
      "Epoch 35, Loss(train/val) 62.47590/63.19828. Took 0.34 sec\n",
      "Epoch 36, Loss(train/val) 62.36992/63.10443. Took 0.34 sec\n",
      "Epoch 37, Loss(train/val) 62.34490/63.03371. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.00691/62.96426. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.01588/62.85778. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 61.84788/62.75016. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.90673/62.66711. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 61.75677/62.56529. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 61.81423/62.43435. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 61.58402/62.25509. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 61.69269/62.04073. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 61.40958/61.80898. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 61.47171/61.63258. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 61.27244/61.47208. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.16785/61.31520. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 61.06454/61.08621. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.08014/60.89273. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 60.96405/60.82285. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.75964/60.81593. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 60.84673/60.70831. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 60.73877/60.57327. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 60.57853/60.47953. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 60.64397/60.42098. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.56090/60.29432. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 60.26627/60.17587. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.27944/60.12226. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 60.41628/60.04126. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 60.30662/59.96552. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 60.26287/59.89548. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.26098/59.86403. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.10071/59.82685. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.03563/59.79631. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.98151/59.75464. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 60.08816/59.68521. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 60.02298/59.66402. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 60.21899/59.65485. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.87718/59.63753. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.84868/59.59251. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.77523/59.55337. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.99671/59.57011. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.73017/59.56474. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.72972/59.54327. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.91499/59.51869. Took 0.34 sec\n",
      "Epoch 78, Loss(train/val) 59.87254/59.50731. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 59.70472/59.50428. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 59.59563/59.48932. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 59.63458/59.48742. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 59.78906/59.47476. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 59.74036/59.44408. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 59.63592/59.42064. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 59.52186/59.42981. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 59.41143/59.43716. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.52258/59.42088. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.68474/59.42733. Took 0.33 sec\n",
      "Epoch 89, Loss(train/val) 59.56375/59.41860. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 59.38960/59.41995. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.50396/59.42205. Took 0.33 sec\n",
      "Epoch 92, Loss(train/val) 59.52856/59.41386. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.55372/59.40927. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.42758/59.36787. Took 0.33 sec\n",
      "Epoch 95, Loss(train/val) 59.37685/59.35904. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.45984/59.35314. Took 0.31 sec\n",
      "Epoch 97, Loss(train/val) 59.50818/59.34378. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 59.34512/59.33378. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.31757/59.31541. Took 0.32 sec\n",
      "ACC: 0.515625, MCC: 0.08534834865229643\n",
      "Epoch 0, Loss(train/val) 71.11168/71.27234. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 70.84268/71.12518. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.62869/70.95681. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.31444/70.75927. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.13868/70.52828. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.84355/70.26539. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 69.44796/69.97778. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 69.17146/69.68831. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.80731/69.40892. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.42303/69.13531. Took 0.33 sec\n",
      "Epoch 10, Loss(train/val) 68.10707/68.86507. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.65088/68.58871. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.09410/68.29017. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 66.76235/67.99391. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.14593/67.72195. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 65.62027/67.47127. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 65.03988/67.23265. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 64.47868/67.02317. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 63.99060/66.81799. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 63.73323/66.60528. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.33222/66.39545. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 63.03492/66.16603. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 62.94740/65.93934. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.68904/65.72469. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 62.37425/65.53378. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.41110/65.36495. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 62.04009/65.23870. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 62.09900/65.13940. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.00732/65.06206. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.82043/64.99338. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.87016/64.94533. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 61.84574/64.90462. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.66392/64.90783. Took 0.34 sec\n",
      "Epoch 33, Loss(train/val) 61.75874/64.92979. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.51964/64.98271. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.55650/65.07884. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 61.38299/65.18034. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.43145/65.26677. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.25029/65.33576. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 61.27367/65.42017. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 61.25947/65.52570. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 61.36799/65.64637. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 61.19392/65.72386. Took 0.34 sec\n",
      "Epoch 43, Loss(train/val) 61.16690/65.79401. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 61.00295/65.86227. Took 0.34 sec\n",
      "Epoch 45, Loss(train/val) 61.00079/65.92790. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 60.74661/66.01059. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.77758/66.11370. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 60.78824/66.27957. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 60.72542/66.44535. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 60.70614/66.57996. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 60.65505/66.80505. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 60.48877/66.95257. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 60.29365/67.02622. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 60.30191/67.14034. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 60.11137/67.36436. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 60.08260/67.45747. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 60.09745/67.53578. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.04847/67.59370. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.22092/67.64956. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 60.01230/67.74797. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.05758/67.73196. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 59.83634/67.80771. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 59.63177/67.85895. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 59.75168/67.82853. Took 0.33 sec\n",
      "Epoch 65, Loss(train/val) 59.75236/67.85832. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 59.70980/67.82542. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 59.68717/67.87716. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 59.31706/67.88918. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.37900/67.87114. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 59.38138/67.93743. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 59.19071/67.84109. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 59.43845/67.91413. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 59.16650/67.78130. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 59.14120/67.79244. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 59.18550/67.80244. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 59.25776/67.72673. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 59.13739/67.79815. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.07560/67.78693. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.95200/67.79497. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 58.90368/67.75742. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 58.90033/67.92069. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.84761/67.70599. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 58.88396/67.77913. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.81663/67.69728. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.87741/67.76067. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.79686/67.60693. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.81022/67.84428. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 58.82291/67.59148. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.85595/67.81778. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 58.71859/67.63574. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 65.26556/64.24187. Took 0.31 sec\n",
      "Epoch 27, Loss(train/val) 65.02247/64.04456. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.93809/63.84000. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.59103/63.62464. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 64.48709/63.39888. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.27508/63.17373. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.09700/62.98420. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.05041/62.82126. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.89296/62.66983. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.76834/62.53193. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.68063/62.39993. Took 0.31 sec\n",
      "Epoch 37, Loss(train/val) 63.55366/62.28270. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.35287/62.16116. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 63.32465/62.06411. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 63.37663/61.96326. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 63.11153/61.86680. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.13520/61.77857. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.12757/61.68413. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.00433/61.57416. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.88654/61.47108. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.87255/61.38033. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.70911/61.29577. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.66967/61.19585. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.59339/61.08588. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 62.48938/60.98470. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.42665/60.87590. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 62.46493/60.78066. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 62.26399/60.68415. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 62.19071/60.59907. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 62.20599/60.49816. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 62.11008/60.40849. Took 0.31 sec\n",
      "Epoch 57, Loss(train/val) 62.09353/60.31371. Took 0.31 sec\n",
      "Epoch 58, Loss(train/val) 61.88865/60.21587. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.96607/60.13639. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.83422/60.06417. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 61.70938/59.99017. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 61.67356/59.92074. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.60760/59.84770. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.40771/59.78037. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.32836/59.70558. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.30713/59.65778. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.24455/59.58855. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 61.22291/59.57852. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.02715/59.43357. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.11556/59.43930. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 61.09569/59.30617. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 61.00004/59.32737. Took 0.31 sec\n",
      "Epoch 73, Loss(train/val) 61.05665/59.21517. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 61.06671/59.16393. Took 0.31 sec\n",
      "Epoch 75, Loss(train/val) 60.69534/59.06292. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 60.67084/59.01471. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 60.64907/58.97608. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.52226/58.92569. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 60.55947/58.82107. Took 0.31 sec\n",
      "Epoch 80, Loss(train/val) 60.57389/58.84107. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.47005/58.78387. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 60.40431/58.75966. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 60.31987/58.68785. Took 0.31 sec\n",
      "Epoch 84, Loss(train/val) 60.21031/58.65416. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 60.20640/58.48782. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.01388/58.58396. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 59.87951/58.49780. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 59.94580/58.53623. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 59.87107/58.43247. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 59.72531/58.49323. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 59.57767/58.43612. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.60736/58.49417. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 59.62968/58.34518. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.61166/58.34621. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 59.65656/58.18275. Took 0.31 sec\n",
      "Epoch 96, Loss(train/val) 59.46476/58.26019. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.37471/58.22181. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 59.30021/58.32085. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.12259/58.10477. Took 0.33 sec\n",
      "ACC: 0.609375, MCC: 0.19852865415368456\n",
      "Epoch 0, Loss(train/val) 70.05057/70.14171. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.83385/69.98831. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.65909/69.83550. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.37146/69.68524. Took 0.31 sec\n",
      "Epoch 4, Loss(train/val) 69.07732/69.53955. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.83277/69.39859. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.53360/69.26169. Took 0.31 sec\n",
      "Epoch 7, Loss(train/val) 68.25011/69.12868. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.86752/69.00647. Took 0.31 sec\n",
      "Epoch 9, Loss(train/val) 67.58673/68.89686. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.20856/68.80014. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.86117/68.72907. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 66.37599/68.67236. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 65.99020/68.60855. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 65.35770/68.55023. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 65.00326/68.47112. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 64.53576/68.37888. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 64.22502/68.26620. Took 0.31 sec\n",
      "Epoch 18, Loss(train/val) 63.85400/68.16412. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 63.83974/68.07606. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 63.61151/68.01128. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 63.41882/67.94539. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 63.23564/67.88771. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 63.09979/67.83907. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 63.14370/67.80260. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 62.88671/67.78237. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 62.95785/67.77264. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 63.00056/67.74721. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 62.87847/67.72407. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 62.81206/67.70753. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 62.68843/67.69365. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 62.64302/67.68526. Took 0.33 sec\n",
      "Epoch 32, Loss(train/val) 62.70142/67.69296. Took 0.33 sec\n",
      "Epoch 33, Loss(train/val) 62.62189/67.69205. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.53188/67.68414. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 62.56299/67.66448. Took 0.33 sec\n",
      "Epoch 36, Loss(train/val) 62.57688/67.65868. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.39363/67.64335. Took 0.33 sec\n",
      "Epoch 38, Loss(train/val) 62.45448/67.64473. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.31151/67.65051. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.31889/67.66404. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 62.16963/67.67980. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.13467/67.67448. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 62.28791/67.67225. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.11644/67.66337. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 62.06641/67.63691. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 62.22176/67.62327. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.02665/67.61588. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.10095/67.59955. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 61.76491/67.58545. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.80552/67.55419. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.85739/67.55209. Took 0.33 sec\n",
      "Epoch 52, Loss(train/val) 61.67012/67.56034. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.79670/67.55917. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.67659/67.55933. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.74299/67.56101. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 61.54705/67.54817. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.54646/67.54149. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 61.41983/67.54494. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 61.56065/67.55321. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.41472/67.55003. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.35437/67.55504. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 61.25769/67.53753. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 61.30714/67.52937. Took 0.33 sec\n",
      "Epoch 64, Loss(train/val) 61.11672/67.50291. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.37109/67.49355. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.22142/67.48956. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 61.07522/67.49081. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.24126/67.45950. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.06902/67.41216. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 61.06989/67.35423. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 61.05900/67.33022. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 60.94502/67.29546. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 60.82664/67.26074. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 60.72558/67.24139. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.87192/67.25819. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 60.64476/67.24905. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.68950/67.22060. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 60.62992/67.18494. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 60.84090/67.14474. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 60.49872/67.12421. Took 0.33 sec\n",
      "Epoch 81, Loss(train/val) 60.58344/67.08820. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.57578/67.03574. Took 0.31 sec\n",
      "Epoch 83, Loss(train/val) 60.53914/67.02905. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.50722/67.03543. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.50773/67.03531. Took 0.31 sec\n",
      "Epoch 86, Loss(train/val) 60.36715/66.93980. Took 0.33 sec\n",
      "Epoch 87, Loss(train/val) 60.33560/66.93339. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 60.19801/66.87650. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.32668/66.82784. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 60.28001/66.71244. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.18888/66.65706. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 59.93275/66.63753. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 60.16081/66.63517. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 59.88170/66.64758. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 59.95961/66.58070. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 59.88966/66.52289. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 59.91801/66.39471. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 59.70418/66.27269. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 59.66531/66.13820. Took 0.33 sec\n",
      "ACC: 0.4375, MCC: -0.06816708894454176\n",
      "Epoch 0, Loss(train/val) 70.15057/70.03355. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.88304/69.91490. Took 0.33 sec\n",
      "Epoch 2, Loss(train/val) 69.60825/69.78585. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 69.35399/69.64004. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.08052/69.47663. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.77450/69.28521. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.40816/69.05365. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.99902/68.78315. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 67.55565/68.45142. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 67.04147/68.04989. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.48159/67.58022. Took 0.33 sec\n",
      "Epoch 11, Loss(train/val) 65.90282/67.06907. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 65.37471/66.55812. Took 0.33 sec\n",
      "Epoch 13, Loss(train/val) 64.84019/66.10347. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 64.33573/65.77749. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 63.88377/65.53742. Took 0.33 sec\n",
      "Epoch 16, Loss(train/val) 63.51547/65.32819. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.20595/65.14828. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.04495/65.02608. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.82361/64.91589. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 62.64065/64.84346. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 62.62398/64.78843. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 62.49879/64.72673. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 62.33254/64.69198. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 62.30171/64.67542. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 62.14261/64.64782. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 61.93565/64.62187. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 61.97166/64.61099. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 61.88894/64.63366. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 61.79841/64.62881. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 61.61587/64.63606. Took 0.33 sec\n",
      "Epoch 31, Loss(train/val) 61.69133/64.59055. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 61.49121/64.53239. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 61.49464/64.48850. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 61.40751/64.45843. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 61.32146/64.38589. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 61.07932/64.27350. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 61.22277/64.31644. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 61.00877/64.22133. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 60.92247/64.21558. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 60.83172/64.10709. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 60.71302/64.20082. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 60.73046/64.18670. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 60.46449/64.18513. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 60.36431/64.24155. Took 0.33 sec\n",
      "Epoch 45, Loss(train/val) 60.25588/64.25134. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 60.14799/64.24946. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 60.08701/64.26372. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 59.86124/64.28001. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 59.77176/64.48694. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 59.47485/64.53059. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 59.59471/64.59666. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 59.36402/64.70558. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 59.28368/64.67439. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 59.06344/64.63180. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 58.97214/64.62385. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 58.90588/64.78007. Took 0.33 sec\n",
      "Epoch 57, Loss(train/val) 59.10024/64.73078. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 58.67717/64.27400. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 58.57509/64.42916. Took 0.33 sec\n",
      "Epoch 60, Loss(train/val) 58.55143/64.26344. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 58.62712/64.49635. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 58.51900/64.42294. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 58.38096/64.25145. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 58.33472/64.07422. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 58.40397/63.93711. Took 0.33 sec\n",
      "Epoch 66, Loss(train/val) 58.14695/63.98324. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 58.10956/63.82081. Took 0.33 sec\n",
      "Epoch 68, Loss(train/val) 58.03844/64.15701. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 58.03182/64.17858. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 57.97027/64.12656. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 57.87894/63.66175. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 57.79721/63.91793. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 57.88387/63.84420. Took 0.33 sec\n",
      "Epoch 74, Loss(train/val) 57.59833/64.09962. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 57.77477/63.94686. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 57.70594/63.95104. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 57.60987/63.83907. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 57.70048/64.12338. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 57.64224/63.70479. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 57.61174/64.26910. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 57.50927/63.85594. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 57.48889/64.19501. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 57.39470/63.91160. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 57.36615/64.07738. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 57.41306/64.16158. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 57.37471/64.16043. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 57.36474/63.86193. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 57.35521/64.05402. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 57.20561/64.26301. Took 0.31 sec\n",
      "Epoch 90, Loss(train/val) 57.18917/64.16802. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 57.24131/64.22167. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 57.06987/63.87434. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 57.16814/64.03706. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 57.15317/64.17944. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 57.00816/64.10880. Took 0.33 sec\n",
      "Epoch 96, Loss(train/val) 56.98201/64.19413. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 57.11352/64.02030. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 56.92541/64.14136. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 56.97136/64.24099. Took 0.32 sec\n",
      "ACC: 0.5, MCC: 0.049969626464415974\n",
      "Epoch 0, Loss(train/val) 70.56258/70.29135. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.43354/70.23866. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.32286/70.18375. Took 0.32 sec\n",
      "Epoch 3, Loss(train/val) 70.14584/70.12247. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 70.05618/70.05522. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.88844/69.97829. Took 0.31 sec\n",
      "Epoch 6, Loss(train/val) 69.72769/69.89320. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.59139/69.79215. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 69.32878/69.67006. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 69.13641/69.53008. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.87023/69.37086. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 68.66969/69.18887. Took 0.31 sec\n",
      "Epoch 12, Loss(train/val) 68.45783/68.98930. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 68.12869/68.77142. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 67.88698/68.54114. Took 0.32 sec\n",
      "Epoch 15, Loss(train/val) 67.52760/68.30537. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 67.42638/68.07208. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 67.19868/67.84607. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 66.83668/67.62426. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 66.71278/67.40155. Took 0.33 sec\n",
      "Epoch 20, Loss(train/val) 66.43107/67.17599. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 66.39403/66.95187. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 66.17344/66.72874. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 66.02407/66.51372. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.88425/66.30635. Took 0.33 sec\n",
      "Epoch 25, Loss(train/val) 65.83159/66.10129. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 65.64709/65.90882. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 65.50375/65.71931. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 65.29279/65.52834. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 65.38123/65.34514. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 65.02970/65.15854. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 64.90603/64.97788. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 64.94079/64.80595. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 64.68277/64.64176. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 64.53897/64.48660. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 64.59135/64.33141. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 64.56052/64.18368. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 64.33536/64.04103. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 64.10679/63.89865. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 64.15777/63.77132. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 64.00110/63.64802. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 63.85487/63.53002. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 63.88891/63.41299. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 63.83553/63.30349. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 63.68047/63.20007. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 63.68438/63.10143. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 63.53251/63.00012. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 63.59664/62.89873. Took 0.31 sec\n",
      "Epoch 48, Loss(train/val) 63.51948/62.79760. Took 0.33 sec\n",
      "Epoch 49, Loss(train/val) 63.50565/62.69329. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 63.29792/62.61357. Took 0.31 sec\n",
      "Epoch 51, Loss(train/val) 63.22987/62.52967. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 63.22819/62.45578. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 63.19075/62.36401. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 63.10978/62.27344. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 63.09052/62.19548. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 63.05991/62.11255. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 62.87104/62.04725. Took 0.33 sec\n",
      "Epoch 58, Loss(train/val) 62.94576/61.96206. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 62.73553/61.90870. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 62.84039/61.88990. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 62.76902/61.85496. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 62.73888/61.81202. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 62.73666/61.74030. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 62.56406/61.74063. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 62.59766/61.66022. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 62.64262/61.64515. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 62.34016/61.61554. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 62.38421/61.58151. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 62.35182/61.57182. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 62.19116/61.49377. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 62.20322/61.50604. Took 0.32 sec\n",
      "Epoch 72, Loss(train/val) 62.38242/61.46164. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 62.16883/61.42919. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 62.19247/61.41140. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 62.05323/61.44228. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 61.89786/61.42685. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 61.97750/61.43562. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.90468/61.42656. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 61.84401/61.36285. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 61.80785/61.34959. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 61.85635/61.38280. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 61.69950/61.36224. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 61.60722/61.34867. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 61.48587/61.35482. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 61.59551/61.33471. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 61.67521/61.36083. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 61.49783/61.40841. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 61.43763/61.42693. Took 0.31 sec\n",
      "Epoch 89, Loss(train/val) 61.14832/61.37959. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 61.28859/61.45669. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 61.21468/61.37110. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 61.15575/61.51948. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 61.27604/61.36054. Took 0.33 sec\n",
      "Epoch 94, Loss(train/val) 61.02936/61.39002. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.94805/61.50047. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 61.04050/61.37016. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 61.08391/61.44545. Took 0.31 sec\n",
      "Epoch 98, Loss(train/val) 60.89194/61.50975. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.78942/61.45542. Took 0.33 sec\n",
      "ACC: 0.4375, MCC: -0.11318329168362205\n",
      "Epoch 0, Loss(train/val) 70.86552/70.88672. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 70.59987/70.82303. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 70.49136/70.75770. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 70.19427/70.69179. Took 0.33 sec\n",
      "Epoch 4, Loss(train/val) 70.03813/70.62144. Took 0.34 sec\n",
      "Epoch 5, Loss(train/val) 69.68659/70.54408. Took 0.34 sec\n",
      "Epoch 6, Loss(train/val) 69.38037/70.44724. Took 0.33 sec\n",
      "Epoch 7, Loss(train/val) 69.13437/70.33363. Took 0.32 sec\n",
      "Epoch 8, Loss(train/val) 68.81802/70.20760. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.50868/70.06387. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 68.23521/69.89861. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.84186/69.70835. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 67.61079/69.48734. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.31885/69.23779. Took 0.32 sec\n",
      "Epoch 14, Loss(train/val) 66.95796/68.95956. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.63212/68.66174. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.33140/68.32088. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 65.92582/67.94066. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 65.71772/67.53334. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.37538/67.12486. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.06307/66.69681. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 64.65446/66.28513. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 64.56910/65.89678. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 64.07074/65.51266. Took 0.33 sec\n",
      "Epoch 24, Loss(train/val) 63.90927/65.14422. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 63.83458/64.82230. Took 0.32 sec\n",
      "Epoch 26, Loss(train/val) 63.72362/64.54242. Took 0.33 sec\n",
      "Epoch 27, Loss(train/val) 63.43084/64.32014. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 63.43389/64.11262. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 63.32728/63.94775. Took 0.33 sec\n",
      "Epoch 30, Loss(train/val) 63.13561/63.82085. Took 0.31 sec\n",
      "Epoch 31, Loss(train/val) 63.05410/63.72524. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.08468/63.64343. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 62.90676/63.56512. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 62.94931/63.51253. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 62.70011/63.46199. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 62.78364/63.42008. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 62.71860/63.37616. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 62.55343/63.33187. Took 0.33 sec\n",
      "Epoch 39, Loss(train/val) 62.60697/63.28947. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.64806/63.25864. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.63614/63.22847. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 62.39966/63.20138. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.41733/63.17122. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.66936/63.14497. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.36242/63.11605. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.23527/63.09110. Took 0.33 sec\n",
      "Epoch 47, Loss(train/val) 62.17239/63.06201. Took 0.32 sec\n",
      "Epoch 48, Loss(train/val) 62.20542/63.02608. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 62.11561/63.01356. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 62.14105/63.01481. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 62.03358/62.99604. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.98303/62.97741. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 62.03127/62.95482. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.96872/62.91648. Took 0.33 sec\n",
      "Epoch 55, Loss(train/val) 61.89177/62.89334. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.90659/62.88408. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.73666/62.86424. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 61.87828/62.84932. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 61.66382/62.84953. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 61.84398/62.84881. Took 0.33 sec\n",
      "Epoch 61, Loss(train/val) 61.66973/62.84848. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 61.73830/62.85513. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 61.53012/62.87299. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 61.75359/62.91583. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 61.60544/62.96206. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 61.42565/63.03053. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 61.39159/63.07788. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 61.27105/63.03540. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 61.37456/63.04273. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 61.42383/63.01259. Took 0.33 sec\n",
      "Epoch 71, Loss(train/val) 61.48008/62.95101. Took 0.31 sec\n",
      "Epoch 72, Loss(train/val) 61.20918/62.95202. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 61.33319/62.98421. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 61.10896/62.95713. Took 0.32 sec\n",
      "Epoch 75, Loss(train/val) 60.97479/62.94728. Took 0.32 sec\n",
      "Epoch 76, Loss(train/val) 61.09082/62.97552. Took 0.33 sec\n",
      "Epoch 77, Loss(train/val) 60.98361/62.91811. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 61.02320/62.79858. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 61.14880/62.76363. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 60.94041/62.84402. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 60.93869/62.90843. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 60.72042/62.83512. Took 0.33 sec\n",
      "Epoch 83, Loss(train/val) 60.81407/62.69815. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 60.79836/62.69690. Took 0.32 sec\n",
      "Epoch 85, Loss(train/val) 60.81621/62.73245. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 60.74094/62.72617. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 60.79892/62.78844. Took 0.33 sec\n",
      "Epoch 88, Loss(train/val) 60.50149/62.76447. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 60.64126/62.73331. Took 0.32 sec\n",
      "Epoch 90, Loss(train/val) 60.56457/62.67890. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 60.52634/62.62290. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 60.76118/62.59553. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 60.56990/62.64389. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 60.54982/62.56979. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 60.45983/62.57010. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 60.44366/62.64625. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 60.43998/62.53923. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 60.35034/62.56692. Took 0.32 sec\n",
      "Epoch 99, Loss(train/val) 60.38592/62.53231. Took 0.32 sec\n",
      "ACC: 0.46875, MCC: -0.11500161355436699\n",
      "Epoch 0, Loss(train/val) 69.90591/69.83000. Took 0.33 sec\n",
      "Epoch 1, Loss(train/val) 69.63561/69.73428. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.31380/69.62076. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.07731/69.49660. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 68.70727/69.35849. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 68.41005/69.21535. Took 0.32 sec\n",
      "Epoch 6, Loss(train/val) 68.07705/69.07391. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 67.68512/68.92164. Took 0.31 sec\n",
      "Epoch 8, Loss(train/val) 67.28248/68.76978. Took 0.32 sec\n",
      "Epoch 9, Loss(train/val) 66.90703/68.61567. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 66.49336/68.45453. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 66.17504/68.29194. Took 0.33 sec\n",
      "Epoch 12, Loss(train/val) 65.77468/68.11761. Took 0.34 sec\n",
      "Epoch 13, Loss(train/val) 65.34501/67.92699. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 64.89566/67.71782. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 64.39720/67.47296. Took 0.34 sec\n",
      "Epoch 16, Loss(train/val) 63.90942/67.18248. Took 0.33 sec\n",
      "Epoch 17, Loss(train/val) 63.42491/66.84682. Took 0.32 sec\n",
      "Epoch 18, Loss(train/val) 63.15145/66.45071. Took 0.33 sec\n",
      "Epoch 19, Loss(train/val) 62.55513/65.98860. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 62.12132/65.48334. Took 0.32 sec\n",
      "Epoch 21, Loss(train/val) 61.53522/64.96418. Took 0.33 sec\n",
      "Epoch 22, Loss(train/val) 61.19945/64.47212. Took 0.32 sec\n",
      "Epoch 23, Loss(train/val) 60.72797/64.02941. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 60.53063/63.65161. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 60.14542/63.39153. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 59.79765/63.18555. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 59.70908/63.01781. Took 0.33 sec\n",
      "Epoch 28, Loss(train/val) 59.38069/62.84571. Took 0.32 sec\n",
      "Epoch 29, Loss(train/val) 59.27050/62.68867. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 59.11801/62.51090. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 58.91420/62.36973. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 58.80931/62.26212. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 58.60929/62.15255. Took 0.33 sec\n",
      "Epoch 34, Loss(train/val) 58.34286/62.06422. Took 0.32 sec\n",
      "Epoch 35, Loss(train/val) 58.35761/61.99122. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 58.13746/61.93332. Took 0.33 sec\n",
      "Epoch 37, Loss(train/val) 58.19300/61.86974. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 58.12638/61.79805. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 57.89633/61.74860. Took 0.33 sec\n",
      "Epoch 40, Loss(train/val) 57.82847/61.68394. Took 0.32 sec\n",
      "Epoch 41, Loss(train/val) 57.84553/61.63984. Took 0.32 sec\n",
      "Epoch 42, Loss(train/val) 57.62392/61.59107. Took 0.33 sec\n",
      "Epoch 43, Loss(train/val) 57.64961/61.56205. Took 0.32 sec\n",
      "Epoch 44, Loss(train/val) 57.68695/61.50424. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 57.61845/61.41006. Took 0.33 sec\n",
      "Epoch 46, Loss(train/val) 57.40785/61.36839. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 57.43402/61.34174. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 57.25902/61.16766. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 57.24492/61.00270. Took 0.32 sec\n",
      "Epoch 50, Loss(train/val) 57.12525/60.77407. Took 0.33 sec\n",
      "Epoch 51, Loss(train/val) 56.99304/60.64280. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 56.96209/60.43895. Took 0.32 sec\n",
      "Epoch 53, Loss(train/val) 56.92836/60.29188. Took 0.33 sec\n",
      "Epoch 54, Loss(train/val) 56.82583/60.27184. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 56.81538/60.23716. Took 0.32 sec\n",
      "Epoch 56, Loss(train/val) 56.61833/60.00681. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 56.56911/60.01591. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 56.66323/59.93266. Took 0.32 sec\n",
      "Epoch 59, Loss(train/val) 56.62424/59.86491. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 56.48908/59.94732. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 56.31467/59.89684. Took 0.32 sec\n",
      "Epoch 62, Loss(train/val) 56.42475/59.64795. Took 0.33 sec\n",
      "Epoch 63, Loss(train/val) 56.32204/59.76106. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 56.41544/59.71378. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 56.28199/59.52168. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 56.25479/59.59809. Took 0.32 sec\n",
      "Epoch 67, Loss(train/val) 56.10723/59.61700. Took 0.31 sec\n",
      "Epoch 68, Loss(train/val) 56.13820/59.68348. Took 0.33 sec\n",
      "Epoch 69, Loss(train/val) 56.03854/59.51702. Took 0.32 sec\n",
      "Epoch 70, Loss(train/val) 56.02324/59.51118. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 56.14255/59.49636. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 55.99959/59.42877. Took 0.32 sec\n",
      "Epoch 73, Loss(train/val) 56.07727/59.52097. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 55.83682/59.51038. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 56.00779/59.38463. Took 0.31 sec\n",
      "Epoch 76, Loss(train/val) 55.87059/59.24611. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 55.78935/59.26152. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 55.78730/59.28617. Took 0.32 sec\n",
      "Epoch 79, Loss(train/val) 55.94166/59.32774. Took 0.33 sec\n",
      "Epoch 80, Loss(train/val) 55.62634/59.25043. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 55.61605/59.22303. Took 0.32 sec\n",
      "Epoch 82, Loss(train/val) 55.88199/59.21009. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 55.70498/59.17706. Took 0.33 sec\n",
      "Epoch 84, Loss(train/val) 55.64062/59.16007. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 55.67855/59.13940. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 55.64003/59.05001. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 55.52708/59.12176. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 55.65572/59.06194. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 55.49811/59.02511. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 55.46123/59.09704. Took 0.32 sec\n",
      "Epoch 91, Loss(train/val) 55.46481/59.09641. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 55.45537/59.08489. Took 0.33 sec\n",
      "Epoch 93, Loss(train/val) 55.26995/58.99504. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 55.20250/58.99429. Took 0.31 sec\n",
      "Epoch 95, Loss(train/val) 55.26282/58.99969. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 55.36360/58.98245. Took 0.32 sec\n",
      "Epoch 97, Loss(train/val) 55.33863/58.98457. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 55.27860/59.00072. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 55.25609/58.93416. Took 0.33 sec\n",
      "ACC: 0.46875, MCC: -0.04222003309207491\n",
      "Epoch 0, Loss(train/val) 70.04053/69.21836. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 69.84749/69.03337. Took 0.32 sec\n",
      "Epoch 2, Loss(train/val) 69.65203/68.83810. Took 0.33 sec\n",
      "Epoch 3, Loss(train/val) 69.46004/68.63194. Took 0.32 sec\n",
      "Epoch 4, Loss(train/val) 69.24946/68.41976. Took 0.32 sec\n",
      "Epoch 5, Loss(train/val) 69.05422/68.19981. Took 0.33 sec\n",
      "Epoch 6, Loss(train/val) 68.86074/67.97807. Took 0.32 sec\n",
      "Epoch 7, Loss(train/val) 68.65108/67.75621. Took 0.33 sec\n",
      "Epoch 8, Loss(train/val) 68.39183/67.52618. Took 0.33 sec\n",
      "Epoch 9, Loss(train/val) 68.18128/67.29244. Took 0.32 sec\n",
      "Epoch 10, Loss(train/val) 67.94062/67.05160. Took 0.32 sec\n",
      "Epoch 11, Loss(train/val) 67.81262/66.81621. Took 0.32 sec\n",
      "Epoch 12, Loss(train/val) 67.47253/66.58054. Took 0.32 sec\n",
      "Epoch 13, Loss(train/val) 67.36095/66.34480. Took 0.33 sec\n",
      "Epoch 14, Loss(train/val) 67.06012/66.11131. Took 0.33 sec\n",
      "Epoch 15, Loss(train/val) 66.77468/65.88017. Took 0.32 sec\n",
      "Epoch 16, Loss(train/val) 66.55883/65.67262. Took 0.32 sec\n",
      "Epoch 17, Loss(train/val) 66.39552/65.48769. Took 0.33 sec\n",
      "Epoch 18, Loss(train/val) 66.16495/65.33172. Took 0.32 sec\n",
      "Epoch 19, Loss(train/val) 65.92723/65.22561. Took 0.32 sec\n",
      "Epoch 20, Loss(train/val) 65.70551/65.12807. Took 0.33 sec\n",
      "Epoch 21, Loss(train/val) 65.50269/65.03500. Took 0.32 sec\n",
      "Epoch 22, Loss(train/val) 65.31522/64.95783. Took 0.33 sec\n",
      "Epoch 23, Loss(train/val) 65.11082/64.87882. Took 0.32 sec\n",
      "Epoch 24, Loss(train/val) 65.00681/64.78315. Took 0.32 sec\n",
      "Epoch 25, Loss(train/val) 64.65121/64.67420. Took 0.33 sec\n",
      "Epoch 26, Loss(train/val) 64.46093/64.55632. Took 0.32 sec\n",
      "Epoch 27, Loss(train/val) 64.31311/64.46437. Took 0.32 sec\n",
      "Epoch 28, Loss(train/val) 64.21738/64.37225. Took 0.33 sec\n",
      "Epoch 29, Loss(train/val) 64.19269/64.26846. Took 0.32 sec\n",
      "Epoch 30, Loss(train/val) 63.71696/64.16717. Took 0.32 sec\n",
      "Epoch 31, Loss(train/val) 63.79689/64.07334. Took 0.32 sec\n",
      "Epoch 32, Loss(train/val) 63.58948/63.96750. Took 0.32 sec\n",
      "Epoch 33, Loss(train/val) 63.40589/63.88464. Took 0.32 sec\n",
      "Epoch 34, Loss(train/val) 63.48060/63.78531. Took 0.33 sec\n",
      "Epoch 35, Loss(train/val) 63.27911/63.70325. Took 0.32 sec\n",
      "Epoch 36, Loss(train/val) 63.25828/63.60601. Took 0.32 sec\n",
      "Epoch 37, Loss(train/val) 63.05567/63.50508. Took 0.32 sec\n",
      "Epoch 38, Loss(train/val) 63.10859/63.41083. Took 0.32 sec\n",
      "Epoch 39, Loss(train/val) 62.76777/63.30252. Took 0.32 sec\n",
      "Epoch 40, Loss(train/val) 62.70930/63.18991. Took 0.33 sec\n",
      "Epoch 41, Loss(train/val) 62.69369/63.08517. Took 0.33 sec\n",
      "Epoch 42, Loss(train/val) 62.57480/62.98344. Took 0.32 sec\n",
      "Epoch 43, Loss(train/val) 62.39890/62.87270. Took 0.33 sec\n",
      "Epoch 44, Loss(train/val) 62.31774/62.74136. Took 0.32 sec\n",
      "Epoch 45, Loss(train/val) 62.43833/62.59681. Took 0.32 sec\n",
      "Epoch 46, Loss(train/val) 62.31866/62.45796. Took 0.32 sec\n",
      "Epoch 47, Loss(train/val) 62.12068/62.30198. Took 0.33 sec\n",
      "Epoch 48, Loss(train/val) 62.17870/62.18003. Took 0.32 sec\n",
      "Epoch 49, Loss(train/val) 61.92129/62.02729. Took 0.33 sec\n",
      "Epoch 50, Loss(train/val) 61.83473/61.87300. Took 0.32 sec\n",
      "Epoch 51, Loss(train/val) 61.74257/61.73396. Took 0.32 sec\n",
      "Epoch 52, Loss(train/val) 61.58245/61.58051. Took 0.33 sec\n",
      "Epoch 53, Loss(train/val) 61.45057/61.39142. Took 0.32 sec\n",
      "Epoch 54, Loss(train/val) 61.36298/61.15148. Took 0.32 sec\n",
      "Epoch 55, Loss(train/val) 61.27059/61.04609. Took 0.33 sec\n",
      "Epoch 56, Loss(train/val) 61.13324/60.89741. Took 0.32 sec\n",
      "Epoch 57, Loss(train/val) 61.01321/60.70950. Took 0.32 sec\n",
      "Epoch 58, Loss(train/val) 60.84383/60.58166. Took 0.33 sec\n",
      "Epoch 59, Loss(train/val) 60.69331/60.44555. Took 0.32 sec\n",
      "Epoch 60, Loss(train/val) 60.88861/60.30557. Took 0.32 sec\n",
      "Epoch 61, Loss(train/val) 60.45690/60.18582. Took 0.33 sec\n",
      "Epoch 62, Loss(train/val) 60.55109/60.05997. Took 0.32 sec\n",
      "Epoch 63, Loss(train/val) 60.28591/59.95568. Took 0.32 sec\n",
      "Epoch 64, Loss(train/val) 60.35903/59.81379. Took 0.32 sec\n",
      "Epoch 65, Loss(train/val) 60.28295/59.73611. Took 0.32 sec\n",
      "Epoch 66, Loss(train/val) 60.09218/59.66403. Took 0.33 sec\n",
      "Epoch 67, Loss(train/val) 60.11756/59.60601. Took 0.32 sec\n",
      "Epoch 68, Loss(train/val) 59.99532/59.53213. Took 0.32 sec\n",
      "Epoch 69, Loss(train/val) 59.95617/59.46138. Took 0.33 sec\n",
      "Epoch 70, Loss(train/val) 59.75000/59.43615. Took 0.32 sec\n",
      "Epoch 71, Loss(train/val) 59.70633/59.36313. Took 0.33 sec\n",
      "Epoch 72, Loss(train/val) 59.46975/59.35101. Took 0.33 sec\n",
      "Epoch 73, Loss(train/val) 59.39739/59.28442. Took 0.32 sec\n",
      "Epoch 74, Loss(train/val) 59.30756/59.26923. Took 0.33 sec\n",
      "Epoch 75, Loss(train/val) 59.25210/59.22166. Took 0.33 sec\n",
      "Epoch 76, Loss(train/val) 59.25982/59.13257. Took 0.32 sec\n",
      "Epoch 77, Loss(train/val) 59.28390/59.06203. Took 0.32 sec\n",
      "Epoch 78, Loss(train/val) 59.19959/59.02884. Took 0.33 sec\n",
      "Epoch 79, Loss(train/val) 58.91322/58.93604. Took 0.32 sec\n",
      "Epoch 80, Loss(train/val) 58.99025/58.85123. Took 0.32 sec\n",
      "Epoch 81, Loss(train/val) 59.00134/58.78412. Took 0.33 sec\n",
      "Epoch 82, Loss(train/val) 58.95504/58.68270. Took 0.32 sec\n",
      "Epoch 83, Loss(train/val) 58.66575/58.58233. Took 0.32 sec\n",
      "Epoch 84, Loss(train/val) 58.84175/58.48011. Took 0.33 sec\n",
      "Epoch 85, Loss(train/val) 58.51786/58.42244. Took 0.32 sec\n",
      "Epoch 86, Loss(train/val) 58.48940/58.32035. Took 0.32 sec\n",
      "Epoch 87, Loss(train/val) 58.56622/58.29898. Took 0.32 sec\n",
      "Epoch 88, Loss(train/val) 58.41199/58.17954. Took 0.32 sec\n",
      "Epoch 89, Loss(train/val) 58.46209/58.09011. Took 0.33 sec\n",
      "Epoch 90, Loss(train/val) 58.31430/58.02320. Took 0.33 sec\n",
      "Epoch 91, Loss(train/val) 58.17330/57.94117. Took 0.32 sec\n",
      "Epoch 92, Loss(train/val) 58.21455/57.89119. Took 0.32 sec\n",
      "Epoch 93, Loss(train/val) 58.15863/57.89843. Took 0.32 sec\n",
      "Epoch 94, Loss(train/val) 57.89221/57.83181. Took 0.32 sec\n",
      "Epoch 95, Loss(train/val) 58.06655/57.85021. Took 0.32 sec\n",
      "Epoch 96, Loss(train/val) 57.87838/57.70584. Took 0.33 sec\n",
      "Epoch 97, Loss(train/val) 57.88683/57.73591. Took 0.32 sec\n",
      "Epoch 98, Loss(train/val) 57.70798/57.74365. Took 0.33 sec\n",
      "Epoch 99, Loss(train/val) 57.65482/57.70355. Took 0.33 sec\n",
      "ACC: 0.53125, MCC: -0.012312225225925604\n"
     ]
    }
   ],
   "source": [
    "## 실행 파일\n",
    "args.data_list = os.listdir(\"C:\\\\Users\\\\USER\\\\JupyterProjects\\\\AdvLSTM\\\\data\\\\kdd17\\\\ourpped\")\n",
    "\n",
    "\n",
    "with open(args.save_file_path + '\\\\' + 'AdvLSTM_result_t.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerow([\"model\", \"stock\", \"entire_exp_time\",  \"avg_test_ACC\", \"avg_test_ACC_std\", \"avg_test_MCC\"])\n",
    "\n",
    "    for data in args.data_list:\n",
    "        \n",
    "        stock = data.split('.')[0]\n",
    "\n",
    "        est = time.time()\n",
    "        setattr(args, 'symbol', stock)\n",
    "        args.new_file_path = args.save_file_path + '\\\\' + \"AdvLSTM_\" + args.symbol\n",
    "        os.makedirs(args.new_file_path)\n",
    "        \n",
    "        \n",
    "        csv_read = stock_csv_read(data,args.x_frames,args.y_frames)\n",
    "        split_data_list = csv_read.cv_split()\n",
    "        \n",
    "        ACC_cv = []\n",
    "        for i, data in enumerate(split_data_list):\n",
    "            args.split_file_path = args.new_file_path + \"\\\\\" + str(i) +\"th_iter\"\n",
    "            os.makedirs(args.split_file_path)\n",
    "            # 0번째에 index 1번째에 stock 1개가 input으로 들어감\n",
    "            trainset = StockDataset(data[0])\n",
    "            valset = StockDataset(data[1])\n",
    "            testset = StockDataset(data[2])\n",
    "        \n",
    "\n",
    "            partition = {'train': trainset, 'val': valset, 'test': testset}\n",
    "\n",
    "\n",
    "            setting, result = experiment(partition, args)\n",
    "            eet = time.time()\n",
    "            entire_exp_time = eet - est\n",
    "\n",
    "            fig = plt.figure()\n",
    "            plt.plot(result['train_losses'])\n",
    "            plt.plot(result['val_losses'])\n",
    "            plt.legend(['train_losses', 'val_losses'], fontsize=15)\n",
    "            plt.xlabel('epoch', fontsize=15)\n",
    "            plt.ylabel('loss', fontsize=15)\n",
    "            plt.grid()\n",
    "            plt.savefig(args.split_file_path + '\\\\' + str(args.symbol) + '_fig' + '.png')\n",
    "            plt.close(fig)\n",
    "            ACC_cv.append(result['ACC'])\n",
    "            # csv파일에 기록하기\n",
    "        ACC_cv_ar = np.array(ACC_cv)\n",
    "        acc_avg = np.mean(ACC_cv_ar)\n",
    "        acc_std = np.std(ACC_cv_ar)\n",
    "\n",
    "        wr.writerow([\"AdvLSTM\", args.symbol, entire_exp_time, acc_avg, acc_std, result['MCC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py38_64",
   "language": "python",
   "name": "py38_64"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
